[
  {
    "arxiv_id": "2512.07833v1",
    "title": "Relational Visual Similarity",
    "abstract": "Humans do not just see attribute similarity -- we also see relational similarity. An apple is like a peach because both are reddish fruit, but the Earth is also like a peach: its crust, mantle, and core correspond to the peach's skin, flesh, and pit. This ability to perceive and recognize relational similarity, is arguable by cognitive scientist to be what distinguishes humans from other species. Yet, all widely used visual similarity metrics today (e.g., LPIPS, CLIP, DINO) focus solely on perceptual attribute similarity and fail to capture the rich, often surprising relational similarities that humans perceive. How can we go beyond the visible content of an image to capture its relational properties? How can we bring images with the same relational logic closer together in representation space? To answer these questions, we first formulate relational image similarity as a measurable problem: two images are relationally similar when their internal relations or functions among visual elements correspond, even if their visual attributes differ. We then curate 114k image-caption dataset in which the captions are anonymized -- describing the underlying relational logic of the scene rather than its surface content. Using this dataset, we finetune a Vision-Language model to measure the relational similarity between images. This model serves as the first step toward connecting images by their underlying relational structure rather than their visible appearance. Our study shows that while relational similarity has a lot of real-world applications, existing image similarity models fail to capture it -- revealing a critical gap in visual computing.",
    "text": "Relational Visual Similarity\nThao Nguyen1, Sicheng Mo2, Krishna Kumar Singh3, Yilin Wang3, Jing Shi3, Nicholas Kolkin3\nEli Shechtman3, Yong Jae Lee1,3,‚Ä†, Yuheng Li3,‚Ä†\n1University of Wisconsin-Madison, 2University of California, Los Angeles, 3Adobe Research\nhttps://thaoshibe.github.io/relsim\nReference\nGroup A\nGroup B\nFigure 1. Would you say images in Group A are similar to the Reference Image? Current state-of-the-art image similarity models (e.g.,\nLPIPS [1], CLIP [2]) would answer no. These models would say only Group B are similar to the reference image, as they equate similarity\nwith a high degree of shared perceptual attribute features (i.e., color, shape, semantic class). However, as humans, we would confidently\nsay yes‚Äîimages in both groups are similar to the reference. While Group B is similar in perceptual attributes, Group A is similar in a\nmore abstract, relational sense (e.g., ‚Äútransformation of {subject} through time‚Äù, first row). In this paper, we propose to model this missing\ndimension of visual similarity, or called relational visual similarity, capturing human-like reasoning over relational structures.\nAbstract\nHumans do not just see attribute similarity‚Äîwe also see\nrelational similarity. An apple is like a peach because both\nare reddish fruit, but the Earth is also like a peach: its\ncrust, mantle, and core correspond to the peach‚Äôs skin, flesh,\nand pit. This ability to perceive and recognize relational\nsimilarity, is arguable by cognitive scientist to be what dis-\ntinguishes humans from other species. Yet, all widely used\nvisual similarity metrics today (e.g., LPIPS, CLIP, DINO)\nfocus solely on perceptual attribute similarity and fail to\ncapture the rich, often surprising relational similarities that\nhumans perceive. How can we go beyond the visible con-\ntent of an image to capture its relational properties? How\n‚Ä† denotes equal advising\ncan we bring images with the same relational logic closer\ntogether in representation space? To answer these questions,\nwe first formulate relational image similarity as a measur-\nable problem: two images are relationally similar when\ntheir internal relations or functions among visual elements\ncorrespond, even if their visual attributes differ. We then\ncurate 114k image‚Äìcaption dataset in which the captions are\nanonymized‚Äîdescribing the underlying relational logic of\nthe scene rather than its surface content. Using this dataset,\nwe finetune a Vision‚ÄìLanguage model to measure the rela-\ntional similarity between images. This model serves as the\nfirst step toward connecting images by their underlying re-\nlational structure rather than their visible appearance. Our\nstudy shows that while relational similarity has a lot of real-\nworld applications, existing image similarity models fail to\ncapture it‚Äîrevealing a critical gap in visual computing.\n1\narXiv:2512.07833v1  [cs.CV]  8 Dec 2025\n\n1. Introduction\nThe ability to perceive and recognize visual similarity is\narguably the most fundamental sense for any visual crea-\nture, including humans, to interact and make sense of the\nworld [3, 4]. We process visual attributes to guide decisions:\nrecognizing that a peach is red might signal that it is edi-\nble. We also notice similarities across different objects (e.g.,\nshape, color, texture) to categorize, remember, and abstract\nthem: an apple and a peach are both red and round, so they\nare likely both fruits. Beyond this, we can see relational sim-\nilarity as well: we abstract familiar patterns to understand\nmore complex or unseen phenomena. For example, we can\nanticipate the Earth is like a peach, as its layers‚Äîcrust, man-\ntle, and core‚Äîroughly correspond to the peach‚Äôs skin, flesh,\nand pit, even though no one has directly observed it. In cogni-\ntive science, attribute similarity and relational similarity are\noften considered the two central pillars when it comes to un-\nderstanding human perception of similarity [5, 6]. Attribute\nsimilarity underlies everyday activities (e.g., recognition [7],\nclassification [8], memorization [9]), while relational sim-\nilarity fuels reasoning and creativity (e.g., analogies [10],\nabstract thought [11]). Some researchers argue that rela-\ntional similarity is even more central to human cognition, as\nit drives analogical learning and creativity‚Äîthe traits that\nset humans apart from other intelligent species [12‚Äì14].\nUnfortunately, current state-of-the-art visual similarity\nframeworks focus almost exclusively on attribute-level sim-\nilarity. Traditionally, image similarity in computer vision\nhas been framed as the task of comparing two images and\ndeciding whether they are visually similar, typically at the\npixel or feature level using handcrafted descriptors [15, 16].\nIn recent years, large-scale hierarchical datasets (e.g., Ima-\ngeNet [17]) and cross-modal datasets (e.g., LAION-2B [18])\nhave enabled deep learning models to move beyond low-\nlevel visual details. Modern approaches (e.g., [2, 19‚Äì23])\ncan recognize different images of the same semantic class or\nimages that match a rough textual description‚Äîfor example,\n‚Äúa photo of matchsticks‚Äù‚Äîeven if they differ in shape, color,\nor other low- to mid-level details (Fig. 1, Group B, first row).\nHowever, by focusing primarily on surface-level features,\nthese models struggle to capture relational similarity (see\nSec. 4.2). For instance, they cannot easily recognize that\nthe burning stages of a match resemble the ripening stages\nof a banana (Fig. 1, Group A, first row). Capturing this\ntype of similarity requires a shift in perspective: instead of\nrelying solely on visual features, we must reason about how\ndifferent visual elements, interact, abstracting the underlying\nrelationships. For example, both the match and the banana\nundergo a gradual transformation over time. The similarity\nlies not in their specific appearance but in the logic of change.\nThis raises questions: which attributes should be preserved\nor ignored during comparison? How can we identify which\nrelational patterns are relevant or useful?\nDataset\nData Format\nExample\nBAPPS\n[1]\nimage triplet\n(low-level perceptual)\nNIGHTS\n[22]\nimage triplet\n(mid-level perceptual)\nImageNet\n[17]\nsemantic class\n(attribute-based)\n‚ÄúBernese \nmountain dog‚Äù\nLAION-2B\n[18]\n{image, caption}\n(attribute-based)\n‚ÄúCats of \nTorcello, \nItaly‚Äù\n‚ÄúAn \nannoyed \ncat‚Äù\nOurs\n(relsim)\n{image,\nanonymous caption}\n(relational-based)\n‚ÄúA {object} stands \nout against gray \nbackground‚Äù\nTable 1. Survey of prominent datasets used for training visual\nsimilarity metrics. All are organized based on attribute similarity,\nwhereas ours focuses on relational similarity.\nInsights from cognitive science, encouragingly, offer a\nspark for these questions. Works [10, 24] showed that hu-\nmans process attribute similarity perceptually, but relational\nsimilarity requires conceptual abstraction, often supported\nby language or prior knowledge. This suggests that recog-\nnizing relational similarity first requires understanding the\nimage, drawing on knowledge, and abstracting its underlying\nstructure. Take the example of a photo of burning matches:\nwe first observe how each match relates to the others‚Äîthey\nburn sequentially from left to right. With prior knowledge,\nwe understand that burning is a temporal transformation, a\nprocess that can occur in many other objects (e.g., a leaf\naging, a banana ripening). If asked to write a caption cap-\nturing this logic rather than the specific objects, one might\nwrite ‚Äútransformation of {subject} over time‚Äù. We call such\ncaptions anonymous captions‚Äîthey do not describe any\nparticular visible object but instead capture the relational\nlogic conveyed by the image. These captions act as the glue\nconnecting images with similar underlying logic. In other\nwords, a successful relational visual similarity model must\nunderstand, abstract, and use anonymous captions to bring\nlogically similar images together.\nTo model relational similarity, we follow a path inspired\nby insights from cognitive science. Since no existing dataset\ncaptures relational visual similarity (see Tab. 1), we first\nfilter a large image corpus, LAION-2B [18], to extract 114k\nimages likely to contain transferable relational structures.\nThis step improves dataset quality by removing low-quality,\nmislabeled, or relationally uninformative images, which are\ncommon in LAION-2B [25, 26]. We then train an anony-\nmous captioning model to generate captions for these im-\nages, creating a set of {image, anonymous caption} pairs.\nFinally, we train a relational visual similarity model, relsim,\non this dataset, optimizing it to bring together images whose\ncaptions encode similar relational abstractions. We demon-\nstrate the utility of relsim for tasks such as relational image\nretrieval and analogical image generation.\n2\n\nIn short, our contributions are as follows:\n‚Ä¢ A new notion of image similarity, relational visual simi-\nlarity, which complements traditional attribute similarity.\n‚Ä¢ A novel relational dataset, consisting of 114k {image-\nanonymous captions} designed to capture the abstraction\nand logic in each image.\n‚Ä¢ A new tuned metric, relsim, that captures the relational\nvisual similarity between two images.\n‚Ä¢ Analysis of the relationship between relational and at-\ntribute similarity, along with experiments demonstrating\nthe limitations of current image similarity models.\n‚Ä¢ Demonstration of downstream applications in image re-\ntrieval and image generation.\n2. Related Works\nSimilarity in Cognitive Science. The question of what\nmakes two subjects similar has always been considered\none of the most significant questions in cognitive sci-\nence [3, 9, 27‚Äì29]. Similarity is fundamental to human\ncognition, as it affects how the mind organizes, categorizes,\nand reasons about the world. For decades, Tversky‚Äôs theory\nof similarity [9], also called the contrast model, has been\nwidely adopted and has inspired multiple domains [1, 22, 30].\nTversky frames similarity as a psychological comparison of\nmatching individual properties or characteristics of objects\n(e.g., size, shape, color). For example, an apple and a banana\nare similar because they are both fruits. While powerful,\nTversky‚Äôs theory cannot account for similarities such as the\none Stephen Hawking made when he said, ‚ÄúI regard the brain\nas a computer‚Äù [31]. There are no obvious visual features\nshared between a human brain and a computer. This kind of\nsimilarity, which cannot be fully accounted for by Tversky‚Äôs\nmodel, was later formalized as relational similarity, along-\nside its counterpart, now called attribute similarity. These\nconcepts emerged from Gentner‚Äôs research on analogy, often\nreferred as Structure-Mapping theory [10]. Relational sim-\nilarity is a comparison based on the relationships between\nobjects. Returning to the previous example, Stephen Hawk-\ning was making a relational comparison: he viewed the brain\nas a biological machine and the process of death as anal-\nogous to a computer breaking down. Substantial research\nshows that while both type of similarity are important, rela-\ntional similarity (often associated with analogical reasoning)\nplays a distinct and often deeper role in human cognition\n(i.e., analogical learning and reasoning [3, 12‚Äì14]).\nImage Similarity. Comparing similarity between two\nvisual signals is a core concept in computer vision, as it\nunderpins many tasks (e.g., object recognition, image re-\ntrieval, image matching).\nBefore the deep learning era,\nmost image similarities were computed directly via pixel-\nlevel metrics (e.g., L1, L2, MSE, RMSE, PSNR) or hand-\ncrafted features (e.g., SSIM [32], FSIM [33], SIFT [15]).\nWith the rise of deep learning and neural networks (e.g.,\nVGG [21], ResNet [23]), deep-feature-based image simi-\nlarity metrics better align with human perceptual judgment\n(e.g., LPIPS [1], PieAPP [34], DISTS [35]). More recently,\nwith the aid of Vision Transformers (ViT) [36] and Self-\nSupervised Learning (SSL), modern vision encoders (e.g.,\nDINO [20], CLIP [2], dreamsim [22], SigLIP [37]) not only\nprovide robust visual embeddings for image similarity, but\nalso enable semantic comparisons that go beyond pixel-level\nmatching. However, all of these approaches rely on the as-\nsumption that image similarity is based solely on attribute\nsimilarity, and thus cannot capture relational similarity, as\nwe demonstrate in our experiments (Sec. 4.2). Here, we, for\nthe first time, propose to consider relational visual similarity.\nMutimodal Large Language Models. Research on mul-\ntimodal models (e.g., [38‚Äì46]) has become an increasingly\nattractive topic in recent years. In particular, progress in\ndeveloping unified models that can both understand and gen-\nerate visual and textual inputs/outputs has transformed how\nwe interpret and interact with visual information. While\ntraditional vision encoders (e.g., CLIP [2]) can mostly only\n‚Äúsee‚Äù what is explicitly shown in an image (e.g., ‚Äúa photo of a\nmother hugging a child‚Äù), integrating them with MLLMs al-\nlows us to capture what is not directly depicted (e.g., ‚Äúthe im-\nage representing a sense of parental care‚Äù). Since relational\nsimilarity often requires a deeper understanding of images\nthat goes beyond mere perception, we choose to leverage\nMLLMs, particularly Vision Language Models (VLMs), as\nthe backbone for image feature extraction.\n3. Relational Visual Similarity\nWe formalize the problem of measuring the relational visual\nsimilarity as follows. Given two input images I1 and I2,\nwe aim to train a visual feature extractor fV such that the\nresulting features capture the relational similarity between\nthe two images. Our core assumption is that if two images\nexhibit high relational similarity, then their corresponding\nanonymous captions, A1 and A2, should also be similar.\nSpecifically, we define the relational similarity score s12\nbetween the two images as:\ns12 = fV (I1) ¬∑ fV (I2) ‚âàfT (A1) ¬∑ fT (A2),\nwhere ‚Äú¬∑‚Äù denotes the cosine similarity between the feature\nembeddings. Here, fT represents a textual encoder that\nproduces embeddings for the corresponding captions.\nIn Sec. 3.1, we describe how to construct the relational\ndataset, including how to sample image {Ii}N\ni=1 and generate\ntheir corresponding anonymous captions {Ai}N\ni=1. Then, in\nSec. 3.2, we detail the training procedure for fV .\n3.1. Creating a Relational Dataset\nFiltering interesting images {Ii}N\ni=1. Not all images are\nequally informative with deep logic for learning relational\n3\n\ncreatively \nuses {Food} \nto resemble a \n{Object}\ncreatively \nuses {Food} \nto resemble a \n{Object}\ncreatively \nuses {Food} \nto resemble a \n{Object}\nùëá1\nùëá2\nùëá3\nùëá4\nùêº1\nùêº2\nùêº3\nùêº4\nInstruction\nrelsim\nText Embedding\nAnonymous\nCaption\nImage\nFilter\nLAION-2B\n(a) Image Filtering\nAnonymous\nCaption\nTransform a \n{Fruit} into a \n{Animal} by \ncarving.\nAnonymous \nCaption 1\nAnonymous \nCaption M\nManually\nVerify\n‚Ä¶\n‚Ä¶\nVLM\n(b) Anonymous Captioning\n(c) Relational Visual Similarity (relsim) Training\nTraining Example\nGroup 1\nGroup M\nFigure 2. Overall pipeline. (a) We train an image filtering model to select high-quality relational images from LAION-2B [18]. (b)\nAnonymous captioning model is trained on groups of images that share the same underlying logic, pairing all images in each group with the\nsame anonymous caption. (c) Training relational visual similarity (relsim) model involves a contrastive loss between image features and their\ncorresponding anonymous captions.\nIncreasing ‚Äúinterestingness‚Äù\nRandom LAION\nFigure 3. Examples of relationally interesting vs. ordinary images.\nstructures. For instance, an image of a single sofa merely\nconveys surface-level object appearance, offering limited\ndeep cues about relational organization. In contrast, a photo\nof ‚Äústrawberry heart‚Äù expresses creatively compositional\nrelations that can be abstracted and transferred to new visual\ncontent (e.g., ‚Äúwalnut brain‚Äù, Fig. 3, second row).\nGiven the vast nature of LAION-2B, we first perform\na filtering step to identify images potentially containing\nhigher-order relational cues (which we refer to as interest-\ning images). We fine-tune Qwen2.5-VL-7B [39] to classify\nwhether an image is relationally interesting, using 1.3k pos-\nitive and 11k negative human-labeled examples (Fig. 2a).\nAnnotators were instructed: ‚ÄúCan you see any relational\npattern, logic, or structure in this image that could be useful\nfor creating or linking to another image?‚Äù. The fine-tuned\nmodel achieves 93% agreement with human judgments, and\nwhen applied to LAION-2B, it yields N = 114k images\nidentified as relationally interesting. Details of the prompt\nand model configuration are provided in the Supp. 7.\nGenerating anonymous captions {Ai}N\ni=1. Writing a\nshared relational attribute from a single image is inherently\nchallenging. For example, given only a sequence depicting a\nbutterfly‚Äôs flight stages (Fig. 4, first row), it is unclear which\nvisual details are irrelevant and which constitute the underly-\ning relational pattern. In contrast, when this image is shown\nA visual representation of {Subject} performing \n{Type of Motion} in progressive stages, \narranged horizontally to demonstrate the flow of \nmovement‚Ä¶\nSeries of images illustrating the {Movement \nType} of a group of {Insect Name}‚Ä¶\nA dynamic sequence of Monarch butterflies‚Ä¶\nA dynamic sequence of nearly identical {Figure} \ntraces an unfolding curvilinear path‚Ä¶\nImage Group\nSingle Image\n‚Ä¶\nFigure 4. Writing an anonymous caption is hard from a single\nimage, but easier with an image group where the pattern is clear.\nalongside others expressing the same logic (Fig. 4, second\nrow), the shared relational structure becomes immediately\napparent, making it easy to articulate a caption that abstracts\naway object specifics.\nMotivated by this observation, we manually curate M =\n532 groups of images, where all images within a group ex-\nhibit the same underlying relational logic or pattern. Each\ngroup has Ng images (a minimum of 2 and a maximum of\n10 images). We present each full group to an frozen VLM\nand prompt it to produce a single anonymous caption Ag‚Äîa\nrelational description that avoids object-specific terms by\nreplacing them with placeholders (e.g., {subject}). This cap-\ntion is then human-verified and paired with every image in\nthe group, yielding an anonymous training dataset (Fig. 2b):\n{(Ig\ni , Ag) | i = 1, . . . , Ng}M\ng=1\nThis procedure encourages the model to assign similar anony-\nmous captions to images expressing the same relational pat-\ntern. We use Qwen2.5-VL-7B [39] to train this captioning\nmodel. After training, we apply it to all ‚Äúinteresting‚Äù images\nidentified in the previous step, yielding a dataset consisting\nof images annotated with anonymous relational captions,\n{Ii, Ai}N\ni=1, where N = 114, 881 to be exact.\n4\n\n3.2. Modeling Relational Visual Similarity\nObjective.\nGiven the collection of relationally interest-\ning images with their corresponding anonymous captions\n{(Ii, Ai)}N\ni=1, we train a visual extractor fV with a frozen\ntext encoder fT to produce normalized embeddings:\nvi =\nfV (Ii)\n‚à•fV (Ii)‚à•,\nti =\nfT (Ai)\n‚à•fT (Ai)‚à•.\nWe compute the similarity between an image and its anony-\nmous caption using a dot product scaled by a learnable tem-\nperature parameter œÑ > 0:\nsij = v‚ä§\ni tj\nœÑ\n.\nFor a batch of size B, we use the InfoNCE training loss [2]:\nL = 1\nB\nPB\ni=1\n\"\n‚àílog\nexp(sii)\nPB\nj=1 exp(sij)\n#\nThis training paradigm encourages the visual extractor to\ncapture relationally meaningful features that align with the\nabstract concepts represented in the anonymous captions.\nModel Selection. Traditional visual similarity methods\nrely on pure vision encoders (e.g., [2, 20, 22]), which derive\nrepresentations solely from attribute-level features. We find\nthese vision-only encoders insufficient for capturing rela-\ntional similarity, even after tuned, as relational reasoning\ngoes beyond mere visual recognition (See 4.2).\nTo address this, we leverage Vision Language Models\n(VLMs) for two reasons: (1) vision encoders emphasize\nvisual attributes or semantics, which can conflict with re-\nlational understanding; and (2) relational reasoning often\nrequires higher-level semantic knowledge‚Äîwhich can be\nfound nowhere better than in a Large Language Model,\nwhere it was already trained with world knowledge. Ac-\ncordingly, we employ a VLM as our visual extractor fV\n(Fig. 2c). Optionally, the task‚Äìinstruction can be paired\nwith the image as a fixed, steering prompt (e.g., ‚ÄúCarefully\nanalyze image to understand its underlying logic...‚Äù).\n4. Experiments\nWe now discuss our experimental settings, baselines, and\nevaluation protocol, followed by additional analyses.\n4.1. Settings\nImplementation. We adopt Qwen2.5-VL-7B [39] as our\nvisual feature extractor fV . Specifically, we append a learn-\nable query token to the end of the image as instruction token,\nand feed them together into the LLM. We use the query\ntoken‚Äôs feature from the LLM‚Äôs last layer as our visual re-\nlational feature. For the text embedding model fT , we use\nall-MiniLM-L6-v2, a widely used and efficient pre-trained\nmodel from the Sentence-Transformers library [47]. We\ntrain QwenVL with LoRA [48] for 15k iterations on a single\nnode with 8√óA100 GPUs and a batch size of 64.\nData. To ensure complete separation between training\nand evaluation, we randomly split the dataset of 114k images\ninto 100k for training and 14k for evaluation. For evalua-\ntion, we consider the image retrieval setting. Specifically,\ngiven a query image, we retrieve the most similar image\nfrom the database (excluding the query itself); ideally, the\nretrieved image should be relationally similar to the query.\nThe database consists of the 14k images from the test set,\ncombined with another 14k new images randomly sampled\nfrom LAION-2B [18] to better approximate a real-world\ndatabase. From this database, 1000 images are randomly\nchosen from 14k test set to serve as query images.\nEvaluation protocol. We employ GPT-4o [40] as an au-\ntomated judge to evaluate retrieval results. For each query\nimage and retrieved image pair, GPT-4o is prompted to as-\nsign a relational similarity score on a scale from 0 to 10,\nwhere 10 indicates highly relationally similar and 0 indicates\nno similarity (See Supp. 7 for full prompt). Along with this\nautomatic evaluation, we conduct a user study to capture\nhuman preferences. Participants are shown a query image\nalong with two retrieved images: one from ours and one\nfrom a baseline method (randomly named as A or B)‚Äîand\nare asked to select which retrieved image is relationally more\nsimilar to the query (A, B, or Same). For each baseline, we\nrandomly constructed 300 triplets, and each triplet was in-\ndependently evaluated by at least three users, resulting in\napproximately 900 responses per baseline. This study allows\nus to quantify the proportion of cases in which users prefer\nour retrieval results over the baselines.\nBaselines. We compare our approach with prominent\nimage similarity metrics, including LPIPS [1], DINO [20],\ndreamsim [22], and CLIP-I [2] (image-to-image). These\nmodels can directly output similarity scores for a pair of\nimages. We also consider baselines that operate via captions.\nIn these settings, we first prompt Qwen [39] to generate\nan anonymous or abstract caption for each image, and then\nperform retrieval using this caption as the query feature. We\nevaluate two variants: (1) Apply CLIP-based text-to-image\nretrieval denoted as CLIP-T; and (2) Text-to-text retrieval\ndenoted as Qwen-T. Note that in both of these caption-based\nbaselines, we use the original Qwen model rather than our\nfinetuned version. This allows us to show the performance of\nprompting a VLM to produce the anonymous caption from\na single image (see Fig. 4) whereas finetuned model is our\nmethod which benefits from a group of images.\n4.2. Evaluations\nCan existing metrics capture relational similarity? Re-\nsults are presented in Fig. 6, where higher values indicate\nbetter performance. As shown, LPIPS [1], which focuses\n5\n\nLPIPS\ndreamsim\nDINO\nCLIP-I\nQwen-T\nNearest Neighbors\nQuery\nOurs\nNearest Neighbors\nLPIPS\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\nLPIPS\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\nLPIPS\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\nQuery\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nFigure 5. Attributes vs. Relational Visual Image Retrieval. Visualization of nearest neighbor using different visual similarity metrics. As\ncan be seen, only ours understands and can detect the relational similarity.\nLPIPS\nDINO\ndreamsim\nCLIP-I\nCLIP-T\nQwen-T\nTuned DINO\nTuned CLIP\nOurs\n5\n6\n7\nGPT Score\n4.56\n5.14\n5.76\n5.91\n5.33\n4.86\n5.62\n6.02\n6.77\nFigure 6. Relational visual similarity performance. All existing\nimage similarity metrics fail to capture relational similarity, even\nafter being tuned. Our final model (relsim) which leverages knowl-\nedge from VLMs, achieves the highest score (6.77).\npurely on perceptual similarity, achieves the lowest score\n(4.56). DINO [20] performs only slightly better (5.14), likely\nbecause it is trained solely in a self-supervised manner on\nimage data. CLIP-I [2] yields the strongest results among\nthe baselines (5.91), presumably because some abstraction\nis sometimes present in image captions. However, CLIP-I\nstill underperforms relative to our method, as achieving a\nbetter score may require the ability to reach even higher-\nlevel abstractions, such as those in anonymous captions. Our\nvision encoder, being equipped with LLM knowledge and\nanonymous captions, yields the highest score (6.77).\nWhy generate anonymous captions from a group? As\ndescribed in the approach section, our anonymous captions\nare generated from manually selected groups of similar im-\nages. Using a group makes it easier to identify the shared\nrelational structure required for a high-quality anonymous\ncaption. The CLIP-T and Qwen-T baselines further illustrate\nthis point (Fig. 6): in both cases, anonymous captions are\nproduced from a single image using the original Qwen2.5-\nVL [39]. We find that, under this setting, the model is hard\nto prompt and often leaks semantic or attribute information,\ncausing retrieval to overly focus on semantics rather than\nrelational similarity, thus yielding poor results (i.e., 5.33 and\n4.86, compared with ours, 6.77).\nKnowledge is essential for capturing relational similar-\nity. Our argument is that relational similarity requires more\nthan visual perception‚Äîit demands a deeper form of image\nunderstanding. Such knowledge is largely absent in vision-\nencoder-only models. To test this hypothesis, we conduct\n6\n\nQuery\nattribute similarity (CLIP)\nrelational similarity (relsim)\nrandom images\nsame logic, look different\nsame logic,\nsame appearance\nFigure 7. Similarity space showing different kinds of visual similarity in terms of degree of relational vs. attribute similarity.\nan ablation study in which we finetune pure vision encoders\n(CLIP [2] and DINO [20]) using the same anonymous cap-\ntions training data and the same loss. The results (denoted\nas Tuned CLIP/DINO), shown in the right panel of Fig. 6,\nindicate that finetuning with anonymous captions does im-\nprove these models‚Äô ability to capture structural relationships.\nHowever, their performance still falls short of our model,\nwhich is equipped with a VLM. This gap is likely because\nVLMs, which integrate visual features with language-based\nworld knowledge, are inherently necessary to understand\nand encode relational similarity.\nDo humans agree with ours? The result of our user\nstudy, shown in Fig. 8, indicates that users consistently prefer\nour method across all baseline comparisons, with preference\nrates ranging from 42.5-60.7%. The gray bars indicate the tie\nrate. This is highly encouraging, as it demonstrates not only\nthat our model, relsim, can successfully retrieve relationally\nsimilar images, but also, again, confirms that humans do\nperceive relational similarity‚Äînot just attribute similarity!\n54.2%\nOurs\n21.5%\n24.3%\nDINO\n48.5%\nOurs\n17.0%\n34.4%\nDreamSim\n42.5%\nOurs\n25.6%\n31.9%\nCLIP-I\n59.7%\nOurs\n12.6%\n27.7%\nCLIP-T\n0\n200\n400\n600\n800\nNumber of User Responses\n60.7%\nOurs\n17.5%\n21.8%\nQwen-T\nFigure 8. User study. AB testing shows that our model aligns\nsignificantly better with human perception of relational similarity\ncompared to the baselines.\nRelational similarity complements attribute similarity.\nAt this point, a skeptical reader might ask: then, which kind\nof similarity is better‚Äîrelational or attribute? The answer\nis not straightforward. Relational and attribute similarities\nserve different but complementary roles: while they are often\nconsidered separate, combining them can reveal richer struc-\ntures in visual data. Inspired by the similarity theory [12],\nwe visualize visual similarity space using a query image\n‚ÄúA dog holding a camera‚Äù, and random 3000 images com-\npared to it (Fig. 7). As shown, combining these two aspects\nof similarity allows us to discover interesting relationships:\n(1) same logic, same appearance: other photos of similar-\nlooking dogs performing human-like activities; (2) same\nlogic, look different: images of other {animal} performing\nhuman-like activities; and (3) random images: most other\nimages fall into this category. This result shows that rela-\ntional and attribute similarities are, perhaps, most powerful\nwhen used together rather than in isolation.\n5. Applications\nIn this section, we illustrate scenarios where relational image\nsimilarity is useful for downstream applications, including,\nbut not limited to, the examples below.\nRetrieved Images\nQuery\nFigure 9. Relational image retrieval. We demonstrate that image\ncan also be searched based on logic or abstraction (relational-based),\nnot only perceptual or semantic similarity.\nRelational image retrieval. Relational similarity im-\nproves retrieval performance in scenarios where attribute-\n7\n\nInput\nFlux-Kontext\nGPT-4o\nNano-Banana\nExample Output\nQwen-Image\nText Instruction\n‚ÄúKeep this idea and \nimagination,\ncreate a new one‚Äù\nBagel\n‚ÄúUsing the same logic \nas the input, generate \nanother image for the \nletter P‚Äù\n‚ÄúCreate a similar \nidea like this,\nany animal works.‚Äù\nOpen-sourced models\nProprietary models\nHuman selected\nFigure 10. Qualitative results for analogical image generation. Proprietary models are generally better at understanding and performing\nsophisticated relational transformations, while open-sourced models still lag behind.\nbased matching fails, allowing users to search for images not\nonly by semantics but also by higher-level interactions and\nfunctions between elements. This approach makes retrieval\nmore aligned with human intuition, which is especially use-\nful for inspiration or creativity. For example, a user might\nwant to retrieve images showing a similarly creative way to\ndecorate a food item with human eyes (Fig. 9, first row).\n‚ÄúGenerate a \ncreative pose \nidea like this‚Äù\nInput\nStandard Image Editing\nAnalogical Image Generation\n‚ÄúCreate another \npun like this‚Äù\n‚ÄúChange her \nshirt to red‚Äù\n‚ÄúMake the\nice-cream cry‚Äù\nText Prompt\nOutput\nText Prompt\nOutput\nFigure 11. Analogical image generation. Unlike standard image\nediting, which modifies surface attributes, analogical generation\ntransfers deeper relational structures and conceptual ideas.\nAnalogical image generation. Relational similarity ex-\ntends image manipulation beyond surface attributes, allow-\ning the transfer of deeper relational structures and concep-\ntual ideas rather than just shape or texture, unlike conven-\ntional image editing. For example, Fig. 11 (second row)\nshows a visual pun realized through typography (i.e., ‚Äúice-\nscream‚Äù); users may wish to generate new images conveying\nthe same concept without predefined constraints on objects\nor attributes. Evaluating how well current image-editing or\nMLLM-based methods preserve such relational structures is\nchallenging, but relational similarity provides a promising\nframework for addressing this gap.\nTo test this, we manually collected 200 image pairs shar-\nModel\nLPIPS (‚Üì)\nCLIP (‚Üë)\nrelsim (‚Üë)\nOpen-sourced model\nFLUX-Kontext [49]\n0.28 ¬± 0.22\n0.87 ¬± 0.12\n0.71 ¬± 0.26\nBagel [41]\n0.32 ¬± 0.19\n0.79 ¬± 0.12\n0.74 ¬± 0.21\nQwen-Image [50]\n0.29 ¬± 0.21\n0.86 ¬± 0.13\n0.71 ¬± 0.22\nProprietary model\nGPT4o-Image [40]\n0.47 ¬± 0.15\n0.77 ¬± 0.10\n0.82 ¬± 0.14\nNano-Banana [51]\n0.41 ¬± 0.20\n0.78 ¬± 0.11\n0.84 ¬± 0.11\nExample Output\n0.60 ¬± 0.17\n0.66 ¬± 0.11\n0.88 ¬± 0.11\nTable 2. Quantitative benchmarking of analogical image gener-\nation. LPIPS, CLIP and relsim measure perceptual, semantic, and\nrelational similarity, respectively, between input and edited images.\ning underlying ideas or logic, along with corresponding\nhuman-written text instructions, forming triplets: {‚ÄúInput‚Äù,\nText Instruction‚Äù, ‚ÄúExample Output‚Äù} (Fig. 11, first three\ncolumns). Each triplet reflects a setting where a user pro-\nvides an input image and a text instruction to generate a\nnew image capturing the same underlying idea or logic. The\nresults (Tab. 2) benchmark open-source and proprietary mod-\nels using CLIP-I [2], LPIPS [1], and relsim scores to evaluate\nsemantic, perceptual, and relational structure preservation.\nKey findings: (i) Example Outputs can be logically similar to\nthe Input Image (highest relsim: 0.88) while visually differ-\ning or belonging to different semantic classes (lowest CLIP:\n0.66, highest LPIPS: 0.60), showing that preserving the un-\nderlying idea can be more important than visual similarity.\n(ii) Open-source models tend to preserve visual similarity\n(i.e., CLIP: 0.8x) but often miss logical transformations com-\npared to closed-source models (relsim: 0.7x vs. 0.8x) (see\nFig. 10). These results highlight both the performance gap\nbetween proprietary and closed-source models; and the need\nfor more challenging analogical image generation datasets\nto improve open-source model training.\n8\n\n6. Conclusion and Discussion\nWe have proposed relsim, a metric modeling relational vi-\nsual similarity‚Äîan important aspect of visual understanding\nthat has been largely overlooked. We show that relsim cap-\ntures image logic and abstraction, which are not effectively\nmeasured by existing attribute-based similarity metrics. We\nfurther demonstrate several applications of relsim, including\nvisual exploration (image similarity space), image retrieval,\nand analogical image generation.\nThat said, our paper is not without limitations. First,\nthe anonymous captioning model is currently trained on 532\nmanually curated image groups, which may be imperfect, po-\ntentially biased, and not scalable. Developing an automated,\nscalable pipeline to expand these image groups, or relational\nlogics, is an important direction for future research. Sec-\nond, like other VLMs, the anonymous captioning model can\nexhibit biases or hallucinations, which can lead to some in-\ncorrect captions. Last but not least, we acknowledge that one\nimage can embody multiple different relational structures,\npotentially leading to multiple valid relational mappings. De-\ntermining how to use text prompts to specify which relational\nstructure a user intends remains an open question. Never-\ntheless, our paper highlights relational visual similarity‚Äîan\noverlooked aspect of image similarity‚Äîand we hope to open\nnew avenues for future research in relational understanding\nand generation for vision systems.\nAcknowledgment\nThis work was supported in part by NSF IIS2404180, and\nInstitute of Information & communications Technology Plan-\nning& Evaluation (IITP) grants funded by the Korea gov-\nernment (MSIT) (No. 2022-0-00871, Development of AI\nAutonomy and Knowledge Enhancement for AI Agent Col-\nlaboration) and (No. RS-2022-00187238, Development of\nLarge Korean Language Model Technology for Efficient\nPre-training).\nData Attributions\nAll images used in this paper are from the publicly available\nLAION-2B dataset [18]. The authors do not own any of\nthe images and acknowledge the dataset creators and/or the\noriginal copyright holders of each image. All images are\nused for research purposes only.\nReferences\n[1] Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman,\nand Oliver Wang. The unreasonable effectiveness of deep\nfeatures as a perceptual metric. In CVPR, 2018. 1, 2, 3, 5, 8\n[2] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya\nRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,\nAmanda Askell, Pamela Mishkin, Jack Clark, Gretchen\nKrueger, and Ilya Sutskever. Learning transferable visual\nmodels from natural language supervision. In ICML, 2021. 1,\n2, 3, 5, 6, 7, 8\n[3] Douglas L Medin, Robert L Goldstone, and Dedre Gentner.\nRespects for similarity. Psychological review, 1993. 2, 3\n[4] Fabian Hutmacher. Why is there so much more research\non vision than on any other sensory modality? Frontiers in\npsychology, 2019. 2\n[5] Douglas L Medin, Robert L Goldstone, and Dedre Gentner.\nSimilarity involving attributes and relations: Judgments of\nsimilarity and difference are not inverses.\nPsychological\nScience, 1990. 2\n[6] Arthur B Markman and Dedre Gentner. Structural alignment\nduring similarity comparisons. Cognitive psychology, 1993.\n2\n[7] Roger N Shepard. Recognition memory for words, sentences,\nand pictures. Journal of verbal Learning and verbal Behavior,\n1967. 2\n[8] Robert M Nosofsky.\nAttention, similarity, and the\nidentification‚Äìcategorization relationship. Journal of experi-\nmental psychology: General, 1986. 2\n[9] Amos Tversky. Features of similarity. Psychological review,\n1977. 2, 3\n[10] Dedre Gentner. Structure-mapping: A theoretical framework\nfor analogy. Cognitive Science, 1983. 2, 3\n[11] Dedre Gentner. Analogical learning. Similarity and analogi-\ncal reasoning, 1989. 2\n[12] Dedre Gentner and Arthur B Markman. Structure mapping in\nanalogy and similarity. American psychologist, 1997. 2, 3, 7\n[13] Keith J Holyoak and Paul Thagard. Mental leaps: Analogy in\ncreative thought. MIT press, 1996.\n[14] Dedre Gentner. Bootstrapping the mind: Analogical processes\nand symbol systems. Cognitive science, 2010. 2, 3\n[15] David G Lowe.\nDistinctive image features from scale-\ninvariant keypoints. International Journal of Computer Vision,\n2004. 2, 3\n[16] Navneet Dalal and Bill Triggs. Histograms of oriented gradi-\nents for human detection. In CVPR, 2005. 2\n[17] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,\nand Li Fei-Fei. Imagenet: A large-scale hierarchical image\ndatabase. In CVPR, 2009. 2\n[18] Christoph Schuhmann, Romain Beaumont, Richard Vencu,\nCade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes,\nAarush Katta, Clayton Mullis, Mitchell Wortsman, et al.\nLaion-5b: An open large-scale dataset for training next gener-\nation image-text models. NeuRIPS, 2022. 2, 4, 5, 9\n[19] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali\nFarhadi. You only look once: Unified, real-time object detec-\ntion. In CVPR, 2016. 2\n[20] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv¬¥e J¬¥egou,\nJulien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg-\ning properties in self-supervised vision transformers.\nIn\nCVPR, 2021. 3, 5, 6, 7\n[21] Karen Simonyan and Andrew Zisserman. Very deep convo-\nlutional networks for large-scale image recognition. arXiv,\n2014. 3\n[22] Stephanie Fu, Netanel Tamir, Shobhita Sundaram, Lucy Chai,\nRichard Zhang, Tali Dekel, and Phillip Isola. Dreamsim:\n9\n\nLearning new dimensions of human visual similarity using\nsynthetic data. In NeurIPS, 2023. 2, 3, 5\n[23] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\nDeep residual learning for image recognition. In CVPR, 2016.\n2, 3\n[24] Robert L Goldstone. The role of similarity in categorization:\nProviding a groundwork. Cognition, 1994. 2\n[25] Abeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahem-\nbwe. Multimodal datasets: misogyny, pornography, and ma-\nlignant stereotypes. arXiv, 2021. 2\n[26] Amro Abbas, Kushal Tirumala, D¬¥aniel Simig, Surya Ganguli,\nand Ari S Morcos. Semdedup: Data-efficient learning at\nweb-scale through semantic deduplication. arXiv, 2023. 2\n[27] Robert L Goldstone and Ji Yun Son. Similarity. The Oxford\nHandbook of Thinking and Reasoning, 2012. 3\n[28] Amos Tversky and Itamar Gati. Studies of similarity. In\nCognition and categorization, 2024.\n[29] Ulrike Hahn and Nick Chater. Concepts and similarity. In\nKnowledge concepts and categories, 2013. 3\n[30] Seyed Sadegh Mohseni Salehi, Deniz Erdogmus, and Ali\nGholipour. Tversky loss function for image segmentation\nusing 3d fully convolutional deep networks. In International\nworkshop on machine learning in medical imaging, 2017. 3\n[31] Ian Sample. Stephen hawking: ‚Äòthere is no heaven; it‚Äôs a fairy\nstory‚Äô. The Guardian, 2011. Accessed: 2025-11-09. 3\n[32] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P\nSimoncelli. Image quality assessment: from error visibility to\nstructural similarity. IEEE transactions on image processing,\n2004. 3\n[33] Lin Zhang, Lei Zhang, Xuanqin Mou, and David Zhang. Fsim:\nA feature similarity index for image quality assessment. IEEE\ntransactions on Image Processing, 2011. 3\n[34] Ekta Prashnani, Hong Cai, Yasamin Mostofi, and Pradeep Sen.\nPieapp: Perceptual image-error assessment through pairwise\npreference. In CVPR, 2018. 3\n[35] Keyan Ding, Kede Ma, Shiqi Wang, and Eero P. Simoncelli.\nImage quality assessment: Unifying structure and texture\nsimilarity. CoRR, 2020. 3\n[36] Alexey Dosovitskiy. An image is worth 16x16 words: Trans-\nformers for image recognition at scale. arXiv, 2020. 3\n[37] Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and\nLucas Beyer. Sigmoid loss for language image pre-training.\nIn CVPR, 2023. 3\n[38] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.\nVisual instruction tuning. NeurIPS, 2023. 3\n[39] Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin\nGe, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang,\net al. Qwen2. 5-vl technical report. arXiv, 2025. 4, 5, 6, 11\n[40] Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman,\nAditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda,\nAlan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv,\n2024. 5, 8\n[41] Chaorui Deng, Deyao Zhu, Kunchang Li, Chenhui Gou, Feng\nLi, Zeyu Wang, Shu Zhong, Weihao Yu, Xiaonan Nie, Ziang\nSong, et al. Emerging properties in unified multimodal pre-\ntraining. arXiv, 2025. 8\n[42] Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan\nIyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman,\nKrishna Kumar Singh, Yong Jae Lee, et al. X-fusion: Intro-\nducing new modality to frozen large language models. In\nICCV, 2025.\n[43] Thao Nguyen, Krishna Kumar Singh, Jing Shi, Trung Bui,\nYong Jae Lee, and Yuheng Li. Yo‚Äôchameleon: Personalized\nvision and language generation. In CVPR, 2025.\n[44] Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-\nBaptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk,\nAndrew M Dai, Anja Hauth, Katie Millican, et al. Gemini: a\nfamily of highly capable multimodal models. arXiv, 2023.\n[45] Thao Nguyen, Haotian Liu, Yuheng Li, Mu Cai, Utkarsh Ojha,\nand Yong Jae Lee. Yo‚Äôllava: Your personalized language and\nvision assistant. In NeurIPS, 2024.\n[46] Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee.\nImproved baselines with visual instruction tuning. In CVPR,\n2024. 3\n[47] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence\nembeddings using siamese bert-networks. arXiv, 2019. 5\n[48] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,\nYuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. Lora:\nLow-rank adaptation of large language models. In ICLR,\n2022. 5\n[49] Stephen Batifol, Andreas Blattmann, Frederic Boesel, Sak-\nsham Consul, Cyril Diagne, Tim Dockhorn, Jack English,\nZion English, Patrick Esser, Sumith Kulal, et al. Flux. 1\nkontext: Flow matching for in-context image generation and\nediting in latent space. arXiv, 2025. 8\n[50] Chenfei Wu, Jiahao Li, Jingren Zhou, Junyang Lin, Kaiyuan\nGao, Kun Yan, Sheng-ming Yin, Shuai Bai, Xiao Xu, Yilei\nChen, et al. Qwen-image technical report. arXiv, 2025. 8\n[51] Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice\nPasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein,\nOri Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing\nthe frontier with advanced reasoning, multimodality, long\ncontext, and next generation agentic capabilities. arXiv, 2025.\n8\n10\n\nRelational Visual Similarity\nSupplementary Material\n7. Implementation Details\nThis section presents implementation details as well as snap-\nshots of the training data and model predictions, which were\nomitted from the main paper due to page constraints.\nInteresting images filtering prompt\nYou are an expert in visual creativity and interesting-\nness. Your task is to determine if the given image is\nvisually interesting or not.\nIf the image is interesting, answer ‚ÄúYes‚Äù.\nIf the image is not interesting, answer ‚ÄúNo‚Äù.\nRemember, you are only allowed to answer ‚ÄúYes‚Äù or\n‚ÄúNo‚Äù, no other words or phrases.\nInteresting Image Filtering. We trained an image filter-\ning model on 1.3k positive images and 11k negative images.\nThe model used was Qwen2.5-VL-7B [39], trained with\nLoRA. Positive images were labeled as ‚ÄúYes‚Äù (the model\nshould answer ‚ÄúYes‚Äù), and negative images were labeled as\n‚ÄúNo‚Äù (the model should answer ‚ÄúNo‚Äù) accordingly.\nExamples of images classified as positive and negative are\nshown in Fig. 12. The keep rate is around 0.7% (i.e., out of\nevery 1k images, the model marks about 7 as ‚Äúinteresting‚Äù).\nWrite anonymous caption for each image prompt\nYou are given a single image.\nCarefully analyze it to understand its underlying\nlogic, layout, structure, or creative concept. Then\ngenerate a single, reusable anonymous caption that\ncould describe any image following the same con-\ncept.\nThe caption must:\n‚Ä¢ Fully capture the general logic or analogy of the\nimage.\n‚Ä¢ Include placeholders (e.g., {Object}, {Word},\n{Character}, {Meaning}, {Color}, etc.) wherever\nvariations can occur.\n‚Ä¢ Be concise and standalone.\nImportant: Only output the anonymous caption. Do\nnot provide any explanations or additional text.\nAnonymous captioning model. The full prompt for ob-\ntaining the anonymous captions for each image group, and\nthe prompt used to train the anonymous captioning model,\nare provided below. We also present an example of a pre-\ndicted caption for each image in Fig. 13.\n‚ÄúArtwork depicting {Animal} with the \nfeatures and traits of a {Historical \nFigure}.‚Äù\n‚ÄúCreative clothing design featuring an \nexaggerated representation of a \n{Object} with vibrant colors and \ndetailed patterns.‚Äù\n‚ÄúCreative arrangement of {Animals} \nmade with {Puzzle Pieces} showcasing \nreal-life counterparts.‚Äù\n‚ÄúA monochrome image with one \n{Object} highlighted in bright {Color}.‚Äù\n‚ÄúIntriguing images of {Animal 1} and \n{Animal 2} forming a unique bond.‚Äù\nFigure 13. Example of predicted anonymous caption\nAnonymous captions for image group\nYou are given two or more images that share a com-\nmon logic, layout, structure, or creative concept (e.g.,\nalphabet worksheets, step-by-step drawings, animals\nmade from peeled fruits, etc.).\nYour task is to carefully analyze all the images, iden-\ntify the shared logic or analogy among them, and\ncreate one anonymous caption that describes all the\nimages.\nThe anonymous caption must:\n‚Ä¢ Be a single, reusable image caption that fully de-\nscribes the general logic of all the images.\n‚Ä¢ Must\ninclude\nplaceholders\n(e.g.,\n{Object},\n{Word}, {Character}, {Meaning}, {Color}, etc.)\nwherever variations occur.\nFor example: ‚ÄúImage of using {Fruit} to create a\n{Animal}‚Äù; ‚ÄúGrowth process of {Subject} described\nin 4 main stages: {Stage 1}, {Stage 2}, {Stage 3},\n{Stage 4}‚Äù\nOnly provide the anonymous caption; Do not include\nany other explanation or content.\n11\n\nnot ‚Äúinteresting‚Äù\n‚Äúinteresting‚Äù images\nFigure 12. Examples of interesting and uninteresting images filtered by the finetuned Image Filtering model.\nAutomated Judgment. We present the full prompt used\nfor automated judgment of a query image and a retrieved\nimage below.\nAutomated Judgment for Image Retrieval\nYou are given two images.\nYour task is to determine whether these two images\nshare a similar underlying logic‚Äîthat is, whether\nthey form an analogical pair.\nDo NOT base your judgment on visual similarity\n(e.g., color, shape, composition) or semantic similar-\nity (such as both showing the same object or class).\nImages that are visually or semantically similar but\ndo NOT share the same underlying logic should re-\nceive a very low score.\nFocus ONLY on whether the two images convey the\nsame conceptual or relational logic. For example, if\none image shows a peach‚Äôs internal structures, and\nthe other shows a Earth‚Äôs internal structures, they\nshare the same logic and should receive a very high\nscore.\nOutput only the number.\n‚Ä¢ 10 = very strong analogical/relational similarity\n(same underlying logic)\n‚Ä¢ 0 = no logical/relational similarity\nPlease directly output the score.\n8. Additional Results\nAdditional image retrieval results can be found in Fig. 14-15\n12\n\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nFigure 14. Additional results for image retrieval (1).\n13\n\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\ndreamsim\nDINO\nCLIP-I\nQwen-T\nOurs\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nNearest Neighbors\nQuery\nFigure 15. Additional results for image retrieval (2).\n14\n",
    "figure_captions": [
      "Figure 1. Would you say images in Group A are similar to the Reference Image? Current state-of-the-art image similarity models (e.g.,",
      "Figure 2. Overall pipeline. (a) We train an image filtering model to select high-quality relational images from LAION-2B [18]. (b)",
      "Figure 3. Examples of relationally interesting vs. ordinary images.",
      "Figure 4. Writing an anonymous caption is hard from a single",
      "Figure 5. Attributes vs. Relational Visual Image Retrieval. Visualization of nearest neighbor using different visual similarity metrics. As",
      "Figure 6. Relational visual similarity performance. All existing",
      "Figure 7. Similarity space showing different kinds of visual similarity in terms of degree of relational vs. attribute similarity.",
      "Figure 8. User study. AB testing shows that our model aligns",
      "Figure 9. Relational image retrieval. We demonstrate that image",
      "Figure 10. Qualitative results for analogical image generation. Proprietary models are generally better at understanding and performing",
      "Figure 11. Analogical image generation. Unlike standard image",
      "Fig. 10). These results highlight both the performance gap",
      "Figure 13. Example of predicted anonymous caption",
      "Figure 12. Examples of interesting and uninteresting images filtered by the finetuned Image Filtering model.",
      "Figure 14. Additional results for image retrieval (1).",
      "Figure 15. Additional results for image retrieval (2)."
    ]
  },
  {
    "arxiv_id": "2512.07832v1",
    "title": "Do Generalisation Results Generalise?",
    "abstract": "A large language model's (LLM's) out-of-distribution (OOD) generalisation ability is crucial to its deployment. Previous work assessing LLMs' generalisation performance, however, typically focuses on a single out-of-distribution dataset. This approach may fail to precisely evaluate the capabilities of the model, as the data shifts encountered once a model is deployed are much more diverse. In this work, we investigate whether OOD generalisation results generalise. More specifically, we evaluate a model's performance across multiple OOD testsets throughout a finetuning run; we then evaluate the partial correlation of performances across these testsets, regressing out in-domain performance. This allows us to assess how correlated are generalisation performances once in-domain performance is controlled for. Analysing OLMo2 and OPT, we observe no overarching trend in generalisation results: the existence of a positive or negative correlation between any two OOD testsets depends strongly on the specific choice of model analysed.",
    "text": "Do Generalisation Results Generalise?\nMatteo Boglioni,1,2\nAndrea Sgobbi,1\nGabriel Tavernini,1\nFrancesco Rita,1\nMarius Mosbach,2,3\nTiago Pimentel1\n1ETH Z√ºrich,\n2Mila - Quebec Artificial Intelligence Institute,\n3McGill University\n{mboglioni, asgobbi, gtavernini, frita01}@ethz.ch,\nmarius.mosbach@mila.quebec, tiago.pimentel@inf.ethz.ch\nAbstract\nA large language model‚Äôs (LLM‚Äôs) out-of-\ndistribution (OOD) generalisation ability is cru-\ncial to its deployment. Previous work assessing\nLLMs‚Äô generalisation performance, however,\ntypically focuses on a single out-of-distribution\ndataset. This approach may fail to precisely\nevaluate the capabilities of the model, as the\ndata shifts encountered once a model is de-\nployed are much more diverse. In this work,\nwe investigate whether OOD generalisation re-\nsults generalise. More specifically, we eval-\nuate a model‚Äôs performance across multiple\nOOD testsets throughout a finetuning run; we\nthen evaluate the partial correlation of perfor-\nmances across these testsets, regressing out in-\ndomain performance. This allows us to assess\nhow correlated are generalisation performances\nonce in-domain performance is controlled for.\nAnalysing OLMo2 and OPT, we observe no over-\narching trend in generalisation results: the ex-\nistence of a positive or negative correlation be-\ntween any two OOD testsets depends strongly\non the specific choice of model analysed.\n1\nIntroduction\nA\nlarge\nlanguage\nmodel‚Äôs\n(LLM‚Äôs)\nout-of-\ndistribution (OOD) generalisation1 performance is\nan essential property for its deployment in the wild.\nNot surprisingly, it has received increased attention\nfrom the community (Xu et al., 2021; Hupkes et al.,\n2023; Yang et al., 2023, 2024, 2025; Yuan et al.,\n2023; Ye, 2024). Most work evaluating generalisa-\ntion, however, relies on a single out-of-distribution\ntestset per task (Mosbach et al., 2023; Joshi and\nHe, 2022; Bhargava et al., 2021).2\nWhen a model achieves high scores on such an\nout-of-distribution testset, authors typically assume\nthe model has found a good solution for the task\n1Throughout this work, generalisation always refers to\nout-of-distribution generalisation.\n2Two notable exceptions are discussed in ¬ß2.\n1a\n2\n3\n4\n5\n6\n7\n1a\n2\n3\n4\n5\n6\n7\n1a\n2\n3\n4\n5\n6\n7\nSNLI\n1b\n2\n3\n4\n5\n6\n7\nOLMo2 7B\n1b\n2\n3\n4\n5\n6\n7\nOLMo2 13B\n1b\n2\n3\n4\n5\n6\n7\nOLMo2 32B\nMNLI\nPositive Correlation\nNegative Correlation\nFigure 1: OLMo2‚Äôs partial OOD correlations on SNLI\n(top) and MNLI (bottom).\nNo clear trends are ob-\nserved. Edge thickness increases with absolute cor-\nrelation value. Legend: 1a.MNLI, 1b.SNLI, 2.WNLI,\n3.SciTail, 4.RTE, 5.HANS, 6.ANLI, and 7.PAWS.\nand that the model does not rely on spurious fea-\ntures to solve it. There is, however, no a priori\nreason why a model which generalises in one OOD\ntestset should also generalise in testsets created\nunder different distribution shifts. Furthermore,\nMosbach et al. (2023) show that generalisation per-\nformance can be quite unstable across training, re-\ninforcing the need for its more precise assessment.\nIn this paper, we investigate whether generalisa-\ntion results generalise. To this end, we analyse how\na model‚Äôs generalisation performances in different\nOOD testsets correlate across a single finetuning\nrun. However, generalisation performances are\nbound to be trivially correlated due to their\ndependency on a common factor: the model‚Äôs\nin-domain performance.\nWe control for that\nfactor by computing partial OOD correlations\ninstead, regressing out in-domain performance.\nThese partial correlations quantify how strongly\ngeneralisation performances correlate beyond their\ndependence on in-domain performance.\nEmpirically, we show that whether generalisa-\ntion performance will transfer across OOD test-\nsets is a complex phenomenon.\nWhile a spe-\n1\narXiv:2512.07832v1  [cs.CL]  8 Dec 2025\n\ncific model‚Äôs generalisation performance may be\nstrongly correlated across two OOD testsets, it\nmight present negative correlations under another\npair.\nSimilarly, while two OOD testsets may\npresent positive partial correlations under one\nmodel, they may present negative correlations un-\nder another. This large variance in generalisation\nperformance highlights that fair generalisation eval-\nuation must span multiple OOD testsets.\n2\nOut-of-distribution Generalisation in\nLanguage Models\nRobust generalisation beyond the training distribu-\ntion has long been a challenge in natural language\nprocessing (NLP). In the quest to improve OOD\ngeneralisation, researchers face an important prob-\nlem: how do we evaluate it in the first place?\nHow to evaluate OOD generalisation?\nAssess-\ning generalisation performance is an intricate game\nof cat-and-mouse: as models tend to saturate on\nexisting benchmarks, new ones are released to ex-\npose new weaknesses. McCoy et al. (2019), for\ninstance, adversarially constructed an OOD testset\n(HANS) to reveal LLMs‚Äô reliance on superficial\ncues to solve a natural language inference (NLI)\ntask. Similarly, Nie et al. (2020) constructed an\nOOD dataset (ANLI) in rounds to continually fool\nNLI models. Further, Liu et al. (2022) used models\ntrained on MNLI (Williams et al., 2018) to generate\ntheir own synthetic (adversarial) datasets.\nDo finetuned models generalise?\nGiven all\nthese benchmarks, we should have a good idea\nabout how well language models generalise. How-\never, the effect of finetuning on a model‚Äôs OOD\ngeneralisation remains a little-understood topic.\nKumar et al. (2022), for instance, show that fine-\ntuning models with randomly initialised classifier\nheads can lead to distorted features and hence poor\ngeneralisation. Recent empirical work (Mosbach\net al., 2023; Yang et al., 2024), however, show\nstrong generalisation of finetuned models on OOD\ndata. Both these works, however, use pattern-based\nfine-tuning (Schick and Sch√ºtze, 2021) instead of\na randomly initialised classifier head, being thus\nnot directly comparable to the findings of Kumar\net al.. A few prior works investigate multiple OOD\ntestsets. E.g., Gupta et al. (2024) evaluate which\nOOD testsets still represent a challenge for fine-\ntuned models. Closest to our work is Sun et al.\n(2023), who compare the rankings achieved by fine-\ntuned models on a number of OOD testsets. More\nspecifically, they compute the correlations across\nOOD testsets of the rankings achieved by several\npretrained models when finetuned to perform NLI.\nTheir analyses, however, do not control for either\nthe models‚Äô in-domain performance, or the used\npretrained models‚Äô size and quality. Instead, we\nwill analyse partial correlations within each train-\ning run, controlling for both factors.\n3\nMeasuring Correlations between OOD\nGeneralisations\nWe aim to assess how robust generalisation results\nare to a specific choice of OOD testset. We can\nquantify this by analysing how correlated generali-\nsation results are across testsets. Language models\nwith better in-domain performance, however, are\nalso likely to perform better out-of-domain (Yang\net al., 2023). Naively computing OOD correlations,\nthus, is likely to mostly capture this trivial (and ar-\nguably uninteresting) source of correlation. To con-\ntrol for this, we measure partial OOD correlations\ninstead: the correlation between two OOD perfor-\nmances once in-domain performance has been re-\ngressed out. How does this work in practice?\nLet pŒ∏ be a language model, which we finetune\non a specific (in-domain) training set. While fine-\ntuning this model, we measure its in-domain per-\nformance, denoted sind\nt\n, on an in-domain testset\nat several checkpoints t; this gives us a vector of\nperformances sind. Simultaneously, we measure\nthis model‚Äôs out-of-domain performance, denoted\nsood:d\nt\n, on several out-of-domain testsets, d, using\nthe same checkpoints; getting a vector of perfor-\nmances sood:d. If we simply wanted to examine the\ncorrelation between OOD performances, we would\nevaluate: corr(sood:d1, sood:d2).\nComputing the partial correlation between two\nOOD datasets, however, requires regressing out in-\ndomain performance. To do this, we train a regres-\nsion model fd : R ‚ÜíR for each OOD dataset d,\nwhich, given an in-domain performance measure-\nment, predicts that checkpoints‚Äô OOD performance:\nsood:d\nt\n‚âàfd(sind\nt\n). Given this model, we compute\na residual ed\nt = sood:d\nt\n‚àífd(sind\nt\n), which quantifies\nhow much better or worse a model performs on d\nthan what would be expected given its in-domain\nperformance. Doing this for all checkpoint steps t,\nwe get a vector of residuals ed. Finally, we compute\nthe partial correlations we are interested in as:\nœÅd1,d2 = corr(ed1, ed2) .\n(1)\n2\n\nMNLI\nModel\nSize\nMNLI‚Ä°\nSNLI\nWNLI\nSciTail\nRTE\nHANS\nANLI\nPAWS\nOPT\n2.7b\n81.6 ¬± 5.9\n72.7 ¬± 17.8\n49.9 ¬± 0.7\n65.8 ¬± 5.9\n62.5 ¬± 2.1\n51.7 ¬± 2.9\n50.5 ¬± 0.5\n46.3 ¬± 1.2\n6.7b\n84.7 ¬± 6.7\n83.7 ¬± 12.6\n50.7 ¬± 1.8\n70.7 ¬± 10.9\n64.3 ¬± 1.0\n55.5 ¬± 7.8\n49.2 ¬± 1.9\n47.3 ¬± 0.8\n13b\n87.3 ¬± 5.6\n83.9 ¬± 13.4\n50.9 ¬± 2.6\n71.3 ¬± 7.6\n67.9 ¬± 1.6\n57.0 ¬± 7.3\n52.3 ¬± 1.5\n48.5 ¬± 2.5\n30b\n89.0 ¬± 5.9\n86.8 ¬± 14.2\n50.7 ¬± 1.1\n74.7 ¬± 3.2\n71.2 ¬± 3.2\n59.3 ¬± 6.2\n53.0 ¬± 1.0\n48.6 ¬± 1.5\nOLMo2\n7B\n75.1 ¬± 1.9\n67.1 ¬± 15.8\n55.7 ¬± 2.6\n55.0 ¬± 8.1\n63.1 ¬± 5.6\n52.7 ¬± 2.2\n55.7 ¬± 4.7\n59.1 ¬± 5.9\n13B\n61.2 ¬± 1.5\n56.7 ¬± 5.9\n52.4 ¬± 1.0\n57.0 ¬± 4.8\n54.0 ¬± 1.9\n51.3 ¬± 2.5\n50.9 ¬± 0.5\n54.7 ¬± 2.5\n32B\n87.4 ¬± 12.0\n81.8 ¬± 24.8\n68.2 ¬± 12.5\n53.7 ¬± 9.5\n69.2 ¬± 4.0\n61.5 ¬± 7.4\n68.3 ¬± 5.4\n66.9 ¬± 2.6\nChance performance\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\nTable 1: Accuracy on each OOD dataset for models trained on MNLI with 128 examples over 3 independent runs.\nMeasurements are taken using the checkpoint with the highest in-domain performance. ‚Ä° in-domain dataset.\nSNLI\nModel\nSize\nSNLI‚Ä°\nMNLI\nWNLI\nSciTail\nRTE\nHANS\nANLI\nPAWS\nOPT\n2.7b\n94.2 ¬± 0.2\n78.6 ¬± 3.1\n50.4 ¬± 0.5\n74.1 ¬± 2.8\n66.4 ¬± 0.7\n51.4 ¬± 1.4\n50.6 ¬± 1.1\n50.6 ¬± 3.8\n6.7b\n94.3 ¬± 1.3\n78.2 ¬± 6.4\n52.2 ¬± 0.6\n68.8 ¬± 13.3\n66.0 ¬± 0.9\n54.9 ¬± 2.4\n51.8 ¬± 3.1\n49.5 ¬± 2.3\n13b\n95.3 ¬± 0.4\n82.0 ¬± 4.0\n49.9 ¬± 0.4\n70.2 ¬± 4.2\n65.3 ¬± 1.3\n53.4 ¬± 3.0\n51.8 ¬± 1.0\n48.6 ¬± 2.3\n30b\n96.1 ¬± 0.1\n86.0 ¬± 3.9\n52.0 ¬± 1.4\n76.8 ¬± 2.3\n70.7 ¬± 2.5\n58.8 ¬± 5.6\n53.0 ¬± 1.3\n49.7 ¬± 4.1\nOLMo2\n7B\n90.6 ¬± 5.0\n70.7 ¬± 11.3\n59.3 ¬± 3.4\n56.9 ¬± 4.3\n61.0 ¬± 4.3\n61.8 ¬± 3.1\n56.3 ¬± 3.7\n64.6 ¬± 3.9\n13B\n80.4 ¬± 2.3\n61.4 ¬± 2.8\n54.9 ¬± 0.2\n54.7 ¬± 2.7\n55.8 ¬± 0.7\n57.3 ¬± 3.2\n52.3 ¬± 1.9\n54.8 ¬± 1.7\n32B\n98.0 ¬± 0.1\n84.1 ¬± 5.1\n73.9 ¬± 1.0\n60.7 ¬± 5.8\n70.9 ¬± 1.2\n66.7 ¬± 2.7\n65.4 ¬± 2.6\n69.6 ¬± 0.9\nChance performance\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\nTable 2: Accuracy on each OOD dataset for models trained on SNLI with 128 examples over 3 independent runs.\nMeasurements are taken using the checkpoint with the highest in-domain performance. ‚Ä° in-domain dataset.\nSince our focus is on observing joint improvement,\nwe choose to capture simple linear correlations be-\ntween these residuals, measuring Pearson‚Äôs corre-\nlations as the corr(¬∑) function. Throughout the pa-\nper, we present results using GAM regressors fd.3\n4\nExperimental Setup\nTask.\nAs a test-bed for our experiments, we fo-\ncus on natural language inference (NLI; Dagan\nand Glickman, 2004; Putra et al., 2024), as gen-\neralisation performance on this task has received\nconsiderable interest (Bhargava et al., 2021; Zhou\nand Tan, 2021; Mosbach et al., 2023; Gupta et al.,\n2024). This task consists in determining the logi-\ncal relationship between a pair of sentences. More\nspecifically, each entry in this task consists of a pair\nof sentences, a premise and a hypothesis; the task is\nthen to determine if the premise entails, contradicts,\nor is neutral about the hypothesis.\nModels.\nWe rely here on two different model\nfamilies: OPT (Zhang et al., 2022), OLMo2 (OLMo\net al., 2024). We choose these models due to them\n3We experiment with both linear and GAM (Hastie and\nTibshirani, 1986) regressors, but find this choice has only a\nminor impact on results. Fig. 7 shows in-domain vs. out-of-\ndomain curves learned by our regressors. We place partial\ncorrelation results using linear regressors in Fig. 8 to 10 in ¬ßD.\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nOPT 30b (MNLI)\nOPT 30b (SNLI)\n0k\n100k\n200k\n300k\n400k\n500k\n600k\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nOLMo2 32B (MNLI)\n0k\n100k\n200k\n300k\n400k\n500k\n600k\nOLMo2 32B (SNLI)\nFigure 2:\nAccuracy (y-axis) across training steps\n(x-axis) of OPT (top) and OLMo2 (bottom) for a single\nfinetuning run on MNLI (left) and SNLI (right). Legend:\nMNLI, SNLI, WNLI, RTE, SciTail, ANLI, HANS and PAWS.\nbeing publicly available in multiple sizes, and due\nto their popularity in recent years for a broad range\nof NLP tasks. Beyond that, OPT also makes our ex-\nperiments more easily comparable to previous work\n(e.g., Mosbach et al., 2023; Srinivasan et al., 2024).\nFollowing Mosbach et al. (2023), we finetune these\nmodels using: a few-shot setting, with 128, 64\nand 32 examples; low-rank adaptation (LoRA; Hu\net al., 2022); and pattern-based finetuning (Schick\nand Sch√ºtze, 2021; Gao et al., 2021), reusing the\npre-trained LM head instead of using a randomly\ninitialised one. More details can be found in ¬ßA.\n3\n\n‚àí1.00\n‚àí0.75\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.20\n0.27 ‚àí0.79 ‚àí0.35 ‚àí0.40 ‚àí0.41\n0.20\n1.00 ‚àí0.13 ‚àí0.23 ‚àí0.03 ‚àí0.48 ‚àí0.49\n0.27 ‚àí0.13 1.00\n0.24\n0.01 ‚àí0.12 0.50\n‚àí0.79 ‚àí0.23 0.24\n1.00\n0.38\n0.27\n0.63\n‚àí0.35 ‚àí0.03 0.01\n0.38\n1.00\n0.28\n0.34\n‚àí0.40 ‚àí0.48 ‚àí0.12 0.27\n0.28\n1.00\n0.71\n‚àí0.41 ‚àí0.49 0.50\n0.63\n0.34\n0.71\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00 ‚àí0.54 ‚àí0.10 ‚àí0.60 ‚àí0.63 ‚àí0.60 0.10\n‚àí0.54 1.00 ‚àí0.03 0.34\n0.31\n0.37 ‚àí0.28\n‚àí0.10 ‚àí0.03 1.00\n0.74\n0.43 ‚àí0.03 0.48\n‚àí0.60 0.34\n0.74\n1.00\n0.74\n0.21\n0.28\n‚àí0.63 0.31\n0.43\n0.74\n1.00\n0.46\n0.37\n‚àí0.60 0.37 ‚àí0.03 0.21\n0.46\n1.00\n0.31\n0.10 ‚àí0.28 0.48\n0.28\n0.37\n0.31\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.38 ‚àí0.44 ‚àí0.65 ‚àí0.38 ‚àí0.72 ‚àí0.32\n0.38\n1.00 ‚àí0.33 ‚àí0.08 0.03 ‚àí0.65 ‚àí0.56\n‚àí0.44 ‚àí0.33 1.00\n0.75\n0.60\n0.50\n0.76\n‚àí0.65 ‚àí0.08 0.75\n1.00\n0.74\n0.56\n0.52\n‚àí0.38 0.03\n0.60\n0.74\n1.00\n0.32\n0.39\n‚àí0.72 ‚àí0.65 0.50\n0.56\n0.32\n1.00\n0.69\n‚àí0.32 ‚àí0.56 0.76\n0.52\n0.39\n0.69\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.51 ‚àí0.36 ‚àí0.15 ‚àí0.45 ‚àí0.43 ‚àí0.57\n0.51\n1.00 ‚àí0.59 ‚àí0.20 ‚àí0.25 ‚àí0.74 ‚àí0.68\n‚àí0.36 ‚àí0.59 1.00\n0.53\n0.40\n0.55\n0.72\n‚àí0.15 ‚àí0.20 0.53\n1.00\n0.52\n0.03\n0.48\n‚àí0.45 ‚àí0.25 0.40\n0.52\n1.00\n0.38\n0.60\n‚àí0.43 ‚àí0.74 0.55\n0.03\n0.38\n1.00\n0.66\n‚àí0.57 ‚àí0.68 0.72\n0.48\n0.60\n0.66\n1.00\nOPT 30b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.24\n0.15\n0.19\n0.09\n0.37 ‚àí0.08\n0.24\n1.00\n0.09\n0.16\n0.02\n0.42 ‚àí0.56\n0.15\n0.09\n1.00\n0.14 ‚àí0.27 ‚àí0.04 0.19\n0.19\n0.16\n0.14\n1.00\n0.34\n0.55\n0.36\n0.09\n0.02 ‚àí0.27 0.34\n1.00\n0.49\n0.18\n0.37\n0.42 ‚àí0.04 0.55\n0.49\n1.00 ‚àí0.14\n‚àí0.08 ‚àí0.56 0.19\n0.36\n0.18 ‚àí0.14 1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.60 ‚àí0.24 0.58\n0.27\n0.72 ‚àí0.22\n0.60\n1.00 ‚àí0.03 0.69\n0.24\n0.51 ‚àí0.67\n‚àí0.24 ‚àí0.03 1.00 ‚àí0.07 ‚àí0.05 ‚àí0.32 0.06\n0.58\n0.69 ‚àí0.07 1.00\n0.46\n0.64 ‚àí0.64\n0.27\n0.24 ‚àí0.05 0.46\n1.00\n0.44 ‚àí0.16\n0.72\n0.51 ‚àí0.32 0.64\n0.44\n1.00 ‚àí0.17\n‚àí0.22 ‚àí0.67 0.06 ‚àí0.64 ‚àí0.16 ‚àí0.17 1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.16\n0.31 ‚àí0.42 ‚àí0.11 0.39\n0.43\n0.16\n1.00 ‚àí0.26 ‚àí0.42 ‚àí0.22 ‚àí0.25 0.45\n0.31 ‚àí0.26 1.00\n0.51\n0.44\n0.69\n0.36\n‚àí0.42 ‚àí0.42 0.51\n1.00\n0.54\n0.51 ‚àí0.26\n‚àí0.11 ‚àí0.22 0.44\n0.54\n1.00\n0.57 ‚àí0.10\n0.39 ‚àí0.25 0.69\n0.51\n0.57\n1.00\n0.06\n0.43\n0.45\n0.36 ‚àí0.26 ‚àí0.10 0.06\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.75 ‚àí0.17 ‚àí0.27 ‚àí0.51 ‚àí0.19 ‚àí0.55\n0.75\n1.00 ‚àí0.36 ‚àí0.48 ‚àí0.75 ‚àí0.50 ‚àí0.67\n‚àí0.17 ‚àí0.36 1.00\n0.65\n0.52\n0.54\n0.40\n‚àí0.27 ‚àí0.48 0.65\n1.00\n0.79\n0.93\n0.04\n‚àí0.51 ‚àí0.75 0.52\n0.79\n1.00\n0.84\n0.46\n‚àí0.19 ‚àí0.50 0.54\n0.93\n0.84\n1.00\n0.11\n‚àí0.55 ‚àí0.67 0.40\n0.04\n0.46\n0.11\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî SNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.93 ‚àí0.87 0.82\n0.68\n0.17 ‚àí0.86\n0.93\n1.00 ‚àí0.69 0.63\n0.79\n0.41 ‚àí0.68\n‚àí0.87 ‚àí0.69 1.00 ‚àí0.93 ‚àí0.35 0.20\n0.93\n0.82\n0.63 ‚àí0.93 1.00\n0.22 ‚àí0.40 ‚àí0.99\n0.68\n0.79 ‚àí0.35 0.22\n1.00\n0.72 ‚àí0.28\n0.17\n0.41\n0.20 ‚àí0.40 0.72\n1.00\n0.34\n‚àí0.86 ‚àí0.68 0.93 ‚àí0.99 ‚àí0.28 0.34\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00 ‚àí0.06 0.48\n0.08\n0.28\n0.17 ‚àí0.33\n‚àí0.06 1.00\n0.25 ‚àí0.17 0.15\n0.25\n0.23\n0.48\n0.25\n1.00 ‚àí0.74 0.69\n0.89\n0.60\n0.08 ‚àí0.17 ‚àí0.74 1.00 ‚àí0.75 ‚àí0.95 ‚àí0.93\n0.28\n0.15\n0.69 ‚àí0.75 1.00\n0.78\n0.59\n0.17\n0.25\n0.89 ‚àí0.95 0.78\n1.00\n0.85\n‚àí0.33 0.23\n0.60 ‚àí0.93 0.59\n0.85\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.08 ‚àí0.08 ‚àí0.01 0.78 ‚àí0.39 ‚àí0.88\n0.08\n1.00\n0.30 ‚àí0.17 ‚àí0.17 0.05 ‚àí0.10\n‚àí0.08 0.30\n1.00\n0.61\n0.21\n0.88\n0.46\n‚àí0.01 ‚àí0.17 0.61\n1.00\n0.31\n0.62\n0.29\n0.78 ‚àí0.17 0.21\n0.31\n1.00\n0.07 ‚àí0.49\n‚àí0.39 0.05\n0.88\n0.62\n0.07\n1.00\n0.75\n‚àí0.88 ‚àí0.10 0.46\n0.29 ‚àí0.49 0.75\n1.00\nOLMo2 32B\nDataset Legend\n1 ‚Äî MNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.69\n0.65\n0.64\n0.18\n0.61 ‚àí0.40\n0.69\n1.00\n0.29\n0.70\n0.08\n0.26 ‚àí0.71\n0.65\n0.29\n1.00\n0.53\n0.33\n0.72\n0.09\n0.64\n0.70\n0.53\n1.00\n0.25\n0.42 ‚àí0.58\n0.18\n0.08\n0.33\n0.25\n1.00\n0.49\n0.29\n0.61\n0.26\n0.72\n0.42\n0.49\n1.00\n0.17\n‚àí0.40 ‚àí0.71 0.09 ‚àí0.58 0.29\n0.17\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.74 ‚àí0.42 ‚àí0.82 ‚àí0.20 0.07 ‚àí0.06\n0.74\n1.00 ‚àí0.31 ‚àí0.87 ‚àí0.14 ‚àí0.11 ‚àí0.23\n‚àí0.42 ‚àí0.31 1.00\n0.59\n0.05 ‚àí0.68 ‚àí0.63\n‚àí0.82 ‚àí0.87 0.59\n1.00\n0.09 ‚àí0.26 ‚àí0.12\n‚àí0.20 ‚àí0.14 0.05\n0.09\n1.00 ‚àí0.02 ‚àí0.00\n0.07 ‚àí0.11 ‚àí0.68 ‚àí0.26 ‚àí0.02 1.00\n0.97\n‚àí0.06 ‚àí0.23 ‚àí0.63 ‚àí0.12 ‚àí0.00 0.97\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.83\n0.36 ‚àí0.57 0.18 ‚àí0.14 ‚àí0.72\n0.83\n1.00\n0.55 ‚àí0.56 0.26 ‚àí0.14 ‚àí0.86\n0.36\n0.55\n1.00\n0.31\n0.86\n0.65 ‚àí0.54\n‚àí0.57 ‚àí0.56 0.31\n1.00\n0.48\n0.73\n0.35\n0.18\n0.26\n0.86\n0.48\n1.00\n0.79 ‚àí0.32\n‚àí0.14 ‚àí0.14 0.65\n0.73\n0.79\n1.00\n0.10\n‚àí0.72 ‚àí0.86 ‚àí0.54 0.35 ‚àí0.32 0.10\n1.00\nOLMo2 32B\nMNLI\nSNLI\nFigure 3: Partial correlations of OPT (top) and OLMo2 (bottom) across model sizes (ordered from left to right) trained\non MNLI (left) and SNLI (right). All these correlations are obtained by fitting a GAM regressor over 3 independent\ntraining runs. See a larger version of this plot in Fig. 11 (in ¬ßD).\nData.\nFor our experiments, we selected 8 differ-\nent NLI datasets: SNLI (Bowman et al., 2015),\nMNLI (Williams et al., 2018), SciTail (Khot et al.,\n2018), WNLI and RTE (Wang et al., 2018), PAWS\n(Zhang et al., 2019), HANS (McCoy et al., 2019),\nANLI (Nie et al., 2020). We run experiments while\nfinetuning our models on either SNLI or MNLI,\nmaking that our in-domain dataset‚Äîand evaluate\nour model on the 7 other OOD datasets. Details\nabout the selected datasets can be found in ¬ßB.\n5\nResults\nFinetuned models tend to generalise, but not\neverywhere.\nTables 1 and 2 present the general-\nisation of our evaluated models across all analysed\ntestsets. These tables present performances for a\nsingle checkpoint per model, where checkpoints\nwere selected based on having the best in-domain\nperformance. The tables show that no testset seems\nto be challenging for all models: every testset has\nat least one model that generalises successfully.\nFurthermore, it also shows that finetuning produces\nmodels that often perform well across a range\nof OOD testsets. However, for any given model,\nthere is always at least one testset at which they\nunderperform. For instance, the same OPT 30B\ncheckpoints achieve 86.0% accuracy on MNLI,\nbut 49.7% on PAWS. This variability highlights\na key limitation of single-testset evaluations. Ad-\nditionally, na√Øvely looking at Tables 1 and 2 might\nlead one to conclude that generalisation results\nare mostly robust: OPT 30B trained on MNLI does\nbetter than all other models in most testsets, and\nboth OPT 30B and OLMo2 32B seem to consistently\nbeat other models when trained on SNLI. This\nconclusion, however, is not necessarily warranted,\nas both model size and in-domain performance\nact as strong confounders. We now look at how\nthe generalisation performance of each of these\nmodels fluctuates throughout training, as a way to\ncontrol for the effect of model size on results.\nOPT‚Äôs generalisation performance oscillates,\nbut OLMo2‚Äôs doesn‚Äôt.\nFig. 2 presents OPT 30B‚Äôs\nand OLMo2\n32B‚Äôs OOD generalisation perfor-\nmances across training. (Results for smaller OPT\nand OLMo2 models are in Fig. 5, in ¬ßD.) Overall,\nthese figures reproduce one of the key results in\nMosbach et al. (2023), showing that OPT‚Äôs gener-\nalisation performance is unstable throughout train-\ning, presenting large (mostly unpredictable) oscil-\nlations. Interestingly, OLMo2‚Äôs performance does\nnot present the same oscillations. Perhaps more im-\nportant for our research question though, we see in\nthis figure that generalisation in some OOD testsets\nseems to track the others; this is most obvious for\nthe results of OPT 30B trained on SNLI. In-domain\nperformance, however, also tracks OOD generalisa-\ntion in these results‚Äîat least to some extent. Next,\nwe thus move to analysing partial correlations as\nintroduced in ¬ß3.\nGeneralisation‚Äôs generalisation is complicated.\nFig. 3 presents the partial correlations across OOD\ntestsets for both OPT and OLMo2 models. In this fig-\nure, we observe that OOD generalisation is a highly\ncomplex property for which no clear trend emerges\nacross testsets. While for a model two OOD testsets\nmight present strong postive partial correlations,\n4\n\nfor another model this correlation might be nega-\ntive. Additional intuition can also be drawn from\nFig. 4, which shows that partial correlations do not\nseem to strengthen with model size or with a partic-\nular choice of training dataset; partial correlations\nfor models finetuned on MNLI do not differ substan-\ntially from their corresponding SNLI counterparts.\nThese findings underscore the importance of con-\nducting a comprehensive evaluation when making\nclaims about a model‚Äôs generalisation capabilities,\nan often-lacking aspect in the current literature.\n6\nConclusions\nOur results highlight the need for generalisation\nresearch to rely on several OOD testsets to ensure\nfair evaluations. We do not observe clear trends\nwhen studying testset-to-testset performance cor-\nrelations: no clear trends arise when comparing\ndifferent training datasets, model families or sizes.\nIn fact, the partial correlation of performances on\na pair of OOD testsets seems to not be an intrinsic\nproperty even of the testset pair itself, depending on\nthe specific model and training dataset considered.\nLimitations\nDue to limited compute resources, it was imprac-\ntical for us to include models larger than 30B\nparameters in our analysis. However, it would be\ninteresting to investigate if the inconsistent trends\nobserved here would carry to other model families\nand to larger sizes. Additionally, we are not sure if\nour studied models (OPT, OLMo2) were exposed to\nthe analysed testsets during pretraining.4 We con-\nducted preliminary experiments using Min-k%++\n(Zhang et al., 2025) and Time Travel in LLMs\n(Golchin and Surdeanu, 2024) to investigate such\ndata contamination, but these experiments were\ninconclusive in most cases. Despite the negative re-\nsults, though, our tests suggest that the models have\nnot outright memorised the OOD testsets, which\nwould allow them to trivialise the task. Finally,\nour experiments focus exclusively on NLI. This\nlimitation results from the lack of dedicated OOD\ntestsets for other tasks, making it difficult to study\nthe extent to which our findings are NLI-specific.\n4Although OLMo2 is trained on open datasets, directly test-\ning for contamination on such a big dataset was a bigger\nchallenge than anticipated, with most solutions relying on\nmassive indexes for lookups (Vu et al., 2023).\n3B\n7B\n13B\n30B\nModel Size\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\nAvg. Partial Correlation\nSNLI\nOPT\nOLMo2\n3B\n7B\n13B\n30B\nModel Size\nMNLI\nOPT\nOLMo2\nFigure 4: Partial correlations averaged across all OOD\ntestset pairs for OPT and OLMo2 with different sizes.\nReferences\nPrajjwal Bhargava, Aleksandr Drozd, and Anna Rogers.\n2021. Generalization in NLI: Ways (not) to go be-\nyond simple heuristics. In Proceedings of the Second\nWorkshop on Insights from Negative Results in NLP,\npages 125‚Äì135, Online and Punta Cana, Dominican\nRepublic. Association for Computational Linguistics.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nIn Proceedings of the 2015 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n632‚Äì642, Lisbon, Portugal. Association for Compu-\ntational Linguistics.\nIdo Dagan and Oren Glickman. 2004. Probabilistic\ntextual entailment: Generic applied modeling of lan-\nguage variability. Learning Methods for Text Under-\nstanding and Mining, 2004(26-29):2‚Äì5.\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021.\nMaking pre-trained language models better few-shot\nlearners. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 3816‚Äì3830, Online. Association for Computa-\ntional Linguistics.\nShahriar Golchin and Mihai Surdeanu. 2024. Time\ntravel in LLMs: Tracing data contamination in large\nlanguage models. In The Twelfth International Con-\nference on Learning Representations.\nAshim Gupta, Rishanth Rajendhran, Nathan Stringham,\nVivek Srikumar, and Ana Marasovic. 2024. Whispers\nof doubt amidst echoes of triumph in NLP robustness.\nIn Proceedings of the 2024 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies\n(Volume 1: Long Papers), pages 5533‚Äì5590, Mexico\nCity, Mexico. Association for Computational Lin-\nguistics.\nTrevor Hastie and Robert Tibshirani. 1986. Generalized\nadditive models. Statistical Science, 1(3):297‚Äì310.\nEdward J. Hu, yelong shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\nWeizhu Chen. 2022. LoRA: Low-rank adaptation of\nlarge language models. In International Conference\non Learning Representations.\n5\n\nDieuwke Hupkes, Mario Giulianelli, Verna Dankers,\nMikel Artetxe, Yanai Elazar, Tiago Pimentel, Chris-\ntos Christodoulopoulos, Karim Lasri, Naomi Saphra,\nArabella Sinclair, Dennis Ulmer, Florian Schottmann,\nKhuyagbaatar Batsuren, Kaiser Sun, Koustuv Sinha,\nLeila Khalatbari, Maria Ryskina, Rita Frieske, Ryan\nCotterell, and Zhijing Jin. 2023. A taxonomy and\nreview of generalization research in NLP. Nature\nMachine Intelligence, 5(10):1161‚Äì1174.\nNitish Joshi and He He. 2022. An investigation of the\n(in)effectiveness of counterfactually augmented data.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 3668‚Äì3681, Dublin, Ireland.\nAssociation for Computational Linguistics.\nTushar Khot, Ashish Sabharwal, and Peter Clark. 2018.\nScitail: A textual entailment dataset from science\nquestion answering. In Proceedings of the AAAI\nconference on artificial intelligence, volume 32.\nAnanya Kumar, Aditi Raghunathan, Robbie Matthew\nJones, Tengyu Ma, and Percy Liang. 2022. Fine-\ntuning can distort pretrained features and underper-\nform out-of-distribution. In International Conference\non Learning Representations.\nAlisa Liu, Swabha Swayamdipta, Noah A. Smith, and\nYejin Choi. 2022. WANLI: Worker and AI collabora-\ntion for natural language inference dataset creation.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2022, pages 6826‚Äì6847, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nR. Thomas McCoy, Ellie Pavlick, and Tal Linzen. 2019.\nRight for the wrong reasons: Diagnosing syntactic\nheuristics in natural language inference. In Proceed-\nings of the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 3428‚Äì3448, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nMarius Mosbach, Tiago Pimentel, Shauli Ravfogel, Di-\netrich Klakow, and Yanai Elazar. 2023. Few-shot\nfine-tuning vs. in-context learning: A fair compari-\nson and evaluation. In Findings of the Association for\nComputational Linguistics: ACL 2023, pages 12284‚Äì\n12314, Toronto, Canada. Association for Computa-\ntional Linguistics.\nYixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,\nJason Weston, and Douwe Kiela. 2020. Adversarial\nNLI: A new benchmark for natural language under-\nstanding. In Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics. As-\nsociation for Computational Linguistics.\nTeam OLMo, Pete Walsh, Luca Soldaini, Dirk Groen-\neveld, Kyle Lo, Shane Arora, Akshita Bhagia, Yuling\nGu, Shengyi Huang, Matt Jordan, Nathan Lambert,\nDustin Schwenk, Oyvind Tafjord, Taira Anderson,\nDavid Atkinson, Faeze Brahman, Christopher Clark,\nPradeep Dasigi, Nouha Dziri, and 21 others. 2024. 2\nOLMo 2 furious. Preprint, arXiv:2501.00656.\nBuu Phan, Marton Havasi, Matthew J. Muckley, and\nKaren Ullrich. 2024. Understanding and mitigating\ntokenization bias in language models. In ICML 2024\nWorkshop on Theoretical Foundations of Foundation\nModels.\nTiago Pimentel and Clara Meister. 2024. How to com-\npute the probability of a word. In Proceedings of the\n2024 Conference on Empirical Methods in Natural\nLanguage Processing, pages 18358‚Äì18375, Miami,\nFlorida, USA. Association for Computational Lin-\nguistics.\nI Made Suwija Putra, Daniel Siahaan, and Ahmad\nSaikhu. 2024. Recognizing textual entailment: A\nreview of resources, approaches, applications, and\nchallenges. ICT Express, 10(1):132‚Äì155.\nMario Sanz-Guerrero, Minh Duc Bui, and Katharina\nvon der Wense. 2025. Mind the gap: A closer look at\ntokenization for multiple-choice question answering\nwith LLMs. In Proceedings of the 2025 Conference\non Empirical Methods in Natural Language Process-\ning, pages 19584‚Äì19594, Suzhou, China. Association\nfor Computational Linguistics.\nTimo Schick, Helmut Schmid, and Hinrich Sch√ºtze.\n2020. Automatically identifying words that can serve\nas labels for few-shot text classification. In Proceed-\nings of the 28th International Conference on Com-\nputational Linguistics, pages 5569‚Äì5578, Barcelona,\nSpain (Online). International Committee on Compu-\ntational Linguistics.\nTimo Schick and Hinrich Sch√ºtze. 2021. Exploiting\ncloze-questions for few-shot text classification and\nnatural language inference. In Proceedings of the\n16th Conference of the European Chapter of the Asso-\nciation for Computational Linguistics: Main Volume,\npages 255‚Äì269, Online. Association for Computa-\ntional Linguistics.\nKrishna Prasad Varadarajan Srinivasan,\nPrasanth\nGumpena, Madhusudhana Yattapu, and Vishal H\nBrahmbhatt. 2024. Comparative analysis of different\nefficient fine tuning methods of large language mod-\nels (LLMs) in low-resource setting. arXiv preprint\narXiv:2405.13181.\nKaiser Sun, Adina Williams, and Dieuwke Hupkes.\n2023. The validity of evaluation results: Assess-\ning concurrence across compositionality benchmarks.\nIn Proceedings of the 27th Conference on Computa-\ntional Natural Language Learning (CoNLL), pages\n274‚Äì293, Singapore. Association for Computational\nLinguistics.\nThuy Vu, Xuanli He, Gholamreza Haffari, and Ehsan\nShareghi. 2023. Koala: An index for quantifying\noverlaps with pre-training corpora. In Proceedings\nof the 2023 Conference on Empirical Methods in Nat-\nural Language Processing: System Demonstrations,\npages 90‚Äì98.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel Bowman. 2018. GLUE:\n6\n\nA multi-task benchmark and analysis platform for nat-\nural language understanding. In Proceedings of the\n2018 EMNLP Workshop BlackboxNLP: Analyzing\nand Interpreting Neural Networks for NLP. Associa-\ntion for Computational Linguistics.\nAdina Williams, Nikita Nangia, and Samuel Bowman.\n2018. A broad-coverage challenge corpus for sen-\ntence understanding through inference. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume\n1 (Long Papers), pages 1112‚Äì1122, New Orleans,\nLouisiana. Association for Computational Linguis-\ntics.\nRunxin Xu, Fuli Luo, Zhiyuan Zhang, Chuanqi Tan,\nBaobao Chang, Songfang Huang, and Fei Huang.\n2021. Raise a child in large language model: To-\nwards effective and generalizable fine-tuning. In Pro-\nceedings of the 2021 Conference on Empirical Meth-\nods in Natural Language Processing, pages 9514‚Äì\n9528.\nHaoran Yang, Yumeng Zhang, Jiaqi Xu, Hongyuan Lu,\nPheng-Ann Heng, and Wai Lam. 2024. Unveiling\nthe generalization power of fine-tuned large language\nmodels. In Proceedings of the 2024 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies (Volume 1: Long Papers), pages 884‚Äì899,\nMexico City, Mexico. Association for Computational\nLinguistics.\nLinyi Yang, Shuibai Zhang, Libo Qin, Yafu Li, Yi-\ndong Wang, Hanmeng Liu, Jindong Wang, Xing\nXie, and Yue Zhang. 2023. GLUE-X: Evaluating\nnatural language understanding models from an out-\nof-distribution generalization perspective. In Find-\nings of the Association for Computational Linguistics:\nACL 2023, pages 12731‚Äì12750.\nRem Yang, Julian Dai, Nikos Vasilakis, and Martin Ri-\nnard. 2025. Evaluating the generalization capabilities\nof large language models on code reasoning. arXiv\npreprint arXiv:2504.05518.\nQinyuan Ye. 2024. Cross-task generalization abilities of\nlarge language models. In Proceedings of the 2024\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies (Volume 4: Student Research\nWorkshop), pages 255‚Äì262, Mexico City, Mexico.\nAssociation for Computational Linguistics.\nLifan Yuan, Yangyi Chen, Ganqu Cui, Hongcheng Gao,\nFangyuan Zou, Xingyi Cheng, Heng Ji, Zhiyuan\nLiu, and Maosong Sun. 2023.\nRevisiting out-of-\ndistribution robustness in NLP: Benchmark, analysis,\nand llms evaluations. In Proceedings of the 37th\nInternational Conference on Neural Information Pro-\ncessing Systems, NIPS ‚Äô23, Red Hook, NY, USA.\nCurran Associates Inc.\nJingyang Zhang, Jingwei Sun, Eric Yeats, Yang Ouyang,\nMartin Kuo, Jianyi Zhang, Hao Frank Yang, and Hai\nLi. 2025. Min-K%++: Improved baseline for pre-\ntraining data detection from large language models.\nIn The Thirteenth International Conference on Learn-\ning Representations.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mi-\nhaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel\nSimig, Punit Singh Koura, Anjali Sridhar, Tianlu\nWang, and Luke Zettlemoyer. 2022.\nOPT: Open\npre-trained transformer language models. Preprint,\narXiv:2205.01068.\nYuan Zhang, Jason Baldridge, and Luheng He. 2019.\nPAWS: Paraphrase adversaries from word scrambling.\nIn Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long and Short Papers), pages 1298‚Äì1308.\nYangqiaoyu Zhou and Chenhao Tan. 2021. Investigat-\ning the effect of natural language explanations on\nout-of-distribution generalization in few-shot NLI.\nIn Proceedings of the Second Workshop on Insights\nfrom Negative Results in NLP, pages 117‚Äì124, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\n7\n\nA\nPattern-based finetuning details\nPattern-based finetuning requires us to specify\nan input pattern and define a mapping between\nthe answer tokens and the actual labels (Schick\net al., 2020). Our experiments with NLI use the\nfollowing pattern:\n{premise} Question: {hypothesis}\nYes or No?\nThe target tokens we consider are, respectively,\n‚Äò_Yes‚Äô for entailment and ‚Äò_No‚Äô otherwise.5\nB\nNLI Datasets\nWe use 2 main large-scale datasets for finetuning\nthe models: SNLI (Bowman et al., 2015), which\ncontains 570K crowdsourced sentence-pairs based\non image captions; and MNLI (Williams et al.,\n2018), which is a set of 433K sentence-pairs meant\nto cover a large range of genres of spoken and writ-\nten text. Compared to SNLI, MNLI offers more lin-\nguistic diversity and difficulty as it includes repre-\nsentative samples from 10 distinct genres of written\nand spoken English.We assessed the generalisation\ncapacity of fine-tuned models using 6 NLI testsets.\nThese comprise 3 adversarial datasets‚Äîdesigned\nespecially to evaluate the models‚Äô robustness to\nheuristics‚Äîas well as 3 more standard NLI datasets\nwith various but comparable input distributions:\n‚Ä¢ Standard: SciTail (Khot et al., 2018) is based\non science multiple-choice exams, WNLI fo-\ncuses on identifying the referent of a certain\npronoun and RTE is a general entailment\ndataset. These last two are a part of the GLUE\nBenchmark (Wang et al., 2018).\n‚Ä¢ Adversarial: PAWS (Zhang et al., 2019) uses\nparaphrase adversaries, HANS (McCoy et al.,\n2019) tackles failure cases of 3 simple heuris-\ntics and ANLI (Nie et al., 2020) finds adver-\nsaries via human feedback.\nTo avoid inconsistencies that can result from\ndifferent annotation policies among datasets, we\nremoved the neutral-labeled samples, enabling us\nto more effectively separate the impacts of domain\nshifts on model performance, and guaranteeing a\nmore consistent assessment framework.\n5The underscores indicate a whitespace in the token. This\nis important to guarantee that the correct token-string repre-\nsenting this character-string is considered (Pimentel and Meis-\nter, 2024; Phan et al., 2024), which may impact prompting\nperformance (Sanz-Guerrero et al., 2025).\nC\nResource Usage\nWe ran our experiments on various machines, de-\npending on memory requirements. Small models\nwere trained on 4x A5000 GPUs (with 24GB each),\nlarger models were trained using 8x A6000 (with\n48GB each) or 4x A100 (with 80GB). The total\nruntime for all the experiments presented here is of\n5,500 GPU hours.\n8\n\nD\nDetailed Results\nD.1\nAverage Performance for other Few-shot Settings\nMNLI\nModel\nSize\nMNLI‚Ä°\nSNLI\nWNLI\nSciTail\nRTE\nHANS\nANLI\nPAWS\nOPT\n2.7b\n67.2 ¬± 2.9\n59.4 ¬± 7.7\n50.9 ¬± 0.3\n59.6 ¬± 6.0\n54.5 ¬± 2.1\n51.7 ¬± 1.5\n50.0 ¬± 0.9\n48.3 ¬± 3.7\n6.7b\n74.4 ¬± 6.6\n66.7 ¬± 15.0\n50.3 ¬± 1.2\n63.8 ¬± 4.0\n57.5 ¬± 4.7\n54.5 ¬± 3.5\n50.6 ¬± 0.6\n50.6 ¬± 4.7\n13b\n79.7 ¬± 8.8\n75.6 ¬± 22.6\n51.0 ¬± 1.7\n73.9 ¬± 3.1\n63.5 ¬± 4.2\n55.0 ¬± 2.5\n50.1 ¬± 2.2\n50.7 ¬± 3.1\n30b\n82.9 ¬± 8.7\n75.0 ¬± 23.0\n51.8 ¬± 2.1\n63.1 ¬± 7.5\n62.0 ¬± 2.4\n57.5 ¬± 1.7\n52.9 ¬± 1.7\n48.7 ¬± 2.8\nOLMo2\n7B\n59.9 ¬± 3.2\n54.0 ¬± 3.8\n50.5 ¬± 0.1\n52.1 ¬± 4.8\n51.9 ¬± 1.5\n51.0 ¬± 1.7\n51.0 ¬± 1.7\n54.2 ¬± 1.5\n13B\n56.3 ¬± 4.5\n52.4 ¬± 2.4\n50.3 ¬± 0.6\n57.0 ¬± 2.1\n51.8 ¬± 1.0\n51.6 ¬± 1.3\n50.7 ¬± 2.1\n51.4 ¬± 2.7\n32B\n82.5 ¬± 12.5\n76.6 ¬± 21.4\n64.9 ¬± 11.1\n55.5 ¬± 5.1\n64.8 ¬± 9.4\n60.4 ¬± 5.8\n64.1 ¬± 9.2\n64.2 ¬± 5.3\nChance performance\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\nTable 3: Accuracy on each OOD dataset for models trained on MNLI with 64 examples. Measurements are taken\nusing the checkpoint with the highest in-domain performance. ‚Ä° in-domain dataset.\nSNLI\nModel\nSize\nSNLI‚Ä°\nMNLI\nWNLI\nSciTail\nRTE\nHANS\nANLI\nPAWS\nOPT\n2.7b\n87.5 ¬± 6.2\n71.8 ¬± 5.8\n51.7 ¬± 0.5\n69.9 ¬± 4.5\n59.0 ¬± 5.7\n52.5 ¬± 1.0\n50.4 ¬± 1.7\n51.5 ¬± 4.2\n6.7b\n88.3 ¬± 4.7\n72.7 ¬± 9.0\n52.7 ¬± 1.9\n62.1 ¬± 16.5\n61.4 ¬± 2.8\n54.3 ¬± 2.8\n51.3 ¬± 2.4\n49.4 ¬± 2.9\n13b\n93.5 ¬± 0.9\n80.8 ¬± 4.7\n50.6 ¬± 1.0\n72.4 ¬± 5.1\n66.1 ¬± 0.3\n54.4 ¬± 3.9\n49.9 ¬± 0.9\n52.1 ¬± 5.1\n30b\n94.5 ¬± 1.3\n78.8 ¬± 4.2\n54.1 ¬± 1.7\n76.3 ¬± 1.8\n67.2 ¬± 6.4\n64.7 ¬± 4.0\n51.6 ¬± 2.2\n53.0 ¬± 4.9\nOLMo2\n7B\n70.3 ¬± 12.5\n56.3 ¬± 5.1\n52.8 ¬± 0.9\n52.3 ¬± 5.6\n53.5 ¬± 1.6\n52.4 ¬± 2.1\n51.8 ¬± 0.7\n56.7 ¬± 2.9\n13B\n59.7 ¬± 5.2\n54.5 ¬± 5.0\n52.8 ¬± 1.0\n54.7 ¬± 4.1\n52.2 ¬± 0.3\n53.6 ¬± 1.0\n50.9 ¬± 0.4\n52.4 ¬± 1.7\n32B\n92.7 ¬± 4.0\n72.1 ¬± 8.7\n61.8 ¬± 7.2\n61.0 ¬± 4.4\n61.1 ¬± 3.6\n60.7 ¬± 1.7\n57.7 ¬± 4.4\n61.7 ¬± 3.6\nChance performance\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\nTable 4: Accuracy on each OOD dataset for models trained on SNLI with 64 examples. Measurements are taken\nusing the checkpoint with the highest in-domain performance. ‚Ä° in-domain dataset.\nMNLI\nModel\nSize\nMNLI‚Ä°\nSNLI\nWNLI\nSciTail\nRTE\nHANS\nANLI\nPAWS\nOPT\n2.7b\n58.8 ¬± 4.6\n52.8 ¬± 4.4\n51.4 ¬± 0.6\n59.1 ¬± 4.2\n52.0 ¬± 2.8\n51.4 ¬± 0.3\n50.3 ¬± 2.3\n49.7 ¬± 4.3\n6.7b\n65.1 ¬± 6.9\n58.0 ¬± 9.3\n50.4 ¬± 1.4\n59.3 ¬± 1.1\n52.7 ¬± 3.4\n52.1 ¬± 1.2\n51.0 ¬± 2.0\n51.4 ¬± 5.1\n13b\n68.1 ¬± 10.0\n59.6 ¬± 15.8\n49.9 ¬± 0.3\n64.1 ¬± 6.4\n55.4 ¬± 8.0\n53.4 ¬± 0.9\n50.0 ¬± 1.9\n52.1 ¬± 6.0\n30b\n68.2 ¬± 6.3\n60.5 ¬± 15.3\n51.2 ¬± 0.5\n57.5 ¬± 4.2\n54.5 ¬± 4.6\n52.3 ¬± 3.8\n52.4 ¬± 3.2\n52.9 ¬± 4.2\nOLMo2\n7B\n57.9 ¬± 4.7\n50.8 ¬± 1.6\n50.7 ¬± 0.6\n52.6 ¬± 3.9\n51.0 ¬± 0.8\n51.2 ¬± 0.6\n50.9 ¬± 0.8\n53.3 ¬± 0.4\n13B\n54.0 ¬± 5.5\n50.3 ¬± 0.5\n51.4 ¬± 0.4\n56.1 ¬± 0.7\n52.0 ¬± 0.9\n52.2 ¬± 0.5\n48.6 ¬± 1.4\n50.5 ¬± 1.7\n32B\n70.6 ¬± 7.5\n60.3 ¬± 8.4\n55.6 ¬± 4.2\n56.0 ¬± 1.9\n58.4 ¬± 6.0\n55.0 ¬± 3.1\n57.5 ¬± 5.1\n58.8 ¬± 3.8\nChance performance\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\nTable 5: Accuracy on each OOD dataset for models trained on MNLI with 32 examples. Measurements are taken\nusing the checkpoint with the highest in-domain performance. ‚Ä° in-domain dataset.\n9\n\nSNLI\nModel\nSize\nSNLI‚Ä°\nMNLI\nWNLI\nSciTail\nRTE\nHANS\nANLI\nPAWS\nOPT\n2.7b\n65.2 ¬± 5.1\n58.3 ¬± 5.9\n51.2 ¬± 0.3\n61.2 ¬± 6.3\n52.1 ¬± 2.0\n52.0 ¬± 1.6\n51.3 ¬± 1.3\n51.9 ¬± 3.2\n6.7b\n69.7 ¬± 3.8\n59.3 ¬± 6.3\n51.4 ¬± 0.9\n64.4 ¬± 6.7\n54.0 ¬± 2.7\n53.3 ¬± 1.4\n50.3 ¬± 0.7\n51.5 ¬± 4.3\n13b\n82.9 ¬± 9.3\n71.9 ¬± 2.7\n51.6 ¬± 0.6\n66.4 ¬± 1.7\n62.7 ¬± 2.8\n57.1 ¬± 4.0\n50.2 ¬± 1.6\n53.1 ¬± 3.2\n30b\n75.8 ¬± 8.2\n62.5 ¬± 8.5\n51.4 ¬± 1.2\n60.9 ¬± 10.9\n54.5 ¬± 7.5\n53.4 ¬± 5.5\n50.8 ¬± 1.3\n50.9 ¬± 4.9\nOLMo2\n7B\n56.7 ¬± 3.4\n53.6 ¬± 0.2\n51.0 ¬± 0.6\n49.3 ¬± 5.7\n52.1 ¬± 0.3\n49.9 ¬± 0.6\n51.0 ¬± 0.9\n53.1 ¬± 1.5\n13B\n52.6 ¬± 1.4\n52.7 ¬± 5.5\n51.3 ¬± 0.3\n56.8 ¬± 1.1\n51.3 ¬± 0.4\n52.5 ¬± 1.2\n50.6 ¬± 0.4\n52.3 ¬± 0.4\n32B\n67.7 ¬± 8.8\n59.0 ¬± 5.5\n54.2 ¬± 3.8\n61.5 ¬± 1.8\n53.9 ¬± 1.5\n52.6 ¬± 2.7\n52.9 ¬± 1.2\n57.0 ¬± 1.7\nChance performance\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\n50.0\nTable 6: Accuracy on each OOD dataset for models trained on SNLI with 32 examples. Measurements are taken\nusing the checkpoint with the highest in-domain performance. ‚Ä° in-domain dataset.\nD.2\nPerformance across Finetuning Runs\n0\n200\n400\n600\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOPT\n2.7b\n6.7b/7B\n13b/13B\n30b/32B\n0\n200\n400\n600\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOLMo2\n0\n200\n400\n600\nTraining Steps\n0\n200\n400\n600\nTraining Steps\nSNLI\nMNLI\nANLI\nRTE\nHANS\nWNLI\nPAWS\nSCITAIL\n(a) 128-shot on MNLI\n0\n200\n400\n600\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOPT\n2.7b\n6.7b/7B\n13b/13B\n30b/32B\n0\n200\n400\n600\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOLMo2\n0\n200\n400\n600\nTraining Steps\n0\n200\n400\n600\nTraining Steps\nSNLI\nMNLI\nANLI\nRTE\nHANS\nWNLI\nPAWS\nSCITAIL\n(b) 128-shot on SNLI\n0\n100\n200\n300\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOPT\n2.7b\n6.7b/7B\n13b/13B\n30b/32B\n0\n100\n200\n300\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOLMo2\n0\n100\n200\n300\nTraining Steps\n0\n100\n200\n300\nTraining Steps\nSNLI\nMNLI\nANLI\nRTE\nHANS\nWNLI\nPAWS\nSCITAIL\n(c) 64-shot on MNLI\n0\n100\n200\n300\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOPT\n2.7b\n6.7b/7B\n13b/13B\n30b/32B\n0\n100\n200\n300\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOLMo2\n0\n100\n200\n300\nTraining Steps\n0\n100\n200\n300\nTraining Steps\nSNLI\nMNLI\nANLI\nRTE\nHANS\nWNLI\nPAWS\nSCITAIL\n(d) 64-shot on SNLI\n0\n50\n100\n150\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOPT\n2.7b\n6.7b/7B\n13b/13B\n30b/32B\n0\n50\n100\n150\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOLMo2\n0\n50\n100\n150\nTraining Steps\n0\n50\n100\n150\nTraining Steps\nSNLI\nMNLI\nANLI\nRTE\nHANS\nWNLI\nPAWS\nSCITAIL\n(e) 32-shot on MNLI\n0\n50\n100\n150\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOPT\n2.7b\n6.7b/7B\n13b/13B\n30b/32B\n0\n50\n100\n150\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOLMo2\n0\n50\n100\n150\nTraining Steps\n0\n50\n100\n150\nTraining Steps\nSNLI\nMNLI\nANLI\nRTE\nHANS\nWNLI\nPAWS\nSCITAIL\n(f) 32-shot on SNLI\nFigure 5: Few-shots results throughout a finetuning run on either MNLI or SNLI. OPT OOD performances (first\nrows) frequently oscillate during training; OLMo2 OOD performances (second rows) are relatively stable across\ntraining. Legend: MNLI, SNLI, WNLI, RTE, SciTail, ANLI, HANS and PAWS\n10\n\nD.3\nOPT‚Äôs Partial OOD Correlation Graphs\n1a\n2\n3\n4\n5\n6\n7\n1a\n2\n3\n4\n5\n6\n7\n1a\n2\n3\n4\n5\n6\n7\n1a\n2\n3\n4\n5\n6\n7\nSNLI\n1b\n2\n3\n4\n5\n6\n7\nOPT 2.7b\n1b\n2\n3\n4\n5\n6\n7\nOPT 6.7b\n1b\n2\n3\n4\n5\n6\n7\nOPT 13b\n1b\n2\n3\n4\n5\n6\n7\nOPT 30b\nMNLI\nPositive Correlation\nNegative Correlation\nFigure 6: OPT partial OOD correlation graphs on SNLI (top) and MNLI (bottom). Edge thickness increases with\nabsolute correlation value. Legend: 1a.MNLI, 1b.SNLI, 2.WNLI, 4.RTE, 3.SciTail, 6.ANLI, 5.HANS, and 7.PAWS\nD.4\nFit of Regressors Used when Computing Partial Correlations\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\nOOD performance\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\nOOD performance\nSNLI\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nWNLI\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nSciTail\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nRTE\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nHANS\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nANLI\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nPAWS\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\nOOD performance\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\n0.5\n0.6\n0.7\n0.8\nOOD performance\nMNLI\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nWNLI\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nSciTail\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nRTE\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nHANS\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nANLI\n0.5\n0.6\n0.7\n0.8\n0.9\nIn-domain accuracy\nPAWS\nFigure 7: Regressors trained to predict OOD performance for 128-shots models. Models were finetuned on MNLI\n(top) and SNLI (bottom). Results for OLMo2 32B on first and third rows, OPT 30B on second and fourth rows.\nLegend: Linear, Ridge and GAM.\n11\n\nD.5\nHeatmaps with Partial OOD Correlations using Linear Regressors\n‚àí1.00\n‚àí0.75\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.34\n0.14\n‚àí0.78 ‚àí0.50 ‚àí0.46 ‚àí0.49\n0.34\n1.00\n‚àí0.07 ‚àí0.31 ‚àí0.14 ‚àí0.46 ‚àí0.52\n0.14\n‚àí0.07\n1.00\n0.36\n0.13\n‚àí0.33\n0.47\n‚àí0.78 ‚àí0.31\n0.36\n1.00\n0.52\n0.13\n0.63\n‚àí0.50 ‚àí0.14\n0.13\n0.52\n1.00\n0.24\n0.41\n‚àí0.46 ‚àí0.46 ‚àí0.33\n0.13\n0.24\n1.00\n0.59\n‚àí0.49 ‚àí0.52\n0.47\n0.63\n0.41\n0.59\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.40 ‚àí0.14 ‚àí0.58 ‚àí0.66 ‚àí0.65 ‚àí0.05\n‚àí0.40\n1.00\n‚àí0.19 ‚àí0.01 ‚àí0.05\n0.38\n‚àí0.60\n‚àí0.14 ‚àí0.19\n1.00\n0.81\n0.58\n‚àí0.27\n0.56\n‚àí0.58 ‚àí0.01\n0.81\n1.00\n0.85\n0.03\n0.53\n‚àí0.66 ‚àí0.05\n0.58\n0.85\n1.00\n0.29\n0.60\n‚àí0.65\n0.38\n‚àí0.27\n0.03\n0.29\n1.00\n0.03\n‚àí0.05 ‚àí0.60\n0.56\n0.53\n0.60\n0.03\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.33\n‚àí0.64 ‚àí0.78 ‚àí0.77 ‚àí0.69 ‚àí0.54\n0.33\n1.00\n‚àí0.22 ‚àí0.06 ‚àí0.09 ‚àí0.71 ‚àí0.58\n‚àí0.64 ‚àí0.22\n1.00\n0.90\n0.80\n0.45\n0.79\n‚àí0.78 ‚àí0.06\n0.90\n1.00\n0.89\n0.49\n0.65\n‚àí0.77 ‚àí0.09\n0.80\n0.89\n1.00\n0.45\n0.61\n‚àí0.69 ‚àí0.71\n0.45\n0.49\n0.45\n1.00\n0.73\n‚àí0.54 ‚àí0.58\n0.79\n0.65\n0.61\n0.73\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.63\n‚àí0.58 ‚àí0.74 ‚àí0.87 ‚àí0.62 ‚àí0.64\n0.63\n1.00\n‚àí0.64 ‚àí0.50 ‚àí0.53 ‚àí0.73 ‚àí0.74\n‚àí0.58 ‚àí0.64\n1.00\n0.77\n0.66\n0.45\n0.80\n‚àí0.74 ‚àí0.50\n0.77\n1.00\n0.88\n0.33\n0.68\n‚àí0.87 ‚àí0.53\n0.66\n0.88\n1.00\n0.57\n0.67\n‚àí0.62 ‚àí0.73\n0.45\n0.33\n0.57\n1.00\n0.57\n‚àí0.64 ‚àí0.74\n0.80\n0.68\n0.67\n0.57\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî SNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.95\n‚àí0.84\n0.85\n0.78\n0.40\n‚àí0.85\n0.95\n1.00\n‚àí0.67\n0.69\n0.87\n0.60\n‚àí0.68\n‚àí0.84 ‚àí0.67\n1.00\n‚àí0.88 ‚àí0.41\n0.00\n0.90\n0.85\n0.69\n‚àí0.88\n1.00\n0.41\n‚àí0.09 ‚àí0.97\n0.78\n0.87\n‚àí0.41\n0.41\n1.00\n0.80\n‚àí0.38\n0.40\n0.60\n0.00\n‚àí0.09\n0.80\n1.00\n0.14\n‚àí0.85 ‚àí0.68\n0.90\n‚àí0.97 ‚àí0.38\n0.14\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.49\n0.70\n0.04\n0.52\n0.19\n‚àí0.60\n‚àí0.49\n1.00\n‚àí0.14 ‚àí0.10 ‚àí0.06\n0.16\n0.45\n0.70\n‚àí0.14\n1.00\n‚àí0.58\n0.73\n0.74\n0.07\n0.04\n‚àí0.10 ‚àí0.58\n1.00\n‚àí0.59 ‚àí0.89 ‚àí0.78\n0.52\n‚àí0.06\n0.73\n‚àí0.59\n1.00\n0.76\n0.19\n0.19\n0.16\n0.74\n‚àí0.89\n0.76\n1.00\n0.65\n‚àí0.60\n0.45\n0.07\n‚àí0.78\n0.19\n0.65\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.03\n‚àí0.58\n0.79\n0.97\n‚àí0.69 ‚àí0.94\n0.03\n1.00\n0.47\n0.08\n0.03\n0.32\n0.08\n‚àí0.58\n0.47\n1.00\n‚àí0.27 ‚àí0.47\n0.95\n0.75\n0.79\n0.08\n‚àí0.27\n1.00\n0.85\n‚àí0.31 ‚àí0.62\n0.97\n0.03\n‚àí0.47\n0.85\n1.00\n‚àí0.56 ‚àí0.86\n‚àí0.69\n0.32\n0.95\n‚àí0.31 ‚àí0.56\n1.00\n0.87\n‚àí0.94\n0.08\n0.75\n‚àí0.62 ‚àí0.86\n0.87\n1.00\nOLMo2 32B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.15\n0.51\n‚àí0.07\n0.01\n0.32\n0.05\n0.15\n1.00\n‚àí0.03\n0.19\n0.00\n0.40\n‚àí0.56\n0.51\n‚àí0.03\n1.00\n‚àí0.24 ‚àí0.18\n0.02\n0.30\n‚àí0.07\n0.19\n‚àí0.24\n1.00\n0.29\n0.47\n0.21\n0.01\n0.00\n‚àí0.18\n0.29\n1.00\n0.48\n0.19\n0.32\n0.40\n0.02\n0.47\n0.48\n1.00\n‚àí0.11\n0.05\n‚àí0.56\n0.30\n0.21\n0.19\n‚àí0.11\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.66\n0.09\n0.58\n0.29\n0.62\n‚àí0.33\n0.66\n1.00\n0.22\n0.73\n0.25\n0.46\n‚àí0.75\n0.09\n0.22\n1.00\n0.05\n0.05\n‚àí0.28 ‚àí0.08\n0.58\n0.73\n0.05\n1.00\n0.39\n0.67\n‚àí0.76\n0.29\n0.25\n0.05\n0.39\n1.00\n0.39\n‚àí0.16\n0.62\n0.46\n‚àí0.28\n0.67\n0.39\n1.00\n‚àí0.30\n‚àí0.33 ‚àí0.75 ‚àí0.08 ‚àí0.76 ‚àí0.16 ‚àí0.30\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.17\n0.36\n‚àí0.40 ‚àí0.24\n0.33\n0.47\n0.17\n1.00\n‚àí0.23 ‚àí0.41 ‚àí0.23 ‚àí0.25\n0.45\n0.36\n‚àí0.23\n1.00\n0.51\n0.20\n0.61\n0.32\n‚àí0.40 ‚àí0.41\n0.51\n1.00\n0.41\n0.47\n‚àí0.31\n‚àí0.24 ‚àí0.23\n0.20\n0.41\n1.00\n0.54\n‚àí0.13\n0.33\n‚àí0.25\n0.61\n0.47\n0.54\n1.00\n0.06\n0.47\n0.45\n0.32\n‚àí0.31 ‚àí0.13\n0.06\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.76\n0.19\n‚àí0.25 ‚àí0.59 ‚àí0.29 ‚àí0.16\n0.76\n1.00\n‚àí0.12 ‚àí0.45 ‚àí0.76 ‚àí0.52 ‚àí0.44\n0.19\n‚àí0.12\n1.00\n0.49\n0.18\n0.27\n0.56\n‚àí0.25 ‚àí0.45\n0.49\n1.00\n0.76\n0.91\n0.01\n‚àí0.59 ‚àí0.76\n0.18\n0.76\n1.00\n0.85\n0.21\n‚àí0.29 ‚àí0.52\n0.27\n0.91\n0.85\n1.00\n‚àí0.03\n‚àí0.16 ‚àí0.44\n0.56\n0.01\n0.21\n‚àí0.03\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî MNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.96\n0.97\n0.89\n0.82\n0.92\n‚àí0.59\n0.96\n1.00\n0.90\n0.88\n0.76\n0.86\n‚àí0.72\n0.97\n0.90\n1.00\n0.91\n0.88\n0.94\n‚àí0.43\n0.89\n0.88\n0.91\n1.00\n0.88\n0.87\n‚àí0.50\n0.82\n0.76\n0.88\n0.88\n1.00\n0.86\n‚àí0.19\n0.92\n0.86\n0.94\n0.87\n0.86\n1.00\n‚àí0.38\n‚àí0.59 ‚àí0.72 ‚àí0.43 ‚àí0.50 ‚àí0.19 ‚àí0.38\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.76\n‚àí0.47 ‚àí0.80 ‚àí0.34\n0.07\n‚àí0.03\n0.76\n1.00\n‚àí0.43 ‚àí0.89 ‚àí0.38 ‚àí0.05 ‚àí0.14\n‚àí0.47 ‚àí0.43\n1.00\n0.54\n0.35\n‚àí0.40 ‚àí0.40\n‚àí0.80 ‚àí0.89\n0.54\n1.00\n0.38\n‚àí0.29 ‚àí0.20\n‚àí0.34 ‚àí0.38\n0.35\n0.38\n1.00\n‚àí0.06 ‚àí0.09\n0.07\n‚àí0.05 ‚àí0.40 ‚àí0.29 ‚àí0.06\n1.00\n0.97\n‚àí0.03 ‚àí0.14 ‚àí0.40 ‚àí0.20 ‚àí0.09\n0.97\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.86\n0.54\n‚àí0.18\n0.45\n0.29\n‚àí0.67\n0.86\n1.00\n0.62\n‚àí0.18\n0.47\n0.28\n‚àí0.80\n0.54\n0.62\n1.00\n0.61\n0.95\n0.89\n‚àí0.35\n‚àí0.18 ‚àí0.18\n0.61\n1.00\n0.69\n0.80\n0.26\n0.45\n0.47\n0.95\n0.69\n1.00\n0.94\n‚àí0.19\n0.29\n0.28\n0.89\n0.80\n0.94\n1.00\n0.02\n‚àí0.67 ‚àí0.80 ‚àí0.35\n0.26\n‚àí0.19\n0.02\n1.00\nOLMo2 32B\nMNLI\nSNLI\nFigure 8: Partial correlations taken with linear regressors of OPT (first and third rows) and OLMo2 (second and forth\nrows) across model sizes (ordered from left to right) trained on MNLI (top) and SNLI (bottom). Models were\nfine-tuned with 128-shots.\n12\n\n‚àí1.00\n‚àí0.75\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.55\n0.85\n0.27\n‚àí0.16 ‚àí0.16 ‚àí0.56\n0.55\n1.00\n0.34\n0.10\n‚àí0.24\n0.06\n‚àí0.41\n0.85\n0.34\n1.00\n0.37\n‚àí0.14 ‚àí0.23 ‚àí0.43\n0.27\n0.10\n0.37\n1.00\n0.19\n0.56\n0.51\n‚àí0.16 ‚àí0.24 ‚àí0.14\n0.19\n1.00\n0.23\n0.32\n‚àí0.16\n0.06\n‚àí0.23\n0.56\n0.23\n1.00\n0.69\n‚àí0.56 ‚àí0.41 ‚àí0.43\n0.51\n0.32\n0.69\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.52\n0.75\n‚àí0.17 ‚àí0.60 ‚àí0.64 ‚àí0.53\n0.52\n1.00\n0.58\n0.32\n‚àí0.22 ‚àí0.11 ‚àí0.01\n0.75\n0.58\n1.00\n0.29\n‚àí0.48 ‚àí0.16 ‚àí0.01\n‚àí0.17\n0.32\n0.29\n1.00\n0.15\n0.49\n0.62\n‚àí0.60 ‚àí0.22 ‚àí0.48\n0.15\n1.00\n0.37\n0.30\n‚àí0.64 ‚àí0.11 ‚àí0.16\n0.49\n0.37\n1.00\n0.86\n‚àí0.53 ‚àí0.01 ‚àí0.01\n0.62\n0.30\n0.86\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.85\n0.32\n‚àí0.24 ‚àí0.54 ‚àí0.20 ‚àí0.71\n0.85\n1.00\n0.38\n0.03\n‚àí0.21 ‚àí0.04 ‚àí0.69\n0.32\n0.38\n1.00\n0.60\n0.24\n‚àí0.21\n0.31\n‚àí0.24\n0.03\n0.60\n1.00\n0.58\n‚àí0.01\n0.47\n‚àí0.54 ‚àí0.21\n0.24\n0.58\n1.00\n0.38\n0.52\n‚àí0.20 ‚àí0.04 ‚àí0.21 ‚àí0.01\n0.38\n1.00\n‚àí0.10\n‚àí0.71 ‚àí0.69\n0.31\n0.47\n0.52\n‚àí0.10\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.85\n0.10\n‚àí0.24 ‚àí0.64 ‚àí0.27 ‚àí0.79\n0.85\n1.00\n0.36\n0.11\n‚àí0.33 ‚àí0.16 ‚àí0.64\n0.10\n0.36\n1.00\n0.73\n0.37\n‚àí0.08\n0.21\n‚àí0.24\n0.11\n0.73\n1.00\n0.66\n0.25\n0.40\n‚àí0.64 ‚àí0.33\n0.37\n0.66\n1.00\n0.35\n0.70\n‚àí0.27 ‚àí0.16 ‚àí0.08\n0.25\n0.35\n1.00\n0.43\n‚àí0.79 ‚àí0.64\n0.21\n0.40\n0.70\n0.43\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî SNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.65\n0.82\n0.23\n0.06\n0.32\n‚àí0.55\n0.65\n1.00\n0.43\n0.56\n0.00\n‚àí0.20 ‚àí0.70\n0.82\n0.43\n1.00\n‚àí0.26\n0.04\n0.68\n‚àí0.11\n0.23\n0.56\n‚àí0.26\n1.00\n‚àí0.14 ‚àí0.81 ‚àí0.87\n0.06\n0.00\n0.04\n‚àí0.14\n1.00\n0.13\n0.01\n0.32\n‚àí0.20\n0.68\n‚àí0.81\n0.13\n1.00\n0.57\n‚àí0.55 ‚àí0.70 ‚àí0.11 ‚àí0.87\n0.01\n0.57\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.22\n0.61\n‚àí0.27 ‚àí0.31 ‚àí0.45\n0.19\n0.22\n1.00\n‚àí0.43\n0.71\n‚àí0.51\n0.02\n0.59\n0.61\n‚àí0.43\n1.00\n‚àí0.74\n0.03\n‚àí0.21 ‚àí0.16\n‚àí0.27\n0.71\n‚àí0.74\n1.00\n‚àí0.49 ‚àí0.10\n0.29\n‚àí0.31 ‚àí0.51\n0.03\n‚àí0.49\n1.00\n0.42\n‚àí0.18\n‚àí0.45\n0.02\n‚àí0.21 ‚àí0.10\n0.42\n1.00\n0.50\n0.19\n0.59\n‚àí0.16\n0.29\n‚àí0.18\n0.50\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.90\n0.87\n0.54\n0.89\n0.71\n‚àí0.54\n0.90\n1.00\n0.94\n0.35\n0.87\n0.75\n‚àí0.26\n0.87\n0.94\n1.00\n0.29\n0.85\n0.76\n‚àí0.20\n0.54\n0.35\n0.29\n1.00\n0.54\n0.64\n‚àí0.26\n0.89\n0.87\n0.85\n0.54\n1.00\n0.83\n‚àí0.19\n0.71\n0.75\n0.76\n0.64\n0.83\n1.00\n0.01\n‚àí0.54 ‚àí0.26 ‚àí0.20 ‚àí0.26 ‚àí0.19\n0.01\n1.00\nOLMo2 32B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.38\n‚àí0.23\n0.06\n0.29\n0.46\n‚àí0.08\n0.38\n1.00\n0.22\n0.32\n‚àí0.03 ‚àí0.22 ‚àí0.43\n‚àí0.23\n0.22\n1.00\n0.23\n‚àí0.23 ‚àí0.83 ‚àí0.09\n0.06\n0.32\n0.23\n1.00\n‚àí0.12 ‚àí0.09 ‚àí0.24\n0.29\n‚àí0.03 ‚àí0.23 ‚àí0.12\n1.00\n0.19\n0.01\n0.46\n‚àí0.22 ‚àí0.83 ‚àí0.09\n0.19\n1.00\n0.39\n‚àí0.08 ‚àí0.43 ‚àí0.09 ‚àí0.24\n0.01\n0.39\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.59\n‚àí0.64\n0.61\n‚àí0.24\n0.29\n‚àí0.62\n0.59\n1.00\n‚àí0.56\n0.55\n‚àí0.65 ‚àí0.21 ‚àí0.27\n‚àí0.64 ‚àí0.56\n1.00\n‚àí0.39\n0.45\n0.03\n0.64\n0.61\n0.55\n‚àí0.39\n1.00\n‚àí0.08\n0.26\n‚àí0.55\n‚àí0.24 ‚àí0.65\n0.45\n‚àí0.08\n1.00\n0.64\n0.13\n0.29\n‚àí0.21\n0.03\n0.26\n0.64\n1.00\n‚àí0.26\n‚àí0.62 ‚àí0.27\n0.64\n‚àí0.55\n0.13\n‚àí0.26\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.34\n0.38\n‚àí0.01 ‚àí0.10 ‚àí0.19\n0.37\n0.34\n1.00\n‚àí0.05\n0.03\n‚àí0.31 ‚àí0.23\n0.47\n0.38\n‚àí0.05\n1.00\n0.16\n‚àí0.16\n0.20\n‚àí0.01\n‚àí0.01\n0.03\n0.16\n1.00\n0.22\n0.72\n0.11\n‚àí0.10 ‚àí0.31 ‚àí0.16\n0.22\n1.00\n0.40\n‚àí0.29\n‚àí0.19 ‚àí0.23\n0.20\n0.72\n0.40\n1.00\n0.07\n0.37\n0.47\n‚àí0.01\n0.11\n‚àí0.29\n0.07\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.49\n0.50\n‚àí0.11 ‚àí0.36 ‚àí0.57\n0.18\n0.49\n1.00\n0.37\n0.19\n‚àí0.12\n0.01\n‚àí0.46\n0.50\n0.37\n1.00\n0.24\n‚àí0.51 ‚àí0.38\n0.17\n‚àí0.11\n0.19\n0.24\n1.00\n0.44\n0.57\n‚àí0.18\n‚àí0.36 ‚àí0.12 ‚àí0.51\n0.44\n1.00\n0.61\n‚àí0.12\n‚àí0.57\n0.01\n‚àí0.38\n0.57\n0.61\n1.00\n‚àí0.31\n0.18\n‚àí0.46\n0.17\n‚àí0.18 ‚àí0.12 ‚àí0.31\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî MNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.57\n0.32\n0.84\n‚àí0.51 ‚àí0.61 ‚àí0.66\n0.57\n1.00\n‚àí0.03\n0.49\n‚àí0.52 ‚àí0.62 ‚àí0.55\n0.32\n‚àí0.03\n1.00\n0.43\n0.10\n‚àí0.30 ‚àí0.58\n0.84\n0.49\n0.43\n1.00\n‚àí0.26 ‚àí0.53 ‚àí0.71\n‚àí0.51 ‚àí0.52\n0.10\n‚àí0.26\n1.00\n0.64\n0.48\n‚àí0.61 ‚àí0.62 ‚àí0.30 ‚àí0.53\n0.64\n1.00\n0.91\n‚àí0.66 ‚àí0.55 ‚àí0.58 ‚àí0.71\n0.48\n0.91\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.05\n‚àí0.34 ‚àí0.48\n0.67\n0.12\n‚àí0.41\n0.05\n1.00\n‚àí0.17\n0.27\n0.33\n‚àí0.28 ‚àí0.34\n‚àí0.34 ‚àí0.17\n1.00\n‚àí0.08 ‚àí0.32\n0.27\n0.45\n‚àí0.48\n0.27\n‚àí0.08\n1.00\n‚àí0.47 ‚àí0.82 ‚àí0.38\n0.67\n0.33\n‚àí0.32 ‚àí0.47\n1.00\n0.25\n‚àí0.21\n0.12\n‚àí0.28\n0.27\n‚àí0.82\n0.25\n1.00\n0.77\n‚àí0.41 ‚àí0.34\n0.45\n‚àí0.38 ‚àí0.21\n0.77\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.56\n0.46\n0.78\n0.87\n0.87\n‚àí0.55\n0.56\n1.00\n0.96\n0.58\n0.58\n0.68\n‚àí0.95\n0.46\n0.96\n1.00\n0.56\n0.49\n0.59\n‚àí0.90\n0.78\n0.58\n0.56\n1.00\n0.81\n0.86\n‚àí0.46\n0.87\n0.58\n0.49\n0.81\n1.00\n0.97\n‚àí0.58\n0.87\n0.68\n0.59\n0.86\n0.97\n1.00\n‚àí0.66\n‚àí0.55 ‚àí0.95 ‚àí0.90 ‚àí0.46 ‚àí0.58 ‚àí0.66\n1.00\nOLMo2 32B\nMNLI\nSNLI\nFigure 9: Partial correlations taken with linear regressors of OPT (first and third rows) and OLMo2 (second and forth\nrows) across model sizes (ordered from left to right) trained on MNLI (top) and SNLI (bottom). Models were\nfine-tuned with 64-shots.\n13\n\n‚àí1.00\n‚àí0.75\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.46\n0.82\n0.38\n0.02\n‚àí0.83 ‚àí0.68\n‚àí0.46\n1.00\n‚àí0.44 ‚àí0.31 ‚àí0.03\n0.39\n0.28\n0.82\n‚àí0.44\n1.00\n0.53\n0.02\n‚àí0.77 ‚àí0.68\n0.38\n‚àí0.31\n0.53\n1.00\n‚àí0.19 ‚àí0.60 ‚àí0.55\n0.02\n‚àí0.03\n0.02\n‚àí0.19\n1.00\n‚àí0.22 ‚àí0.42\n‚àí0.83\n0.39\n‚àí0.77 ‚àí0.60 ‚àí0.22\n1.00\n0.94\n‚àí0.68\n0.28\n‚àí0.68 ‚àí0.55 ‚àí0.42\n0.94\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.33\n0.95\n0.44\n‚àí0.45 ‚àí0.81 ‚àí0.44\n0.33\n1.00\n0.38\n0.23\n0.00\n0.04\n0.04\n0.95\n0.38\n1.00\n0.27\n‚àí0.49 ‚àí0.78 ‚àí0.38\n0.44\n0.23\n0.27\n1.00\n0.15\n‚àí0.32 ‚àí0.42\n‚àí0.45\n0.00\n‚àí0.49\n0.15\n1.00\n0.46\n0.04\n‚àí0.81\n0.04\n‚àí0.78 ‚àí0.32\n0.46\n1.00\n0.76\n‚àí0.44\n0.04\n‚àí0.38 ‚àí0.42\n0.04\n0.76\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.69\n0.95\n0.38\n‚àí0.58 ‚àí0.79\n0.86\n0.69\n1.00\n0.79\n0.51\n‚àí0.20 ‚àí0.78\n0.53\n0.95\n0.79\n1.00\n0.60\n‚àí0.45 ‚àí0.88\n0.81\n0.38\n0.51\n0.60\n1.00\n‚àí0.18 ‚àí0.72\n0.30\n‚àí0.58 ‚àí0.20 ‚àí0.45 ‚àí0.18\n1.00\n0.43\n‚àí0.41\n‚àí0.79 ‚àí0.78 ‚àí0.88 ‚àí0.72\n0.43\n1.00\n‚àí0.59\n0.86\n0.53\n0.81\n0.30\n‚àí0.41 ‚àí0.59\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.55\n0.92\n0.71\n‚àí0.18 ‚àí0.76 ‚àí0.85\n0.55\n1.00\n0.75\n0.13\n‚àí0.26 ‚àí0.01 ‚àí0.29\n0.92\n0.75\n1.00\n0.60\n‚àí0.26 ‚àí0.52 ‚àí0.70\n0.71\n0.13\n0.60\n1.00\n‚àí0.18 ‚àí0.76 ‚àí0.81\n‚àí0.18 ‚àí0.26 ‚àí0.26 ‚àí0.18\n1.00\n0.07\n0.21\n‚àí0.76 ‚àí0.01 ‚àí0.52 ‚àí0.76\n0.07\n1.00\n0.94\n‚àí0.85 ‚àí0.29 ‚àí0.70 ‚àí0.81\n0.21\n0.94\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî SNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.70\n0.81\n0.54\n0.55\n‚àí0.28 ‚àí0.94\n0.70\n1.00\n0.43\n0.35\n0.26\n‚àí0.02 ‚àí0.64\n0.81\n0.43\n1.00\n0.75\n0.61\n‚àí0.02 ‚àí0.65\n0.54\n0.35\n0.75\n1.00\n0.48\n0.21\n‚àí0.38\n0.55\n0.26\n0.61\n0.48\n1.00\n0.27\n‚àí0.53\n‚àí0.28 ‚àí0.02 ‚àí0.02\n0.21\n0.27\n1.00\n0.43\n‚àí0.94 ‚àí0.64 ‚àí0.65 ‚àí0.38 ‚àí0.53\n0.43\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.07\n0.28\n0.33\n‚àí0.61 ‚àí0.76 ‚àí0.04\n‚àí0.07\n1.00\n‚àí0.18 ‚àí0.19\n0.11\n0.12\n‚àí0.02\n0.28\n‚àí0.18\n1.00\n‚àí0.49\n0.12\n‚àí0.19\n0.74\n0.33\n‚àí0.19 ‚àí0.49\n1.00\n‚àí0.64 ‚àí0.51 ‚àí0.63\n‚àí0.61\n0.11\n0.12\n‚àí0.64\n1.00\n0.60\n0.37\n‚àí0.76\n0.12\n‚àí0.19 ‚àí0.51\n0.60\n1.00\n0.03\n‚àí0.04 ‚àí0.02\n0.74\n‚àí0.63\n0.37\n0.03\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.95\n0.96\n0.47\n0.84\n0.72\n‚àí0.50\n0.95\n1.00\n0.90\n0.38\n0.73\n0.63\n‚àí0.40\n0.96\n0.90\n1.00\n0.67\n0.90\n0.83\n‚àí0.38\n0.47\n0.38\n0.67\n1.00\n0.71\n0.84\n0.04\n0.84\n0.73\n0.90\n0.71\n1.00\n0.91\n‚àí0.20\n0.72\n0.63\n0.83\n0.84\n0.91\n1.00\n‚àí0.01\n‚àí0.50 ‚àí0.40 ‚àí0.38\n0.04\n‚àí0.20 ‚àí0.01\n1.00\nOLMo2 32B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.43 ‚àí0.58 ‚àí0.76 ‚àí0.39\n0.83\n0.05\n‚àí0.43\n1.00\n0.31\n0.45\n0.15\n‚àí0.53 ‚àí0.49\n‚àí0.58\n0.31\n1.00\n0.83\n0.08\n‚àí0.76 ‚àí0.34\n‚àí0.76\n0.45\n0.83\n1.00\n0.16\n‚àí0.86 ‚àí0.44\n‚àí0.39\n0.15\n0.08\n0.16\n1.00\n‚àí0.28\n0.06\n0.83\n‚àí0.53 ‚àí0.76 ‚àí0.86 ‚àí0.28\n1.00\n0.43\n0.05\n‚àí0.49 ‚àí0.34 ‚àí0.44\n0.06\n0.43\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.22 ‚àí0.80 ‚àí0.87\n0.22\n0.54\n‚àí0.44\n‚àí0.22\n1.00\n0.50\n0.47\n0.18\n0.09\n0.12\n‚àí0.80\n0.50\n1.00\n0.77\n‚àí0.03 ‚àí0.32\n0.36\n‚àí0.87\n0.47\n0.77\n1.00\n‚àí0.11 ‚àí0.39\n0.25\n0.22\n0.18\n‚àí0.03 ‚àí0.11\n1.00\n0.70\n0.33\n0.54\n0.09\n‚àí0.32 ‚àí0.39\n0.70\n1.00\n0.24\n‚àí0.44\n0.12\n0.36\n0.25\n0.33\n0.24\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.24\n0.65\n‚àí0.31\n0.14\n0.58\n0.50\n‚àí0.24\n1.00\n‚àí0.18\n0.33\n‚àí0.22 ‚àí0.41 ‚àí0.38\n0.65\n‚àí0.18\n1.00\n‚àí0.02\n0.06\n0.69\n0.57\n‚àí0.31\n0.33\n‚àí0.02\n1.00\n‚àí0.15 ‚àí0.30 ‚àí0.40\n0.14\n‚àí0.22\n0.06\n‚àí0.15\n1.00\n0.48\n0.17\n0.58\n‚àí0.41\n0.69\n‚àí0.30\n0.48\n1.00\n0.81\n0.50\n‚àí0.38\n0.57\n‚àí0.40\n0.17\n0.81\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.04\n0.20\n0.32\n0.09\n0.07\n0.32\n0.04\n1.00\n0.52\n0.44\n0.40\n‚àí0.46\n0.24\n0.20\n0.52\n1.00\n0.95\n0.56\n‚àí0.54\n0.79\n0.32\n0.44\n0.95\n1.00\n0.55\n‚àí0.63\n0.70\n0.09\n0.40\n0.56\n0.55\n1.00\n‚àí0.39\n0.51\n0.07\n‚àí0.46 ‚àí0.54 ‚àí0.63 ‚àí0.39\n1.00\n0.00\n0.32\n0.24\n0.79\n0.70\n0.51\n0.00\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî MNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.46\n0.30\n‚àí0.31 ‚àí0.09\n0.32\n‚àí0.05\n‚àí0.46\n1.00\n‚àí0.19\n0.77\n0.29\n‚àí0.17\n0.35\n0.30\n‚àí0.19\n1.00\n0.16\n0.09\n0.77\n0.53\n‚àí0.31\n0.77\n0.16\n1.00\n0.17\n0.32\n0.78\n‚àí0.09\n0.29\n0.09\n0.17\n1.00\n0.18\n0.04\n0.32\n‚àí0.17\n0.77\n0.32\n0.18\n1.00\n0.77\n‚àí0.05\n0.35\n0.53\n0.78\n0.04\n0.77\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.16 ‚àí0.01\n0.50\n0.10\n0.32\n0.17\n‚àí0.16\n1.00\n‚àí0.53\n0.39\n‚àí0.25 ‚àí0.43\n0.27\n‚àí0.01 ‚àí0.53\n1.00\n‚àí0.56\n0.37\n0.65\n‚àí0.57\n0.50\n0.39\n‚àí0.56\n1.00\n‚àí0.01 ‚àí0.61\n0.07\n0.10\n‚àí0.25\n0.37\n‚àí0.01\n1.00\n0.02\n‚àí0.53\n0.32\n‚àí0.43\n0.65\n‚àí0.61\n0.02\n1.00\n0.08\n0.17\n0.27\n‚àí0.57\n0.07\n‚àí0.53\n0.08\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.22 ‚àí0.15 ‚àí0.21\n0.59\n0.54\n0.79\n‚àí0.22\n1.00\n0.64\n‚àí0.24 ‚àí0.71 ‚àí0.54 ‚àí0.64\n‚àí0.15\n0.64\n1.00\n‚àí0.75 ‚àí0.79 ‚àí0.74 ‚àí0.35\n‚àí0.21 ‚àí0.24 ‚àí0.75\n1.00\n0.32\n0.57\n‚àí0.21\n0.59\n‚àí0.71 ‚àí0.79\n0.32\n1.00\n0.73\n0.76\n0.54\n‚àí0.54 ‚àí0.74\n0.57\n0.73\n1.00\n0.57\n0.79\n‚àí0.64 ‚àí0.35 ‚àí0.21\n0.76\n0.57\n1.00\nOLMo2 32B\nMNLI\nSNLI\nFigure 10: Partial correlations taken with linear regressors of OPT (first and third rows) and OLMo2 (second and\nforth rows) across model sizes (ordered from left to right) trained on MNLI (top) and SNLI (bottom). Models were\nfine-tuned with 32-shots.\n14\n\nD.6\nHeatmaps with Partial OOD Correlations using GAM Regressors\n‚àí1.00\n‚àí0.75\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.20\n0.27\n‚àí0.79 ‚àí0.35 ‚àí0.40 ‚àí0.41\n0.20\n1.00\n‚àí0.13 ‚àí0.23 ‚àí0.03 ‚àí0.48 ‚àí0.49\n0.27\n‚àí0.13\n1.00\n0.24\n0.01\n‚àí0.12\n0.50\n‚àí0.79 ‚àí0.23\n0.24\n1.00\n0.38\n0.27\n0.63\n‚àí0.35 ‚àí0.03\n0.01\n0.38\n1.00\n0.28\n0.34\n‚àí0.40 ‚àí0.48 ‚àí0.12\n0.27\n0.28\n1.00\n0.71\n‚àí0.41 ‚àí0.49\n0.50\n0.63\n0.34\n0.71\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.54 ‚àí0.10 ‚àí0.60 ‚àí0.63 ‚àí0.60\n0.10\n‚àí0.54\n1.00\n‚àí0.03\n0.34\n0.31\n0.37\n‚àí0.28\n‚àí0.10 ‚àí0.03\n1.00\n0.74\n0.43\n‚àí0.03\n0.48\n‚àí0.60\n0.34\n0.74\n1.00\n0.74\n0.21\n0.28\n‚àí0.63\n0.31\n0.43\n0.74\n1.00\n0.46\n0.37\n‚àí0.60\n0.37\n‚àí0.03\n0.21\n0.46\n1.00\n0.31\n0.10\n‚àí0.28\n0.48\n0.28\n0.37\n0.31\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.38\n‚àí0.44 ‚àí0.65 ‚àí0.38 ‚àí0.72 ‚àí0.32\n0.38\n1.00\n‚àí0.33 ‚àí0.08\n0.03\n‚àí0.65 ‚àí0.56\n‚àí0.44 ‚àí0.33\n1.00\n0.75\n0.60\n0.50\n0.76\n‚àí0.65 ‚àí0.08\n0.75\n1.00\n0.74\n0.56\n0.52\n‚àí0.38\n0.03\n0.60\n0.74\n1.00\n0.32\n0.39\n‚àí0.72 ‚àí0.65\n0.50\n0.56\n0.32\n1.00\n0.69\n‚àí0.32 ‚àí0.56\n0.76\n0.52\n0.39\n0.69\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.51\n‚àí0.36 ‚àí0.15 ‚àí0.45 ‚àí0.43 ‚àí0.57\n0.51\n1.00\n‚àí0.59 ‚àí0.20 ‚àí0.25 ‚àí0.74 ‚àí0.68\n‚àí0.36 ‚àí0.59\n1.00\n0.53\n0.40\n0.55\n0.72\n‚àí0.15 ‚àí0.20\n0.53\n1.00\n0.52\n0.03\n0.48\n‚àí0.45 ‚àí0.25\n0.40\n0.52\n1.00\n0.38\n0.60\n‚àí0.43 ‚àí0.74\n0.55\n0.03\n0.38\n1.00\n0.66\n‚àí0.57 ‚àí0.68\n0.72\n0.48\n0.60\n0.66\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî SNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.93\n‚àí0.87\n0.82\n0.68\n0.17\n‚àí0.86\n0.93\n1.00\n‚àí0.69\n0.63\n0.79\n0.41\n‚àí0.68\n‚àí0.87 ‚àí0.69\n1.00\n‚àí0.93 ‚àí0.35\n0.20\n0.93\n0.82\n0.63\n‚àí0.93\n1.00\n0.22\n‚àí0.40 ‚àí0.99\n0.68\n0.79\n‚àí0.35\n0.22\n1.00\n0.72\n‚àí0.28\n0.17\n0.41\n0.20\n‚àí0.40\n0.72\n1.00\n0.34\n‚àí0.86 ‚àí0.68\n0.93\n‚àí0.99 ‚àí0.28\n0.34\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.06\n0.48\n0.08\n0.28\n0.17\n‚àí0.33\n‚àí0.06\n1.00\n0.25\n‚àí0.17\n0.15\n0.25\n0.23\n0.48\n0.25\n1.00\n‚àí0.74\n0.69\n0.89\n0.60\n0.08\n‚àí0.17 ‚àí0.74\n1.00\n‚àí0.75 ‚àí0.95 ‚àí0.93\n0.28\n0.15\n0.69\n‚àí0.75\n1.00\n0.78\n0.59\n0.17\n0.25\n0.89\n‚àí0.95\n0.78\n1.00\n0.85\n‚àí0.33\n0.23\n0.60\n‚àí0.93\n0.59\n0.85\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.08\n‚àí0.08 ‚àí0.01\n0.78\n‚àí0.39 ‚àí0.88\n0.08\n1.00\n0.30\n‚àí0.17 ‚àí0.17\n0.05\n‚àí0.10\n‚àí0.08\n0.30\n1.00\n0.61\n0.21\n0.88\n0.46\n‚àí0.01 ‚àí0.17\n0.61\n1.00\n0.31\n0.62\n0.29\n0.78\n‚àí0.17\n0.21\n0.31\n1.00\n0.07\n‚àí0.49\n‚àí0.39\n0.05\n0.88\n0.62\n0.07\n1.00\n0.75\n‚àí0.88 ‚àí0.10\n0.46\n0.29\n‚àí0.49\n0.75\n1.00\nOLMo2 32B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.24\n0.15\n0.19\n0.09\n0.37\n‚àí0.08\n0.24\n1.00\n0.09\n0.16\n0.02\n0.42\n‚àí0.56\n0.15\n0.09\n1.00\n0.14\n‚àí0.27 ‚àí0.04\n0.19\n0.19\n0.16\n0.14\n1.00\n0.34\n0.55\n0.36\n0.09\n0.02\n‚àí0.27\n0.34\n1.00\n0.49\n0.18\n0.37\n0.42\n‚àí0.04\n0.55\n0.49\n1.00\n‚àí0.14\n‚àí0.08 ‚àí0.56\n0.19\n0.36\n0.18\n‚àí0.14\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.60\n‚àí0.24\n0.58\n0.27\n0.72\n‚àí0.22\n0.60\n1.00\n‚àí0.03\n0.69\n0.24\n0.51\n‚àí0.67\n‚àí0.24 ‚àí0.03\n1.00\n‚àí0.07 ‚àí0.05 ‚àí0.32\n0.06\n0.58\n0.69\n‚àí0.07\n1.00\n0.46\n0.64\n‚àí0.64\n0.27\n0.24\n‚àí0.05\n0.46\n1.00\n0.44\n‚àí0.16\n0.72\n0.51\n‚àí0.32\n0.64\n0.44\n1.00\n‚àí0.17\n‚àí0.22 ‚àí0.67\n0.06\n‚àí0.64 ‚àí0.16 ‚àí0.17\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.16\n0.31\n‚àí0.42 ‚àí0.11\n0.39\n0.43\n0.16\n1.00\n‚àí0.26 ‚àí0.42 ‚àí0.22 ‚àí0.25\n0.45\n0.31\n‚àí0.26\n1.00\n0.51\n0.44\n0.69\n0.36\n‚àí0.42 ‚àí0.42\n0.51\n1.00\n0.54\n0.51\n‚àí0.26\n‚àí0.11 ‚àí0.22\n0.44\n0.54\n1.00\n0.57\n‚àí0.10\n0.39\n‚àí0.25\n0.69\n0.51\n0.57\n1.00\n0.06\n0.43\n0.45\n0.36\n‚àí0.26 ‚àí0.10\n0.06\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.75\n‚àí0.17 ‚àí0.27 ‚àí0.51 ‚àí0.19 ‚àí0.55\n0.75\n1.00\n‚àí0.36 ‚àí0.48 ‚àí0.75 ‚àí0.50 ‚àí0.67\n‚àí0.17 ‚àí0.36\n1.00\n0.65\n0.52\n0.54\n0.40\n‚àí0.27 ‚àí0.48\n0.65\n1.00\n0.79\n0.93\n0.04\n‚àí0.51 ‚àí0.75\n0.52\n0.79\n1.00\n0.84\n0.46\n‚àí0.19 ‚àí0.50\n0.54\n0.93\n0.84\n1.00\n0.11\n‚àí0.55 ‚àí0.67\n0.40\n0.04\n0.46\n0.11\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî MNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.69\n0.65\n0.64\n0.18\n0.61\n‚àí0.40\n0.69\n1.00\n0.29\n0.70\n0.08\n0.26\n‚àí0.71\n0.65\n0.29\n1.00\n0.53\n0.33\n0.72\n0.09\n0.64\n0.70\n0.53\n1.00\n0.25\n0.42\n‚àí0.58\n0.18\n0.08\n0.33\n0.25\n1.00\n0.49\n0.29\n0.61\n0.26\n0.72\n0.42\n0.49\n1.00\n0.17\n‚àí0.40 ‚àí0.71\n0.09\n‚àí0.58\n0.29\n0.17\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.74\n‚àí0.42 ‚àí0.82 ‚àí0.20\n0.07\n‚àí0.06\n0.74\n1.00\n‚àí0.31 ‚àí0.87 ‚àí0.14 ‚àí0.11 ‚àí0.23\n‚àí0.42 ‚àí0.31\n1.00\n0.59\n0.05\n‚àí0.68 ‚àí0.63\n‚àí0.82 ‚àí0.87\n0.59\n1.00\n0.09\n‚àí0.26 ‚àí0.12\n‚àí0.20 ‚àí0.14\n0.05\n0.09\n1.00\n‚àí0.02 ‚àí0.00\n0.07\n‚àí0.11 ‚àí0.68 ‚àí0.26 ‚àí0.02\n1.00\n0.97\n‚àí0.06 ‚àí0.23 ‚àí0.63 ‚àí0.12 ‚àí0.00\n0.97\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.83\n0.36\n‚àí0.57\n0.18\n‚àí0.14 ‚àí0.72\n0.83\n1.00\n0.55\n‚àí0.56\n0.26\n‚àí0.14 ‚àí0.86\n0.36\n0.55\n1.00\n0.31\n0.86\n0.65\n‚àí0.54\n‚àí0.57 ‚àí0.56\n0.31\n1.00\n0.48\n0.73\n0.35\n0.18\n0.26\n0.86\n0.48\n1.00\n0.79\n‚àí0.32\n‚àí0.14 ‚àí0.14\n0.65\n0.73\n0.79\n1.00\n0.10\n‚àí0.72 ‚àí0.86 ‚àí0.54\n0.35\n‚àí0.32\n0.10\n1.00\nOLMo2 32B\nMNLI\nSNLI\nFigure 11: Partial correlations taken with GAM regressors of OPT (first and third rows) and OLMo2 (second and\nforth rows) across model sizes (ordered from left to right) trained on MNLI (top) and SNLI (bottom). Models were\nfine-tuned with 128-shots.\n15\n\n‚àí1.00\n‚àí0.75\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.50\n0.86\n0.44\n‚àí0.01\n0.05\n‚àí0.39\n0.50\n1.00\n0.27\n0.08\n‚àí0.19\n0.12\n‚àí0.35\n0.86\n0.27\n1.00\n0.45\n‚àí0.02 ‚àí0.17 ‚àí0.32\n0.44\n0.08\n0.45\n1.00\n0.22\n0.48\n0.54\n‚àí0.01 ‚àí0.19 ‚àí0.02\n0.22\n1.00\n0.12\n0.21\n0.05\n0.12\n‚àí0.17\n0.48\n0.12\n1.00\n0.68\n‚àí0.39 ‚àí0.35 ‚àí0.32\n0.54\n0.21\n0.68\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.41\n0.50\n0.12\n‚àí0.48 ‚àí0.42 ‚àí0.41\n0.41\n1.00\n0.55\n0.57\n‚àí0.14\n0.06\n0.19\n0.50\n0.55\n1.00\n0.72\n‚àí0.27\n0.33\n0.31\n0.12\n0.57\n0.72\n1.00\n0.05\n0.46\n0.60\n‚àí0.48 ‚àí0.14 ‚àí0.27\n0.05\n1.00\n0.16\n0.19\n‚àí0.42\n0.06\n0.33\n0.46\n0.16\n1.00\n0.87\n‚àí0.41\n0.19\n0.31\n0.60\n0.19\n0.87\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.85\n0.15\n‚àí0.22 ‚àí0.21\n0.08\n‚àí0.74\n0.85\n1.00\n0.37\n0.13\n0.01\n0.11\n‚àí0.64\n0.15\n0.37\n1.00\n0.59\n0.64\n0.12\n0.36\n‚àí0.22\n0.13\n0.59\n1.00\n0.56\n0.06\n0.33\n‚àí0.21\n0.01\n0.64\n0.56\n1.00\n0.31\n0.46\n0.08\n0.11\n0.12\n0.06\n0.31\n1.00\n‚àí0.10\n‚àí0.74 ‚àí0.64\n0.36\n0.33\n0.46\n‚àí0.10\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.83\n0.20\n0.36\n‚àí0.22\n0.03\n‚àí0.65\n0.83\n1.00\n0.39\n0.53\n‚àí0.04\n0.00\n‚àí0.48\n0.20\n0.39\n1.00\n0.76\n0.36\n‚àí0.01\n0.23\n0.36\n0.53\n0.76\n1.00\n0.33\n0.23\n0.13\n‚àí0.22 ‚àí0.04\n0.36\n0.33\n1.00\n0.19\n0.52\n0.03\n0.00\n‚àí0.01\n0.23\n0.19\n1.00\n0.46\n‚àí0.65 ‚àí0.48\n0.23\n0.13\n0.52\n0.46\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî SNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.18\n0.70\n‚àí0.18 ‚àí0.02\n0.36\n‚àí0.03\n0.18\n1.00\n0.05\n0.41\n‚àí0.05 ‚àí0.33 ‚àí0.38\n0.70\n0.05\n1.00\n‚àí0.63 ‚àí0.22\n0.72\n0.48\n‚àí0.18\n0.41\n‚àí0.63\n1.00\n‚àí0.02 ‚àí0.92 ‚àí0.87\n‚àí0.02 ‚àí0.05 ‚àí0.22 ‚àí0.02\n1.00\n‚àí0.01 ‚àí0.07\n0.36\n‚àí0.33\n0.72\n‚àí0.92 ‚àí0.01\n1.00\n0.84\n‚àí0.03 ‚àí0.38\n0.48\n‚àí0.87 ‚àí0.07\n0.84\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.72\n‚àí0.14\n0.41\n‚àí0.36\n0.18\n0.80\n0.72\n1.00\n‚àí0.51\n0.77\n‚àí0.56 ‚àí0.02\n0.66\n‚àí0.14 ‚àí0.51\n1.00\n‚àí0.71\n0.30\n0.58\n‚àí0.01\n0.41\n0.77\n‚àí0.71\n1.00\n‚àí0.66 ‚àí0.45\n0.41\n‚àí0.36 ‚àí0.56\n0.30\n‚àí0.66\n1.00\n0.16\n‚àí0.50\n0.18\n‚àí0.02\n0.58\n‚àí0.45\n0.16\n1.00\n0.37\n0.80\n0.66\n‚àí0.01\n0.41\n‚àí0.50\n0.37\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.86\n0.87\n‚àí0.29\n0.73\n0.46\n‚àí0.39\n0.86\n1.00\n0.88\n‚àí0.12\n0.79\n0.64\n0.00\n0.87\n0.88\n1.00\n‚àí0.14\n0.85\n0.66\n0.01\n‚àí0.29 ‚àí0.12 ‚àí0.14\n1.00\n‚àí0.24\n0.38\n0.22\n0.73\n0.79\n0.85\n‚àí0.24\n1.00\n0.67\n0.22\n0.46\n0.64\n0.66\n0.38\n0.67\n1.00\n0.33\n‚àí0.39\n0.00\n0.01\n0.22\n0.22\n0.33\n1.00\nOLMo2 32B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.27\n‚àí0.43 ‚àí0.07\n0.27\n0.53\n‚àí0.03\n0.27\n1.00\n0.04\n0.30\n0.02\n‚àí0.17 ‚àí0.50\n‚àí0.43\n0.04\n1.00\n0.31\n‚àí0.06 ‚àí0.83 ‚àí0.19\n‚àí0.07\n0.30\n0.31\n1.00\n‚àí0.21 ‚àí0.15 ‚àí0.20\n0.27\n0.02\n‚àí0.06 ‚àí0.21\n1.00\n0.05\n0.05\n0.53\n‚àí0.17 ‚àí0.83 ‚àí0.15\n0.05\n1.00\n0.51\n‚àí0.03 ‚àí0.50 ‚àí0.19 ‚àí0.20\n0.05\n0.51\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.18 ‚àí0.24\n0.42\n0.36\n0.50\n‚àí0.54\n‚àí0.18\n1.00\n0.06\n0.35\n‚àí0.40 ‚àí0.33\n0.24\n‚àí0.24\n0.06\n1.00\n‚àí0.11\n0.07\n‚àí0.00\n0.53\n0.42\n0.35\n‚àí0.11\n1.00\n0.26\n0.31\n‚àí0.45\n0.36\n‚àí0.40\n0.07\n0.26\n1.00\n0.77\n‚àí0.22\n0.50\n‚àí0.33 ‚àí0.00\n0.31\n0.77\n1.00\n‚àí0.30\n‚àí0.54\n0.24\n0.53\n‚àí0.45 ‚àí0.22 ‚àí0.30\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.37\n0.09\n0.26\n0.06\n‚àí0.04\n0.23\n0.37\n1.00\n‚àí0.10\n0.05\n‚àí0.26 ‚àí0.19\n0.48\n0.09\n‚àí0.10\n1.00\n0.38\n‚àí0.09\n0.35\n‚àí0.28\n0.26\n0.05\n0.38\n1.00\n0.23\n0.73\n0.23\n0.06\n‚àí0.26 ‚àí0.09\n0.23\n1.00\n0.38\n‚àí0.24\n‚àí0.04 ‚àí0.19\n0.35\n0.73\n0.38\n1.00\n0.12\n0.23\n0.48\n‚àí0.28\n0.23\n‚àí0.24\n0.12\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.45\n0.53\n‚àí0.30 ‚àí0.53 ‚àí0.62 ‚àí0.11\n0.45\n1.00\n0.40\n0.21\n‚àí0.17 ‚àí0.01 ‚àí0.61\n0.53\n0.40\n1.00\n0.20\n‚àí0.54 ‚àí0.35\n0.08\n‚àí0.30\n0.21\n0.20\n1.00\n0.44\n0.69\n‚àí0.35\n‚àí0.53 ‚àí0.17 ‚àí0.54\n0.44\n1.00\n0.65\n‚àí0.17\n‚àí0.62 ‚àí0.01 ‚àí0.35\n0.69\n0.65\n1.00\n‚àí0.21\n‚àí0.11 ‚àí0.61\n0.08\n‚àí0.35 ‚àí0.17 ‚àí0.21\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî MNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.53\n‚àí0.27\n0.60\n‚àí0.43 ‚àí0.39 ‚àí0.30\n0.53\n1.00\n‚àí0.08\n0.44\n‚àí0.45 ‚àí0.56 ‚àí0.55\n‚àí0.27 ‚àí0.08\n1.00\n‚àí0.00\n0.38\n‚àí0.04 ‚àí0.30\n0.60\n0.44\n‚àí0.00\n1.00\n0.00\n‚àí0.20 ‚àí0.35\n‚àí0.43 ‚àí0.45\n0.38\n0.00\n1.00\n0.63\n0.49\n‚àí0.39 ‚àí0.56 ‚àí0.04 ‚àí0.20\n0.63\n1.00\n0.91\n‚àí0.30 ‚àí0.55 ‚àí0.30 ‚àí0.35\n0.49\n0.91\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.03\n‚àí0.45 ‚àí0.34\n0.62\n‚àí0.07 ‚àí0.45\n0.03\n1.00\n‚àí0.14\n0.35\n0.36\n‚àí0.30 ‚àí0.33\n‚àí0.45 ‚àí0.14\n1.00\n0.07\n‚àí0.46\n0.19\n0.44\n‚àí0.34\n0.35\n0.07\n1.00\n‚àí0.29 ‚àí0.78 ‚àí0.51\n0.62\n0.36\n‚àí0.46 ‚àí0.29\n1.00\n0.07\n‚àí0.24\n‚àí0.07 ‚àí0.30\n0.19\n‚àí0.78\n0.07\n1.00\n0.86\n‚àí0.45 ‚àí0.33\n0.44\n‚àí0.51 ‚àí0.24\n0.86\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.37\n0.30\n0.53\n0.61\n0.61\n‚àí0.43\n0.37\n1.00\n0.97\n0.57\n0.47\n0.64\n‚àí0.96\n0.30\n0.97\n1.00\n0.57\n0.41\n0.59\n‚àí0.92\n0.53\n0.57\n0.57\n1.00\n0.55\n0.71\n‚àí0.51\n0.61\n0.47\n0.41\n0.55\n1.00\n0.88\n‚àí0.58\n0.61\n0.64\n0.59\n0.71\n0.88\n1.00\n‚àí0.71\n‚àí0.43 ‚àí0.96 ‚àí0.92 ‚àí0.51 ‚àí0.58 ‚àí0.71\n1.00\nOLMo2 32B\nMNLI\nSNLI\nFigure 12: Partial correlations taken with GAM regressors of OPT (first and third rows) and OLMo2 (second and\nfourth rows) across model sizes (ordered from left to right) trained on MNLI (top) and SNLI (bottom). Models were\nfine-tuned with 64-shots.\n16\n\n‚àí1.00\n‚àí0.75\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.11\n0.06\n‚àí0.16 ‚àí0.03 ‚àí0.01\n0.06\n‚àí0.11\n1.00\n‚àí0.14 ‚àí0.24 ‚àí0.12\n0.19\n0.12\n0.06\n‚àí0.14\n1.00\n0.31\n0.02\n‚àí0.10 ‚àí0.18\n‚àí0.16 ‚àí0.24\n0.31\n1.00\n‚àí0.21 ‚àí0.48 ‚àí0.34\n‚àí0.03 ‚àí0.12\n0.02\n‚àí0.21\n1.00\n‚àí0.37 ‚àí0.57\n‚àí0.01\n0.19\n‚àí0.10 ‚àí0.48 ‚àí0.37\n1.00\n0.89\n0.06\n0.12\n‚àí0.18 ‚àí0.34 ‚àí0.57\n0.89\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.00\n0.87\n0.70\n‚àí0.33 ‚àí0.67 ‚àí0.42\n0.00\n1.00\n0.23\n‚àí0.25 ‚àí0.06\n0.35\n0.24\n0.87\n0.23\n1.00\n0.46\n‚àí0.33 ‚àí0.51 ‚àí0.30\n0.70\n‚àí0.25\n0.46\n1.00\n‚àí0.06 ‚àí0.66 ‚àí0.43\n‚àí0.33 ‚àí0.06 ‚àí0.33 ‚àí0.06\n1.00\n0.22\n‚àí0.03\n‚àí0.67\n0.35\n‚àí0.51 ‚àí0.66\n0.22\n1.00\n0.89\n‚àí0.42\n0.24\n‚àí0.30 ‚àí0.43 ‚àí0.03\n0.89\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.67\n0.85\n0.63\n0.14\n‚àí0.69\n0.40\n0.67\n1.00\n0.66\n0.36\n0.22\n‚àí0.67\n0.12\n0.85\n0.66\n1.00\n0.78\n0.22\n‚àí0.80\n0.29\n0.63\n0.36\n0.78\n1.00\n‚àí0.14 ‚àí0.76\n0.10\n0.14\n0.22\n0.22\n‚àí0.14\n1.00\n0.04\n0.28\n‚àí0.69 ‚àí0.67 ‚àí0.80 ‚àí0.76\n0.04\n1.00\n0.05\n0.40\n0.12\n0.29\n0.10\n0.28\n0.05\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.52\n0.85\n0.75\n‚àí0.48 ‚àí0.54 ‚àí0.77\n0.52\n1.00\n0.77\n‚àí0.04 ‚àí0.20\n0.26\n‚àí0.12\n0.85\n0.77\n1.00\n0.49\n‚àí0.42 ‚àí0.14 ‚àí0.47\n0.75\n‚àí0.04\n0.49\n1.00\n‚àí0.38 ‚àí0.71 ‚àí0.76\n‚àí0.48 ‚àí0.20 ‚àí0.42 ‚àí0.38\n1.00\n0.28\n0.43\n‚àí0.54\n0.26\n‚àí0.14 ‚àí0.71\n0.28\n1.00\n0.90\n‚àí0.77 ‚àí0.12 ‚àí0.47 ‚àí0.76\n0.43\n0.90\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî SNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.78\n0.90\n0.60\n0.53\n‚àí0.38 ‚àí0.96\n0.78\n1.00\n0.68\n0.67\n0.45\n0.00\n‚àí0.73\n0.90\n0.68\n1.00\n0.61\n0.49\n‚àí0.25 ‚àí0.81\n0.60\n0.67\n0.61\n1.00\n0.24\n0.02\n‚àí0.51\n0.53\n0.45\n0.49\n0.24\n1.00\n0.10\n‚àí0.56\n‚àí0.38\n0.00\n‚àí0.25\n0.02\n0.10\n1.00\n0.49\n‚àí0.96 ‚àí0.73 ‚àí0.81 ‚àí0.51 ‚àí0.56\n0.49\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.08\n0.32\n0.35\n‚àí0.66 ‚àí0.78 ‚àí0.05\n‚àí0.08\n1.00\n‚àí0.15 ‚àí0.21\n0.14\n0.09\n‚àí0.01\n0.32\n‚àí0.15\n1.00\n‚àí0.49\n0.11\n‚àí0.17\n0.75\n0.35\n‚àí0.21 ‚àí0.49\n1.00\n‚àí0.63 ‚àí0.58 ‚àí0.63\n‚àí0.66\n0.14\n0.11\n‚àí0.63\n1.00\n0.70\n0.37\n‚àí0.78\n0.09\n‚àí0.17 ‚àí0.58\n0.70\n1.00\n0.04\n‚àí0.05 ‚àí0.01\n0.75\n‚àí0.63\n0.37\n0.04\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.94\n0.96\n0.34\n0.86\n0.69\n‚àí0.62\n0.94\n1.00\n0.92\n0.34\n0.74\n0.63\n‚àí0.47\n0.96\n0.92\n1.00\n0.50\n0.85\n0.76\n‚àí0.55\n0.34\n0.34\n0.50\n1.00\n0.35\n0.68\n‚àí0.09\n0.86\n0.74\n0.85\n0.35\n1.00\n0.81\n‚àí0.50\n0.69\n0.63\n0.76\n0.68\n0.81\n1.00\n‚àí0.18\n‚àí0.62 ‚àí0.47 ‚àí0.55 ‚àí0.09 ‚àí0.50 ‚àí0.18\n1.00\nOLMo2 32B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.42 ‚àí0.59 ‚àí0.82 ‚àí0.33\n0.80\n0.19\n‚àí0.42\n1.00\n0.31\n0.45\n0.11\n‚àí0.52 ‚àí0.57\n‚àí0.59\n0.31\n1.00\n0.83\n0.05\n‚àí0.79 ‚àí0.44\n‚àí0.82\n0.45\n0.83\n1.00\n0.12\n‚àí0.90 ‚àí0.48\n‚àí0.33\n0.11\n0.05\n0.12\n1.00\n‚àí0.17\n0.14\n0.80\n‚àí0.52 ‚àí0.79 ‚àí0.90 ‚àí0.17\n1.00\n0.58\n0.19\n‚àí0.57 ‚àí0.44 ‚àí0.48\n0.14\n0.58\n1.00\nOPT 2.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.15 ‚àí0.79 ‚àí0.86\n0.31\n0.51\n‚àí0.25\n‚àí0.15\n1.00\n0.40\n0.45\n0.18\n0.16\n0.14\n‚àí0.79\n0.40\n1.00\n0.73\n‚àí0.08 ‚àí0.25\n0.33\n‚àí0.86\n0.45\n0.73\n1.00\n‚àí0.17 ‚àí0.30\n0.11\n0.31\n0.18\n‚àí0.08 ‚àí0.17\n1.00\n0.75\n0.36\n0.51\n0.16\n‚àí0.25 ‚àí0.30\n0.75\n1.00\n0.41\n‚àí0.25\n0.14\n0.33\n0.11\n0.36\n0.41\n1.00\nOPT 6.7b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.19\n0.68\n‚àí0.38\n0.09\n0.69\n0.51\n‚àí0.19\n1.00\n‚àí0.14\n0.09\n0.19\n‚àí0.03 ‚àí0.13\n0.68\n‚àí0.14\n1.00\n‚àí0.20 ‚àí0.03\n0.82\n0.63\n‚àí0.38\n0.09\n‚àí0.20\n1.00\n0.23\n‚àí0.11 ‚àí0.28\n0.09\n0.19\n‚àí0.03\n0.23\n1.00\n0.12\n‚àí0.11\n0.69\n‚àí0.03\n0.82\n‚àí0.11\n0.12\n1.00\n0.78\n0.51\n‚àí0.13\n0.63\n‚àí0.28 ‚àí0.11\n0.78\n1.00\nOPT 13b\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n0.00\n‚àí0.08\n0.01\n‚àí0.24\n0.39\n0.15\n0.00\n1.00\n0.50\n0.44\n0.44\n‚àí0.33\n0.11\n‚àí0.08\n0.50\n1.00\n0.91\n0.37\n‚àí0.19\n0.68\n0.01\n0.44\n0.91\n1.00\n0.25\n‚àí0.34\n0.50\n‚àí0.24\n0.44\n0.37\n0.25\n1.00\n‚àí0.16\n0.32\n0.39\n‚àí0.33 ‚àí0.19 ‚àí0.34 ‚àí0.16\n1.00\n0.50\n0.15\n0.11\n0.68\n0.50\n0.32\n0.50\n1.00\nOPT 30b\nDataset Legend\n1 ‚Äî MNLI\n2 ‚Äî WNLI\n3 ‚Äî SciTail\n4 ‚Äî RTE\n5 ‚Äî HANS\n6 ‚Äî ANLI\n7 ‚Äî PAWS\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.50\n0.21\n‚àí0.31 ‚àí0.46\n0.21\n‚àí0.10\n‚àí0.50\n1.00\n‚àí0.22\n0.77\n0.41\n‚àí0.20\n0.35\n0.21\n‚àí0.22\n1.00\n0.16\n‚àí0.12\n0.73\n0.52\n‚àí0.31\n0.77\n0.16\n1.00\n0.31\n0.35\n0.78\n‚àí0.46\n0.41\n‚àí0.12\n0.31\n1.00\n‚àí0.02\n0.01\n0.21\n‚àí0.20\n0.73\n0.35\n‚àí0.02\n1.00\n0.79\n‚àí0.10\n0.35\n0.52\n0.78\n0.01\n0.79\n1.00\nOLMo2 7B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.25 ‚àí0.01\n0.23\n‚àí0.05\n0.56\n0.46\n‚àí0.25\n1.00\n‚àí0.58\n0.59\n‚àí0.50 ‚àí0.56\n0.36\n‚àí0.01 ‚àí0.58\n1.00\n‚àí0.66\n0.52\n0.62\n‚àí0.76\n0.23\n0.59\n‚àí0.66\n1.00\n‚àí0.29 ‚àí0.61\n0.45\n‚àí0.05 ‚àí0.50\n0.52\n‚àí0.29\n1.00\n0.14\n‚àí0.45\n0.56\n‚àí0.56\n0.62\n‚àí0.61\n0.14\n1.00\n‚àí0.08\n0.46\n0.36\n‚àí0.76\n0.45\n‚àí0.45 ‚àí0.08\n1.00\nOLMo2 13B\n1\n2\n3\n4\n5\n6\n7\n1\n2\n3\n4\n5\n6\n7\n1.00\n‚àí0.08\n0.00\n‚àí0.24\n0.55\n0.50\n0.74\n‚àí0.08\n1.00\n0.53\n‚àí0.10 ‚àí0.66 ‚àí0.40 ‚àí0.57\n0.00\n0.53\n1.00\n‚àí0.73 ‚àí0.67 ‚àí0.69 ‚àí0.10\n‚àí0.24 ‚àí0.10 ‚àí0.73\n1.00\n0.20\n0.54\n‚àí0.39\n0.55\n‚àí0.66 ‚àí0.67\n0.20\n1.00\n0.68\n0.65\n0.50\n‚àí0.40 ‚àí0.69\n0.54\n0.68\n1.00\n0.47\n0.74\n‚àí0.57 ‚àí0.10 ‚àí0.39\n0.65\n0.47\n1.00\nOLMo2 32B\nMNLI\nSNLI\nFigure 13: Partial correlations taken with GAM regressors of OPT (first and third rows) and OLMo2 (second and\nfourth rows) across model sizes (ordered from left to right) trained on MNLI (top) and SNLI (bottom). Models were\nfine-tuned with 32-shots.\n17\n\nD.7\nAverage Correlationg across Model Sizes\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\nAvg. Partial Correlation\nSNLI - 32 Shots\nOPT\nOLMo2\nSNLI - 64 Shots\nOPT\nOLMo2\nSNLI - 128 Shots\nOPT\nOLMo2\n3B\n7B\n13B\n30B\nModel Size\n‚àí0.50\n‚àí0.25\n0.00\n0.25\n0.50\n0.75\nAvg. Partial Correlation\nMNLI - 32 Shots\nOPT\nOLMo2\n3B\n7B\n13B\n30B\nModel Size\nMNLI - 64 Shots\nOPT\nOLMo2\n3B\n7B\n13B\n30B\nModel Size\nMNLI - 128 Shots\nOPT\nOLMo2\nFigure 14: Average partial correlations across model sizes between OPT and OLMo2 generalisation results taken with\nGAM regressors.\n18\n",
    "figure_captions": [
      "Figure 1: OLMo2‚Äôs partial OOD correlations on SNLI",
      "Figure 2:",
      "Figure 3: Partial correlations of OPT (top) and OLMo2 (bottom) across model sizes (ordered from left to right) trained",
      "Fig. 2 presents OPT 30B‚Äôs",
      "Fig. 3 presents the partial correlations across OOD",
      "Fig. 4, which shows that partial correlations do not",
      "Figure 4: Partial correlations averaged across all OOD",
      "Figure 5: Few-shots results throughout a finetuning run on either MNLI or SNLI. OPT OOD performances (first",
      "Figure 6: OPT partial OOD correlation graphs on SNLI (top) and MNLI (bottom). Edge thickness increases with",
      "Figure 7: Regressors trained to predict OOD performance for 128-shots models. Models were finetuned on MNLI",
      "Figure 8: Partial correlations taken with linear regressors of OPT (first and third rows) and OLMo2 (second and forth",
      "Figure 9: Partial correlations taken with linear regressors of OPT (first and third rows) and OLMo2 (second and forth",
      "Figure 10: Partial correlations taken with linear regressors of OPT (first and third rows) and OLMo2 (second and",
      "Figure 11: Partial correlations taken with GAM regressors of OPT (first and third rows) and OLMo2 (second and",
      "Figure 12: Partial correlations taken with GAM regressors of OPT (first and third rows) and OLMo2 (second and",
      "Figure 13: Partial correlations taken with GAM regressors of OPT (first and third rows) and OLMo2 (second and",
      "Figure 14: Average partial correlations across model sizes between OPT and OLMo2 generalisation results taken with"
    ]
  },
  {
    "arxiv_id": "2512.07828v1",
    "title": "The Adoption and Usage of AI Agents: Early Evidence from Perplexity",
    "abstract": "This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors -- such as digital technology, academia, finance, marketing, and entrepreneurship -- are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics, Productivity & Workflow and Learning & Research, account for 57% of all agentic queries, while the two largest subtopics, Courses and Shopping for Goods, make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.",
    "text": "The Adoption and Usage of AI Agents:\nEarly Evidence from Perplexity‚àó\nJeremy Yang1 Noah Yonack2\nKate Zyskowski2 Denis Yarats2 Johnny Ho2 Jerry Ma2\n1Harvard University\n2Perplexity\nDecember 7, 2025\nAbstract\nThis paper presents the first large-scale field study of the adoption, usage intensity, and use\ncases of general-purpose AI agents operating in open-world web environments. Our analysis\ncenters on Comet, an AI-powered browser developed by Perplexity, and its integrated agent,\nComet Assistant. Drawing on hundreds of millions of anonymized user interactions, we\naddress three fundamental questions: Who is using AI agents? How intensively are they\nusing them? And what are they using them for? Our findings reveal substantial heterogeneity\nin adoption and usage across user segments.\nEarlier adopters, users in countries with\nhigher GDP per capita and educational attainment, and individuals working in digital or\nknowledge-intensive sectors‚Äîsuch as digital technology, academia, finance, marketing, and\nentrepreneurship‚Äîare more likely to adopt or actively use the agent.\nTo systematically\ncharacterize the substance of agent usage, we introduce a hierarchical agentic taxonomy\nthat organizes use cases across three levels: topic, subtopic, and task.\nThe two largest\ntopics‚ÄîProductivity & Workflow and Learning & Research‚Äîaccount for 57% of all agentic\nqueries, while the two largest subtopics‚ÄîCourses and Shopping for Goods‚Äîmake up 22%.\nThe top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries,\nwhile professional and educational contexts comprise 30% and 16%, respectively. In the\nshort term, use cases exhibit strong stickiness, but over time, users tend to shift toward more\ncognitively oriented topics. The diffusion of increasingly capable AI agents carries important\nimplications for researchers, businesses, policymakers, and educators, inviting new lines of\ninquiry into this rapidly emerging class of AI capabilities.\n‚àóJ.Y. and N.Y. contributed equally. We thank Gustav Lindqvist, Alexis Weill, and many other Perplexity staff for helpful insights, discussions,\nand technical assistance. All errors are the authors‚Äô own. Correspondence to jeryang@hbs.edu and jerry@perplexity.ai.\n1\narXiv:2512.07828v1  [cs.LG]  8 Dec 2025\n\n1\nIntroduction\n2025 is frequently heralded as the year of agentic AI, as the frontier shifts from conversational\nLarge Language Model (LLM) chatbots to action-oriented AI agents.1 This narrative has emerged\nas AI agents have progressed from a largely theoretical construct to widely productized assistants,\ndemonstrating strong potential to transform work and daily life by planning and executing com-\nplex tasks in response to high-level human instructions with little supervision [Wooldridge and\nJennings, 1995].2 AI agents could profoundly reshape individual workflows, as well as organiza-\ntional and market structures, by increasing productivity and efficiency and lowering transaction\ncosts as autonomous participants in both consumption and production processes [Hadfield and\nKoh, 2025, Rothschild et al., 2025, Shahidi et al., 2025]. In aggregate, Precedence Research\nestimates that the global agentic AI market size will grow from $8 billion in 2025 to $199 billion\nby 2034.3 PwC forecasts that the overall associated economic contribution could reach between\n$2.6 trillion and $4.4 trillion annually by 2030.4\nDespite this enthusiasm and its far-reaching economic implications, systematic behavioral\nevidence on how people actually adopt and use AI agents in the field remains limited, often relying\non non-representative firm surveys [Pan et al., 2025] or focusing on specialized agents such as\ncoding assistants [Sarkar, 2025].5 Launched in July 2025, Comet by Perplexity is among the\nfirst widely adopted AI browsers and offers the embedded Comet Assistant as a general-purpose\nAI agent capable of performing user-specified tasks across open-world web environments. By\nstudying hundreds of millions of anonymized user interactions with Comet and Comet Assistant,\nwe narrow the gap by providing early insights into three fundamental questions: Who is using AI\nagents? How intensively are they using them? And what are they using them for?\nAI Agents\nWe define agentic AI systems as AI assistants capable of autonomously pursuing user-defined\ngoals by planning and taking multi-step actions on a user‚Äôs behalf to interact with and effect\noutcomes across real-world environments.\nIn general, agentic AI is a concept that resists precise definition. Despite variations, the\ndefinitions share several common themes: goal orientation, action taking, and autonomy. For\ninstance, Shavit et al. [2023] defines agentic AI systems as those capable of taking actions\nthat consistently contribute toward achieving goals over extended periods without their behavior\nbeing explicitly specified in advance, and Schluntz and Zhang [2024] describes agents as systems\nthat dynamically direct their own processes and tool use, maintaining control over how they\n1https://finance.yahoo.com/news/nvidia-jensen-huang-says-ai-044815659.html\nhttps://x.com/gdb/status/1879327050819104778\nhttps://www.aboutamazon.com/news/company-news/amazon-ceo-andy-jassy-on-generative-ai\nhttps://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality\n2Examples of such agentic AI products or features include Perplexity‚Äôs Comet browser; OpenAI‚Äôs ChatGPT Operator, Codex, and Atlas\nbrowser; Anthropic‚Äôs Claude Code and Computer Use; Google‚Äôs Gemini Assistant; and Microsoft‚Äôs Copilot.\n3https://www.precedenceresearch.com/agentic-ai-market\n4https://www.pwc.com/m1/en/publications/agentic-ai-the-new-frontier-in-genai.html\n5https://knowledge.wharton.upenn.edu/special-report/2025-ai-adoption-report/\n2\n\ncomplete tasks. Perplexity Team [2025] refines these definitions by replacing the term ‚Äúagent‚Äù\nwith ‚Äúassistant,‚Äù arguing that each AI agent is best understood as a personal, powerful generalist\nserving the interests of a single user or customer, in contrast to a human agent who typically\nmanages multiple clients within narrow professional roles or licensing constraints and often faces\nconflicting incentives. In addition, we place particular emphasis on the agent‚Äôs ability not only to\nexchange information with its environment but also to actively modify it.\nUnder the ReAct framework, an agentic workflow typically cycles automatically between\nthree iterative phases to achieve the end goal: thinking, acting, and observing [Yao et al., 2022].6\nIn the thinking phase, the agent interprets the goal from the query and devises a step-by-step\nplan to achieve it.7 In the acting phase, the agent executes actions by controlling external tools\nto interact with its environment. In the observing phase, the agent processes feedback from its\nenvironment and returns to the thinking phase to confirm or revise its plan as needed.\nIt is also useful to contrast LLM chatbots and AI agents. Both chatbots and agents build\non LLMs, but agents extend chatbots‚Äô capabilities beyond conversations to include autonomous\nactions. LLMs serve as the ‚Äúbrain‚Äù of an agent, functioning as the central reasoning engine\nthat processes information, evaluates options, and makes decisions. Tools are the ‚Äúhands‚Äù that\nconnect the agent‚Äôs reasoning to the external world, enabling it to act upon its environment. More\nadvanced agent capabilities also include multi-agent orchestration‚Äîthe ability to interface with\nand manage workflows across multiple collaborating agents‚Äîand self-evolution‚Äîthe ability to\nidentify gaps in pre-specified resources and dynamically expand them.8\nResearch Setting: Perplexity and Comet\nPerplexity is an AI-powered platform that helps users discover, analyze, and act on information.\nInstead of requiring users to navigate through pages of results (‚Äúblue links‚Äù), as traditional search\nengines do, Perplexity interacts with the web on users‚Äô behalf to deliver direct, verifiable, and\nconversational answers.\nEach answer includes inline citations and links to original sources,\nenabling users to verify information and explore topics in more detail.9\nComet is a browser from Perplexity that embeds an AI assistant directly into the browsing\nexperience, helping users discover, analyze, and act on information more effectively. Its core\nfeature, Comet Assistant, operates as an autonomous agent that takes actions and completes\nopen-world web-based tasks on behalf of users. To fulfill user requests, Comet Assistant can\nexecute a variety of tasks, including scheduling meetings, editing documents, sending emails,\nbooking flights, making purchases, and more.10\nComet was launched on July 9, 2025, on desktop for subscribers to Perplexity‚Äôs Max tier11,\nalong with selected users from a pre-launch waitlist.12 Access expanded to Pro subscribers on\n6https://huggingface.co/learn/agents-course/en/unit1/agent-steps-and-structure\n7We use query and prompt interchangeably.\n8https://www.kaggle.com/whitepaper-introduction-to-agents\n9https://www.perplexity.ai/help-center/en/articles/10352155-what-is-perplexity\n10We provide some sample agentic queries in Figure 9 and an example of the agent executing a real task in Figure 10 in Appendix B.\n11Perplexity offers three consumer subscription tiers: Free, Pro ($20 per month), and Max ($200 per month).\n12https://www.perplexity.ai/hub/blog/introducing-comet\n3\n\nAugust 13, 2025, beginning with users in the United States.13 On October 2, 2025, Comet became\navailable to all users worldwide.14 In addition to these general cohorts, Comet was opened to\nuniversity students globally on September 3, 2025.\nData\nOur analysis relies on three samples collected from Comet desktop users between July 9 and\nOctober 22, 2025.15 First, we use anonymized data from the entire population of Comet users and\ntheir queries to provide high-level, aggregated statistics on agent adoption and usage intensity;\nthis sample includes millions of users and hundreds of millions of queries. Second, we analyze\na random sample of 100,000 Comet users and classify their O*NET occupation clusters and\nsubclusters based on the National Career Clusters Framework to examine variation across occu-\npations.16 Third, we analyze a separate random sample of 100,000 agent users and classify all of\ntheir agentic queries using a novel hierarchical agentic taxonomy to better understand common\nuse cases at the topic, subtopic, and task levels.\nSummary of Findings\nWe report two sets of results on the adoption and use of AI agents: the extensive and intensive\nmargins and a comprehensive taxonomy of use cases.\nAdoption and usage intensity\nOverall, agent adoption and usage intensity demonstrate sustained growth with acceleration\nfollowing the general availability (GA) of Comet. The post-GA period accounts for 60% of agent\nadopters and 50% of agentic queries throughout our sampling period. Earlier Comet adopters\n(those with pre-GA access) represent a disproportionately large share of agent adopters and\nagentic queries relative to their user share. The disparity is more pronounced in usage intensity\nthan in adoption‚Äîan average user in the first cohort (July 9) is twice as likely to adopt the agent\nand makes nine times as many agentic queries as an average user in the GA cohort (October\n2). At the country level, adoption and usage intensity show strong positive correlations with\nGDP per capita and average years of education. At the occupational level, adopters and queries\ntend to come more from digital or knowledge-intensive domains. Digital technology17 represents\nthe largest occupational cluster, comprising 28% of adopters and 30% of queries, followed by\nacademia, finance, marketing, and entrepreneurship. These occupational clusters collectively\n13https://www.perplexity.ai/hub/blog/the-intelligent-business-introducing-comet-for-enterprise-pro\n14https://www.perplexity.ai/hub/blog/comet-is-now-available-to-everyone-worldwide\n15We define Comet users as those who made at least one query on Comet during our study period. We use October 22, 2025, as the cutoff\ndate because a major agent update began rolling out to selected users on October 23, which could affect adoption and usage patterns thereafter.\nThe new agent was launched to all users on November 6. The updated agent performs 23% better than the previous version and offers greater\nmultitasking capacity across multiple tabs. The agent we analyze in our data operates in a single web environment. For more details, see:\nhttps://www.perplexity.ai/hub/blog/the-new-comet-assistant.\n16https://www.onetonline.org/find/career?c=0\nhttps://careertech.org/career-clusters/\n17The Digital Technology Career Cluster focuses on developing digital systems for communication and data storage using critical technologies\nsuch as artificial intelligence (AI), data analytics, and cybersecurity. https://careertech.org/career-clusters/digital-technology/.\n4\n\naccount for over 70% of total adopters and queries. They also tend to have higher agent adopter\nor agentic query shares than their user shares.\nUse cases\nWe illustrate the hierarchical structure of our agentic taxonomy in Figure 1 and report our complete\ntaxonomy in Table 1. Productivity is the dominant topic with a 36% share. It is followed by\nlearning (21%), media (16%), and shopping (10%). The most prevalent subtopics with over\n5% query share include courses (13%), goods shopping (9%), research (8%), document editing\n(8%), account management (7%), and social media (7%). The most frequently observed tasks\nare exercise assistance (9%), research information summarization and analysis (7%), document\ncreation and editing (7%), product search and filtering (6%), and research information search\nand filtering (6%). We also study the use of agents across environments, which are the websites\non which these tasks are performed. The concentration of environments varies substantially\nacross subtopics: the top five environments account for 97% of queries in music, 97% in videos,\nand 96% in professional networking, compared to only 28% in account management, 35% in\nshopping for services, and 37% in project management. Across all use cases, 55% of agentic\nqueries originate from personal use settings, 30% from professional use settings, and 16%\nfrom educational use settings. In the short term, users show strong within-topic persistence,\ndemonstrating stickiness in use cases; when topic transitions occur, they are more likely to\nmigrate toward productivity, learning, or media topics. Over time, query shares shift from travel\nand media topics to productivity, learning, and career topics.\n5\n\nNote: A topic contains multiple subtopics; a subtopic contains multiple tasks; a task can be connected to multiple\nenvironments; and an environment can be connected to one or multiple tasks within or across different topics and\nsubtopics. The colors indicate different topics, solid lines indicate connections between topics, subtopics, and tasks,\nand dashed lines indicate which tasks are performed in which environments. Note that task 1.1.1 can be performed\nin environments A and B, whereas task 1.1.2 can only be performed in environment B. Tasks 2.1.1 and 2.1.2\nindicate similar patterns. Environment B spans subtopics 1.1 and 2.1, whereas environments A and C are specific\nto a single subtopic. We substantiate the structure with some examples. The query ‚Äúunsubscribe me from all\npromotional emails that I receive more than twice per month‚Äù would be labeled as {Topic: Productivity &\nWorkflow, Subtopic: Email Management, Task: Search or filter emails, Delete or unsubscribe emails}. In this case,\nsearching or filtering emails, and deleting or unsubscribing from them, can both be performed in environments such\nas Gmail or Outlook. Now imagine another query that gets classified into {Topic: Shopping & Commerce,\nSubtopic: Shopping for Goods, Task: Search discounts, Make product purchase}; both tasks can be performed on\nInstacart, whereas only search discounts can be performed on SimplyCodes, as it only shows discount codes and\ndoes not sell products directly. Facebook is one example of a cross-topic environment‚Äîit could be the environment\nfor Media & Entertainment queries, but also for Shopping & Commerce queries when they are about products listed\non Facebook Marketplace.\nFigure 1: Hierarchical Structure of the Agentic Taxonomy\n6\n\nTopics\nSubtopics\nTasks\nProductivity & Workflow\nAccount Management\nRegister/log in to accounts, Manage settings/profiles, Manage files,\nSummarize/analyze account information\nDocument & Form Editing\nCreate/edit documents, Search/filter documents, Summarize/analyze\ndocuments\nMultimedia Editing\nCreate/edit multimedia, Search/filter multimedia, Summarize/analyze\nmultimedia\nEmail Management\nSearch/filter emails, Create/edit emails, Send emails,\nDelete/unsubscribe emails, Summarize/analyze emails\nSpreadsheet & Data Editing\nCreate/edit spreadsheets, Search/filter spreadsheets,\nSummarize/analyze spreadsheets\nComputer Programming\nCreate/edit code, Execute code, Summarize/analyze code\nInvestments & Banking\nSearch/filter stocks, Buy/sell stocks, Summarize/analyze investment\ninformation, Summarize/analyze banking information\nProject Management\nCreate/edit projects, Summarize/analyze project information\nCalendar Management\nCreate/edit events, Check availability, Search/filter events,\nSummarize/analyze events\nLearning & Research\nCourses\nNavigate courses, Summarize/analyze course materials, Assist\nexercises\nResearch\nSearch/filter research information, Summarize/analyze research\ninformation\nMedia & Entertainment\nSocial Media & Messaging\nSearch/filter social media posts, Summarize/analyze social media\nposts, Create social media posts, Engage with social media posts, Send\nsocial media/text messages\nOnline Games\nSearch/filter online games, Summarize/analyze online game\ninformation, Play online games\nMovies, TV, & Videos\nSearch/filter videos, Summarize/analyze videos, Play videos, Navigate\nwithin videos, Manage playlists\nMusic & Podcasts\nSearch/filter music/podcasts, Summarize/analyze music/podcasts, Play\nmusic/podcasts, Manage playlists\nNews\nSearch/filter news, Summarize/analyze news\nSports\nSearch/filter match/player information, Summarize/analyze\nmatch/player statistics\nShopping & Commerce\nGoods\nSearch/filter products, Search discounts, Summarize/analyze product\ninformation, Add products to cart, Make product purchase, Manage\norders\nServices\nSearch/filter products, Search discounts, Summarize/analyze product\ninformation, Add products to cart, Make product purchase, Manage\norders\nTravel & Leisure\nFlights & Transportation\nSearch/filter flights & transportation, Summarize/analyze flights &\ntransportation, Add flights & transportation to cart, Book flights &\ntransportation\nTrip Itineraries\nSearch/filter destinations, Plan trips, Summarize/analyze trips\nLodging\nSearch/filter lodging, Summarize/analyze lodging information, Add\nlodging to cart, Book lodging\nRestaurants\nSearch/filter restaurants, Summarize/analyze restaurant information,\nBook restaurants\nJob & Career\nJob Search & Application\nSearch/filter jobs, Summarize/analyze job descriptions, Complete\napplications\nProfessional Networking\nSearch/filter professional profiles, Summarize/analyze professional\nprofiles, Send professional connection requests/messages, Engage with\nprofessional profiles/posts\nNote: The table contains all topics, subtopics, and tasks in the agentic taxonomy, except ‚ÄúOther‚Äù. Topics and subtopics are general goals,\nand tasks are specific tasks the agent is expected to complete to achieve those goals. A query is classified into one topic, one subtopic\nunderneath that topic, and one or more tasks underneath that subtopic. Queries that cannot be classified into the taxonomy at a given level\nare labeled as ‚ÄúOther‚Äù at that level and all subsequent levels. For example, a query that does not belong to any of the topics would be\nlabeled as ‚ÄúOther‚Äù at topic, subtopic, and task levels; a query that belongs to productivity but does not belong to any of the subtopics under\nproductivity will be labeled as ‚ÄúOther‚Äù at subtopic and task levels; a query that belongs to productivity and email management but does\nnot belong to any of the tasks under email management will be labeled as ‚ÄúOther‚Äù at the task level.\nTable 1: Agentic Taxonomy‚ÄîTopics, Subtopics, and Tasks\n7\n\nThe remainder of this paper is structured as follows. Section 2 reviews related literature and\nhighlights our contributions. Section 3 describes our sampling methodology and data privacy\nsafeguards. Section 4 explains the development of our hierarchical agentic taxonomy. Section 5\npresents our main findings on AI agent adoption patterns, usage intensity, and use cases. Finally,\nSection 6 discusses the implications of our findings for researchers, businesses, and policymakers,\nwhile acknowledging limitations and identifying promising avenues for future research that we\naim to pursue. Key figures and tables are included in the main text. Additional figures, tables,\nand other supplementary materials are provided in the Appendices.\n2\nRelated Work\nOur paper is directly related to the literature on how people use LLMs and AI agents in real-world\nsettings.18 Our paper extends recent work on the adoption and usage of LLM chatbots. Several\nprominent studies have examined this topic, including Handa et al. [2025c], which documents\nuser interactions with Claude, and Zhao et al. [2024] and Chatterji et al. [2025], which analyze\nhow people use ChatGPT. Anthropic has also released detailed analyses focusing on specific\nuser groups, such as university students [Handa et al., 2025a], educators [Bent et al., 2025],\nand different geographies and enterprises [Appel et al., 2025]. In addition, Aubakirova et al.\n[2025] uses OpenRouter data to study LLM chatbot usage across both open and closed-source\nmodels. These papers developed taxonomies to categorize standard Q&A queries. We also create\na taxonomy using internal data from an AI product; however, our key contribution is the focus on\nagentic queries. The main difference is that Q&A queries focus on information exchange between\nthe user and model in a conversation. In contrast, agentic queries focus on the agent executing\ntasks on behalf of the user in an external environment.\nEvidence on how people use AI agents in the field is more limited and usually focused on\nspecific use cases, such as coding. For example, Anthropic [2025b] studies the usage of Claude\nCode, a coding agent, in software development, and Sarkar [2025] investigates the adoption,\nusage, and productivity impact of coding agents in Cursor. Our contribution differs in that we\nanalyze a general-purpose agent operating across all common use cases.19\n3\nData\nSampling\nOur analysis leverages three samples collected between July 9 and October 22, 2025‚Äîthat is,\nfrom the launch date to 20 days after general availability. Each sample is tailored to a particular\n18Following our definition of AI agents, we do not discuss papers that do not involve the agent taking actions to manipulate their environments.\n19Although not directly related to the focus of our paper, it is worth noting adjacent research that examines the adoption and usage of LLM\nchatbots through user surveys (e.g., Humlum and Vestergaard [2025], Bick et al. [2024], Handa et al. [2025b]); the productivity and performance\nimpact of LLM chatbots across various occupations and tasks through field (e.g., Dell‚ÄôAcqua et al. [2023], Wiles et al. [2024], Brynjolfsson et al.\n[2025], Cui et al. [2025], Vendraminelli et al. [2025]) and lab experiments (e.g., Noy and Zhang [2023], Peng et al. [2023], Merali [2024]); and\nthe behavior of AI agents and human‚Äìagent collaboration through case studies (e.g., Anthropic [2025a]), firm surveys (e.g., Pan et al. [2025]), or\nlab experiments (e.g., Allouah et al. [2025], Ju and Aral [2025]).\n8\n\nset of research questions.\nWe define a Comet user as a user who has made at least one query on Comet during the\nstudy period. At the user level, we exclude all enterprise users, users under the Perplexity for\nGovernment program, users who deleted their accounts during the sampling period, users who\nopted out of data retention for model training during that period, and logged-out users. At the\nquery level, we define an agentic query as one that involves the agent taking control of the browser\nor taking actions on external applications‚Äîsuch as email or calendar clients‚Äîthrough connectors\nbuilt on the Model Context Protocol (MCP) or via API calls.20 Under this stricter definition, we\ndo not consider all queries with tool use (such as web search or code interpreter) as agentic, since\nthese tools merely exchange information with external environments but do not manipulate them.\nWhen users onboard onto Comet, sample agentic queries are shown for demonstration purposes;\nwe remove these queries to focus only on user-initiated ones. In rare cases, a single agentic query\nmight trigger multiple browser-control, MCP, or API calls; we exclude such cases to focus on\nqueries that trigger a single call, ensuring a clean inference of user intent. Lastly, we exclude\nqueries made in Comet‚Äôs incognito mode. We describe the three samples we analyze below.\nSample A: The population of Comet users and queries\nWe use the entire population of millions of users and hundreds of millions of queries on\nComet‚Äîboth agentic and non-agentic‚Äîduring the sampling period to understand overall patterns\nin adoption and usage intensity.\nSample B: A random sample of Comet users and queries\nWe draw random samples of 100,000 Comet users and their recent queries‚Äîboth agentic and\nnon-agentic‚Äîduring the study period to infer their O*NET occupation clusters and subclusters,\nenabling us to examine variation in adoption and usage intensity across occupations.21\nThe\nsampling includes two stages. First, a random set of users is selected, then for each user, a\nrandom set of queries from recent dates is selected. The sampled queries are then concatenated\ninto a single string and labeled using a classifier against the occupation taxonomy. We include\nuniversity students as a separate cluster as they are not included in the occupation taxonomy.22\nSample C: A random sample of Comet agent users and all their agentic queries\nWe draw another random sample of 100,000 agent users and classify all their agentic queries\nusing a novel agentic taxonomy to identify common use cases. The sampling is performed only\nat the user level: once a user is selected, all their agentic queries are included in the analysis.\nThis procedure allows us to track within-user agent usage trajectories and uncover longitudinal\npatterns. In large user samples, the queries are also representative of query-level estimands,\n20https://www.anthropic.com/news/model-context-protocol\n21https://www.onetonline.org/find/career?c=0\n22Students are treated as a distinct cluster, separate from the education cluster, which is reserved for education professionals. Student status\nis verified through a third-party vendor.\n9\n\nincluding common use cases.\nFor the same sample of users, we further infer their O*NET\noccupation clusters and subclusters.\nData Privacy\nWe follow industry standards and implement multiple safeguards to ensure that no human uses\nany personally identifiable information (PII) at any point in the analysis.23\nFirst, as noted above, enterprise users, users under the Perplexity for Government program,\nusers who deleted their accounts during the sampling period, users who opted out of data retention\nfor model training during that period, logged-out users, and queries made in incognito mode are\nexcluded from the analysis. Second, our analysis does not use any demographic information,\nnames, email addresses, or other real-world identifiers; all user-level matching is performed\nthrough internal numerical user IDs. Third, we employ automated classifiers to label occupations\nand use cases. The classifier input is not the raw query text but a reformulated description of the\nunderlying intent, enriched with context such as prior queries in the same conversation and the\nwebsite on which the query was made. Lastly, all results reported in the paper are presented only\nin a highly aggregated form.\n4\nAgentic Taxonomy\nWe develop a hierarchical agentic taxonomy guided by two principles. First, it should com-\nprehensively capture common agentic intents so that it can generalize to other agentic products\nbeyond Comet. Second, it should have a hierarchical structure that reveals higher-level goals\nwhile distinguishing specific lower-level tasks and actions.\nTo achieve these goals, we adopt a bottom-up approach consisting of three phases: exploration,\nrefinement, and classification. In the exploration phase, we draw a random sample of agentic\nqueries, extract their embeddings, and apply K-means clustering to group them based on semantic\nsimilarity. Queries are then sampled from each cluster and concatenated into a single string\nrepresenting that cluster. We then summarize each concatenated string to interpret the meaning\nof each cluster. In the refinement phase, we manually examine the cluster labels identified in the\nprevious step to merge, split, trim, or expand them, following the guiding principles. When a\nsignificant share of queries is labeled as ‚ÄúOther‚Äù, suggesting that the provided taxonomy does not\nsufficiently capture them, we re-classify the queries in that cluster using the bottom-up approach\nin the first step to identify clusters missing from the taxonomy and update it. Finally, we classify\nagentic queries within the finalized taxonomy using a query classification model.\nOur final taxonomy consists of three hierarchical levels‚Äîtopic, subtopic, and task‚Äîas illus-\ntrated in a stylized diagram in Figure 1, along with their connections to the environments the\ntasks are performed in.24 The full taxonomy is summarized in Table 1.\n23For more details on Perplexity‚Äôs privacy policy, see https://www.perplexity.ai/hub/legal/privacy-policy.\n24Queries that cannot be classified into the taxonomy at a given level are labeled as ‚ÄúOther‚Äù at that level and all subsequent levels. For\nexample, a query that does not belong to any of the topics would be labeled as ‚ÄúOther‚Äù at the topic, subtopic, and task levels; a query that belongs\nto productivity but does not belong to any of the subtopics under productivity will be labeled as ‚ÄúOther‚Äù at the subtopic and task levels; a query\nthat belongs to productivity and email management but does not belong to any of the tasks under email management will be labeled as ‚ÄúOther‚Äù\n10\n\nTopics and subtopics are top- and mid-level use cases of the agent, indicating the overall goal,\nwhile tasks are the specific tasks the agent is expected to complete to achieve that goal. Each\nquery is classified into one topic, one subtopic, and one or more tasks. For instance, the query\n‚Äúunsubscribe me from all promotional emails that I receive more than twice per month‚Äù would\nbe labeled as {Topic: Productivity & Workflow, Subtopic: Email Management, Task: Search or\nfilter emails, Delete or unsubscribe emails}.\nThe environments the agent operates in are observed in the data and can be connected to our\ntaxonomy. Tasks in a particular subtopic are performed in a specific set of environments, and\neach environment might involve one or more of these tasks. For instance, under the subtopic\nEmail Management, tasks such as Search or filter emails and Delete or unsubscribe emails can\nboth be performed in environments such as Gmail or Outlook; under Shopping for Goods, Search\ndiscounts and Make product purchase can both be performed on Instacart, whereas only Search\ndiscounts can be performed on SimplyCodes as it only shows discount codes and does not sell\nproducts directly. Furthermore, an environment might cut across multiple topics and subtopics.\nFor instance, Facebook could be the environment for Media & Entertainment queries, but also\nShopping & Commerce queries when they are about products listed on Facebook Marketplace.\nWe further categorize the usage context into personal, professional, and educational domains.\nWe validate the classification accuracy against a golden dataset of 1,000 anonymized and\ndesensitized queries. The classifier-assigned labels agree with the topics, subtopics, tasks, and\nusage context in the golden dataset 89%, 83%, 81%, and 83% of the time, respectively. More\ndetails about the validation are provided in Appendix D.\n5\nMain Results\nWe first discuss the results on the adoption (extensive margin) and usage intensity (intensive\nmargin), and then the use cases (agentic taxonomy).\n5.1\nAdoption and Usage Intensity\nWe define agent adopters as users who had at least one agentic query in the sampling period. The\nresults below are all based on Sample A, except for occupation, which is based on Sample B.\nFigure 6 in Appendix A shows that agent adoption and overall usage as measured by agentic\nquery volumes are growing steadily over the period studied, with an increased pace after Comet\nbecame generally available. About 60% of agent users were acquired, and 50% of agentic queries\noccurred post-GA. The query volumes grow at a slightly higher rate than adopters.\nWe analyze the adoption and usage patterns of user segments defined by cohort, country, and\noccupation. To capture the magnitude of adoption and usage within a user segment relative to\nits user share, we define the Perplexity Agent Adoption Ratio (AAR) and the Agent Usage Ratio\n(AUR) as the ratio of a segment‚Äôs agent adopter share or agentic query share to its user share.25\nat the task level.\n25These ratio-based metrics are often used to quantify the relative degrees of adoption and usage (e.g., Appel et al. [2025])\n11\n\nAn AAR or AUR greater than one indicates that a segment is over-represented in the adopters or\nqueries relative to their population base, and vice versa.\nBy cohort\nTable 2 shows that among the three cohorts by access dates, earlier adopters (those with access\nbefore GA) account for about 30% of total users, but about 50% of agent adopters and 70%\nof agentic queries. The disparity is more pronounced in usage intensity than in adoption‚Äîan\naverage user in the first cohort (July 9) is twice as likely to adopt the agent but makes nine times\nas many agentic queries as an average user in the GA cohort (October 2). AAR and AUR both\ndecrease in the order of access cohorts.\nIn general, the composition of early adopters is endogenous to the rollout plan; in our case, it\nis based on the subscription tiers. Nonetheless, these results are consistent with general patterns\nin the adoption and usage of new technologies [Moore, 1991]: early adopters disproportionately\ndrive initial adoption and usage, and subsequent diffusion may require additional educational\nefforts. With improved agent-to-agent collaboration capabilities and standardized protocols, one\nmight expect stronger network effects that could accelerate adoption and usage in the future.26\nCohort\nUser Share (%)\nAgent Adopter Share (%)\nAgentic Query Share (%)\nAAR\nAUR\nJuly 9\n4.3\n7.7\n18.9\n1.79\n4.40\nAugust 13\n28.3\n38.1\n48.5\n1.35\n1.71\nOctober 2\n67.4\n54.2\n32.7\n0.80\n0.49\nNote: The table shows the agent adoption and agentic query by cohort. User share is the number of users in each cohort divided by the total\nusers. Agent adopter and query share are the numbers of adopters and agentic queries in each cohort, divided by the total number of adopters\nand agentic queries. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AUR (Agent Usage Ratio) is the ratio\nbetween agentic query share and user share. AAR and AUR greater (less) than 1 indicate that a cohort is over-represented (under-represented)\nin agent adopters and queries relative to their user base.\nTable 2: Agent Adoption and Agentic Query by Cohort\nBy country\nFigure 2 and 3 show that there are strong positive correlations between log agent adopters per\nmillion population and log GDP per capita (r = 0.85, p < 0.001, R2 = 0.73) and years of\neducation (r = 0.75, p < 0.001, R2 = 0.56), where r is the correlation coefficient, p is the\np-value of the correlation coefficient, and R2 is the R-squared of the regression lines.\nThe\ncorrelations between log agentic queries per million population and log GDP per capita (r =\n0.86, p < 0.001, R2 = 0.74) and years of education (r = 0.75, p < 0.001, R2 = 0.57) follow a\nsimilar pattern. Together, they suggest that relatively more economically developed and educated\ncountries tend to adopt and use the agent more.27\n26For instance, Agent2Agent Protocol (A2A). https://a2a-protocol.org/latest/.\n27Results remain consistent when population is replaced with working population.\n12\n\n(a) Log GDP Per Capita vs. Log Agent Adopters Per Million Population\n(b) Average Years of Education vs.\nLog Agent Adopters Per Million Population\nNote: The plots show the scatterplots and best-fitting lines of log GDP per capita and average years of education vs. the log of agent adopter per\nmillion population for the top 100 countries by agent adopter count. The plots are on a log scale, but the labels are in absolute values for better\nreadability. Jitter is applied to the country labels to provide better visual separation. r is the correlation coefficient, p is the p-value of the\nregression coefficient, and R2 is the R-squared of the regression lines. The GDP and population data are from World Bank World Development\nIndicators (2024)a and the average years of education data are from UNDP Human Development Report (2024)b.\nahttps://data.worldbank.org/\nbhttps://hdr.undp.org/content/human-development-report-2023-24\nFigure 2: Log GDP Per Capita and Average Years of Education vs.\nLog Agent Adopters Per Million Population by Country\n13\n\n(a) Log GDP Per Capita vs. Log Agentic Queries Per Million Population\n(b) Average Years of Education vs.\nLog Agentic Queries Per Million Population\nNote: The plots show the scatterplots and best-fitting lines of log GDP per capita and average years of education vs. the log of agentic query per\nmillion population for the top 100 countries by agentic query count. The plots are on a log scale, but the labels are in absolute values for better\nreadability. Jitter is applied to the country labels to provide better visual separation. r is the correlation coefficient, p is the p-value of the\nregression coefficient, and R2 is the R-squared of the regression lines. The GDP and population data are from World Bank World Development\nIndicators (2024)a, and the average years of education data are from UNDP Human Development Report (2024)b\nahttps://data.worldbank.org/\nbhttps://hdr.undp.org/content/human-development-report-2023-24\nFigure 3: Log GDP Per Capita and Average Years of Education vs.\nLog Agentic Queries Per Million Population by Country\n14\n\nBy occupation\nTable 3 ranks occupation clusters (including the student cluster) by user share, adopter share,\nand AAR. Digital technology is by far the largest cluster, accounting for 28% of adopters,\nslightly higher than its user share. Academics (including the student and education clusters) and\nfinancial workers have an adopter share of more than 10%. Workers in marketing, design, and\nentrepreneurship have an adopter share of more than 5%. Clusters with lower adopter shares\nare typically those that require interacting with the physical environment. The hospitality cluster\nhas the highest AAR at 1.36, although the sample size is significantly smaller; it is followed by\nmarketing and entrepreneurship at 1.24 and 1.17, respectively.\nTable 4 ranks occupation clusters by user share, query share, and AUR. The patterns track\nadoption closely‚Äîtop clusters remain the same with slight changes in the rank. Comparing the\nAUR and AAR for the same cluster reveals patterns in the degree of usage intensity relative to the\ndegree of adoption: students and workers in entrepreneurship, marketing, and digital technology\nall have AUR / AAR greater than one, suggesting that their tendency to use the agent conditional\non adoption is even stronger than their tendency to adopt.\nTables 8 and 9 in Appendix A show the top ten occupation subclusters and their user shares\nby agent adopter shares and AAR, and agentic query share and AUR, respectively. Patterns at\nthe subcluster level are largely consistent with those at the cluster level, with software engineers\nbeing the largest subcluster, accounting for 14% of adopters and 15% of queries, and having AAR\nand AUR around 1.1 and 1.2, respectively. All other subclusters are below 6% in both adopter\nand query shares. Subclusters in marketing‚Äîsuch as business development and sales, digital\nmarketing, and market research‚Äîand in entrepreneurship‚Äîsuch as information management,\noperations, and strategy‚Äîtend to have the highest AAR and AUR.\nThese results may reflect differences in the task composition of each occupation and how\nclosely those tasks align with common agent use cases, which the next section examines.\n15\n\nAgent Adoption by Occupation Cluster: By AAR\nCluster\nUser Share (%)\nUser Share Rank\nAgent Adopter Share (%)\nAgent Adopter Share Rank\nAAR\nHospitality, Events, & Tourism\n2.5\n11\n3.4\n9\n1.36\nMarketing & Sales\n7.2\n6\n8.9\n4\n1.24\nManagement & Entrepreneurship\n6.5\n7\n7.6\n6\n1.17\nDigital Technology\n26.4\n1\n27.7\n1\n1.05\nSupply Chain & Transportation\n2.2\n13\n2.3\n12\n1.05\nFinancial Services\n10.0\n3\n10.1\n3\n1.01\nStudent\n12.4\n2\n12.4\n2\n1.00\nConstruction\n2.3\n12\n2.2\n13\n0.96\nEnergy & Natural Resources\n0.9\n14\n0.8\n14\n0.89\nArts, Entertainment, & Design\n9.1\n4\n8.0\n5\n0.88\nEducation\n7.7\n5\n6.4\n7\n0.83\nHealthcare & Human Services\n4.9\n8\n4.0\n8\n0.82\nAdvanced Manufacturing\n3.5\n9\n2.8\n10\n0.80\nPublic Service & Safety\n3.4\n10\n2.7\n11\n0.79\nAgriculture\n0.9\n15\n0.7\n15\n0.78\nNote: The table shows agent adoption by O*NET occupation cluster. The ‚ÄúOther‚Äù category is removed. We put students in a separate cluster and\neducators in the Education cluster. User share is the number of users in each cluster divided by the total users. Agent adopter share is the number of\nadopters in each cluster divided by the total adopters. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AAR\ngreater (less) than 1 indicates that a cluster is over-represented (under-represented) in agent adoption relative to their user base.\nTable 3: Agent Adoption by Occupation Cluster\nAgentic Query by Occupation Cluster: By AUR\nCluster\nUser Share (%)\nUser Share Rank\nAgentic Query Share (%)\nAgentic Query Share Rank\nAUR\nMarketing & Sales\n7.2\n6\n10.5\n3\n1.46\nManagement & Entrepreneurship\n6.5\n7\n9.0\n4\n1.38\nStudent\n12.4\n2\n15.6\n2\n1.26\nDigital Technology\n26.4\n1\n29.6\n1\n1.12\nHospitality, Events, & Tourism\n2.5\n11\n2.6\n9\n1.04\nSupply Chain & Transportation\n2.2\n13\n2.0\n10\n0.91\nFinancial Services\n10.0\n3\n8.6\n5\n0.86\nArts, Entertainment, & Design\n9.1\n4\n6.9\n6\n0.76\nEducation\n7.7\n5\n5.6\n7\n0.73\nConstruction\n2.3\n12\n1.6\n13\n0.70\nHealthcare & Human Services\n4.9\n8\n3.3\n8\n0.67\nAgriculture\n0.9\n15\n0.5\n15\n0.56\nEnergy & Natural Resources\n0.9\n14\n0.5\n14\n0.56\nAdvanced Manufacturing\n3.5\n9\n1.9\n11\n0.54\nPublic Service & Safety\n3.4\n10\n1.8\n12\n0.53\nNote: The table shows usage intensity by O*NET occupation cluster. The ‚ÄúOther‚Äù category is removed. We put students in a separate cluster and\neducators in the Education cluster. User share is the number of users in each cluster divided by the total users. Agent query share is the number of\nagentic queries in each cluster divided by the total agentic queries. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share.\nAUR greater (less) than 1 indicates that a cluster is over-represented (under-represented) in agent usage relative to their user base.\nTable 4: Agentic Query by Occupation Cluster\n16\n\n5.2\nUse Cases\nWe document the use cases by topic, subtopic, task, environment (the websites on which the tasks\nare performed), and usage context. All results are based on Sample C.\nTopics and subtopics\nTopics and subtopics capture the high-level goals of an agentic query. Figure 4 presents the topic\nshare and subtopic share breakdown by topic. Productivity is the largest category, accounting for\n36% of all agentic queries. Learning, media, and shopping are the other topics with over 10%\nquery share. The two largest topics‚Äîproductivity and learning‚Äîtogether account for 57% of\nall queries. Some topics, such as learning, shopping, and career, have a dominant subtopic that\naccounts for more than half of the queries in that topic. Table 10 in Appendix A also shows the\noverall query share of each subtopic. Courses account for 13% of all queries, followed by goods\nshopping, document editing, account management, social media, and email.\nNote: The plot shows the percentage shares of subtopics within each topic. Bar width is proportional to topic percentage, and box height within\neach bar is proportional to subtopic percentage. ‚ÄúOther‚Äù category (3.4%) is not shown among the topics. The labels for subtopics that account\nfor less than 5% within a topic are suppressed. Topic shares are shown in the labels on the x-axis. The subtopics within each topic are sorted by\npercentage in decreasing order from top to bottom. The darker shades within a topic represent subtopics with higher percentages.\nFigure 4: Topic Breakdown by Subtopic Percentage\n17\n\nTable 5 shows the topic distribution by occupation cluster. Topic-wise, productivity remains\nthe largest topic for most occupations, whereas learning and research is the largest for students\nand educators, and travel is the largest for the hospitality cluster. Occupation-wise, workers in\nfinance have the largest query share in productivity, students have the largest share in learning,\ndesigners have the largest share in media, workers in advanced manufacturing have the largest\nshare in shopping, workers in entrepreneurship have the largest share in career, and workers in\nhospitality have the largest share in travel.\nCluster / Topic\nProductivity &\nLearning &\nMedia &\nShopping &\nJob &\nTravel &\nWorkflow (%)\nResearch (%)\nEntertainment (%)\nCommerce (%)\nCareer (%)\nLeisure (%)\nDigital Technology\n41.0\n19.9\n14.7\n9.3\n9.1\n6.0\nStudent\n29.1\n43.3\n10.6\n5.3\n8.1\n3.7\nManagement & Entrepreneurship\n45.8\n13.7\n12.3\n9.8\n12.2\n6.2\nMarketing & Sales\n37.5\n12.1\n23.8\n14.0\n8.2\n4.5\nFinancial Services\n46.7\n15.2\n14.0\n9.8\n5.7\n8.6\nEducation\n34.1\n37.0\n13.8\n6.6\n2.6\n5.8\nArts, Entertainment, & Design\n39.4\n12.1\n25.0\n11.3\n6.0\n6.2\nHealthcare & Human Services\n38.6\n23.3\n14.3\n10.2\n5.9\n7.7\nAdvanced Manufacturing\n30.4\n19.8\n11.8\n25.4\n5.4\n7.1\nPublic Service & Safety\n39.7\n26.2\n17.7\n7.2\n3.2\n6.0\nHospitality, Events, & Tourism\n29.9\n6.6\n13.4\n12.2\n2.7\n35.2\nSupply Chain & Transportation\n40.3\n13.4\n12.5\n18.6\n5.3\n10.0\nConstruction\n39.1\n14.9\n14.1\n16.3\n7.7\n7.9\nEnergy & Natural Resources\n42.9\n18.8\n13.1\n10.4\n4.9\n9.8\nAgriculture\n41.5\n20.5\n13.9\n12.4\n5.4\n6.3\nNote: The table shows the distribution of topics by occupation cluster. Topic percentage (P(Topic | Occupation)) is\nthe topic share among all agentic queries from a given occupation cluster. Percentages may not sum to 100% due to\nrounding.\nTable 5: Topic Distribution by Occupation Cluster\nWe also examine transition patterns between consecutive queries. Figure 7 in Appendix A\nshows the transition probability matrix from the previous query to the next query for all query\npairs, aggregated at the user level. The results show that in most cases, topics transition into\nthemselves, suggesting the stickiness of agent use cases. Productivity, learning, and career topics\nare the most sticky, whereas travel is the least sticky; media and shopping topics fall in between.\nWhen cross-topic transitions occur, they most likely transition into productivity, learning, or\nmedia topics. Then we compare users‚Äô first queries‚Äîtheir entry points into the agent‚Äîand all\nqueries. Figure 8 in Appendix A contrasts the topic distribution among the first agentic query for\neach user with the overall distribution. Over time, the share of queries on productivity, learning,\nand career topics has increased, suggesting a shift toward more cognitively oriented use cases.\nTasks\nTasks under topics and subtopics capture the low-level tasks the agent is expected to complete\nto achieve the end goals. We show the top ten tasks in Table 6. Half of the top ten are in\nlearning, including various learning and research assistance.\nThe other five are split across\nproductivity (edit documents and manage account settings), shopping (search or summarize\nproduct information), and media (search social media).\n18\n\nTopic\nSubtopic\nTask\nOverall (%)\nLearning & Research\nCourses\nAssist exercises\n9.41\nLearning & Research\nResearch\nSummarize/analyze research information\n6.71\nProductivity & Workflow\nDocument & Form Editing\nCreate/edit documents/forms\n6.58\nShopping & Commerce\nGoods\nSearch/filter products\n6.43\nLearning & Research\nResearch\nSearch/filter research information\n5.95\nShopping & Commerce\nGoods\nSummarize/analyze product information\n5.18\nProductivity & Workflow\nAccount Management\nManage settings/profiles\n4.33\nLearning & Research\nCourses\nSummarize/analyze course materials\n3.69\nLearning & Research\nCourses\nNavigate courses\n3.31\nMedia & Entertainment\nSocial Media & Messaging\nSearch/filter social media posts/messages\n3.29\nNote: The table shows the top 10 tasks among all agentic queries. P(Task Overall) = P(Topic, Subtopic, Task) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Task | Topic, Subtopic).\nTable 6: The Top 10 Tasks\nTables 11, 12, 13, 14, 15, and 16 in Appendix A show the main tasks under each topic and\nsubtopic with over 5% query shares within a subtopic. Note that because query share measures\nthe fraction of queries in which a task is present and a query might contain multiple tasks, the\ntask percentages under each subtopic can add up to over 100. A few subtopics contain a dominant\ntask that appears in over 80% of all queries in that subtopic. For instance, searching for flights\nand lodging both appear in 93% of queries in the flight and lodging subtopics; editing documents\nand summarizing research information both appear in 85% of queries in the document editing\nand research subtopics, respectively.\nIn contrast, some subtopics show more dispersed task\ndistributions: for instance, searching videos‚Äîthe top task in the video subtopic‚Äîappears in only\n48% of all queries in that category; searching email‚Äîthe top task in the email subtopic‚Äîappears\nin only 49% of all queries in that category.\nTable 17 in Appendix A shows the top five tasks in each occupation cluster. In general,\nresearch, document editing, and shopping-related tasks appear consistently across clusters. Some\noccupation clusters feature a prominent task. For instance, search products appear in 21% of\nqueries from the advanced manufacturing cluster. Other clusters, in contrast, have a more diffuse\ntask composition.\nThe top tasks in the entrepreneurship and design clusters‚Äîsummarizing\nresearch information and searching products‚Äîappear in fewer than 8% of their queries. The\ntop tasks by occupation also shed light on why certain occupations tend to adopt and use the\nagent more. Knowledge-intensive sectors such as digital technology, entrepreneurship, finance,\nand academia tend to use the agent for research and learning-related tasks. In contrast, highly\ndigitized sectors such as marketing and design tend to use the agent for media-related tasks.\nEnvironments\nEnvironment refers to the external world with which the agent interacts while performing a task\nto achieve its goals. In our context, the environment is the specific website on which the agent\noperates for a given query. We show the top environments by overall query shares in Table 7. The\ntop 10 environments together account for 63% of queries; they are typically the leading websites\nin their corresponding domains.\nWe break down the top five environments under each subtopic and their query shares in Tables\n18, 19, 20, 21, 22, and 23 in Appendix A. A single environment dominates some subtopics.\n19\n\nFor instance, linkedin.com alone accounts for 93% of queries in professional networking, and\nthe query shares of youtube.com and docs.google.com28‚Äîthe top environments in video and\nspreadsheet editing subtopics‚Äîare more than twenty times larger than the share of the second\nenvironments in those subtopics. On the other hand, there is only a 2% difference between\ncoursera.org and netacad.com under courses, and a 3% difference between instagram.com and\nx.com under social media. Table 24 in Appendix A shows the combined shares of the top five\nenvironments in each subtopic. A higher share indicates the agent usage is more concentrated in\na few environments. The level of concentration varies significantly: the top five environments\naccount for 97% of queries in music, 97% in videos, and 96% in professional networking,\ncompared to only 28% in account management, 35% in services shopping, and 37% in project\nmanagement, respectively. Lastly, Table 25 in Appendix A shows the top 5 environments for each\noccupation cluster, which are closely related to the main use cases for each occupation.\nEnvironment\nOverall (%)\ndocs.google.com\n11.97\nemail services combined\n11.23\nlinkedin.com\n9.42\nyoutube.com\n7.03\namazon.com\n3.46\ninstagram.com\n2.56\nmessenger services combined\n2.47\nmaps.google.com\n2.20\ncoursera.org\n2.04\nx.com\n2.00\ngithub.com\n1.85\nfacebook.com\n1.77\nnetacad.com\n1.75\ncanva.com\n1.49\ncanvas.com\n1.44\nnotion.so\n1.13\nNote: The table shows all environments with a query share\nabove 1% among all agentic queries. docs.google.com in-\ncludes Google Docs, Sheets, Slides, and Forms. All email\ndomains are grouped into ‚Äúemail services combined‚Äù and\nall online messengers are grouped into ‚Äúmessenger services\ncombined‚Äù.\nTable 7: Top Agent Environments\n28docs.google.com includes Google Docs, Sheets, Slides, and Forms.\n20\n\nUsage context\nLastly, we investigate agent usage across personal, professional, and educational contexts.29\nPersonal use comprises about 55% of total agentic queries, with professional and educational\ncontexts representing 30% and 16%, respectively. There is a slight increase in the share of\neducational use and a slight decrease in the share of personal use over time, while the share\nof professional use remains stable. This could be driven by the public launch time of Comet\noverlapping with the start of the fall semester and by on-campus promotional efforts, such as early\naccess for university students, rather than by a systematic shift in the underlying composition of\nuser groups and use cases.\nWe show the distribution of topics by usage context in Figure 5. For personal use, produc-\ntivity and media together account for 62% of all agentic queries. For professional use, 80% of\nagentic queries are productivity- and career-related. Educational usage is dominated by learn-\ning, comprising 89% of agentic queries. We also show the distribution of subtopic, task, and\nenvironment by usage context in Tables 26, 27, and 28 in Appendix A. The top subtopics for\npersonal, professional, and educational use are goods shopping, document editing, and courses,\nrespectively. The top environments for personal, professional, and educational use are emails,\nlinkedin.com, and docs.google.com, respectively.\nNote: The plot shows the percentage shares of topics within each usage context. The ‚ÄúOther‚Äù category is removed from contexts. Bar width is\nproportional to context percentage, and box height within each bar is proportional to topic percentage. The labels for topics that account for less\nthan 5% within a context are suppressed. Context shares are shown in the x-axis labels. The same topic is shown in the same color across\ncontexts. The topic percentage overall is shown as a baseline for comparison. The topics within each context are sorted in the same order as the\noverall for easier comparison across contexts. The topics in the overall category are sorted by topic percentage, from highest to lowest.\nFigure 5: Topic Distribution by Usage Context\n29Note that our use case taxonomy is orthogonal mainly to the usage context. For instance, a user may ask the agent to reply to an email\nfrom a friend (personal), a colleague (professional), or a professor (educational). Similarly, users may ask the agent to shop for personal items,\nworkplace equipment, or school supplies.\n21\n\n6\nDiscussion\nOur paper provides the first systematic evidence on the adoption, usage intensity, and use cases of\ngeneral-purpose AI agents, based on large-scale behavioral data from Comet by Perplexity. Our\nfindings reveal substantial differences in the propensity to adopt and use the agent across user\nsegments. Earlier adopters, users in countries with higher GDP per capita and higher average\nyears of education, and individuals working in more digital or knowledge-intensive fields‚Äîsuch\nas digital technology, academia, finance, marketing, and entrepreneurship‚Äîtend to adopt and\nuse the agent more actively. Agent use cases span a broad range of categories. The two largest\ntopics‚Äîproductivity and learning‚Äîtogether comprise 57% of all agentic queries. The two largest\nsubtopics‚Äîcourses and goods shopping‚Äîtogether account for 22% of all agentic queries. The\ntop 10 out of 90 tasks represent 55% of all agentic queries. We also document heterogeneity in use\ncases across occupation clusters, reflecting the degree to which they align with each occupation‚Äôs\ntask composition. Topics such as productivity, learning, and career exhibit higher stickiness,\nas users are more likely to make consecutive queries within these categories. Over time, users\nalso shift toward more cognitively oriented tasks. In addition, the environments in which agentic\nqueries are made show significant variation in concentration across topics and subtopics.\nAlthough our paper is primarily descriptive and does not make normative claims or directly\nexamine downstream impacts, its methods and findings offer valuable implications for researchers,\nbusinesses, policymakers, and educators. For researchers, we contribute to a nascent but rapidly\nexpanding literature on the adoption and usage of LLMs and AI agents, and our agentic taxonomy\nprovides a structure for future analysis to build on and extend. For firms developing AI agents,\nour results offer guidance on target user segments and high-frequency use cases. For businesses\nthat provide the environments in which agents operate, our findings suggest opportunities to\nstreamline interfaces to better serve users interacting with AI agents. For both policymakers and\neducators, a central concern is that uneven adoption and usage of AI agents could exacerbate\nexisting productivity and learning disparities. Consequently, equipping citizens and students with\nthe skills to leverage AI agents effectively and preparing them for a near future in which such\nagents are embedded in work and everyday life will become increasingly important.\nWe note a few important caveats of our dataset. First, because Comet is a new product,\nour sample primarily reflects early adopters, who may skew toward more tech-savvy users. We\ncharacterize these early adopters using an internal survey in Appendix C. Relatedly, given the short\ntime span of our data, we do not systematically investigate changes in usage patterns over time,\nand any longitudinal results should be interpreted within this context. Second, the classification\nof an agentic query depends on internal query understanding modules that trigger the agent based\non predicted query intent. These intent predictors show high prediction accuracy in internal\nvalidation studies; nonetheless, the data may include both false positives (when a non-agentic\nintent triggers the agent) and false negatives (when an agentic intent does not trigger the agent).30\n30Two sets of classifiers determine agent activation: one for browser control and one for specific apps. The browser control classifier is a\nsupervised model trained on user queries labeled as either showing or not showing agentic intent. Five features are used for prediction: the current\nquery, the currently viewed page, the user‚Äôs previous queries in the same conversation, enabled connectors, and the number of attachments. The\nclassifier achieves an ROC-AUC of 0.95 and both precision and recall of 0.90 at the optimal threshold. Each connector additionally has its own\nclassifier, following a similar process.\n22\n\nSimilarly, the classification into our agentic taxonomy, usage context, and occupation clusters\nalso contains noise. Third, although AI agents‚Äô autonomy and task horizons continue to expand,\nour results should not be interpreted as suggesting any particular balance between automation\nand augmentation in use cases. For instance, an agentic session may appear to be automation,\nbut users may be breaking a task into smaller pieces and delegating only some subtasks to the\nagent, which is closer to an augmentation case. A comprehensive treatment on such a topic would\nrequire having a complete picture of how users manage their workflows outside of Comet.\nThere are several natural extensions to this study that we aim to pursue. First, with the\nexpansion of Comet to mobile devices and other environments, it will be valuable to document\ncross-platform differences in how users interact with AI agents.31 In particular, whereas agentic\nqueries on desktops are predominantly text-based, the voice-to-voice mode on mobile may offer\na more natural interface. Second, while our sample does not capture enterprise users directly, the\nsubstantial share of professionally-oriented agentic queries suggests the need for complementary\nresearch on related topics in organizational settings. Third, the adoption and usage of AI agents\nis closely tied to their performance across tasks; we plan to investigate agent evaluation, common\nfailure modes, and strategies for improvement. Fourth, identifying which tasks are best suited\nfor delegation to the agent and designing optimal human-agent collaborative workflows are\nalso important questions.\nFor example, tasks that users can easily complete manually may\nnot warrant delegation. High-stakes or irreversible tasks might require exceptionally reliable\nagent performance, a high degree of user trust, and increased human supervision.\nFifth, in\naddition to awareness and performance, another key barrier to adoption and use is measuring and\nsubstantiating value and impact; we seek to quantify the economic value users derive from agent\nuse, an essential dimension of the downstream impact of AI agents.\nGeneral-purpose AI agents represent one of the most consequential technological advance-\nments of our time. Understanding their real-world adoption and usage with large-scale behavioral\ndata has become both urgent and essential for informing their development and deployment. We\nhope this work catalyzes further investigation in this rapidly evolving domain.\n31The Android version of Comet was launched to everyone worldwide on November 20, 2025, with the iOS version scheduled to be released\nin December 2025. https://www.perplexity.ai/hub/blog/comet-for-android-is-here\n23\n\nReferences\nA. Allouah, O. Besbes, J. D. Figueroa, Y. Kanoria, and A. Kumar. What Is Your AI Agent\nBuying? Evaluation, Implications, and Emerging Questions for Agentic E-Commerce. arXiv\npreprint arXiv:2508.02630, 2025.\nAnthropic. Project Vend: Can Claude Run a Small Shop? (And Why Does That Matter?), 2025a.\nURL https://www.anthropic.com/research/project-vend-1.\nAnthropic. Anthropic Economic Index: AI‚Äôs Impact on Software Development, 2025b. URL\nhttps://www.anthropic.com/research/impact-software-development.\nR. Appel, P. McCrory, A. Tamkin, M. Stern, M. McCain, and T. Neylon. Anthropic Economic\nIndex Report: Uneven Geographic and Enterprise AI Adoption, 2025. URL www.anthropic.\ncom/research/anthropic-economic-index-september-2025-report.\nM. Aubakirova, A. Atallah, J. Summerville, and A. Midha. State of AI: An Empirical 100 Trillion\nToken Study with OpenRouter. Technical report, OpenRouter, 2025.\nD. Bent, K. Handa, E. Durmus, A. Tamkin, M. McCain, S. Ritchie, R. Donegan, J. Martinez, and\nJ. Jones. Anthropic Education Report: How Educators Use Claude, 2025. URL https://www.\nanthropic.com/news/anthropic-education-report-how-educators-use-claude.\nA. Bick, A. Blandin, and D. J. Deming. The Rapid Adoption of Generative AI. Technical report,\nNational Bureau of Economic Research, 2024.\nE. Brynjolfsson, D. Li, and L. Raymond. Generative AI at Work. The Quarterly Journal of\nEconomics, 140(2):889‚Äì942, 2025.\nA. Chatterji, T. Cunningham, D. J. Deming, Z. Hitzig, C. Ong, C. Y. Shan, and K. Wadman. How\nPeople Use ChatGPT. Technical report, National Bureau of Economic Research, 2025.\nZ. K. Cui, M. Demirer, S. Jaffe, L. Musolff, S. Peng, and T. Salz. The Effects of Generative AI\non High-Skilled Work: Evidence from Three Field Experiments with Software Developers.\nAvailable at SSRN 4945566, 2025.\nF. Dell‚ÄôAcqua, E. McFowland III, E. R. Mollick, H. Lifshitz-Assaf, K. Kellogg, S. Rajendran,\nL. Krayer, F. Candelon, and K. R. Lakhani. Navigating the Jagged Technological Frontier: Field\nExperimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality.\nHarvard Business School Technology & Operations Mgt. Unit Working Paper, (24-013), 2023.\nG. K. Hadfield and A. Koh. An Economy of AI Agents. arXiv preprint arXiv:2509.01063, 2025.\nK. Handa, D. Bent, A. Tamkin, M. McCain, E. Durmus, M. Stern, M. Schiraldi, S. Huang,\nS. Ritchie, S. Syverud, K. Jagadish, M. Vo, M. Bell, and D. Ganguli. Anthropic Education\nReport: How University Students Use Claude, 2025a. URL https://www.anthropic.com/\nnews/anthropic-education-report-how-university-students-use-claude.\n24\n\nK. Handa, M. Stern, S. Huang, J. Hong, E. Durmus, M. McCain, G. Yun, A. Alt, T. Millar,\nA. Tamkin, J. Leibrock, S. Ritchie, and D. Ganguli. Introducing Anthropic Interviewer: What\n1,250 Professionals Told Us About Working with AI, 2025b. URL https://anthropic.\ncom/research/anthropic-interviewer.\nK. Handa, A. Tamkin, M. McCain, S. Huang, E. Durmus, S. Heck, J. Mueller, J. Hong, S. Ritchie,\nT. Belonax, et al. Which Economic Tasks Are Performed with AI? Evidence from Millions of\nClaude Conversations. arXiv preprint arXiv:2503.04761, 2025c.\nA. Humlum and E. Vestergaard.\nThe Unequal Adoption of ChatGPT Exacerbates Existing\nInequalities Among Workers.\nProceedings of the National Academy of Sciences, 122(1):\ne2414972121, 2025.\nH. Ju and S. Aral. Collaborating with AI Agents: Field Experiments on Teamwork, Productivity,\nand Performance. arXiv preprint arXiv:2503.18238, 2025.\nA. Merali. Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted\nTranslation. arXiv preprint arXiv:2409.02391, 2024.\nG. A. Moore. Crossing the Chasm: Marketing and Selling High-Tech Products to Mainstream\nCustomers. HarperBusiness, New York, 1991.\nS. Noy and W. Zhang. Experimental Evidence on the Productivity Effects of Generative Artificial\nIntelligence. Science, 381(6654):187‚Äì192, 2023.\nM. Z. Pan, N. Arabzadeh, R. Cogo, Y. Zhu, A. Xiong, L. A. Agrawal, H. Mao, E. Shen, S. Pallerla,\nL. Patel, et al. Measuring Agents in Production. arXiv preprint arXiv:2512.04123, 2025.\nS. Peng, E. Kalliamvakou, P. Cihon, and M. Demirer. The Impact of AI on Developer Productivity:\nEvidence from GitHub Copilot. arXiv preprint arXiv:2302.06590, 2023.\nPerplexity Team.\nAgents or Bots?\nMaking Sense of AI on the Open Web, 2025.\nURL https://www.perplexity.ai/hub/blog/agents-or-bots-making-sense-of-\nai-on-the-open-web.\nD. M. Rothschild, M. Mobius, J. M. Hofman, E. W. Dillon, D. G. Goldstein, N. Immorlica, S. Jaffe,\nB. Lucier, A. Slivkins, and M. Vogel. The Agentic Economy. arXiv preprint arXiv:2505.15799,\n2025.\nS. K. Sarkar. AI Agents, Productivity, and Higher-Order Thinking: Early Evidence from Software\nDevelopment. Available at SSRN 5713646, 2025.\nE. Schluntz and B. Zhang. Building Effective Agents, 2024. URL https://www.anthropic.\ncom/engineering/building-effective-agents.\nP. Shahidi, G. Rusak, B. S. Manning, A. Fradkin, and J. J. Horton. The Coasean Singularity?\nDemand, Supply, and Market Design with AI Agents. Technical report, National Bureau of\nEconomic Research, 2025.\n25\n\nY. Shavit, S. Agarwal, M. Brundage, S. Adler, C. O‚ÄôKeefe, R. Campbell, T. Lee, P. Mishkin,\nT. Eloundou, A. Hickey, et al. Practices for Governing Agentic AI Systems. Research Paper,\nOpenAI, 2023.\nL. Vendraminelli, M. DosSantos DiSorbo, A. Hildebrandt, E. McFowland III, A. Karunakaran,\nand I. Bojinov.\nThe GenAI Wall Effect: Examining the Limits to Horizontal Expertise\nTransfer Between Occupational Insiders and Outsiders. Harvard Business School Technology\n& Operations Mgt. Unit Working Paper, (26-011):26‚Äì011, 2025.\nE. Wiles, L. Krayer, M. Abbadi, U. Awasthi, R. Kennedy, P. Mishkin, D. Sack, and F. Candelon.\nGenai as an exoskeleton: Experimental evidence on knowledge workers using genai on new\nskills. Available at SSRN 4944588, 2024.\nM. Wooldridge and N. R. Jennings. Intelligent Agents: Theory and Practice. The Knowledge\nEngineering Review, 10(2):115‚Äì152, 1995.\nS. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao. ReAct: Synergizing\nReasoning and Acting in Language Models. In The Eleventh International Conference on\nLearning Representations, 2022.\nW. Zhao, X. Ren, J. Hessel, C. Cardie, Y. Choi, and Y. Deng. WildChat: 1M ChatGPT Interaction\nLogs in the Wild. arXiv preprint arXiv:2405.01470, 2024.\n26\n\nAppendices\nA\nFigures and Tables\nA.1\nAdoption and Usage Intensity\n(a) Cumulative Agent Adopter\n(b) Cumulative Agentic Query\nNote: The plots show the cumulative number of agent adopters and agentic queries. The exact numbers on the y-axis are masked, and the\npercentages show the relative magnitude of adopters and queries relative to the end date as the baseline. Adopter and query numbers grow\nsteadily over time with a noticeable jump when Comet became generally available. The three dashed vertical lines mark the dates for the change\nin access. July 9: launch date and open to Max subscribers and selected users on a waitlist. August 13: extended access to Pro subscribers.\nOctober 2: extended access to everyone worldwide.\nFigure 6: Cumulative Agent Adopter and Agentic Query\n27\n\nAgent Adoption by Occupation Subcluster: The Top 10 Subclusters by Agent Adoption Share\nCluster\nSubcluster\nUser Share (%)\nAgent Adopter Share (%)\nAAR\nDigital Technology\nSoftware Development & Engineering\n13.0\n13.9\n1.07\nMarketing & Sales\nDigital Marketing & Social Media\n3.9\n4.7\n1.21\nDigital Technology\nIT Support & Infrastructure\n4.0\n4.3\n1.08\nArts, Entertainment, & Design\nDesign & Digital Arts\n5.0\n4.3\n0.86\nFinancial Services\nFinancial Planning & Analysis\n4.1\n4.3\n1.05\nDigital Technology\nData Science & AI\n3.9\n4.0\n1.03\nEducation\nTeaching & Instruction\n4.9\n4.0\n0.82\nFinancial Services\nFinancial Strategy & Investments\n3.8\n3.9\n1.03\nManagement & Entrepreneurship\nBusiness Information Management\n3.2\n3.8\n1.19\nManagement & Entrepreneurship\nLeadership & Operations\n2.6\n3.1\n1.19\nAgent Adoption by Occupation Subcluster: The Top 10 Subclusters by AAR\nCluster\nSubcluster\nUser Share (%)\nAgent Adopter Share (%)\nAAR\nMarketing & Sales\nBusiness Development & Sales\n1.2\n1.6\n1.33\nMarketing & Sales\nDigital Marketing & Social Media\n3.9\n4.7\n1.21\nManagement & Entrepreneurship\nBusiness Information Management\n3.2\n3.8\n1.19\nManagement & Entrepreneurship\nLeadership & Operations\n2.6\n3.1\n1.19\nMarketing & Sales\nMarket Research, Analytics, & Ethics\n1.1\n1.3\n1.18\nManagement & Entrepreneurship\nStrategy & Consulting\n2.2\n2.5\n1.14\nSupply Chain & Transportation\nPlanning & Logistics\n1.1\n1.2\n1.09\nDigital Technology\nIT Support & Infrastructure\n4.0\n4.3\n1.08\nDigital Technology\nSoftware Development & Engineering\n13.0\n13.9\n1.07\nMarketing & Sales\nBrand Management & Strategy\n1.4\n1.5\n1.07\nNote: The tables show the top 10 O*NET occupation subclusters by adoption. The ‚ÄúOther‚Äù category is removed. When a user appears in\nmultiple subclusters, their data is used in all relevant subclusters. User share is the number of users in each subcluster divided by the total\nusers. Agent adopter share is the number of adopters in each subcluster, divided by the total number of adopters. AAR (Agent Adoption\nRatio) is the ratio between agent adopter share and user share. AAR greater (less) than 1 indicates that a subcluster is over-represented\n(under-represented) in agent adoption relative to their user base. AAR rank is among the subclusters with a user share over 1%.\nTable 8: Agent Adoption by Occupation Subcluster\n28\n\nAgentic Query by Occupation Subcluster: The Top 10 Subclusters by Agentic Query Share\nCluster\nSubcluster\nUser Share (%)\nAgentic Query Share (%)\nAUR\nDigital Technology\nSoftware Development & Engineering\n13.0\n15.4\n1.18\nMarketing & Sales\nDigital Marketing & Social Media\n3.9\n5.9\n1.51\nDigital Technology\nIT Support & Infrastructure\n4.0\n5.3\n1.32\nManagement & Entrepreneurship\nBusiness Information Management\n3.2\n4.7\n1.47\nFinancial Services\nFinancial Planning & Analysis\n4.1\n3.9\n1.05\nDigital Technology\nData Science & AI\n3.9\n3.9\n1.00\nManagement & Entrepreneurship\nLeadership & Operations\n2.6\n3.9\n1.50\nArts, Entertainment, & Design\nDesign & Digital Arts\n5.0\n3.8\n0.76\nEducation\nTeaching & Instruction\n4.9\n3.6\n0.73\nFinancial Services\nFinancial Strategy & Investments\n3.8\n3.9\n1.03\nAgentic Query by Occupation Subcluster: The Top 10 Subclusters by AUR\nCluster\nSubcluster\nUser Share (%)\nAgentic Query Share (%)\nAUR\nMarketing & Sales\nBusiness Development & Sales\n1.2\n2.1\n1.75\nMarketing & Sales\nDigital Marketing & Social Media\n3.9\n5.9\n1.51\nManagement & Entrepreneurship\nLeadership & Operations\n2.6\n3.9\n1.50\nManagement & Entrepreneurship\nBusiness Information Management\n3.2\n4.7\n1.47\nMarketing & Sales\nBrand Management & Strategy\n1.4\n1.9\n1.36\nManagement & Entrepreneurship\nStrategy & Consulting\n2.2\n3.0\n1.36\nDigital Technology\nIT Support & Infrastructure\n4.0\n5.3\n1.32\nMarketing & Sales\nMarket Research, Analytics, & Ethics\n1.1\n1.4\n1.27\nDigital Technology\nSoftware Development & Engineering\n13.0\n15.4\n1.18\nSupply Chain & Transportation\nPlanning & Logistics\n1.1\n1.1\n1.00\nNote: The tables show the top 10 O*NET occupation subclusters by usage intensity. The ‚ÄúOther‚Äù category is removed. When a user\nappears in multiple subclusters, their data is used in all relevant subclusters. User share is the number of users in each subcluster divided\nby the total users. Agent query share is the number of agentic queries in each subcluster divided by the total agentic queries. AUR\n(Agent Usage Ratio) is the ratio between agentic query share and user share. AUR greater (less) than 1 indicates that a subcluster is\nover-represented (under-represented) in agent usage relative to their user base. AUR rank is among the subclusters with a user share over\n1%.\nTable 9: Agentic Query by Occupation Subcluster\n29\n\nA.2\nUse Cases\nA.2.1\nTopics and Subtopics\nTopic\nTopic (%)\nSubtopic\nSubtopic (%)\nOverall (%)\nProductivity & Workflow\n36.2\nDocument & Form Editing\n21.5\n7.78\nAccount Management\n20.5\n7.43\nEmail Management\n15.8\n5.73\nSpreadsheet & Data Editing\n11.1\n4.01\nComputer Programming\n10.3\n3.73\nInvestments & Banking\n6.2\n2.25\nMultimedia Editing\n6.1\n2.22\nProject Management\n5.1\n1.85\nCalendar Management\n2.5\n0.91\nOther\n0.8\n0.30\nLearning & Research\n20.8\nCourses\n61.9\n12.86\nResearch\n37.9\n7.88\nOther\n0.2\n0.04\nMedia & Entertainment\n15.8\nSocial Media & Messaging\n42.4\n6.69\nMovies, TV, & Videos\n20.1\n3.17\nOnline Games\n19.6\n3.08\nMusic & Podcasts\n10.7\n1.68\nNews\n3.8\n0.59\nSports\n2.7\n0.42\nOther\n0.8\n0.13\nShopping & Commerce\n10.0\nGoods\n89.0\n8.94\nServices\n10.3\n1.03\nOther\n0.7\n0.07\nJob & Career\n7.1\nProfessional Networking\n50.1\n3.56\nJob Search & Application\n49.5\n3.52\nOther\n0.4\n0.03\nTravel & Leisure\n6.7\nFlights & Transportation\n40.7\n2.73\nLodging\n27.3\n1.83\nTrip Itineraries\n24.8\n1.66\nRestaurants\n5.7\n0.38\nOther\n1.5\n0.10\nOther\n3.4\nOther\n100.0\n3.42\nNote: The table shows the distribution of topics and subtopics. The topic percentage (P(Topic)) is the\ntopic‚Äôs share among all agentic queries.\nSubtopic percentage (P(Subtopic | Topic)) is the percentage\nof a subtopic within a topic. Overall percentage (P(Subtopic) = P(Topic, Subtopic) = P(Topic) √ó\nP(Subtopic | Topic)) is the subtopic share among all agentic queries. Percentages may not sum to 100%\ndue to rounding.\nTable 10: Topic and Subtopic Distribution\n30\n\nNote: The plot shows the transition matrix from the previous query to the following query, aggregated from the user level. Most query topics\ntransition into themselves (the off-diagonal). Other than themselves, topics are most likely to transition into Productivity & Workflow (the first\ncolumn). Productivity & Workflow, Learning & Research, and Job & Career are the most sticky with the highest self-transition probabilities.\nWhereas Travel & Leisure is the least sticky, and Media & Entertainment and Shopping & Commerce are in between. The steady state\nprobability distribution based on this transition matrix and the observed share are closely matched‚Äî39% vs 37% respectively for Productivity &\nWorkflow, 24% vs 22% for Learning & Research, 16% vs. 16% for Media & Entertainment, 10% vs. 10% for Shopping & Commerce, 7% vs\n7% for Job & Career, and 7% vs 7% for Travel & Leisure. Note that to be aligned with the transition matrix, the observed shares used here do\nnot include the ‚ÄúOther‚Äù category in Table 10; the shares used here are based on the topic shares in that table divided by 0.96.\nFigure 7: Topic Transition Matrix: Previous vs. Next Agentic Query\n31\n\nNote: The plot shows the distribution of topics among users‚Äô first agentic queries versus all agentic queries. Over time, the query shares are\nshifting from Travel & Leisure, and Media & Entertainment to Productivity & Workflow, Learning & Research, and Job & Career. Shopping &\nCommerce share stays relatively stable.\nFigure 8: Topic Distribution by First vs. All Agentic Queries\n32\n\nA.2.2\nTasks\nTopic\nSubtopic\nTask\nTask (%)\nOverall (%)\nProductivity & Workflow\n(36.2)\nDocument & Form Editing\n(21.5)\nCreate/edit documents/forms\n84.6\n6.58\nSummarize/analyze documents/forms\n24.1\n1.87\nSearch/filter documents/forms\n11.4\n0.89\nAccount Management\n(20.5)\nManage settings/profiles\n58.3\n4.33\nRegister/log in to accounts\n31.2\n2.32\nSummarize/analyze account information\n24.0\n1.79\nManage files\n15.8\n1.18\nEmail Management\n(15.8)\nSearch/filter emails\n49.1\n2.81\nCreate/edit emails\n32.8\n1.88\nDelete/unsubscribe emails\n30.6\n1.75\nSummarize/analyze emails\n22.8\n1.31\nSend emails\n9.6\n0.55\nSpreadsheet & Data Editing\n(11.1)\nCreate/edit spreadsheets/data\n72.5\n2.91\nSummarize/analyze spreadsheets/data\n38.7\n1.55\nSearch/filter spreadsheets/data\n27.5\n1.10\nComputer Programming\n(10.3)\nCreate/edit code\n63.8\n2.38\nSummarize/analyze code\n48.5\n1.81\nExecute code\n20.3\n0.76\nInvestments & Banking\n(6.2)\nSummarize/analyze investment information\n75.0\n1.69\nSearch/filter stocks\n28.8\n0.65\nSummarize/analyze banking information\n11.7\n0.26\nBuy/sell stocks\n7.8\n0.18\nMultimedia Editing\n(6.1)\nCreate/edit multimedia\n81.0\n1.80\nSummarize/analyze multimedia\n23.6\n0.52\nSearch/filter multimedia\n15.3\n0.34\nProject Management\n(5.1)\nCreate/edit projects\n64.6\n1.19\nSummarize/analyze project information\n48.0\n0.89\nCalendar Management\n(2.5)\nCreate/edit events\n71.0\n0.64\nSearch/filter events\n24.6\n0.22\nSummarize/analyze events\n22.0\n0.20\nNote: The table shows all tasks under Productivity & Workflow with a share of more than 5% within the subtopic. The share of the topic among\nall agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage (P(Task | Topic, Subtopic)) is the task\nshare within the subtopic. The overall percentage is the task share among all agentic queries. P(Task Overall) = P(Topic, Subtopic, Task) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Task | Topic, Subtopic)). Note that because task percentage measures the fraction of queries in which\na task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\nTable 11: Task Distribution for Productivity & Workflow\n33\n\nTopic\nSubtopic\nTask\nTask (%)\nOverall (%)\nLearning & Research\n(20.8)\nCourses\n(61.9)\nAssist exercises\n73.2\n9.41\nSummarize/analyze course materials\n28.7\n3.69\nNavigate courses\n25.6\n3.29\nResearch\n(37.9)\nSummarize/analyze research information\n85.2\n6.71\nSearch/filter research information\n75.6\n5.95\nNote: The table shows all tasks under Learning & Research with a share of more than 5% within the subtopic. The share of the topic among all\nagentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage (P(Task | Topic, Subtopic)) is the task\nshare within the subtopic. The overall percentage is the task share among all agentic queries. P(Task Overall) = P(Topic, Subtopic, Task) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Task | Topic, Subtopic)). Note that because task percentage measures the fraction of queries in which a\ntask is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\nTable 12: Task Distribution for Learning & Research\n34\n\nTopic\nSubtopic\nTask\nTask (%)\nOverall (%)\nMedia & Entertainment\n(15.8)\nSocial Media & Messaging\n(42.4)\nSearch/filter social media posts/messages\n49.5\n3.31\nSummarize/analyze social media posts/messages\n35.3\n2.36\nCreate social media posts/messages\n34.0\n2.28\nEngage with social media posts/messages\n29.3\n1.96\nSend social media/text messages\n20.7\n1.39\nMovies, TV, & Videos\n(20.1)\nSearch/filter videos\n48.4\n1.53\nSummarize/analyze videos\n43.8\n1.39\nPlay videos\n27.1\n0.86\nNavigate within videos\n18.4\n0.58\nManage playlists\n6.2\n0.20\nOnline Games\n(19.6)\nPlay online games\n76.8\n2.37\nSummarize/analyze online game information\n30.7\n0.95\nSearch/filter online games\n14.5\n0.45\nMusic & Podcasts\n(10.7)\nSearch/filter music/podcasts\n75.4\n1.27\nPlay music/podcasts\n61.2\n1.03\nManage playlists\n25.5\n0.43\nSummarize/analyze music/podcasts\n9.7\n0.16\nNews\n(3.8)\nSearch/filter news\n70.7\n0.42\nSummarize/analyze news\n56.6\n0.34\nSports\n(2.7)\nSummarize/analyze match/player information\n77.0\n0.32\nSearch/filter match/player information\n67.7\n0.28\nNote: The table shows all tasks under Media & Entertainment with a share of more than 5% within the subtopic. The share of the topic among\nall agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage (P(Task | Topic, Subtopic)) is the task\nshare within the subtopic. The overall percentage is the task share among all agentic queries. P(Task Overall) = P(Topic, Subtopic, Task) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Task | Topic, Subtopic)). Note that because task percentage measures the fraction of queries in which a\ntask is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\nTable 13: Task Distribution for Media & Entertainment\n35\n\nTopic\nSubtopic\nTask\nTask (%)\nOverall (%)\nShopping & Commerce\n(10.0)\nGoods\n(89.0)\nSearch/filter products\n71.9\n6.43\nSummarize/analyze product information\n57.9\n5.18\nAdd products to cart\n19.8\n1.77\nSearch discounts\n10.2\n0.92\nServices\n(10.3)\nSearch/filter products\n54.5\n0.56\nSummarize/analyze product information\n45.1\n0.46\nMake product purchase\n20.2\n0.21\nSearch discounts\n12.5\n0.13\nAdd products to cart\n7.6\n0.08\nManage orders\n7.0\n0.07\nNote: The table shows all tasks under Shopping & Commerce with a share of more than 5% within the subtopic. The share of the topic among\nall agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage (P(Task | Topic, Subtopic)) is the task\nshare within the subtopic. The overall percentage is the task share among all agentic queries. P(Task Overall) = P(Topic, Subtopic, Task) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Task | Topic, Subtopic)). Note that because task percentage measures the fraction of queries in which\na task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\nTable 14: Task Distribution for Shopping & Commerce\n36\n\nTopic\nSubtopic\nTask\nTask (%)\nOverall (%)\nJob & Career\n(7.1)\nJob Search & Application\n(50.1)\nComplete applications\n65.7\n2.31\nSearch/filter jobs\n57.1\n2.01\nSummarize/analyze job descriptions\n26.3\n0.93\nProfessional Networking\n(49.5)\nSearch/filter professional profiles\n53.8\n1.92\nSummarize/analyze professional profiles\n39.9\n1.42\nSend professional connection requests/messages\n31.4\n1.12\nEngage with professional profiles/posts\n24.0\n0.85\nNote: The table shows all tasks under Job & Career with a share of more than 5% within the subtopic.\nThe share of the topic among all\nagentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage (P(Task | Topic, Subtopic)) is the task\nshare within the subtopic. The overall percentage is the task share among all agentic queries. P(Task Overall) = P(Topic, Subtopic, Task) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Task | Topic, Subtopic)). Note that because task percentage measures the fraction of queries in which a task\nis present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\nTable 15: Task Distribution for Job & Career\n37\n\nTopic\nSubtopic\nTask\nTask (%)\nOverall (%)\nTravel & Leisure\n(6.7)\nFlights & Transportation\n(40.7)\nSearch/filter flights & transportation\n93.4\n2.55\nSummarize/analyze flights & transportation\n63.1\n1.72\nBook flights & transportation\n9.5\n0.26\nLodging\n(27.3)\nSearch/filter lodging\n92.9\n1.70\nSummarize/analyze lodging information\n67.5\n1.23\nBook lodging\n5.5\n0.10\nTrip Itineraries\n(24.8)\nPlan trips\n87.4\n1.45\nSummarize/analyze trips\n48.9\n0.81\nSearch/filter destinations\n48.8\n0.81\nRestaurants\n(5.7)\nSearch/filter restaurants\n73.8\n0.28\nSummarize/analyze restaurant information\n54.2\n0.21\nBook restaurants\n25.0\n0.09\nManage bookings\n5.7\n0.02\nNote: The table shows all tasks under Travel & Leisure with a share of more than 5% within the subtopic. The share of the topic among all\nagentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage (P(Task | Topic, Subtopic)) is the task\nshare within the subtopic. The overall percentage is the task share among all agentic queries. P(Task Overall) = P(Topic, Subtopic, Task) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Task | Topic, Subtopic)). Note that because task percentage measures the fraction of queries in which a\ntask is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\nTable 16: Task Distribution for Travel & Leisure\n38\n\nCluster\nTask\nTask (%)\nDigital Technology\nAssist exercises\n9.1\nSearch/filter products\n6.4\nCreate/edit documents/forms\n6.2\nSummarize/analyze research information\n6.2\nManage settings/profiles\n5.7\nStudent\nAssist exercises\n26.5\nSummarize/analyze course materials\n10.7\nNavigate courses\n7.8\nCreate/edit documents/forms\n7.1\nSummarize/analyze research information\n5.4\nManagement & Entrepreneurship\nSummarize/analyze research information\n7.7\nCreate/edit documents/forms\n7.5\nSearch/filter research information\n6.8\nSearch/filter products\n6.3\nCreate/edit spreadsheets/data\n5.2\nMarketing & Sales\nCreate social media posts/messages\n8.1\nSearch/filter social media posts/messages\n8.1\nSummarize/analyze product information\n8.1\nSummarize/analyze research information\n8.0\nSearch/filter products\n7.6\nFinancial Services\nSummarize/analyze investment information\n11.9\nSummarize/analyze research information\n7.0\nSearch/filter products\n6.7\nSearch/filter research information\n6.1\nSummarize/analyze product information\n5.2\nEducation\nAssist exercises\n19.6\nCreate/edit documents/forms\n9.8\nSummarize/analyze course materials\n8.6\nSummarize/analyze research information\n7.0\nSearch/filter research information\n6.9\nArts, Entertainment, & Design\nSearch/filter products\n7.8\nCreate/edit documents/forms\n7.4\nCreate/edit multimedia\n7.3\nSummarize/analyze product information\n6.1\nSummarize/analyze research information\n5.8\nHealthcare & Human Services\nSummarize/analyze research information\n9.5\nSearch/filter research information\n9.4\nCreate/edit documents/forms\n7.9\nSearch/filter products\n6.6\nAssist exercises\n5.5\nAdvanced Manufacturing\nSearch/filter products\n20.9\nSummarize/analyze product information\n18.1\nSummarize/analyze research information\n7.8\nSearch/filter research information\n7.5\nAssist exercises\n6.6\nPublic Service & Safety\nSearch/filter research information\n15.7\nSummarize/analyze research information\n15.1\nCreate/edit documents/forms\n10.2\nSearch/filter products\n5.1\nAssist exercises\n4.3\nHospitality, Events, & Tourism\nSearch/filter flights & transportation\n11.9\nSearch/filter lodging\n9.6\nSearch/filter products\n8.3\nSummarize/analyze flights & transportation information\n8.1\nSummarize/analyze lodging information\n7.6\nSupply Chain & Transportation\nSearch/filter products\n12.7\nSummarize/analyze product information\n10.6\nCreate/edit documents/forms\n7.4\nSummarize/analyze research information\n7.2\nSearch/filter research information\n6.4\nConstruction\nSearch/filter products\n11.0\nSummarize/analyze product information\n9.1\nSummarize/analyze research information\n8.8\nSearch/filter research information\n8.3\nCreate/edit documents/forms\n5.6\nEnergy & Natural Resources\nCreate/edit documents/forms\n10.5\nSummarize/analyze research information\n10.4\nSearch/filter research information\n10.4\nSearch/filter products\n7.7\nSummarize/analyze product information\n6.0\nAgriculture\nCreate/edit documents/forms\n10.3\nSearch/filter products\n8.5\nSummarize/analyze research information\n8.4\nSearch/filter research information\n8.4\nSummarize/analyze product information\n7.2\nNote: The table shows the top 5 tasks under each occupation cluster. Task percentage (P (Task | Cluster)) is the task share\namong all agentic queries within a cluster.\nTable 17: The Top 5 Tasks by Occupation Cluster\n39\n\nA.2.3\nEnvironments\nTopic\nSubtopic\nEnvironment\nEnvironment (%)\nOverall (%)\nProductivity & Workflow\n(36.2)\nDocument & Form Editing\n(21.5)\ndocs.google.com\n66.6\n5.18\nnotion.so\n6.4\n0.50\ncanva.com\n2.5\n0.19\noverleaf.com\n2.0\n0.16\nperplexity.ai\n1.3\n0.10\nAccount Management\n(20.5)\nperplexity.ai\n10.4\n0.77\ndocs.google.com\n7.6\n0.56\nsettings\n4.0\n0.30\ngithub.com\n3.2\n0.24\nlinkedin.com\n3.1\n0.23\nEmail Management\n(15.8)\nmail.google.com\n69.9\n4.00\noutlook.office.com\n10.8\n0.62\noutlook.live.com\n2.9\n0.17\nmail.yahoo.com\n1.5\n0.09\nmail.yandex.ru\n0.5\n0.03\nSpreadsheet & Data Editing\n(11.1)\ndocs.google.com\n78.9\n3.17\nnotion.so\n4.4\n0.18\nairtable.com\n2.3\n0.09\nexcel.cloud.microsoft\n1.4\n0.06\napp.powerbi.com\n1.1\n0.04\nComputer Programming\n(10.3)\ngithub.com\n30.7\n1.14\ncolab.research.google.com\n5.3\n0.20\nleetcode.com\n4.9\n0.18\naistudio.google.com\n4.2\n0.16\nscript.google.com\n3.1\n0.12\nInvestments & Banking\n(6.2)\ntradingview.com\n47.3\n1.06\nbinance.com\n5.7\n0.13\nkite.zerodha.com\n4.9\n0.11\ngroww.in\n4.6\n0.10\nperplexity.ai\n4.4\n0.10\nMultimedia Editing\n(6.1)\ncanva.com\n42.9\n0.95\nfigma.com\n8.6\n0.19\ndocs.google.com\n5.3\n0.12\nyoutube.com\n5.3\n0.12\naistudio.google.com\n3.5\n0.08\nProject Management\n(5.1)\napp.clickup.com\n9.6\n0.18\ntrello.com\n8.1\n0.15\nnotion.so\n7.3\n0.13\nlinear.app\n6.5\n0.12\nadsmanager.facebook.com\n5.4\n0.10\nCalendar Management\n(2.5)\ncalendar.google.com\n50.3\n0.45\noutlook.office.com\n7.7\n0.07\nmeet.google.com\n3.7\n0.03\nmail.google.com\n3.5\n0.03\nteams.microsoft.com\n1.4\n0.01\nNote: The table shows the top 5 environments under Productivity & Workflow. The share of the topic among all agentic queries\nand the share of the subtopic within a topic are shown in parentheses. Environment percentage (P(Environment | Topic, Subtopic))\nis the environment share within the subtopic.\nThe overall percentage is the environment share among all agentic queries.\nP(Topic, Subtopic, Environment) = P(Topic) √ó P(Subtopic | Topic) √ó P(Environment | Topic, Subtopic). Note that, unlike tasks, an\nenvironment is not unique to a subtopic, so P(Topic, Subtopic, Environment) is the share of an environment when it is used under that\nsubtopic and does not equal P(Environment), which is the share under all subtopics.\nTable 18: The Top 5 Environments Distribution for Productivity & Workflow\n40\n\nTopic\nSubtopic\nEnvironment\nEnvironment (%)\nOverall (%)\nLearning & Research\n(20.8)\nCourses\n(61.9)\ncoursera.org\n18.0\n2.32\nnetacad.com\n15.6\n2.01\ncanvas.com\n12.6\n1.62\nlearning.mheducation.com\n8.3\n1.07\ndocs.google.com\n6.4\n0.82\nResearch\n(37.9)\nyoutube.com\n17.8\n1.40\nperplexity.ai\n6.1\n0.48\ngithub.com\n5.8\n0.46\nmaps.google.com\n5.4\n0.43\ndocs.google.com\n3.9\n0.31\nNote: The table shows the top 5 environments under Learning & Research. The share of topics and subtopics among all agentic\nqueries is shown in parentheses. Environment percentage (P(Environment | Topic, Subtopic)) is the environment share within the\nsubtopic. The overall percentage is the environment share among all agentic queries. P(Topic, Subtopic, Environment) = P(Topic)√ó\nP(Subtopic | Topic) √ó P(Environment | Topic, Subtopic). Note that, unlike tasks, an environment is not unique to a subtopic, so\nP(Topic, Subtopic, Environment) is the share of an environment when it is used under that subtopic and does not equal P(Environment),\nwhich is the share under all subtopics.\nTable 19: The Top 5 Environments Distribution for Learning & Research\n41\n\nTopic\nSubtopic\nEnvironment\nEnvironment (%)\nOverall (%)\nMedia & Entertainment\n(15.8)\nSocial Media & Messaging\n(42.4)\ninstagram.com\n21.3\n1.43\nx.com\n18.0\n1.21\nwhatsapp.com\n13.6\n0.91\nfacebook.com\n10.1\n0.68\nlinkedin\n6.1\n0.41\nMovies, TV, & Videos\n(20.1)\nyoutube.com\n89.9\n2.85\nnetflix.com\n4.1\n0.13\nin.bookmyshow.com\n1.3\n0.04\ntwitch.tv\n0.7\n0.02\ntiktok.com\n0.6\n0.02\nOnline Games\n(19.6)\nchess.com\n32.5\n1.01\nstore.steampowered.com\n15.0\n0.46\nnytimes.com\n14.2\n0.44\nroblox.com\n6.8\n0.21\nhumanbenchmark.com\n5.4\n0.17\nMusic & Podcasts\n(10.7)\nopen.spotify.com\n46.1\n0.78\nyoutube.com\n39.9\n0.67\nsuno.com\n6.2\n0.10\nsoundcloud.com\n2.7\n0.05\nmusic.apple.com\n2.4\n0.04\nNews\n(3.8)\nyoutube.com\n21.0\n0.13\ntrends.google.com\n13.6\n0.08\nnytimes.com\n8.7\n0.05\nperplexity.ai\n7.9\n0.05\nx.com\n5.8\n0.03\nSports\n(2.7)\nyoutube.com\n28.3\n0.12\nfantasy.espn.com\n20.1\n0.09\nsleeper.com\n7.8\n0.03\nsofascore.com\n3.3\n0.01\nlivescore.in\n1.8\n0.01\nNote: The table shows the top 5 environments under Media & Entertainment. The share of topics and subtopics among all agentic\nqueries is shown in parentheses.\nEnvironment percentage (P(Environment | Topic, Subtopic)) is the environment share within\nthe subtopic. The overall percentage is the environment share among all agentic queries. P(Topic, Subtopic, Environment) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Environment | Topic, Subtopic). Note that, unlike tasks, an environment is not unique to a\nsubtopic, so P(Topic, Subtopic, Environment) is the share of an environment when it is used under that subtopic and does not equal\nP(Environment), which is the share under all subtopics.\nTable 20: The Top 5 Environments Distribution for Media & Entertainment\n42\n\nTopic\nSubtopic\nEnvironment\nEnvironment (%)\nOverall (%)\nShopping & Commerce\n(10.0)\nGoods\n(89.0)\namazon.com\n43.2\n3.84\nflipkart.com\n6.2\n0.55\nadmin.shopify.com\n5.3\n0.47\nalibaba.com\n3.7\n0.33\nozon.ru\n3.4\n0.30\nServices\n(10.3)\nperplexity.ai\n12.2\n0.13\nmaps.google.com\n8.7\n0.09\namazon.com\n5.1\n0.05\nfiverr.com\n5.1\n0.05\navito.ru\n4.1\n0.04\nNote: The table shows the top 5 environments under Shopping & Commerce. The share of topics and subtopics among all agentic\nqueries is shown in parentheses. Environment percentage (P(Environment | Topic, Subtopic)) is the environment share within\nthe subtopic. The overall percentage is the environment share among all agentic queries. P(Topic, Subtopic, Environment) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Environment | Topic, Subtopic). Note that, unlike tasks, an environment is not unique\nto a subtopic, so P(Topic, Subtopic, Environment) is the share of an environment when it is used under that subtopic and does\nnot equal P(Environment), which is the share under all subtopics.\nTable 21: The Top 5 Environments Distribution for Shopping & Commerce\n43\n\nTopic\nSubtopic\nEnvironment\nEnvironment (%)\nOverall (%)\nJob & Career\n(7.1)\nProfessional Networking\n(50.1)\nlinkedin.com\n92.5\n3.29\nupwork.com\n1.3\n0.05\napp.apollo.io\n0.8\n0.03\nnaukri.com\n0.6\n0.02\ninstagram.com\n0.5\n0.02\nJob Search & Application\n(49.5)\nlinkedin.com\n60.2\n2.12\nnaukri.com\n6.3\n0.22\nziprecruiter.com\n2.7\n0.09\nindeed.com\n2.5\n0.09\ndice.com\n2.4\n0.08\nNote: The table shows the top 5 environments under Job & Career. The share of topics and subtopics among all agentic queries\nis shown in parentheses. Environment percentage (P(Environment | Topic, Subtopic)) is the environment share within the\nsubtopic. The overall percentage is the environment share among all agentic queries. P(Topic, Subtopic, Environment) =\nP(Topic)√óP(Subtopic | Topic)√óP(Environment | Topic, Subtopic). Note that, unlike tasks, an environment is not unique\nto a subtopic, so P(Topic, Subtopic, Environment) is the share of an environment when it is used under that subtopic and\ndoes not equal P(Environment), which is the share under all subtopics.\nTable 22: The Top 5 Environments Distribution for Job & Career\n44\n\nTopic\nSubtopic\nEnvironment\nEnvironment (%)\nOverall (%)\nTravel & Leisure\n(6.7)\nFlights & Transportation\n(40.7)\nskyscanner.com\n35.6\n0.97\nmaps.google.com\n18.4\n0.50\nmakemytrip.com\n7.2\n0.20\nirctc.co.in\n6.1\n0.17\nexpedia.com\n4.0\n0.11\nLodging\n(27.3)\nbooking.com\n54.9\n1.00\nairbnb.com\n19.5\n0.36\nexpedia.com\n4.6\n0.08\nmaps.google.com\n4.0\n0.07\nagoda.com\n3.5\n0.06\nTrip Itineraries\n(24.8)\nmaps.google.com\n85.2\n1.42\ndocs.google.com\n4.2\n0.07\nyandex.ru\n1.3\n0.02\nskyscanner.com\n1.2\n0.02\nbooking.com\n0.8\n0.01\nRestaurants\n(5.7)\nmaps.google.com\n54.7\n0.21\nopentable.com\n6.5\n0.02\nmap.naver.com\n5.2\n0.02\nswiggy.com\n4.6\n0.02\nubereats.com\n3.9\n0.01\nNote: The table shows the top 5 environments under Travel & Leisure. The share of topics and subtopics among all agentic\nqueries is shown in parentheses. Environment percentage (P(Environment | Topic, Subtopic)) is the environment share within\nthe subtopic. The overall percentage is the environment share among all agentic queries. P(Topic, Subtopic, Environment) =\nP(Topic) √ó P(Subtopic | Topic) √ó P(Environment | Topic, Subtopic). Note that, unlike tasks, an environment is not unique\nto a subtopic, so P(Topic, Subtopic, Environment) is the share of an environment when it is used under that subtopic and\ndoes not equal P(Environment), which is the share under all subtopics.\nTable 23: The Top 5 Environments Distribution for Travel & Leisure\n45\n\nTopic\nSubtopic\nSum of the Top 5 Environments (%)\nProductivity & Workflow\nSpreadsheet & Data Editing\n88.1\nEmail Management\n85.1\nDocument & Form Editing\n78.8\nInvestments & Banking\n66.9\nCalendar Management\n66.6\nMultimedia Editing\n65.6\nComputer Programming\n48.2\nProject Management\n36.9\nAccount Management\n28.3\nLearning & Research\nCourses\n60.9\nResearch\n39.0\nMedia & Entertainment\nMusic & Podcasts\n97.3\nMovies, TV, & Videos\n96.6\nOnline Games\n73.9\nSocial Media & Messaging\n69.1\nSports\n61.3\nNews\n57.0\nShopping & Commerce\nGoods\n61.8\nServices\n35.2\nJob & Career\nProfessional Networking\n95.7\nJob Search & Application\n74.1\nTravel & Leisure\nTrip Itineraries\n92.7\nLodging\n86.5\nRestaurants\n74.9\nFlights & Transportation\n71.3\nNote: The table shows the sum of the top 5 environments‚Äô shares by topic and subtopic. A higher (lower)\nshare indicates agentic queries are more (less) concentrated in a small number of environments. This metric\ncan be interpreted as the agent usage market share of environments among agent adopters on Comet.\nTable 24: Sum of the Top 5 Environment Shares by Topic and Subtopic\n46\n\nCluster\nEnvironment\nEnvironment (%)\nDigital Technology\nlinkedin.com\n6.5\nemail services combined\n5.4\ndocs.google.com\n4.0\nyoutube.com\n3.3\namazon.com\n2.4\nStudent\ndocs.google.com\n7.8\nlinkedin.com\n6.1\nemail services combined\n4.3\ncanvas.com\n3.4\nyoutube.com\n3.0\nManagement & Entrepreneurship\nlinkedin.com\n10.3\nemail services combined\n8.8\ndocs.google.com\n7.7\nyoutube.com\n2.0\namazon.com\n1.8\nMarketing & Sales\nlinkedin.com\n7.8\ndocs.google.com\n6.8\ninstagram.com\n6.5\nx.com\n5.2\nemail services combined\n4.5\nFinancial Services\nemail services combined\n6.6\ndocs.google.com\n5.0\nlinkedin.com\n4.3\nyoutube.com\n3.6\ntradingview.com\n2.6\nEducation\ndocs.google.com\n9.9\nemail services combined\n6.5\nyoutube.com\n4.4\ncanvas.com\n2.4\namazon.com\n2.1\nArts, Entertainment, & Design\nyoutube.com\n7.0\nemail services combined\n5.1\ndocs.google.com\n4.9\nlinkedin.com\n3.6\ninstagram.com\n3.2\nHealthcare & Human Services\nemail services combined\n7.3\ndocs.google.com\n5.8\nlinkedin.com\n4.7\nyoutube.com\n3.0\namazon.com\n2.5\nAdvanced Manufacturing\nemail services combined\n5.5\nlinkedin.com\n4.6\ndocs.google.com\n4.3\nyoutube.com\n3.7\namazon.com\n3.4\nPublic Service & Safety\nemail services combined\n6.2\ndocs.google.com\n4.9\nyoutube.com\n4.1\ntrends.google.com\n3.9\nlinkedin.com\n2.8\nHospitality, Events, & Tourism\nemail services combined\n6.4\nmaps.google.com\n5.6\ndocs.google.com\n5.4\nbooking.com\n3.6\nskyscanner.com\n2.9\nSupply Chain & Transportation\nemail services combined\n8.0\ndocs.google.com\n4.9\nlinkedin.com\n3.7\namazon.com\n3.0\nmaps.google.com\n2.5\nConstruction\nemail services combined\n8.2\nlinkedin.com\n6.3\ndocs.google.com\n4.3\nyoutube.com\n3.1\namazon.com\n2.8\nEnergy & Natural Resources\nemail services combined\n7.4\ndocs.google.com\n6.6\nlinkedin.com\n3.8\namazon.com\n3.4\nyoutube.com\n2.9\nAgriculture\ndocs.google.com\n7.4\nemail services combined\n6.9\nyoutube.com\n3.6\nlinkedin.com\n3.6\namazon.com\n2.4\nNote:\nThe table shows the top 5 environments by occupation cluster.\nEnvironment percent-\nage (P (Environment | Cluster)) is the environment share among all agentic queries in that cluster.\ndocs.google.com includes Google Docs, Sheets, Slides, and Forms. All email accounts are grouped into\n‚Äúemail services combined‚Äù.\nTable 25: The Top 5 Environments by Occupation Cluster\n47\n\nA.2.4\nUsage Context\nContext\nTopic\nSubtopic\nSubtopic (%)\nPersonal\nShopping & Commerce\nGoods\n15.6\nMedia & Entertainment\nSocial Media & Messaging\n9.9\nProductivity & Workflow\nAccount Management\n8.0\nProductivity & Workflow\nEmail Management\n7.6\nMedia & Entertainment\nOnline Games\n6.0\nProfessional\nProductivity & Workflow\nDocument & Form Editing\n13.3\nJob & Career\nProfessional Networking\n12.5\nJob & Career\nJob Search & Application\n11.0\nProductivity & Workflow\nAccount Management\n10.2\nLearning & Research\nResearch\n8.9\nEducational\nLearning & Research\nCourses\n83.9\nLearning & Research\nResearch\n5.3\nProductivity & Workflow\nDocument & Form Editing\n5.0\nProductivity & Workflow\nAccount Management\n1.1\nProductivity & Workflow\nComputer Programming\n0.9\nNote: The table shows the distribution of the top 5 subtopics by usage context. Subtopic\npercentage (P(Subtopic | Context)) is the subtopic share among all agentic queries in a\ngiven usage context.\nTable 26: The Top 5 Subtopic Distribution by Usage Context\n48\n\nContext\nTopic\nSubtopic\nTask\nTask (%)\nPersonal\nShopping & Commerce\nGoods\nSearch/filter products\n8.6\nShopping & Commerce\nGoods\nSummarize/analyze product information\n6.5\nTravel & Leisure\nFlights & Transportation\nSearch/filter flights & transportation\n3.4\nMedia & Entertainment\nSocial Media & Messaging\nSearch/filter social media posts/messages\n3.4\nProductivity & Workflow\nDocument & Form Editing\nCreate/edit documents/forms\n3.2\nProfessional\nProductivity & Workflow\nDocument & Form Editing\nCreate/edit documents/forms\n8.1\nLearning & Research\nResearch\nSummarize/analyze research information\n5.9\nJob & Career\nJob Search & Application\nComplete applications\n5.4\nProductivity & Workflow\nAccount Management\nManage settings/profiles\n5.1\nJob & Career\nProfessional Networking\nSearch/filter professional profiles\n4.8\nEducational\nLearning & Research\nCourses\nAssist exercises\n48.1\nLearning & Research\nCourses\nSummarize/analyze course materials\n18.8\nLearning & Research\nCourses\nNavigate courses\n16.0\nProductivity & Workflow\nDocument & Form Editing\nCreate/edit documents/forms\n3.6\nLearning & Research\nResearch\nSummarize/analyze research information\n3.4\nNote: The table shows the distribution of the top 5 tasks by usage context. Task percentage (P(Task | Context)) is the task share\namong all agentic queries in a given usage context.\nTable 27: The Top 5 Task Distribution by Usage Context\n49\n\nContext\nEnvironment\nEnvironment (%)\nPersonal\nemail services combined\n14.5\nyoutube.com\n10.8\ndocs.google.com\n10.7\namazon.com\n6.3\nmaps.google.com\n3.8\nProfessional\nlinkedin.com\n29.6\ndocs.google.com\n11.4\nemail services combined\n9.6\ngithub.com\n3.8\nadmin.shopify.com\n2.8\nEducational\ndocs.google.com\n14.8\ncoursera.org\n14.6\nnetacad.com\n12.7\ncanvas.com\n10.2\nlearning.mheducation.com\n6.8\nNote: The table shows the distribution of the top 5 environments by usage context.\nEnvironment percentage (P(Environment | Context)) is the environment share among\nall agentic queries in a given usage context. docs.google.com includes Google Docs,\nSheets, Slides, and Forms.\nAll email domains are grouped into ‚Äúemail services\ncombined‚Äù.\nTable 28: The Top 5 Environment Distribution by Usage Context\n50\n\nB\nAgent Demo\nB.1\nSample Agentic Queries\nFigure 9: Sample Agentic Queries from Perplexity at Work\n51\n\nSample Query\nTopic\nSubtopic\nTask\nFind the latest published journal articles...\nLearning & Research\nResearch\nSearch/filter research information, Summarize/an-\nalyze research information\nFind all unanswered emails...\nProductivity & Workflow\nEmail Management\nSearch/filter emails, Create/edit emails\nGroup my tabs by topic...\nProductivity & Workflow\nAccount Management\nManage settings/profiles\nApply for the open job listings...\nJob & Career\nJob Search & Application\nComplete application\nFind and pull up the YouTube video...\nMedia & Entertainment\nMovies, TV, & Videos\nSearch/filter videos, Navigate within videos\nLook through these customer case studies...\nLearning & Research\nResearch\nSearch/filter research information, Summarize/an-\nalyze research information\nGo through Amazon...\nShopping & Commerce\nGoods\nSearch/filter products, Make product purchase\nNote: The table shows how the sample agentic queries map to our taxonomy.\nTable 29: Sample Agentic Queries Mapped to the Taxonomy\n52\n\nB.2\nAgent Behavior for a Real Task\nThe prompt asks the agent to find a round-trip flight between Boston and San Diego to attend\nthe 2025 NeurIPS conference. The user prefers late-night direct flights and a lower price. The\nFigures below show some key steps in how the agent completes the task.32\nNote: The agent first creates a to-do list that breaks the task into three steps. Because the flight dates are not specified, the agent first searches for\nthe 2025 NeurIPS conference dates and confirms that they are found.\nFigure 10: Agent Behavior 1\n32See https://www.perplexity.ai/search/search-for-the-best-flights-be-TNxDicWmSiW9gmcpa2pHNg#0 for all the steps.\n53\n\nNote: The agent then updates the to-do list and proceeds to the next item by searching flights. It operates on the website by entering destinations\nand dates.\nFigure 11: Agent Behavior 2\n54\n\nNote: The agent then applies the nonstop filter to narrow the search to direct flights only. But the flights shown on the website do not match the\nuser‚Äôs preferred flight time, so the agent applies a time filter to find late-night flights.\nFigure 12: Agent Behavior 3\n55\n\nNote: The agent applies a price filter and observes options. Because options are limited, it expands the travel dates to look for red-eye flights.\nFigure 13: Agent Behavior 4\n56\n\nNote: The agent expands the dates and confirms that red-eye flights departing a day earlier are much cheaper.\nFigure 14: Agent Behavior 5\n57\n\nNote: The agent clicks on an outbound flight with the lowest price and proceeds to the inbound flight.\nFigure 15: Agent Behavior 6\n58\n\nNote: The agent completes the task by presenting the recommendations to the user.\nFigure 16: Agent Behavior 7\n59\n\nC\nEarly Adopter Survey\nTo better understand who the early users of Comet are, we invited a subset of users to complete a\nsurvey in November 2025. A typical respondent is a male aged 35 or older who works full-time\nin the technology industry, is either a current Perplexity user or has a strong interest in\nAI-powered browsing, and uses Comet roughly equally across professional and personal\ncontexts. As is often the case with new technology products, we expect user composition to\nchange significantly over time as Comet diffuses into the population.\nD\nValidation of Agent Use Cases Classifier\nWe randomly select 1,000 agentic queries for manual labeling. Note that because of our focus\non agentic queries, we cannot evaluate the classifier‚Äôs performance on public Q&A query\ndatasets such as WildChat.33 These queries are sampled from a larger set previously classified as\ncontaining no harmful content. To maintain representativeness, we retain queries that may\ncontain personal information and redact names, email addresses, addresses, and phone numbers.\nEach query in the sample is independently labeled by two or three annotators using our agentic\ntaxonomy. Out of the 1,000 queries, 370 show disagreement among annotators on what the\nprimary topic and subtopic are. Most disagreements stemmed from variations in labeling\nquality across annotators. For each query that shows disagreement, our team manually reviews\nit and labels it against our taxonomy. The final golden dataset includes the 630 queries on which\nall annotators agreed, along with the 370 queries we labeled. We validate the classifier against\nthe golden dataset and across multiple runs, and the agreement rates are listed in Table 30.\nVariable\nGolden Dataset (%)\nAcross Runs (%)\nTopic\n89.4\n97.2\nSubtopic\n83.2\n94.6\nTask\n81.3\n88.2\nUsage Context\n82.9\n96.3\nNote: The table shows the agreement rate between the classifier label and the\ngolden dataset and across runs. The tasks are specific to subtopics, so when the\nclassifier disagrees with the golden dataset or with itself across runs, the tasks\nwill by definition have zero agreement rates. Therefore, the task agreement rate is\nconditional on topic- and subtopic-level agreement. The across-runs agreement\nrate is the average pairwise agreement rate across three runs.\nTable 30: Agent Use Case Classification Validation\n33https://wildchat.allen.ai/\n60\n",
    "figure_captions": [
      "Figure 1: Hierarchical Structure of the Agentic Taxonomy",
      "Figure 6 in Appendix A shows that agent adoption and overall usage as measured by agentic",
      "Figure 2 and 3 show that there are strong positive correlations between log agent adopters per",
      "Figure 2: Log GDP Per Capita and Average Years of Education vs.",
      "Figure 3: Log GDP Per Capita and Average Years of Education vs.",
      "Figure 4: Topic Breakdown by Subtopic Percentage",
      "Figure 5: Topic Distribution by Usage Context",
      "Figure 6: Cumulative Agent Adopter and Agentic Query",
      "Figure 7: Topic Transition Matrix: Previous vs. Next Agentic Query",
      "Figure 8: Topic Distribution by First vs. All Agentic Queries",
      "Figure 9: Sample Agentic Queries from Perplexity at Work",
      "Figure 10: Agent Behavior 1",
      "Figure 11: Agent Behavior 2",
      "Figure 12: Agent Behavior 3",
      "Figure 13: Agent Behavior 4",
      "Figure 14: Agent Behavior 5",
      "Figure 15: Agent Behavior 6",
      "Figure 16: Agent Behavior 7"
    ]
  },
  {
    "arxiv_id": "2512.07827v1",
    "title": "An Adaptive Multi-Layered Honeynet Architecture for Threat Behavior Analysis via Deep Learning",
    "abstract": "The escalating sophistication and variety of cyber threats have rendered static honeypots inadequate, necessitating adaptive, intelligence-driven deception. In this work, ADLAH is introduced: an Adaptive Deep Learning Anomaly Detection Honeynet designed to maximize high-fidelity threat intelligence while minimizing cost through autonomous orchestration of infrastructure. The principal contribution is offered as an end-to-end architectural blueprint and vision for an AI-driven deception platform. Feasibility is evidenced by a functional prototype of the central decision mechanism, in which a reinforcement learning (RL) agent determines, in real time, when sessions should be escalated from low-interaction sensor nodes to dynamically provisioned, high-interaction honeypots. Because sufficient live data were unavailable, field-scale validation is not claimed; instead, design trade-offs and limitations are detailed, and a rigorous roadmap toward empirical evaluation at scale is provided. Beyond selective escalation and anomaly detection, the architecture pursues automated extraction, clustering, and versioning of bot attack chains, a core capability motivated by the empirical observation that exposed services are dominated by automated traffic. Together, these elements delineate a practical path toward cost-efficient capture of high-value adversary behavior, systematic bot versioning, and the production of actionable threat intelligence.",
    "text": "An Adaptive Multi-Layered Honeynet Architecture\nfor Threat Behavior Analysis via Deep Learning\nLukas Johannes M√∂ller1,\n1Georgia Institute of Technology Atlanta, United States of America (e-mail: lmoller6@gatech.edu\nThis work was supported in part by the Federal Office for Information Security - BSI\nABSTRACT The escalating sophistication and variety of cyber threats have rendered static honeypots\ninadequate, necessitating adaptive, intelligence-driven deception. In this work, ADLAH is introduced: an\nAdaptive Deep Learning Anomaly Detection Honeynet designed to maximize high-fidelity threat intelligence\nwhile minimizing cost through autonomous orchestration of infrastructure. The principal contribution is\noffered as an end-to-end architectural blueprint and vision for an AI-driven deception platform. Feasibility is\nevidenced by a functional prototype of the central decision mechanism, in which a reinforcement learning\n(RL) agent determines, in real time, when sessions should be escalated from low-interaction sensor nodes to\ndynamically provisioned, high-interaction honeypots. Because sufficient live data were unavailable, field-\nscale validation is not claimed; instead, design trade-offs and limitations are detailed, and a rigorous roadmap\ntoward empirical evaluation at scale is provided. Beyond selective escalation and anomaly detection, the\narchitecture pursues automated extraction, clustering, and versioning of bot attack chains, a core capability\nmotivated by the empirical observation that exposed services are dominated by automated traffic. Together,\nthese elements delineate a practical path toward cost-efficient capture of high-value adversary behavior,\nsystematic bot versioning, and the production of actionable threat intelligence.\nINDEX TERMS adaptive honeynet, reinforcement learning, dynamic container deployment, cybersecurity,\nthreat intelligence\nI. INTRODUCTION\nA. THE EVOLVING CYBER THREAT LANDSCAPE AND\nSTRATEGIC MOTIVATION\nThe cybersecurity landscape has undergone a dramatic trans-\nformation, with cyber threats becoming increasingly sophisti-\ncated, persistent, and economically damaging [1]. Global cy-\nbercrime damages are projected to reach $10.5 trillion annually\nby 2025 [2], driven by the proliferation of connected devices\nand the professionalization of cybercriminal organizations.\nModern attacks are complex, multi-stage campaigns that can\npersist undetected for extended periods, with a median dwell\ntime of 11 days [3].\nThis research is situated within the strategic context of\nnational cybersecurity agencies, such as the German Federal\nOffice for Information Security (BSI), which are responsible\nfor protecting critical digital infrastructure. A primary goal\nfor such agencies is the rapid detection of novel threats to\nprovide timely warnings. While existing sensor networks like\nthe BSI‚Äôs MADCAT offer a valuable baseline, the increasing\nsophistication of application-layer attacks necessitates more\nadvanced analysis capabilities. The Artificial Intelligence (AI)-\ndriven, adaptive architecture presented in this paper aims to\naddress this need, providing a significant leap in capability\nbeyond static sensor grids and directly supporting the BSI‚Äôs\nmission to enhance the nation‚Äôs cyber resilience.\nB. BSI COLLABORATION AND MADCAT PROJECT\nOVERVIEW\nThe work presented here has been conducted in collaboration\nwith the German Federal Office for Information Security (BSI)\nand is designed to complement and extend the BSI‚Äôs opera-\ntional capabilities. At the core of the current sensor layer stands\nMADCAT (Mass Attack Detection Connection Acceptance\nTools) [4], a low-interaction, honeypot-like suite purpose-\nbuilt to capture Internet-scale, early-stage attack activity for\nsituational awareness and mass-attack analytics.\nIn recent years, mass attacks on Internet users have in-\ncreased markedly, with new procedures and attack patterns\nemerging continuously. Large-scale outages (e.g., in 2016, an\nincident affected roughly 900,000 consumer connections in\nGermany) illustrate how mass events can ripple into critical\nservices [5]‚Äì[7]. Mass attacks often serve as a staging ground\nfor later targeted operations against specific victims. Many\nattempts remain undetected or unreported to BSI because they\ncause no immediately visible impact.\nTo fulfill its legal mandate under ¬ß 7b Abs. 4 BSIG, BSI\nmust therefore operate its infrastructure for collecting and\nanalyzing data on attacks and attempted attacks. Honeypots\nare a widely used tool for this purpose. By operating its sensors,\nBSI reduces dependencies on third parties, enables faster and\nautonomous incident response in significant events, and accu-\n1\narXiv:2512.07827v1  [cs.CR]  8 Dec 2025\n\nmulates longitudinal data to forecast evolving attack trends.\nA prominent example is the Log4Shell vulnerability (CVE-\n2021-44228), disclosed on 10 December 2021. [8] Exploita-\ntion attempts are often detectable in the very first network\nrequest via malicious JNDI lookups, making them suitable\nfor\"First-Flight\" analysis. Although the vulnerability is now\nwell known, exploitation remains observable in current traffic,\nfor instance, scanning activity on TCP port 25565 (popular in\nMinecraft servers) increased noticeably after disclosure and\npersists to this day.\nMADCAT was developed by BSI (C 26) as a universal, low-\ninteraction cyber threat detection suite. It is honeypot-like in\nthat it records all contact attempts without binding itself to\nspecific services.\"Low interaction\" indicates that, in its current\nv2 deployment, responses are limited to the technically nec-\nessary minimum to establish a connection and capture attack\nvectors. Internally, an evolved version of MADCAT v2 is in\noperational use. The extensions proposed in this work enable\nthe analysis of all layers above, including session, presentation,\nand application-layer behavior, thereby supporting scalable\nprioritization, advanced Layer 7 analytics, and triage across\nlarge sensor fleets and dynamically orchestrated honeypots.\nSensors are deployed both at consumer-grade, Internet-\nreachable access links and on leased servers (e.g., at mass\nhosters). In controlled test phases, small-scale deployments\nhave recorded on the order of hundreds of thousands of events\nper day, exhibiting complex and constantly changing mass-\nattack activity. These observations empirically motivate an\nadaptive escalation layer that concentrates scarce high-interaction\nresources on the most valuable sessions. 1\nThe program serves BSI‚Äôs statutory tasks (e.g., ¬ß 3 Abs. 1\nS. 2 Nr. 1 bis 4, 10, 14 BSIG) by building and maintaining\nexpertise in the detection and analysis of attack patterns, and by\nenabling peer-level information exchange with ISPs, operators,\nand partner organizations.\nIn the course of this work, an exchange between Telekom\nSecurity, BSI, and the author was conducted to explore whether\nT-Pot datasets could be made available for research. The con-\ntact at Telekom Security indicated that many similar requests\nare received and that corresponding approval processes can\nbe lengthy. Access could therefore not be granted within the\nthesis timeline. To mitigate this, a self-hosted T-Pot instance\nwas deployed and used to collect exploratory data. While\nthis analysis is not central to the present results, the result-\ning dataset is expected to play a role in future iterations of\nthe architecture, particularly for improving application-layer\nanomaly detection.\nMADCAT focuses on recording initial contact attempts\nacross all reachable ports and protocols with minimal response\nsurface, enabling broad deployment at scale (e.g., consumer\nlinks and leased servers). In controlled deployments, MAD-\nCAT sensors have observed on the order of hundreds of thou-\nsands of events per day across a pretty limited number of\n1Valuable sessions are defined as interactions that exhibit novel, complex,\nor persistent behavior, indicating a higher likelihood of yielding actionable\nintelligence about new threats or adversary TTPs.\nsensors, underscoring the need for efficient downstream pro-\ncessing.\nFrom an architectural standpoint, MADCAT provides a\nmodular, ingest-ready telemetry layer:\n‚Ä¢ Capture Modules (TCP/UDP/ICMP/RAW): Protocol-\nspecific collectors record first packets and flows. The\nTCP path includes a postprocessor that correlates SYN\nand connection objects and optionally leverages system\nconntrack; its status is summarized via ct_status\n(Found/Changed/Failed/None). The RAW path uses libp-\ncap filters to quantify traffic classes (e.g., IPv6)2 beyond\nthe core protocol set.\n‚Ä¢ Enrichment Processor: Normalizes and augments events\n(e.g., external sensor IP resolution, geo-IP), performs\noptional payload splitting for large events using a con-\nsistent SPLIT tag, and writes structured logs for shipper\ningestion.\n‚Ä¢ Monitoring Module: Provides operational and security\ntelemetry (CPU/memory/disk, process watchdogs, au-\ndited executions, listener whitelists) to support secure,\nreliable field operation of sensors.\nThis paper positions MADCAT as the scalable, low-interaction\nsensing layer in a larger, adaptive system. The proposed AD-\nLAH architecture learns, in real time, when to escalate a\nsession from a MADCAT Sensor Node to a dynamically pro-\nvisioned, high-interaction honeypot. In this way, ADLAH\npreserves MADCAT‚Äôs breadth and safety while adding depth\nwhere it matters.\nBy driving selective, context-aware escalation decisions,\nADLAH provides the following benefits for BSI and MAD-\nCAT operations:\n‚Ä¢ increases the intelligence yield per MADCAT event by\ncapturing post-compromise behavior only when warranted,\n‚Ä¢ reduces analyst and compute load in ELK or MongoDB\nby prioritizing sessions with higher expected value,\n‚Ä¢ supports timely national warnings through earlier identi-\nfication of novel tools and techniques, and\n‚Ä¢ maintains a small exposure surface on widely deployed\nSensor Nodes while concentrating risk within isolated,\nephemeral high-interaction backends.\nThis collaboration goal is to deliver an adaptive, ML-driven\norchestration layer that directly leverages MADCAT data and\ninfrastructure, thereby enhancing BSI‚Äôs operational resilience\nand the strategic value of its sensor network.\nC. LIMITATIONS OF TRADITIONAL HONEYPOT SYSTEMS\nTraditional honeypot and honeynet systems, while valuable for\nthreat intelligence collection, suffer from several fundamen-\ntal limitations that reduce their effectiveness against modern\nthreats [9]. Static configuration represents perhaps the most\nsignificant limitation, as traditional honeypots are typically de-\nployed with fixed configurations that cannot adapt to changing\n2Attacks using IPv6 are yet relatively rare compared to IPv4, thus special-\nized IPv6-capable modules are still under development.\n2\n\nattack patterns or emerging threats. 3 This static nature makes\nthem increasingly ineffective against sophisticated adversaries\nwho can quickly identify and avoid honeypots through recon-\nnaissance and behavioral analysis, a trend highlighted in the\nENISA Threat Landscape report [1].\nLimited correlation capabilities prevent traditional systems\nfrom connecting related attack activities across multiple ses-\nsions, periods, or infrastructure components. This limitation\nis particularly problematic when dealing with advanced per-\nsistent threats that employ multi-stage attack campaigns span-\nning weeks or months. Without the ability to correlate activ-\nities across sessions, security analysts miss critical patterns\nthat could reveal the full scope and intent of sophisticated\nattacks [10].\nResource inefficiency is another critical limitation, as tra-\nditional honeypots often consume significant computational\nand network resources regardless of the actual threat level\nor value of collected intelligence. This inefficient resource\nutilization limits the scale at which honeypots can be deployed\nand reduces their cost-effectiveness for many organizations.\nAdditionally, traditional systems cannot dynamically adjust\ntheir engagement strategies based on adversary behavior, miss-\ning opportunities to collect more valuable intelligence from\nsophisticated threats while wasting resources on low-value\nautomated scanning [11].\nDetection evasion has become increasingly problematic as\nadversaries develop more sophisticated techniques for identify-\ning and avoiding honeypots. Modern attack tools often include\nhoneypot detection capabilities that can identify common\nhoneypot signatures, network configurations, and behavioral\npatterns [12]. Once identified, adversaries avoid these systems,\nrendering them ineffective for intelligence collection.\nD. THE PROMISE OF ADAPTIVE HONEYNETS\nAdaptive honeynets represent a paradigm shift in cyber de-\nception technology, offering the potential to overcome the\nlimitations of traditional static systems through intelligent\nautomation and machine learning [13]. By incorporating Re-\ninforcement Learning (RL) algorithms, adaptive honeynets\ncan learn from their behavior and continuously optimize their\ndeployment of adversary strategies to maximize intelligence\ncollection while minimizing resource consumption [14]‚Äì[16].\nThe integration of real-time anomaly detection enables adap-\ntive systems to identify novel attack patterns and zero-day ex-\nploits that signature-based systems would miss. This capability\nis particularly valuable in the current threat landscape, where\nadversaries increasingly rely on custom tools and techniques\ndesigned to evade traditional detection methods. Machine\nlearning-based anomaly detection can identify subtle patterns\nin network traffic, system behavior, and attack sequences that\nhuman analysts might overlook [17]‚Äì[20].\nDynamic resource allocation enables adaptive honeynets\nto automatically scale their deployment according to current\nthreat levels and available resources. This capability ensures\n3This static nature also extends to the network level.\nthat computational resources are focused on the most valuable\nthreats while maintaining cost-effectiveness. During periods\nof high attack activity, the system can automatically deploy ad-\nditional honeypot instances to capture more intelligence, while\nscaling back during quiet periods to conserve resources [11],\n[21]‚Äì[23].\nCross-session correlation capabilities enable adaptive hon-\neynets to track sophisticated attack campaigns across multiple\nsessions, periods, and infrastructure components. This correla-\ntion is crucial for comprehending the full extent of advanced\npersistent threats and devising effective countermeasures. By\nmaintaining persistent adversary profiles and tracking the\nevolution of adversary behavior over time, adaptive systems\ncan provide valuable insights into adversary motivations, ca-\npabilities, and likely future targets [24]‚Äì[26].\nCrucially, this research shifts the paradigm of adaptation\nfrom the \"in-service\" level, where a single honeypot alters\nits responses, to the infrastructure level, where the system\norchestrates the deployment of deception resources themselves.\nThis fundamental distinction positions ADLAH as bridging the\ngap between single-service adaptation and full infrastructure\nautomation.\nThis shift towards infrastructure-level orchestration pro-\nvides significant economic and ecological benefits. By se-\nlectively deploying resource-intensive, high-interaction hon-\neypots only when a threat is deemed credible, the system\nradically reduces operational costs. This \"smart deployment\"\napproach minimizes baseline computing power and energy\nconsumption, leading to a more sustainable and cost-effective\nsecurity posture. Furthermore, it lowers the data overhead\nassociated with constant, large-scale logging, focusing ana-\nlytical resources where they are most needed. This efficiency\nprovides a practical entry point for creating more diverse and\nintelligent honeypot deployments that can extend beyond SSH\nto a broader range of services, enhancing the overall strategic\ncapability of the deception infrastructure.\nE. RESEARCH OBJECTIVES AND CONTRIBUTIONS\nThis research addresses the critical gap between traditional\nstatic honeypot systems and the dynamic, intelligent defense\ncapabilities required to counter modern cyber threats. The\nprimary objective is to develop and demonstrate a practical\nadaptive honeynet architecture that combines reinforcement\nlearning and dynamic container orchestration, bridging the\ngap between single-service adaptation and full infrastructure\nautomation.\nThe research makes several key contributions to the field of\ncybersecurity:\n1) It presents a practical prototype of an RL-driven de-\nployment trigger. The system uses a Deep Q-Network\n(DQN) agent combined with a Long Short-Term Mem-\nory (LSTM) [27] to analyze sequences of network events\nand automatically decides when to escalate a session\nfrom a low-interaction sensor to a high-interaction hon-\neypot.\n3\n\n2) It provides a comprehensive architectural framework\nfor adaptive honeynets that addresses not only technical\nimplementation but also operational, ethical, and legal\nconsiderations. This framework serves as a blueprint for\norganizations seeking to implement adaptive deception\ntechnologies.\n3) It contributes to the broader understanding of how ma-\nchine learning can be effectively applied to cybersecu-\nrity challenges, providing insights that extend beyond\nhoneypot systems.\nF. SCOPE AND LIMITATIONS\nThis research focuses on the development and demonstration\nof an adaptive honeynet for network-based threat detection.\nThe scope includes the design of RL algorithms for deploy-\nment decision-making, the integration of anomaly detection,\nand the development of container orchestration for dynamic\nhoneypot deployment. However, it is crucial to acknowledge\nseveral significant limitations that define the boundaries of the\ncurrent work and provide a clear path for future research.\n‚Ä¢ Focus on Network-Level Triggers: The prototype‚Äôs\ndecision-making is based entirely on first-packet network\ndata. While effective for identifying scans and initial\nconnection attempts, it lacks visibility into encrypted\ntraffic and sophisticated application-layer attacks that\nmay only manifest after a session is established. The\nsystem can decide to deploy a honeypot, but it cannot an-\nalyze the complex, post-compromise behavior within that\nhoneypot to the full extent envisioned in the architecture.\n4\n‚Ä¢ Reward Function Sophistication: The RL agent‚Äôs ef-\nfectiveness is fundamentally tied to the quality of its\nreward function. The prototype employs a temporary and\nsimplistic, quantity-based metric where the reward is\ncalculated based on the amount of logs generated (Nlogs).\nThis approach creates a potential vulnerability: it can\nbe gamed by a low-sophistication adversary generating\nhigh volumes of noise, which the agent might incorrectly\nvalue more than a stealthy, advanced adversary making\nfew but critical actions. Future implementations should\nincorporate more sophisticated metrics, such as anomaly\nscores, which can better quantify the actual \"worth\" of an\nagent‚Äôs decision by evaluating the novelty and potential\nsignificance of the captured interaction. Designing a re-\nward function that accurately quantifies this \"intelligence\nvalue\" by balancing novelty, severity, and relevance re-\nmains a major open research challenge [28], [29].\n‚Ä¢ Dependency on Live Traffic for Training: Offline train-\ning is only partially applicable. While the agent learns\nfrom the consequences of its actions (deploying a hon-\neypot) in a live feedback loop, which complicates pure\noffline evaluation, methods from Offline RL/Batch RL\n4Post-compromise behavior includes lateral movement, privilege escalation,\ndata staging, and tool installation, which are critical for understanding an\nattacker‚Äôs ultimate objectives.\ncould be explored with logged interactions and modeled\nor retrospective rewards. This remains future work; our\ncurrent prototype assumes live interaction for meaningful\npolicy learning.\n‚Ä¢ Vulnerability to Honeypot Detection: The system‚Äôs effi-\ncacy rests on the assumption that adversaries will interact\nwith the deployed honeypots. However, sophisticated ad-\nversaries actively employ anti-honeypot and anti-Virtual\nMachine (VM)/container detection techniques. They may\nprobe for environmental artifacts, network latency incon-\nsistencies introduced by the redirection mechanism, or\npredictable behaviors of emulated services to unmask the\ndeception and evade capture [30].\n‚Ä¢ Scalability and Performance Bottlenecks: The proto-\ntype, while functional, is not designed for large-scale,\nhigh-traffic environments. The imperative ‚Äòiptables‚Äò redi-\nrection mechanism could become a bottleneck on the\nsensor node. Furthermore, the computational require-\nments for the ELK (Elasticsearch, Logstash, Kibana)\nstack and a fleet of ML models can be substantial, po-\ntentially limiting the number of concurrent sessions that\ncan be analyzed and managed, posing a challenge for\nresource-constrained organizations.\n‚Ä¢ Prototype-to-Production Gap: The current implementa-\ntion is a prototype designed to demonstrate feasibility, not\na production-hardened system. A significant engineering\neffort would be required to achieve operational readiness,\nincluding implementing high-availability and failover\nmechanisms, comprehensive security hardening of all\nmanagement components, and developing a more robust,\ndeclarative traffic management system to replace the\nprototype‚Äôs script-based approach.\n‚Ä¢ Ethical and Legal Considerations: The deployment\nof honeypots, particularly high-interaction ones, oper-\nates in a complex ethical and legal landscape. Issues\nsurrounding entrapment, the collection and storage of\npotentially sensitive adversary data (including person-\nally identifiable information), and compliance with data\nprotection regulations like the General Data Protection\nRegulation (GDPR) must be carefully evaluated by any\norganization deploying such a system within its specific\nlegal jurisdiction [9].\nG. DOCUMENT ORGANIZATION\nThe remainder of this paper is organized as follows. Section II\nestablishes a clear lexicon by defining the core concepts, tech-\nnical terms, and evaluation metrics used throughout the paper.\nSection III provides a comprehensive review of foundational\nresearch in honeypot technology, machine learning for network\ndefense, and adaptive cyber deception, identifying the key\nresearch gap this work addresses. Section IV offers a detailed\nanalysis of modern cyber threats, including Advanced Persis-\ntent Threats (APTs) and ransomware, providing the strategic\ncontext for the proposed architecture. Section VI presents the\ncomplete, high-level architecture of the proposed adaptive\nhoneynet, detailing its modular components, data flows, and\n4\n\nan AI-driven pipeline for intelligent orchestration. Section V\ndiscusses the challenge of honeynet detection, reviews state-of-\nthe-art evasion and counter-evasion techniques, and outlines\nthe architecture‚Äôs approach to achieving stealth. Section VII\ndetails the research methodology, including the experimental\nenvironment, the process of data collection from live traffic,\nand the feature engineering pipeline used to prepare data for the\nmachine learning models. Section VIII describes the practical\nimplementation of the functional prototype, focusing on the\nreinforcement learning agent, dynamic container deployment,\nand the traffic redirection mechanism. Section IX proposes\nhow to evaluate the system‚Äôs performance and effectiveness.\nThe paper concludes in Section X with a summary of key con-\ntributions, followed by Section XI, which outlines a detailed\nroadmap for future research directions.\nII. TERMINOLOGY AND DEFINITIONS\nThis section provides clear definitions of key terms and con-\ncepts used throughout this paper to ensure consistent under-\nstanding and avoid ambiguity.\nA. CORE CONCEPTS\nA honeypot is a security mechanism designed to detect, de-\nflect, or study attempts at unauthorized use of information\nsystems [9]. Honeypots are decoy systems that appear to be\nlegitimate targets but are isolated and monitored environments\ndesigned to attract and analyze malicious activity.\nA honeynet is a network of honeypots designed to capture\nand analyze malicious traffic on a larger scale [10]. Unlike\nindividual honeypots, honeynets offer comprehensive monitor-\ning capabilities across multiple systems, enabling the detection\nof coordinated attacks that span various targets.\nAn adaptive honeynet is a honeynet system that can dy-\nnamically adjust its configuration, deployment strategy, and\nresponse mechanisms based on observed threat patterns and\nsystem performance [13]. Adaptive honeynets utilize machine\nlearning and automation to optimize resource allocation and\nenhance the effectiveness of threat detection.\nReinforcement learning (RL) is a machine learning paradigm\nwhere an agent learns to make decisions by interacting with\nan environment and receiving feedback in the form of rewards\nor penalties [31]. In the context of honeynets, RL agents learn\noptimal deployment strategies through trial and error.\nB. TECHNICAL TERMS\nA Deep Q-Network (DQN) is a reinforcement learning algo-\nrithm that combines Q-learning with deep neural networks to\nhandle high-dimensional state spaces [32]. DQN enables the\nagent to learn complex decision-making policies in environ-\nments with large state spaces.\nAn autoencoder is a neural network architecture designed\nto learn efficient representations of input data by training the\nnetwork to reconstruct the input from a compressed latent rep-\nresentation [33]. In anomaly detection, autoencoders identify\nunusual patterns by measuring reconstruction error.\nContainer orchestration refers to the automated management\nof containerized applications, including deployment, scaling,\nand monitoring [34]. Kubernetes is the primary container\norchestration technology referenced in this work; the prototype\nspecifically implements the lightweight k3s distribution, while\nproduction use would typically favor managed offerings such\nas GKE.\nA pod is the smallest deployable unit in Kubernetes, repre-\nsenting a group of one or more containers (a \"pod\") sharing\nstorage and network resources [35]. In this context, pods\nrepresent individual honeypot instances.\nC. NETWORK AND SECURITY CONCEPTS\nFirst-packet data are the initial packets or connection attempts\nthat occur when a session is established [36]. First-packet\ndata provide early indicators of adversary intent and behavior\nbefore full engagement occurs.\nDestination NAT (DNAT) is a network address translation\ntechnique that redirects incoming traffic to different destina-\ntions [37]. In honeynet deployments, DNAT is used to redirect\nadversary traffic to appropriate honeypot instances transpar-\nently.\nAn attack chain is a sequence of related attack actions\nperformed by the same threat actor or group across multiple\nsessions or timeframes. Attack chains represent coordinated\nattack campaigns that span various stages and targets [38].\nThreat intelligence refers to threat information that has been\naggregated, transformed, analyzed, interpreted, or enriched\nto provide the necessary context for decision-making pro-\ncesses [39]. In honeynet contexts, threat intelligence is derived\nfrom analysis of adversary behavior, tools, and techniques.\nD. EVALUATION METRICS\nDetection accuracy is the ability of the system to correctly iden-\ntify malicious activity while minimizing false positives [40].\nIt is measured through precision, recall, F1-score, and area\nunder the ROC curve (AUC).\nResource efficiency is the optimal use of computational\nresources, including CPU, memory, storage, and network band-\nwidth [41]. Resource efficiency is critical for cost-effective\nhoneynet deployment.\nResponse time is the time required for the system to detect\na threat and initiate appropriate countermeasures [42]. Low\nresponse times are essential for effective threat mitigation.\nThreat coverage is the percentage of different attack types\nand vectors that the system can successfully detect and an-\nalyze [43]. Comprehensive threat coverage provides broad\nprotection against a wide range of attack methodologies.\nE. OPERATIONAL TERMS\nA field trial is a real-world test of the system in an operational\nenvironment with actual Internet traffic and genuine adversary\ninteractions [44]. Field trials provide validation of system\neffectiveness under realistic conditions.\nCross-session analysis is the ability to correlate and ana-\nlyze attack patterns across multiple sessions, timeframes, and\n5\n\nnetwork segments [24]. Cross-session analysis is essential for\ndetecting sophisticated, multi-stage attacks.\nBehavioral profiling is the process of analyzing and cate-\ngorizing adversary behavior patterns to identify threat actors,\nattack methodologies, and campaign objectives [45]. Behav-\nioral profiling enables proactive threat detection and response.\nAdaptive deployment is the dynamic allocation of honeypot\nresources based on real-time threat assessment and system\nperformance [46]. Adaptive deployment optimizes resource\nutilization while maintaining effective threat detection capa-\nbilities.\nIII. RELATED WORK\nA comparative analysis of related works is presented in Table 1.\nA. FOUNDATIONS IN HONEYPOT AND DECEPTION\nTECHNOLOGY\nThe concept of a honeypot, a decoy system designed to be\nprobed, attacked, and compromised, has been a cornerstone\nof defensive security for decades. Early work, famously docu-\nmented by Clifford Stoll in \"The Cuckoo‚Äôs Egg\" [51], demon-\nstrated the immense value of observing adversaries in a con-\ntrolled environment to understand their methods. This con-\ncept was formalized and popularized by pioneers like Lance\nSpitzner, whose work laid the groundwork for classifying\nhoneypots based on their level of interaction and purpose\n(research vs. production) [9].\nLow-interaction honeypots, such as the BSI‚Äôs MADCAT\nSensor Node [4] used in this research, emulate services at\na superficial level. They are designed to capture initial con-\nnection attempts, scans, and basic probes with minimal risk\nand resource consumption. Their primary advantage is scala-\nbility; they can be deployed widely to gather broad statistics\non network-level activity. However, they cannot engage so-\nphisticated adversaries or capture complex, post-exploitation\nbehavior.\nHigh-interaction honeypots, in contrast, provide a real, fully\nfunctional operating system and services for adversaries to in-\nteract with. Systems like Cowrie [52] emulate an SSH and Tel-\nnet environment, allowing for the capture of detailed command\nsequences, tool downloads, and lateral movement attempts.\nThe trade-off is a significantly higher resource footprint and\nan increased security risk, as the honeypot itself could be used\nas a staging ground for further attacks if not properly isolated.\nThe concept of a honeynet, a network of multiple honeypots,\nwas introduced by The Honeynet Project to create a more\nconvincing and extensive deception environment, enabling the\nanalysis of more complex, coordinated attacks [10]. Modern\nhoneypot distributions, such as T-Pot [53], bundle multiple\nhoneypot types into a single platform.\nDespite their value, these traditional systems are funda-\nmentally static. They are deployed with a fixed configuration\nand remain unchanged, making them susceptible to detection\nby experienced adversaries and inefficient in their use of\nresources. This static nature is the primary motivation for\nthe shift towards adaptive systems.\nA seminal example of this early paradigm is the work by\nWagener et al. [13], often termed \"in-service adaptation.\"\nTheir system utilized a game-theoretic model combined with\nreinforcement learning to enable a single honeypot to make\nreal-time decisions on how to handle an attacker‚Äôs commands.\nThe agent‚Äôs actions were to ‚Äòallow‚Äò, ‚Äòblock‚Äò, ‚Äòsubstitute‚Äò, or\n‚Äòinsult‚Äò the command, thereby manipulating the interactive\nsession to maximize information gain. While groundbreaking,\nthis approach focuses on optimizing the behavior within a\nsingle, active honeypot. The architecture presented in this\npaper, ADLAH, operates at a higher, complementary level\nof abstraction. Instead of adapting responses to commands,\nADLAH adapts the infrastructure itself, using RL to make the\nstrategic decision of whether to deploy a high-interaction hon-\neypot in the first place, thus focusing on resource orchestration\nrather than session manipulation.\nB. THE ADVENT OF ADAPTIVE CYBER DECEPTION\nThe limitations of static honeypots led to research into adaptive\nsystems that could dynamically alter their behavior in response\nto adversary actions. Early work by Wagener et al. proposed\nthe concept of self-configurable honeypots that could adjust\ntheir services and configurations based on observed traffic,\nlaying the conceptual groundwork for the field [13].\nThe integration of machine learning advanced this paradigm.\nResearchers began to explore how ML could automate the\ndecision-making process, moving beyond simple rule-based\nadaptations. For example, some systems focused on using\nML to improve the believability of the honeypot. Dowling\net al. proposed a framework for agile honeypots that could\ndynamically change their properties to mimic real systems\nbetter and evade detection [11]. Other research focused on\nusing machine learning for post-facto analysis, such as the\nUNADA system, which applied clustering to NetFlow data\nfrom honeypots to autonomously characterize attacks [48],\n[54]. While powerful, these systems often relied on aggregated\nor flow-level data, making them unsuitable for the kind of\nreal-time, first-packet decision-making required for dynamic\nresource allocation.\nC. EVOLUTION OF REINFORCEMENT LEARNING IN\nHONEYPOT SYSTEMS\nReinforcement Learning (RL) emerged as a particularly promis-\ning paradigm for adaptive honeypots because it allows an\nagent to learn optimal behavior through direct interaction with\nan environment, a natural fit for the adversarial dynamics of\ncybersecurity. The core idea is to treat the honeypot as an agent\nthat learns a policy to maximize a reward, which is typically\ntied to the quality of intelligence gathered.\nThe evolution of RL in honeypot systems can be traced\nthrough several key developments. Pioneering work in this area\nincludes RASSH by Pauna et al., which used Q-learning to\nenable an SSH honeypot to learn which responses to adversary\ncommands would prolong the session and elicit more interest-\ning behavior [44]. This represented a significant step forward,\nas the honeypot was no longer just a passive recorder but an\n6\n\nTABLE 1. Comparative Analysis of Related Work in Anomaly Detection and Adaptive Honeypots\nWork\nPrimary Goal\nCore Methodology\nAdaptation Level\nKey Contribution\nResearch Gap Ad-\ndressed by ADLAH\nThis Work (ADLAH)\nAdaptive Honeynet\nOrchestration\nDQN\nReinforce-\nment Learning\nInfrastructure-\nLevel\nNovel use of RL\nfor\ndynamic,\ncontainerized\ndeployment\ndecisions\nbased\non\nfirst-packet\ndata.\nN/A (Represents the\nproposed solution)\nRASSH [44]\nAdaptive Honeypot\nEngagement\nQ-Learning / SARSA\nIn-Service (Session)\nFoundational\nwork\napplying\nRL\nto\nmanipulate\nSSH\nsessions to maximize\ninteraction time.\nLimited to adapting\nresponses\nwithin\na\nsingle,\nnon-\ncontainerized\nservice;\nno\ninfrastructure\norchestration.\nAsguard [46]\nAdaptive Honeypot\nEngagement\nDeep\nQ-Network\n(DQN)\nIn-Service (Session)\nModernizes\nRL-\nbased\nhoneypots\nwith DQNs for more\nnuanced interaction\nand\ncommand\nhandling.\nFocus\nremains\non\nsingle-service\nengagement,\nnot\ninfrastructure\norchestration.\nGASH [47]\nAdaptive Honeypot\nEngagement\nDQN + Generative\nAI (LLM)\nIn-Service (Session)\nIntegrates an LLM\n(GPT-4o) to generate\nrealistic and convinc-\ning responses to at-\ntacker commands.\nFocuses on improv-\ning the quality of in-\nteraction within a sin-\ngle service, not on the\nstrategic deployment\nof resources.\nUNADA [48]\nAutonomous Attack\nCharacterization\nUnsupervised\nSub-\nspace Clustering\nOffline Analysis\nAutonomous,\nnear\nreal-time\ncharacterization\nof\nattacks from NetFlow\ndata without prior\nknowledge.\nRelies on classical\nML and aggregated\nflow data, missing\nearly, packet-level in-\ndicators for real-time\ndecisions.\nRNN-IDS [49]\nNetwork\nIntrusion\nDetection\nRecurrent\nNeural\nNetwork (RNN)\nN/A (Classification)\nDemonstrates\ndeep\nlearning for general\nintrusion\ndetection\non\npre-processed\ndatasets\n(NSL-\nKDD).\nDesigned for clas-\nsification on static\ndatasets, not for real-\ntime orchestration de-\ncisions on live, raw\ntraffic.\nRaw Packet Transformers [50]\nMalicious\nTraffic\nClassification\nTransformer (ByT5)\nN/A (Classification)\nProves the feasibility\nof end-to-end learn-\ning directly on raw\npacket bytes for clas-\nsification.\nHigh computational\ncost and focus on\nclassification make it\nunsuitable for real-\ntime orchestration.\nactive participant in the deception. The reward function in\nRASSH was primarily based on session duration, with longer\nsessions being rewarded as they were assumed to yield more\nintelligence.\nSubsequent research built upon this foundation. Asguard\nby Touch and Colin modernized the approach by using a\nDeep Q-Network (DQN), allowing the agent to handle a much\nlarger state space and learn more nuanced interaction poli-\ncies [46]. Similar to RASSH, Asguard‚Äôs reward mechanism\nwas also based on session duration, but the DQN architecture\nenabled more sophisticated decision-making about command\nresponses.\nOther researchers have explored using RL to manage the\ntrade-off between interaction and resource consumption. For\ninstance, Veluchamy and Kathavarayan used deep RL to build\nhoneypots that could mitigate DoS attacks [16], while Limouchi\nand Mahgoub used RL to optimize thresholds for adapting IoT\nhoneypots [22].\nHowever, a common thread in this body of work is that the\n\"adaptation\" is confined to the behavior of a single, running\nservice (in-service adaptation). The RL agent learns what com-\nmand to issue or what banner to present. It does not, however,\nmake decisions about the underlying infrastructure itself, such\nas whether to deploy a honeypot in the first place. Moreover,\nthe reward functions in these systems are typically simplistic,\nfocusing on session duration or resource consumption rather\nthan the quality or novelty of the intelligence gathered.\nIn contrast, this work proposes a quality-based reward func-\ntion that values novel and significant adversary interactions\nover mere session longevity. This represents a considerable\nadvancement over simpler metrics from prior work, addressing\nthe \"quality vs. quantity\" intelligence problem.\n7\n\nD. DEEP LEARNING FOR NETWORK TRAFFIC ANALYSIS\nParallel to the advancements in adaptive honeypots, the broader\nfield of network intrusion detection has been revolutionized by\ndeep learning [55]. Researchers have successfully applied var-\nious neural network architectures to the problem of classifying\nmalicious network traffic.\nWorks like RNN-IDS by Yin et al. demonstrated the ef-\nfectiveness of Recurrent Neural Networks (RNNs) for cap-\nturing the sequential nature of network flows [49]. Autoen-\ncoders have been widely used for unsupervised anomaly de-\ntection, with systems like DeepLog [56] and other similar\napproaches [17]‚Äì[19] learning a model of normal behavior\nand flagging deviations. These methods are highly relevant to\nthe \"post-interaction log analysis\" component of the proposed\narchitecture.\nMore recently, state-of-the-art research has focused on ap-\nplying advanced models directly to raw packet data. Sharan\net al. demonstrated the use of Transformer models on raw\npacket bytes for malicious traffic classification, removing\nthe need for manual feature engineering [50]. While these\napproaches achieve high classification accuracy, they come\nwith two significant drawbacks for this use case: they are\ncomputationally intensive, making them difficult to run in real-\ntime for every single incoming packet, and their primary goal\nis classification, not the orchestration and resource allocation\ndecision-making that is central to this thesis.\nE. SYNTHESIS AND IDENTIFICATION OF THE RESEARCH\nGAP\nThe existing body of literature reveals a clear trajectory: from\nstatic, passive honeypots to interactive, ML-driven systems.\nHowever, it also illuminates a critical, unaddressed gap in the\nresearch landscape, which this thesis directly targets. Current\nresearch can be broadly categorized into two camps:\n1) In-Service Adaptation: RL-based honeypots that learn\nto optimize their interaction within a single, already-\nrunning service (e.g., choosing the best SSH command\nresponse).\n2) Offline Classification: Deep learning models that are\nhighly effective at classifying network traffic or logs\nas malicious or benign, but are typically too resource-\nintensive for real-time, per-packet decisions and are not\ndesigned to control infrastructure.\nThe gap lies at the intersection of these two areas: the use of\nmachine learning, specifically reinforcement learning, for the\ndynamic, real-time orchestration of the honeynet infrastructure\nitself. No existing work focuses on using first-packet analysis\nto drive an RL agent that makes the foundational decision\nof whether to expend resources to deploy a containerized,\nhigh-interaction honeypot from a pool of available types. This\nwork bridges the divide between single-service adaptation\nand full infrastructure automation, proposing a system that is\nadaptive not just in its responses but in its very composition.\nSpecifically, this research introduces the novel application of\nRL for infrastructure-level orchestration based on real-time\nanalysis of network traffic, a significant advancement over\nexisting approaches that focus solely on in-service adaptation\nor offline analysis.\nIV. CONTEMPORARY THREAT LANDSCAPE ANALYSIS\nA. EVOLUTION OF CYBER ATTACK METHODOLOGIES\nThe contemporary cyber threat landscape is characterized by a\nfundamental shift from opportunistic, single-vector attacks to\nsophisticated, multi-stage campaigns that leverage advanced\ntechniques and persistent access. This evolution reflects the\nincreasing professionalization of cybercriminal organizations\nand the growing economic incentives for successful cyber\nattacks [1].\n1) Advanced Persistent Threats (APTs)\nAdvanced Persistent Threats (APTs) represent the most sophis-\nticated category of cyberattacks, typically attributed to nation-\nstate actors or well-resourced criminal organizations [57], [58].\nAPT campaigns are characterized by their extended duration,\nrefined techniques, and specific strategic objectives. Recent\nanalysis by cybersecurity firms indicates that APT groups are\nincreasingly adopting living-off-the-land techniques, utilizing\nlegitimate system tools and processes to avoid detection by\ntraditional security measures [59], [60].\nThe APT lifecycle typically consists of multiple phases:\ninitial reconnaissance and target selection, initial compromise\nthrough spear-phishing or supply chain attacks, establishment\nof persistent access through backdoors and legitimate cre-\ndentials, lateral movement to identify and access high-value\ntargets, data exfiltration or system manipulation to achieve\nstrategic objectives, and long-term persistence to maintain\naccess for future operations [38]. Each phase presents unique\nchallenges for detection and mitigation, requiring adaptive\ndefense mechanisms that can identify subtle indicators across\nextended periods. 5\nNotable APT groups, such as APT29 (Cozy Bear), APT28\n(Fancy Bear), and the Lazarus Group, have demonstrated re-\nmarkable adaptability in their techniques, continuously evolv-\ning their tools and methods in response to defensive mea-\nsures [59]. This adaptability highlights the need for equally\nadaptable defensive technologies that can grow alongside the\ncapabilities of threat actors.\n2) Ransomware Evolution and Industrialization\nThe ransomware threat landscape has undergone a dramatic\ntransformation, evolving from simple file encryption attacks\nto complex, multi-stage operations that combine data theft,\nsystem disruption, and extortion. Modern ransomware opera-\ntions often follow a double or triple extortion model, where\nadversaries not only encrypt the victim‚Äôs data but also threaten\nto publicly release sensitive information and target the victim‚Äôs\ncustomers, partners, or stakeholders [61].\n5Subtle indicators may include low-and-slow scanning, use of encrypted\nC2 channels, or living-off-the-land binaries (LoLBins) that are difficult to\ndistinguish from legitimate administrative activity.\n8\n\nRansomware-as-a-Service (RaaS) platforms have democ-\nratized access to sophisticated attack capabilities, enabling\nless technically skilled actors to launch devastating attacks.\nPrimary RaaS operations such as Conti, REvil, and Lock-\nBit have operated with corporate-like structures, including\ncustomer support, affiliate programs, and quality assurance\nprocesses [61], [62]. The industrialization of ransomware has\nled to an increase in attack frequency, sophistication, and\neconomic impact.\nThe emergence of targeted ransomware attacks against crit-\nical infrastructure has significantly raised the stakes. Attacks\non Colonial Pipeline [63], JBS [64], and Kaseya [65] demon-\nstrated the potential for ransomware to disrupt essential ser-\nvices and supply chains, highlighting the urgent need for more\neffective defensive technologies. These attacks often involve\nextensive reconnaissance, lateral movement, and privilege\nescalation before the final ransomware deployment, creating\nmultiple opportunities for detection by adaptive honeynets. As\nillustrated in Figure 1, the economic scale of these attacks is\nsubstantial.\n3) Supply Chain Attacks and Third-Party Risks\nSupply chain attacks have emerged as one of the most con-\ncerning threat vectors, as they leverage the trust relationships\nbetween organizations and their technology providers. High-\nprofile incidents such as SolarWinds [66], Codecov [67], XZ [68]\nand Kaseya [65] have demonstrated how adversaries can com-\npromise software development and distribution processes to\ngain access to thousands of downstream victims simultane-\nously [3].\nThese attacks are particularly challenging to detect because\nthey often involve legitimate software and trusted communi-\ncation channels. Traditional security measures may not iden-\ntify malicious activity that appears to originate from trusted\nsources. The complexity of modern software supply chains,\nwith multiple layers of dependencies and third-party com-\nponents, creates numerous potential attack vectors that are\ndifficult to monitor comprehensively [60].\nThe increasing adoption of cloud services and software-as-\na-service (SaaS) platforms has expanded the attack surface for\nsupply chain compromises. Adversaries can potentially gain\naccess to multiple organizations by compromising a single\ncloud service provider or SaaS platform. This interconnect-\nedness requires security solutions that can identify subtle\nanomalies in trusted communications and detect indicators\nof compromise across complex, distributed environments [1].\nB. THREAT ACTOR CATEGORIZATION AND CAPABILITIES\nUnderstanding the diverse landscape of threat actors is es-\nsential for developing effective defensive strategies. Different\ncategories of threat actors possess varying capabilities, mo-\ntivations, and operational patterns that influence their attack\nmethodologies and the types of threats they pose [39].\n1) Nation-State Actors\nNation-state threat actors represent the most sophisticated and\nwell-resourced category of cyber adversaries. These actors typ-\nically have access to zero-day exploits, custom malware, and\nextensive infrastructure for conducting long-term campaigns.\nTheir objectives often include espionage, intellectual prop-\nerty theft, disrupting critical infrastructure, and conducting\ninfluence operations [59].\nNation-state actors are characterized by their patience and\npersistence, often maintaining access to target networks for\nyears while carefully avoiding detection. They employ so-\nphisticated operational security practices, including the use\nof legitimate infrastructure, encrypted communications, and\ncareful timing of activities to blend with regular network\ntraffic. Their advanced capabilities and resources make them\nparticularly challenging opponents for traditional security\nmeasures [58], [69].\nRecent trends indicate that nation-state actors are increas-\ningly targeting cloud infrastructure, software supply chains,\nand managed service providers to maximize their reach and\nimpact. They are also becoming more aggressive in their\noperations, with some groups conducting destructive attacks\nin conjunction with traditional espionage activities [3].\n2) Cybercriminal Organizations\nProfessional cybercriminal organizations have evolved into\nsophisticated enterprises with specialized roles, hierarchical\nstructures, and business-like operations. These organizations\noften focus on financially motivated attacks, including ran-\nsomware, banking fraud, cryptocurrency theft, and data mone-\ntization [62].\nModern cybercriminal groups demonstrate remarkable oper-\national sophistication, employing techniques such as initial ac-\ncess brokers who specialize in gaining entry to target networks,\nransomware operators who deploy and manage encryption at-\ntacks, money laundering services that facilitate the conversion\nof stolen funds, and customer support operations that assist\nvictims with ransom payments [62].\nThe professionalization of cybercrime has led to increased\nspecialization and efficiency in attack operations. Criminal\ngroups often purchase access to compromised networks from\ninitial access brokers, reducing the time and resources required\nto launch attacks. This ecosystem approach enables the rapid\nscaling of criminal operations, making it more difficult for\nlaw enforcement to disrupt entire criminal enterprises [60].\n3) Hacktivist Groups\nHacktivist organizations are motivated by political, social, or\nideological objectives rather than financial gain. These groups\noften target organizations or governments that they perceive as\nopposing their beliefs or values. While hacktivist attacks may\nbe less sophisticated than nation-state operations, they can still\ncause significant disruption and reputational damage [70].\nHacktivist groups often employ tactics such as distributed\ndenial-of-service (DDoS) attacks, website defacements, data\n9\n\nFIGURE 1. Ransomware Payment Size Analysis by Chainanalysis. [61]\nleaks, and social media manipulation [70]. Recent trends in-\ndicate that some hacktivist groups are adopting more sophis-\nticated techniques, including ransomware and destructive at-\ntacks, blurring the lines between hacktivism and cybercrime [1].\nThe decentralized nature of many hacktivist organizations\nmakes them difficult to predict and counter. These groups often\noperate through loose networks of volunteers with varying skill\nlevels, making their attack patterns less predictable than those\nof professional criminal organizations or nation-state actors.\n4) Insider Threats\nInsider threats represent a unique category of risk that com-\nbines legitimate access with malicious intent or negligent\nbehavior. Malicious insiders may be motivated by financial\ngain, revenge, ideology, or coercion by external actors. Negli-\ngent insiders may inadvertently create security vulnerabilities\nthrough poor security practices or by falling victim to social\nengineering [71].\nInsider threats are particularly challenging to detect be-\ncause they often involve legitimate access to systems and data.\nTraditional perimeter-based security measures are ineffective\nagainst threats that originate from within the organization [71].\nDetecting insider threats requires behavioral analysis, anomaly\ndetection, and careful monitoring of privileged access activi-\nties [60].\nRecent trends indicate that insider threats are becoming\nmore sophisticated, with some malicious insiders collaborating\nwith external threat actors to maximize the impact of their\nactivities. The increasing adoption of remote work and cloud\nservices has expanded the potential attack surface for insider\nthreats, making comprehensive monitoring more challenging.\nC. ATTACK VECTOR ANALYSIS\nModern cyberattacks employ diverse attack vectors that exploit\ndifferent aspects of an organization‚Äôs infrastructure, processes,\nand human behavior. Understanding these attack vectors is es-\nsential for developing comprehensive defensive strategies [43].\n1) Network-Based Attack Vectors\nNetwork-based attacks remain a primary concern for organi-\nzations, as they can provide adversaries with initial access to\ntarget environments and enable lateral movement within com-\npromised networks. Common network attack vectors include\nexploitation of unpatched vulnerabilities in network services,\nbrute force attacks against authentication systems, man-in-the-\nmiddle attacks against network communications, and exploita-\ntion of misconfigured network devices and services. [1], [60],\n[72]\nThe increasing adoption of cloud services and remote work\nhas significantly expanded the network attack surface. Or-\nganizations now must secure not only their traditional on-\npremises infrastructure but also cloud environments, remote\naccess solutions, and the network connections between these\ndiverse components. This expanded attack surface creates\nnew opportunities for adversaries and new challenges for\ndefenders. [1], [73]\nNetwork segmentation and zero-trust architectures have\nemerged as critical defensive strategies, but they require sophis-\nticated monitoring and analysis capabilities to be effective [74].\nAdaptive honeynets can play a crucial role in network defense\nby providing early warning of attack activities and detailed\nintelligence about adversary techniques and objectives.\n10\n\n2) Application-Level Attack Vectors\nApplication vulnerabilities continue to be a significant source\nof security incidents, with web applications being highly desir-\nable targets due to their accessibility and the valuable data they\noften contain. Common application attack vectors include SQL\ninjection, cross-site scripting (XSS), remote code execution,\nauthentication bypass, and business logic flaws [75].\nThe rapid pace of software development and deployment in\nmodern organizations often leads to security vulnerabilities\nbeing introduced and deployed to production environments.\nDevSecOps practices aim to address this challenge by integrat-\ning security testing into the development pipeline [76]. Still,\nthe complexity of modern applications and the pressure for\nrapid deployment continue to create opportunities for adver-\nsaries.\nAPI security has become increasingly important as orga-\nnizations adopt microservices architectures and API-driven\nintegrations. APIs often lack the same level of security con-\ntrols as traditional web applications, creating new avenues\nfor sophisticated threat actors to exploit [77]. The prolifer-\nation of APIs and the complexity of API ecosystems make\ncomprehensive security monitoring a challenging task.\n3) Social Engineering and Human-Centric Attacks\nSocial engineering attacks exploit human psychology and\nbehavior rather than technical vulnerabilities, making them\nparticularly effective and challenging to defend against [78].\nThese attacks often serve as the initial vector for more so-\nphisticated campaigns, providing adversaries with legitimate\ncredentials and access to target environments.\nPhishing attacks have evolved significantly in sophistica-\ntion, with adversaries employing detailed reconnaissance to\ncreate highly targeted and convincing messages [79]. Spear-\nphishing attacks often incorporate information gathered from\nsocial media, corporate websites, and data breaches to create\npersonalized messages that are difficult to distinguish from\nlegitimate communications.\nBusiness email compromise (BEC) attacks represent a par-\nticularly damaging category of social engineering, often re-\nsulting in significant financial losses. These attacks typically\ninvolve compromising or spoofing executive email accounts\nto authorize fraudulent financial transactions. The success of\nBEC attacks demonstrates the importance of implementing\ncomprehensive security awareness training and technical con-\ntrols that can detect anomalous communication patterns. [80],\n[81]\nD. EMERGING THREAT TRENDS\nThe cyber threat landscape continues to evolve rapidly, with\nnew trends and techniques emerging regularly. Understanding\nthese emerging trends is essential for developing adaptive\ndefensive strategies that can address future threats [82].\n1) AI-Powered Attacks\nThe increasing availability of artificial intelligence and ma-\nchine learning technologies is enabling adversaries to develop\nmore sophisticated and automated attack capabilities. AI-powered\nattacks can include automated vulnerability discovery, intelli-\ngent evasion of security controls, deepfake technology for so-\ncial engineering, and automated spear-phishing campaigns [83].\nMachine learning algorithms can be used to analyze de-\nfender behavior and adapt attack strategies in real-time, creat-\ning a dynamic adversarial environment where both adversaries\nand defenders employ AI technologies. This trend underscores\nthe importance of developing AI-powered defensive technolo-\ngies, such as adaptive honeypots, that can effectively counter\nAI-powered attacks.\nThe democratization of AI technologies through cloud ser-\nvices and open-source frameworks is making these capabilities\naccessible to a broader range of threat actors, potentially accel-\nerating the adoption of AI-powered attack techniques across\ndifferent threat actor categories [84].\n2) Cloud-Native Attacks\nAs organizations increasingly adopt cloud infrastructure and\ncloud-native technologies, adversaries are developing special-\nized techniques for targeting these environments. Cloud-native\nattacks often exploit misconfigurations in cloud services, abuse\nlegitimate cloud APIs, and leverage the shared responsibility\nmodel to target areas where security controls may be unclear\nor inadequate. [73]\nContainer and Kubernetes security has become a partic-\nular concern as organizations adopt containerized applica-\ntions and orchestration platforms. Adversaries are develop-\ning techniques to escape container environments, exploit Ku-\nbernetes misconfigurations, a threat detailed in hardening\nguides [85], and abuse container registries to distribute mali-\ncious images [86].\nThe complexity of cloud environments and the rapid pace\nof cloud service development create ongoing challenges for se-\ncurity teams. Traditional security tools and processes may not\nbe effective in cloud environments, requiring new approaches\nto monitoring, detection, and response.\n3) IoT and Edge Computing Threats\nThe proliferation of Internet of Things (IoT) devices and edge\ncomputing infrastructure is creating new attack vectors and\nexpanding the overall attack surface. IoT devices often lack\nrobust security controls and may be difficult to update or patch,\nmaking them attractive targets for adversaries [87].\nIoT botnets have become a significant threat, with adver-\nsaries compromising large numbers of IoT devices to conduct\ndistributed denial-of-service attacks, cryptocurrency mining,\nand other malicious activities [88]. The scale and distributed\nnature of IoT botnets make them challenging to detect and\nmitigate using traditional security approaches.\nEdge computing environments present unique security chal-\nlenges due to their distributed nature and the need to balance\nsecurity with performance and latency requirements. Securing\nedge environments requires new approaches to monitoring\nand threat detection that can operate effectively in resource-\nconstrained and distributed environments [89].\n11\n\nE. IMPACT ASSESSMENT AND ECONOMIC CONSEQUENCES\nThe economic impact of cyberattacks continues to grow, with\norganizations facing direct financial losses, operational disrup-\ntions, regulatory penalties, and long-term reputational damage.\nUnderstanding these impacts is essential for justifying invest-\nments in advanced defensive technologies such as adaptive\nhoneynets.\n1) Direct Financial Losses\nCyber attacks can result in immediate financial losses through\ntheft of funds, ransom payments, system recovery costs, and\nbusiness interruption. The average cost of a data breach reached\n$4.44 million in 2025, according to IBM‚Äôs Cost of a Data\nBreach Report, with costs varying significantly based on the\nsize of the organization, industry sector, and geographic loca-\ntion [90].\nExceptionally high direct costs are imposed by ransomware\nattacks, forcing difficult decisions on whether ransoms should\nbe paid, system restoration should be pursued, or prolonged\noperational downtime should be accepted. In 2024 alone, ran-\nsomware payments were reported to total $813.55 million [61].\nThe increasing sophistication of financial fraud attacks,\nincluding business email compromise (BEC) and payment\nfraud, has resulted in significant direct economic losses for\norganizations. The FBI‚Äôs Internet Crime Complaint Center\nreported over $2.77 billion in losses from business email\ncompromise attacks in 2024 alone [80].\n2) Operational Disruption and Recovery Costs\nBeyond direct financial theft, cyberattacks often result in\nsignificant operational disruptions that can have cascading\neffects throughout an organization and its supply chain. System\ndowntime, data recovery efforts, and the need to implement\nalternative processes can result in substantial indirect costs\nthat may exceed the direct financial impact of an attack. [90]\nThe time required to recover from a sophisticated cyber at-\ntack fully can extend for months or even years, particularly for\nattacks that involve extensive data theft or system compromise.\nDuring this recovery period, organizations may face reduced\noperational efficiency, increased security costs, and ongoing\nuncertainty about the full scope of the compromise. [90]\nCritical infrastructure attacks can have particularly severe\noperational impacts, potentially affecting essential services\nsuch as power generation, transportation, healthcare, and com-\nmunications. The 2021 Colonial Pipeline ransomware attack\ndemonstrated how cyberattacks on critical infrastructure can\nhave widespread economic and social impacts that extend far\nbeyond the directly targeted organization. [91]\n3) Regulatory and Legal Consequences\nThe increasing focus on data protection and cybersecurity regu-\nlations has created significant potential for legal and regulatory\nconsequences following cyberattacks. Organizations may face\nsubstantial fines under rules such as the General Data Protec-\ntion Regulation (GDPR) [92] and the California Consumer\nPrivacy Act (CCPA) [93], as well as various industry-specific\nrequirements.\nBeyond regulatory fines, organizations may face civil lit-\nigation from customers, partners, and shareholders who are\naffected by cyber attacks. Class action lawsuits following\nmajor data breaches can result in settlement costs that reach\nhundreds of millions of dollars, particularly when sensitive\npersonal or financial information is compromised. [94], [95]\nV. THE ART OF INVISIBILITY: EVADING HONEYNET\nDETECTION\nA. INTRODUCTION: THE ADVERSARY‚ÄôS ADVANTAGE\nA honeynet‚Äôs value is directly proportional to its believability.\nAdversaries, aware of deception technologies, are strongly\nmotivated to detect them to avoid analysis, prevent wasting re-\nsources, and, in some cases, to study the defenders‚Äô techniques.\nThis leads to a cat-and-mouse game where adversaries actively\n‚Äò‚Äòfingerprint‚Äô‚Äô systems to expose the artifacts of a controlled\nenvironment. If a honeynet can be easily identified, its ability\nto capture high-fidelity intelligence from sophisticated actors\nis severely reduced. 6\nB. STATE-OF-THE-ART IN HONEYNET DETECTION (THE\n‚Äò‚ÄòOFFENSE‚Äô‚Äô)\nOver the years, adversaries have developed a sophisticated\narsenal of techniques to unmask honeynets. These methods, as\nsurveyed by Holz et al. [96], primarily fall into three categories:\n1) Environmental Artifacts\nThe most common detection vector is the search for artifacts\nleft by virtualization or containerization [97], [98]. In their\nfoundational work on detecting virtual machines, subtle dif-\nferences in CPU instructions, memory layout, and I/O timing\ncan betray the presence of a hypervisor. Adversaries search for\nspecific MAC address prefixes (e.g., ‚Äò00:0C:29‚Äò for VMware),\nunique hardware identifiers, or the presence of guest tools\ndrivers that would not exist on a bare-metal machine.\n2) Behavioral Quirks and Interaction Probes\nLow-interaction honeypots, while efficient, often exhibit be-\nhavioral quirks that can be detected. They may present service\nbanners that are slightly different from a real service, have\nunnatural response delays, or implement only a partial set of a\nprotocol‚Äôs features. Sophisticated adversaries employ multi-\nstage fingerprinting frameworks [99], which automate a series\nof interaction probes. These frameworks test for known vul-\nnerabilities, measure system responses, and analyze protocol\nhandshakes to determine if a target is a honeypot. Another crit-\nical vulnerability is handoff inconsistency, which can occur\nin multi-layered systems like ADLAH. When a connection\nis passed from a low-interaction sensor to a high-interaction\nhoneypot, any discrepancy in the protocol handshake (e.g.,\n6High-fidelity intelligence implies detailed, actionable data about adversary\ntools, infrastructure, and intent, as opposed to the low-fidelity data from\nautomated scans.\n12\n\ndifferent SSH server banners, cipher suites, or authentication\nmethods) can reveal the deception.\n3) Network-Level Indicators\nAnalysis of network traffic can also reveal a honeynet. For\nexample, Time-To-Live (TTL) values in IP packets can some-\ntimes suggest that traffic has passed through an additional hop\n(the hypervisor) compared to a real host on the same subnet.\nFurthermore, TCP/IP stack fingerprinting tools like ‚Äònmap‚Äò\ncan identify discrepancies between the advertised operating\nsystem and the actual network behavior. A significant temporal\nartifact is deployment latency; the delay introduced when pro-\nvisioning a honeypot on demand can create a noticeable pause\nduring the connection handshake, which is highly suspicious\nand can be used for fingerprinting.\nC. STATE-OF-THE-ART IN COUNTER-EVASION (THE\n‚Äò‚ÄòDEFENSE‚Äô‚Äô)\nIn response, defenders have developed techniques to make\ntheir honeynets more credible:\n1) High-Interaction Honeypots\nThe most effective defense is to use a high-interaction hon-\neypot that provides a real, full-fledged operating system and\napplications. This minimizes behavioral quirks, as the adver-\nsary is interacting with the genuine software. Systems like\nArgos [100] pushed this concept further by using dynamic\ntaint analysis to provide high-interaction emulation with better\nperformance and control, making them much more challenging\nto detect than their low-interaction counterparts.\n2) System Hardening and Obfuscation\nThis involves manually or semi-automatically altering the\nhoneypot‚Äôs environment to remove noticeable artifacts. This\ncan include changing MAC addresses, modifying the registry\non Windows systems, and eliminating vendor-specific drivers\nor files associated with the virtualization platform. However,\nthis is a painstaking process that must be constantly updated\nas new detection techniques emerge.\nD. ADLAH‚ÄôS APPROACH TO ADVANCED STEALTH\nADLAH is designed to move beyond these static defenses by\ntreating stealth as a dynamic, intelligent process.\n1) Current Capabilities: Dynamic Reconfiguration\nThe current ADLAH prototype leverages its container orches-\ntration backbone (k3s) to implement a ‚Äò‚Äòmoving target‚Äô‚Äô de-\nfense. By rapidly deploying and destroying honeypot instances\nfrom a pool of different container images (e.g., various Linux\ndistributions, different service versions), it presents a con-\nstantly changing attack surface. This dynamic reconfiguration\ncomplicates long-term fingerprinting, as an adversary cannot\nrely on a single set of artifacts to identify the honeynet over\ntime.\n2) Target Architecture: Intelligent, Adaptive Stealth (Vision)\nThe full vision for ADLAH integrates stealth directly into\nthe reinforcement learning agent‚Äôs decision-making process.\nThe goal is not merely to engage an adversary, but to engage\nwithout being discovered. This is achieved through two key\nconcepts:\n‚Ä¢ RL-Driven Obfuscation: The RL agent‚Äôs reward func-\ntion will be modified to explicitly penalize the deploy-\nment of honeypot configurations that are known to be\neasily fingerprinted. For instance, if interactions with\na specific honeypot type consistently lead to behavior\nindicative of detection (e.g., the use of fingerprinting\ntools), the agent will learn to avoid that configuration.\nA high detectability score should result in a negative\nreward, teaching the agent to avoid configurations that\ncan be easily fingerprinted.\n‚Ä¢ Observability and Feedback Loop: The system will be\nenhanced to monitor for signs of detection actively. By\ncorrelating adversary actions with known fingerprinting\ntechniques, ADLAH can create a ‚Äò‚Äòdetectability score‚Äô‚Äô in\nreal-time. This score becomes a critical input for the RL\nagent, allowing it to adapt its strategy dynamically, per-\nhaps by migrating the interaction to a higher-interaction,\nmore credible honeypot if it suspects it is being probed.\nThis creates a closed-loop system where the honeynet\nlearns to become progressively stealthier over time.\nVI. FULL ADAPTIVE HONEYNET ARCHITECTURE\nThe proposed adaptive honeynet architecture, illustrated in\nFigure 2 and with its data flow detailed in Figure 3, is a modu-\nlar, cloud-native system designed for advanced threat analysis,\ndynamic deception, and real-time analyst support. It integrates\nfour key conceptual components: a low-interaction Sensor\nNode for initial contact, a central \"Hive\" for data aggregation\nand decision-making, a lightweight Kubernetes (k3s) cluster\nfor dynamic high-interaction honeypot deployment, and a\nsophisticated AI pipeline for threat analysis and orchestration.\nThis section describes the high-level design and data flow of\nthis architecture, while Section VIII will detail the specific\nimplementation of the working prototype.\nA. FIRST-FLIGHT ANALYSIS (PROTOTYPE) &\nREINFORCEMENT LEARNING DEPLOYMENT\nThe prototype makes deployment decisions from live telemetry\nindexed in Elasticsearch rather than exclusively from raw first-\npacket bytes. An event source polls Elasticsearch for recent\ndocuments and forms short, per-source-IP sequences that are\nfed to a reinforcement learning agent. At each step, the agent\nobserves a state vector derived from the most recent events\nof a single source IP, chooses an action (deploy or wait),\nand later receives a delayed reward based on interactions of\nthe adversary with the honeypot pod. When a deployment\nis triggered, the system configures connection tracking on\nthe Sensor Node, transparently forwarding subsequent traffic\nfrom the attacker to the designated honeypot pod. Although the\nbroader vision includes multiple honeypot types, the current\n13\n\nFIGURE 2. Visual overview of the adaptive honeynet architecture.\nFIGURE 3. Detailed data flow of an adversary session, from initial contact\nto high-interaction engagement.\naction space is binary and focused on deciding if and when to\nescalate a source to a high-interaction pod.\nB. POST-INTERACTION LOG ANALYSIS AND ANOMALY\nDETECTION\nAll logs from both low- and high-interaction sources are cen-\ntrally aggregated in the Hive. While the prototype‚Äôs RL agent\nacts on first-packet data, the whole architecture envisions\na sophisticated AI Analytics Pipeline for post-interaction\nanalysis of logs from high-interaction honeypots like Cowrie.\nThis pipeline serves as a critical component for identifying\nnovel adversary behaviors that deviate from previously ob-\nserved patterns and for continuously improving the system‚Äôs\nunderstanding of threat landscapes.\n1) Adaptive Autoencoder for Log Anomaly Detection\nA core component of this pipeline is an adaptive autoencoder,\ndesigned to analyze sequences of events from high-interaction\nlogs. Unlike traditional anomaly detection systems that are\ntrained once on a static dataset, this autoencoder is designed\nfor continuous online learning. The intelligence refinement\nloop leverages both the autoencoder approach for novelty\ndetection and complementary techniques from the literature,\nsuch as RNNs/LSTMs for TTP classification, to provide a\ncomprehensive analysis of adversary behavior.\nThe process is as follows:\n1) Feature Extraction: Logs from a completed high-interaction\nsession (e.g., a series of commands entered in Cowrie)\nare transformed into a numerical feature vector. This\ncan include features such as command frequency, use\nof specific tools, session duration, and payload charac-\nteristics.\n2) Anomaly Scoring: The feature vector Y ‚ààRd is fed\ninto the autoencoder, producing a reconstruction ÀÜx. The\nanomaly score is computed as the mean squared recon-\nstruction error:\ns(x) = 1\nd\nd\nX\nj=1\n(xj ‚àíyj)2 ,\n(1)\nwhere x is the original feature vector, y is its reconstruc-\ntion, and d is the number of features. This formulation\nfollows established practice in autoencoder-based in-\ntrusion detection [17]. A higher s(x) indicates that the\n14\n\nobserved behavior deviates more strongly from what the\nmodel has learned as ‚Äò‚Äònormal.‚Äô‚Äô\n3) Online Training: The autoencoder is continuously re-\ntrained on feature vectors from incoming logs, allow-\ning its definition of ‚Äò‚Äònormal‚Äô‚Äô to evolve over time. As\nspecific attack patterns become frequent, the model\nlearns to reconstruct them with low error, so that a\nhigh reconstruction error becomes a strong indicator\nof truly novel or significantly mutated attack patterns.\nThis mitigates the impact of concept drift [101], [102],\nwhere adversary tactics change over time.\nThis mechanism allows the system to automatically surface\nthe most interesting and unusual interactions for security ana-\nlysts, prioritizing novel threats over the background noise of\ncommon automated attacks. If this approach is working, needs\nto be evaluated.\n2) Integration with Reinforcement Learning Reward\nThe anomaly score generated by the adaptive autoencoder\nprovides a powerful signal for refining the RL agent‚Äôs reward\nfunction. The long-term vision is to move beyond a purely\nquantity-based reward to a quality-based one, addressing the\n\"quality vs. quantity\" intelligence problem. The reward func-\ntion could be augmented as follows:\nR =\n\u00001 + œâ ¬∑ ÀúAscore\n\u0001\n¬∑ Nlogs ‚àíŒª ¬∑ C,\n(2)\nwhere Ascore is the normalized reconstruction error from\nthe autoencoder for that session‚Äôs logs, and œâ is a weighting\nhyperparameter. This creates a system that not only learns to\nengage adversaries but preferentially learns to engage novel\nand interesting adversaries, thereby maximizing the value of\nthe collected intelligence.\nC. ATTACK CHAIN DETECTION\nA central innovation of the architecture is the reconstruction\nof attack chains. All logs from a single source Internet Proto-\ncol (IP) are grouped as a candidate attack chain. To address\ndistributed or proxy-based attacks, an advanced AI correla-\ntion model analyzes behavioral indicators (e.g., command\nsequences, timing, tool fingerprints) to link sessions from\ndifferent IPs that likely originate from the same adversary.\nThis enables the system to track complex, multi-session attack\ncampaigns and attribute activity to persistent adversaries.\nThe attack chain correlation engine employs graph-based\nalgorithms to model relationships between sessions based\non temporal proximity, behavioral similarity, and shared in-\nfrastructure [103]. Session features are embedded in a high-\ndimensional space where similarity metrics capture both ex-\nplicit feature matching and implicit behavioral patterns. Ma-\nchine learning classifiers categorize detected chains based\non attack type, complexity, and automation level, enabling a\nprioritized response to high-risk campaigns.\nTemporal analysis techniques identify patterns in attack\ntiming that may indicate the use of automated tools, human-\noperated attacks, or coordinated campaigns across multiple\nthreat actors. The system maintains persistent adversary pro-\nfiles that evolve, capturing changes in tactics, techniques, and\nprocedures (TTPs) as adversaries adapt to defensive measures.\nCross-organizational correlation capabilities enable the system\nto identify attack campaigns that span multiple organizations,\nproviding valuable intelligence about broader threat actor\nactivities.\nD. BOT BEHAVIOR VERSIONING & MITRE MAPPING\nThe system is designed to identify and label recurring auto-\nmated bot activity. Detected attack chains are fingerprinted\nusing behavioral signatures that capture both static and dy-\nnamic characteristics of the attack tools. These signatures are\nbased on command sequences, timing patterns, protocol usage,\nand other behavioral indicators that remain consistent across\ndifferent deployments of the same bot family.\nThe fingerprinting process employs fuzzy matching tech-\nniques to identify variants of known bot families, enabling\nthe system to track the evolution of automated attack tools\nover time. Detected attack chains are mapped to known Tac-\ntics, Techniques, and Procedures (TTPs) from the MITRE\nATT&CK framework [72], providing standardized catego-\nrization that facilitates threat intelligence sharing, often us-\ning standards like STIX‚Ñ¢[104], [105], and correlation with\nexternal security tools. The mapping process uses semantic\nsimilarity measures to associate observed behaviors with the\nmost relevant ATT&CK techniques, even when the exact im-\nplementation differs from documented examples.\nIf a new attack chain closely matches a known bot pattern\nbut exhibits subtle changes, it is flagged as a new variant and\nversioned accordingly using a hierarchical versioning scheme.\nVersioning tracks changes in payload structures, command\nsequences, evasion techniques, and communication protocols,\nproviding detailed lineage information about how bot families\nevolve in response to defensive measures. These insights are\ntracked and managed through a dedicated GUI module, which\nsupports longitudinal bot tracking and threat intelligence en-\nrichment.\nE. ADAPTIVE HIGH-INTERACTION PODS\nUnlike static honeypots, the architecture supports adaptive\npod behavior. Deployed pods are capable of modifying their\nresponses in real-time, aiming to maximize information gain\nabout adversary tools and behavior. This may include dynamic\nresponse crafting, interactive deception, or runtime behav-\nioral modulation based on observed adversary input, enabling\ndeeper engagement with both automated and human-driven\nthreats.\nThe adaptive pod framework utilizes a plugin-based archi-\ntecture that enables the dynamic loading of various response\nmodules based on the detected threat profile. Response mod-\nules are designed to mimic specific vulnerable services while\nincorporating subtle variations that can help identify sophis-\nticated adversaries who may be probing for inconsistencies.\nThe system maintains a library of response templates that can\n15\n\nbe combined and modified in real-time to create convincing\ndeceptions.\nInteractive deception techniques include progressive dis-\nclosure of system information, where adversaries are gradu-\nally provided with more detailed system information as they\ndemonstrate persistence and capability. This approach helps\ndistinguish between opportunistic scanners and targeted ad-\nversaries while maximizing the intelligence value of extended\nengagements. Runtime behavioral modulation adjusts pod\nresponses based on real-time analysis of adversary behavior,\nensuring that interactions remain credible while collecting\nmaximum intelligence about adversary tools and methodolo-\ngies.\n1) Deep Emulation Portfolio (Integrable Pods)\nAfter escalation and pod provisioning, the orchestrator selects\nwhich high-interaction backend to instantiate. In addition to\nCowrie [52], the following projects can be integrated as stan-\ndalone pods:\n‚Ä¢ Conpot (ICS/SCADA) [106] industrial/OT protocols.\n‚Ä¢ Dionaea (malware catcher) [107] collects shellcode and\nmalware samples across common services.\n‚Ä¢ Glastopf (web) [108] web applications/HTTP attacks.\n‚Ä¢ Heralding (credential catcher) [109] targeted capture of\nauthentication attempts.\n‚Ä¢ Honeytrap (framework) [110] protocol-agnostic honey-\npot framework.\n‚Ä¢ Elastichoney [111] Elasticsearch-Decoys.\n‚Ä¢ Wordpot [112] WordPress-specific decoys.\n‚Ä¢ IoTPOT (reference design) [113] IoT/Telnet campaigns.\n‚Ä¢ Amun [114] complementary legacy environments.\n2) Adaptive Honeypots\nIn addition to standard pods, research-grade adaptive back-\nends can be integrated (e.g., Asguard [46], Self-Guarded [30],\nQRASSH/RASSH [15], [23], [44], HoneyIoT [21]). These\nserve as building blocks for RL- or rule-based adaptation of\nservice interaction and stealth strategies.\n3) Attacker-Dedicated Emulation Networks\nFuture iterations of the architecture need not constrain ad-\nversary engagement to a single high-interaction pod. Instead,\neach escalated adversary could be provisioned with an isolated,\nattacker-dedicated emulation network that more closely mir-\nrors a real enterprise environment. Such a network could con-\ntain multiple interconnected pods simulating heterogeneous\nhosts and services, allowing the adversary to perform privilege\nescalation, lateral movement, and multi-stage attacks within\na contained virtual environment. For example, an attacker\nmight encounter a simulated Active Directory domain, pivot\nbetween workstations and servers, or exploit vulnerable ser-\nvices on internal segments. This richer engagement surface\nwould enable the collection of higher-fidelity behavioral data,\nparticularly regarding post-compromise tactics, techniques,\nand procedures (TTPs), and support more realistic testing of\nadaptive defense and deception strategies.\nF. VISUALIZED ATTACK CHAINS & ANALYST INTERFACE\nA graphical user interface (GUI), which can be built with tools\nlike Kibana [115] or Grafana [116], [116], provides interactive\nvisualizations of attack chains, session flows, and anomaly\nscores, often powered by backends like Prometheus [117],\n[118] and OpenTelemetry [119]. Analysts can manage bot\nversion history, track MITRE ATT&CK correlations, and re-\nview AI-based chain linking. The interface also offers real-\ntime insight into deployed pods and the RL agent‚Äôs decision\nprocess, supporting both operational monitoring and forensic\ninvestigation.\nThe visualization framework utilizes force-directed graph\nlayouts to represent attack chains, where nodes represent in-\ndividual sessions and edges represent temporal or behavioral\nrelationships between sessions. With interactive filtering, ana-\nlysts can focus on certain times, types of threats, or ways of\nattacking. Timeline views that show how attack campaigns\nhave changed over time and heatmap displays that show times\nwhen attacks are most active are examples of temporal visual-\nization features.\nAdvanced analytics capabilities include statistical summaries\nof attack characteristics, comparison tools for identifying sim-\nilarities between different attack campaigns, and predictive\nmodeling features that help analysts anticipate future attack\nactivities. The interface integrates with external threat intelli-\ngence platforms, automatically enriching displayed informa-\ntion with context from public and private threat feeds. Col-\nlaboration features enable multiple analysts to simultaneously\ninvestigate threats, with shared annotations and discussion\nthreads attached to specific attack chains or sessions.\nG. AUTOMATED BOT VERSIONING AND CAMPAIGN\nTRACKING\nBased on empirical analysis of MADCAT and T-Pot traffic,\nit was observed that most externally exposed sessions are\ngenerated by automated agents (\"bots\"), whereas sustained\nhuman interaction is comparatively rare. Accordingly, in the\nfuture architecture the capability set is envisioned to extend\nbeyond anomaly detection and selective escalation: recurring\nbot attack chains are to be extracted automatically, clustered\ninto families, and versioned. The intended outcome is a contin-\nuously updated, machine-generatable catalog of bot families\nand versions that can be referenced, detected, and shared.\n1) From Sessions to Canonical Attack Chains\nIn the envisioned architecture, high-interaction pods are in-\ntended to capture full multi-step behaviors. Each session would\nbe converted into a canonical attack chain by:\n‚Ä¢ Normalization: tokenize and normalize commands (low-\nercasing, variable masking, path canonicalization), de-\nduplicate transient markers (timestamps, PIDs), and ab-\nstract parameters (e.g., IPs/URLs to classes).\n‚Ä¢ Sequencing: order events by causality and time; merge\nretries; compress short loops; preserve protocol bound-\naries (SSH/HTTP/Telnet, etc.).\n16\n\n‚Ä¢ Graphization: represent the chain as a labeled multi-\ngraph (nodes: actions/resources; edges: temporal/causal),\nwhich is robust to benign reordering.\n2) Similarity, Clustering, and Family Detection\nAn online clustering pipeline is proposed to group chains into\nbot families:\n‚Ä¢ Sequence/Graph similarity: dynamic-time-warping over\naction sequences and motif/subgraph similarity over the\ngraph form.\n‚Ä¢ Feature embedding: bag-of-actions + n-grams + graph\nkernels, projected into a vector space for approximate\nnearest-neighbor search.\n‚Ä¢ Incremental clustering: streaming DBSCAN/HDBSCAN\nfor density-based grouping with outlier discovery, yield-\ning stable families with drift tolerance.\nClusters would be periodically stabilized into families. A fam-\nily would be promoted when support (number of chains, tem-\nporal span, multi-sensor presence) exceeds thresholds and\nwhen core motifs remain stable under canonicalization.\n3) Cross-Session Stitching Across IPs\nTo counter typical evasion tactics in which an operator ro-\ntates source IP addresses or alternates short bursts of activity\nacross sessions, cross-session stitching is envisioned. Sessions\nfrom different source IPs and even different sensors would be\nlinked into a single, coherent attack chain when probabilis-\ntic evidence supports a common origin. Evidence sources\nwould include: (i) high-similarity command subsequences\nand rare action motifs, (ii) shared infrastructure indicators\n(domains, URLs, file hashes, SSH fingerprints), (iii) consistent\nenvironment-discovery behaviors (e.g., identical probing order,\nidiosyncratic typos/flags), and (iv) temporal proximity within\nconfigurable windows. A session-linking model (e.g., a graph-\nbased linkage with learned edge weights or a sequence labeling\napproach) would assign link probabilities; chains exceeding\na confidence threshold would be aggregated into one multi-\nsession attack chain. In this way, bursty actions issued from\nmultiple IPs are expected to be reconstructed into a single\ncampaign entity, enabling accurate family assignment and\nversioning.\n4) Versioning Model\nWithin a family, semantically meaningful versions are to be\nassigned based on chain changes. A three-tier scheme inspired\nby semantic versioning is proposed:\n‚Ä¢ MAJOR: structural change of the attack graph (new stage\nadded/removed/reordered, new capability such as lateral\nmovement, binary delivery vector change). Detected via\nmotif divergence or graph edit distance above a major\nthreshold.\n‚Ä¢ MINOR: stage preserved, but different tools/URLs/encodings\nor altered parameters/decoders; command templates change\nwhile intent remains. Detected via template delta beyond\na minor threshold.\n‚Ä¢ PATCH: cosmetic or operational tweaks (timing, sleep,\nbenign obfuscation) that do not affect capabilities; de-\ntected via low-impact deltas.\nTo ensure global uniqueness and operational clarity, it is pro-\nposed that each bot be named as:\nADLAH.BOT.<family>.<proto>.<vector>.<pla\ntform>:<MAJOR>.<MINOR>.<PATCH>\nwhere <family> is a short, mnemonic identifier promoted\nfrom the dominant cluster label (e.g., mirailike); <proto>\nencodes the primary ingress protocol (e.g., SSH, TELNET,\nHTTP); <vector> denotes the first weaponization step (e.g.,\nwget-curl, bruteforce, redis-rce); and <plat-\nform> captures the observed target OS/arch when inferable\n(e.g., linux-arm).\nThe version tuple follows the rules above.\nExamples: ADLAH.BOT.mirailike.TELNET.brutef\norce.linux:2.1.0.\n5) Change Detection and Version Bumping\nNew chains would be compared against a family‚Äôs canoni-\ncal representatives. If graph edit distance or template deltas\nwere to cross MINOR/MAJOR thresholds, a new version\nwould be proposed and audited automatically in the analyst\nUI. Patch increments may be auto-accepted to reduce analyst\nload. Thresholds are intended to be learned from historical\nvariance per family to avoid over-fragmentation.\n6) Detection and Export\nOnce a family/version was established, the following artifacts\nwould be automatically materialized:\n‚Ä¢ Online signatures: light-weight behavioral rules for the\nSensor Node and first-flight filters (e.g., action subse-\nquences, header fingerprints) to triage and route.\n‚Ä¢ IDS/YARA/Rule exports: export to Snort/Suricata and\nYARA-L, linked to family/version identifiers.\n‚Ä¢ TI artifacts: compact STIX objects with family/version\nmetadata and canonical chains for sharing.\n7) RL Integration\nFamilies and their novelty scores would feed back into the RL\nloop: (i) escalation would be promoted when a chain is closest\nto unknown families; (ii) pods with richer telemetry would\nbe prioritized for uncertain families; (iii) confirmation of MI-\nNOR/MAJOR changes would be rewarded. This coupling is\nintended to steer resources toward emerging variants while\nkeeping familiar bots inexpensive to process.\n8) Why Versioning Matters\nIn a bot-dominated exposure model, versioning is expected\nto provide: (i) stable referents for operators and partners; (ii)\nimmediate rules for early triage; (iii) quantitative measures\nof ecosystem drift; and (iv) a foundation for longitudinal\nintelligence (campaign continuity, infrastructure reuse, kit\nlineage). The capability described in this section forms part\n17\n\nof the planned, future architecture rather than the present\nprototype.\nH. OVERVIEW AND DESIGN PRINCIPLES\nThe adaptive honeynet architecture is built upon several key\ndesign principles that ensure effective threat detection, re-\nsource efficiency, and operational flexibility. The system em-\nploys a modular design that separates concerns across distinct\ncomponents, enabling independent development, testing, and\ndeployment of each subsystem while maintaining seamless\nintegration through well-defined interfaces. This modular ap-\nproach facilitates maintenance, troubleshooting, and future\nenhancements while reducing the complexity of individual\ncomponents.\nScalability is achieved through containerized deployment\nand cloud-native architecture, enabling the system to scale\nresources based on threat volume and computational demands\ndynamically. The containerized approach ensures consistent\ndeployment across various environments, while allowing for\nrapid scaling and resource optimization. Security is maintained\nthrough network isolation, secure communication channels,\nand comprehensive logging that provides visibility into all sys-\ntem activities while protecting against potential compromise\nof the honeynet infrastructure itself.\nThe architecture prioritizes real-time processing capabili-\nties, enabling immediate response to detected threats through\nrapid pod deployment and traffic redirection. This real-time\ncapability is essential for maintaining the illusion of vulnerable\nsystems that adversaries expect to encounter, ensuring that\nhoneypots are available when needed to capture valuable threat\nintelligence. The system also emphasizes adaptability through\nmachine learning integration, allowing it to evolve its threat\ndetection and response capabilities based on observed attack\npatterns and system performance. 7\nThe architecture is fundamentally designed to scale from\nits current single-sensor prototype to a large, geographically\ndistributed honeynet. This scalability is rooted in the clear\nseparation of the lightweight Sensor Nodes from the central\nHive. Multiple sensor nodes can be deployed across diverse\nnetworks and regions, each acting as an independent data\ncollector and enforcement point. These sensors report threat\ntelemetry to a central Hive, which aggregates intelligence and\ncentralizes the computationally intensive AI/ML workloads.\nThe use of Kubernetes for high-interaction honeypot deploy-\nment is another key enabler of scale; as the number of required\nengagements grows, the cluster can be expanded by adding\nmore worker nodes. This distributed model not only broadens\nthreat visibility but also creates a resilient infrastructure capa-\nble of supporting large-scale intelligence operations without\ncreating performance bottlenecks at the edge.\n7This is often referred to as online or continuous learning, where the model\nupdates itself incrementally as new data arrives, in contrast to static models\ntrained offline.\nI. SENSOR NODE\nThe Sensor Node runs MADCAT, a low-interaction honeypot\ndeveloped by the BSI that records all connection attempts\nwithout committing to particular services [4]. While MAD-\nCAT provides a crucial baseline for threat observation, this\narchitecture elevates it from a passive sensor to an intelligent\ntripwire for a dynamic, adaptive system. By integrating a\nsophisticated AI stack, this work directly supports the BSI‚Äôs\nstrategic goals: to accelerate the detection of new attacks and to\ngain more profound, more actionable insights into application-\nlayer threats. This enhanced understanding is vital for the BSI‚Äôs\nmission to produce timely and effective public warnings and\nadvisories. MADCAT opens all ports and accepts Transmis-\nsion Control Protocol (TCP) [120], User Datagram Protocol\n(UDP) [121], and raw traffic, providing only the technically\nnecessary responses to establish data connections with po-\ntential adversaries. This low-interaction approach enables the\ncapture of attack vectors while minimizing the risk of detection.\nThe Sensor Node is deployed as a container on a Virtual\nMachine (VM) with two network interfaces: one for adversary-\nfacing traffic and one for internal Hive communication. The\nMADCAT configuration has been modified to log first-packet\nmetadata (headers, payload, timestamps) to ‚Äò/var/log/madcat‚Äò,\nwhich is then forwarded via Logstash over Transport Layer\nSecurity (TLS) to the Hive node.\nJ. HIVE NODE\nThe Hive node hosts an ELK (Elasticsearch, Logstash, Kibana)\nstack for centralized data processing [122]. Logstash receives\nstructured MADCAT logs via TCP [120], applies parsing\nfilters, and indexes them into Elasticsearch. Kibana is secured\nbehind a reverse proxy and used for interactive analysis. The\nRL decision agent also runs on the Hive and continuously polls\nElasticsearch for recent sensor events to drive deployment\ndecisions in real time.\nK. REINFORCEMENT LEARNING AGENT\nThe RL agent runs as a containerized Python service on the\nHive node. It consumes recent events via an Elasticsearch\npolling source and builds short sequences per source IP. The\nagent is a TensorFlow-based Deep Q-Network with an LSTM\nencoder and a dueling head (separate value and advantage\nstreams) optimized with Adam (gradient clipping) and Huber\nloss [123]. It uses experience replay, a target network, and\nan œµ-greedy policy. The discrete action space is {wait, de-\nploy}. Decisions are executed directly via the Kubernetes\nAPI client, which creates a labeled honeypot deployment;\nthe sensor side is configured for forwarding by a controlled\nbootstrap mechanism. For the prototype, a constrained, non-\ninteractive SSH channel is used over key-based auth with\nhost verification; a production deployment should replace this\nwith an agent-based approach (e.g., mTLS control plane or\nSSM-like mechanism) to reduce attack surface. When cluster\nutilization is low, the event loop may promote a wait decision\nto deploy (heuristic: promote if max(CPU, memory) < 0.6;\nconfigurable) to avoid idle capacity. Rewards are assigned\n18\n\nasynchronously: successful honeypot hits yield positive re-\nwards; expired deployments or deploys skipped due to resource\npressure incur small negative rewards. Advanced anomaly\ndetection is part of the roadmap, but not active in the prototype.\nL. CLUSTER NODE AND POD DEPLOYMENT\nThe cluster node runs a lightweight ‚Äòk3s‚Äò Kubernetes installa-\ntion [124] for the prototype; in a managed production setting,\nGKE or a full Kubernetes distribution would be preferable. It\nreceives deployment instructions from the Hive‚Äôs RL agent and\ninstantiates honeypot pods in isolated namespaces. Pods are\nlabeled with the attacker‚Äôs source IP to support later lookup\nof their assigned pod IP. Traffic steering is not performed\nin the cluster; instead, the event loop configures sensor-side\nforwarding to the pod IP for the relevant ports and links it\nback to the source IP of the session. Pods are preloaded and\nthen, after the deploy decision, renamed, and the traffic gets\nforwarded to them. Utilizing pre-loaded base images is a\ndeliberate countermeasure against detection via deployment\nlatency, as it minimizes the provisioning delay that could be\nfingerprinted by an adversary.\nM. TRAFFIC FORWARDING AND REDIRECTION\nA core challenge is transparently redirecting adversary traffic\nfrom the low-interaction Sensor Node to a high-interaction\nhoneypot on the cluster node without alerting the adversary.\nThe system must maintain session integrity while redirecting\ntraffic between the distributed components. The prototype\nimplementation, detailed in Section VIII, uses dynamic ipta-\nbles rules to achieve this, ensuring that the adversary remains\nunaware of the infrastructure transition.\nN. INTEGRATION WITH TRADITIONAL INTRUSION\nDETECTION SYSTEMS\nThe architecture is designed for extensibility and can be in-\ntegrated with traditional signature-based Intrusion Detection\nSystems (IDS) such as Snort [125]. This integration creates a\nsynergistic defense mechanism that combines the strengths of\nboth behavioral analysis and signature matching. Snort can be\ndeployed on the Sensor Node, where it would monitor inbound\ntraffic in parallel with MADCAT.\nAlerts generated by Snort can serve as a valuable, additional\ninput for the RL agent. The state vector for the DQN could\nbe augmented with features derived from Snort alerts, such as\nsignature priority or threat classification. This would provide\nthe agent with a richer context, allowing it to make more\ninformed decisions about whether to deploy a high-interaction\nhoneypot. For instance, a high-priority Snort alert can serve\nas a strong signal to escalate a session for further analysis.\nFurthermore, Snort logs can be forwarded to the ELK stack\non the Hive node. This enables analysts to correlate signature-\nbased alerts with the behavioral data captured by the honeypots,\nall within a single Kibana dashboard. This unified view is\ncritical for comprehensive threat analysis. In a more advanced\nimplementation, a feedback loop could be established where\nthe AI Analytics Pipeline analyzes novel attack patterns from\nthe high-interaction pods and automatically generates new\nSnort rules. This would enable the adaptive honeynet to harden\nthe traditional IDS against zero-day threats dynamically.\nVII. METHODOLOGY\nThis section details the research methodology, including the\nexperimental design, data collection procedures, and data\nanalysis techniques.\nA. DATA COLLECTION AND ENVIRONMENT\nThe primary dataset is sourced from the MADCAT Sensor\nNode‚Äôs JSON-based logging output, aggregated in an Elas-\nticsearch index. Each document in the index represents a\nnetwork event. The prototype was deployed in a live environ-\nment connected to the public internet and exposed to genuine,\nunsolicited traffic.\nIn parallel, the possibility of obtaining T-Pot data from\nTelekom Security for research use was explored in coordina-\ntion with BSI. Due to the high volume of external requests and\nassociated review processes, access was not feasible within the\ntime frame of this thesis. To partially compensate, an indepen-\ndent T-Pot instance was provisioned, and exploratory data were\ncollected. These data are not used in the present evaluation\nbut are intended to inform future versions of the architecture,\nespecially for application-layer anomaly detection and model\npretraining.\nB. DATA ANALYSIS AND FEATURE ENGINEERING\nThe foundation of any machine learning-driven security sys-\ntem is the data it consumes. The raw data generated by the\nMADCAT Sensor Node, while comprehensive, is not immedi-\nately suitable for direct input into the reinforcement learning\nagent. This section details the critical process of data analysis,\ncleaning, and feature engineering required to transform raw\nlog entries into a meaningful state representation for the RL\nagent.\n1) Raw Data Characteristics\nAn initial analysis of the dataset reveals several essential\ncharacteristics. The data exhibits high cardinality and sparsity,\ncontaining more than one hundred unique fields, many of\nwhich are protocol-specific and therefore present in only a\nsubset of records. The features span mixed data types, includ-\ning numerical, categorical, boolean, and complex string-based\nvalues, with many numerical fields requiring type conversion.\nSignificant redundancy is also present, for example, in dupli-\ncated keyword fields, and missing values occur frequently,\nnecessitating systematic handling.\n2) Data Preprocessing and Cleaning\nBefore feature engineering, the raw data passes through a\nrigorous cleaning and preprocessing pipeline. Numerical fea-\ntures are converted to their correct data types, while missing\nvalues are handled by imputing zeros for numerical fields\nand introducing a dedicated ‚Äômissing‚Äô category for categorical\n19\n\nvariables. Categorical features with low cardinality are one-\nhot encoded to ensure compatibility with downstream models.\nTemporal information is extracted from timestamps in the form\nof cyclical features, enabling the learning of temporal patterns\nsuch as diurnal or weekly attack behaviors.\nVIII. PROTOTYPE IMPLEMENTATION AND\nDEMONSTRATION\nThe prototype implements the core components of the RL-\ndriven orchestration loop: the RL agent itself, the integration\nwith the MADCAT sensor, and the dynamic pod deployment\nand redirection mechanism. This section details the practi-\ncal implementation of these components, demonstrating the\nfeasibility of the proposed approach and providing a solid foun-\ndation for the future enhancements outlined in the architectural\nvision.\nA. IMPLEMENTATION DETAILS\nThe prototype was built using a combination of open-source\ntools and custom scripts, deployed on Google Cloud Plat-\nform. The complete source code, deployment scripts, and\ndocumentation are available in the project‚Äôs GitHub repository\nat https://github.com/JohannesLks/adlah.git.\nIn addition, prebuilt Docker images are published on Docker\nHub to facilitate quick setup and reproducibility. Table 2 lists\nthe main images for the sensor and hive components.\nTABLE 2. Published Docker Images on Docker Hub\nComponent\nDocker Hub Repository\nSensor\nadlah-sensor-madcat\nSensor\nadlah-sensor-filebeat\nHive\nadlah-hive-elasticsearch\nHive\nadlah-hive-kibana\nHive\nadlah-hive-rl-agent\nHive\nadlah-hive-logstash\nHive\nadlah-hive-nginx\nThe Sensor Node is implemented using a modified MAD-\nCAT configuration to enhance logging for the RL agent. The\nHive node runs an ELK stack (Elasticsearch, Logstash, Kibana)\nfor centralized data processing and hosts the RL agent. The\ncluster node uses ‚Äòk3s‚Äò for lightweight Kubernetes orchestra-\ntion. When the agent triggers a deployment, it instantiates an\nSSH honeypot (for example, Cowrie [52]). A visual overview\nof the RL-Agent architecture and data flow is provided in\nFigure 4, which illustrates the integration between the RL\ndecision-making loop, container orchestration, and log aggre-\ngation.\nThe system state implemented in the prototype demonstrates\nan operational end-to-end loop for first-flight detection and\ndecision-making. However, the attacker forwarding mecha-\nnism, which was planned to use WireGuard [126] for secure\ntunneling, could not be successfully implemented despite ex-\ntensive effort. This limitation prevented the collection of high-\ninteraction (deep emulation) session data, which is essential for\nvalidating the anomaly detection pipeline and the envisioned\nquality-weighted reward function. Although a DNAT-based\nforwarding mechanism later became available, it arrived too\nlate in the development cycle to produce a fully running proof-\nof-concept with post-escalation data capture.\nFIGURE 4. Visual overview of the prototype‚Äôs RL-Agent architecture.\nA custom Bash script, reinstall.sh, handles the com-\nplete setup for all nodes.\nB. DATA-DRIVEN AGENT DESIGN: A FOUNDATIONAL\nANALYSIS\nTo ensure the reinforcement learning agent‚Äôs architecture is\ngrounded in real-world conditions, a comprehensive prelimi-\nnary analysis was conducted on a large-scale dataset provided\nby the German Federal Office for Information Security (BSI).\nThis dataset, captured by their MADCAT Sensor Node net-\nwork throughout November 2024, contains millions of log\nentries and represents a realistic snapshot of typical internet\nbackground noise and unsolicited traffic. This analysis was not\nmerely for environmental context, but served as a foundational\nstep in designing the agent‚Äôs core logic.\n20\n\nThe statistical properties of this data directly informed key\narchitectural decisions. For instance, the distribution of events\nper source IP was heavily skewed, as shown in Table 3. While\nthe average number of events per IP was high due to aggressive\nscanners, the median was significantly lower. The median of\n4.0 interactions per IP indicates that at least half of the source\naddresses appear at most four times. This guided a design\nthat supports early decisions on short sequences while still\nmodeling longer interactions: the agent consumes up to the last\nN = 10 observations with masking of zero-padded positions.\nTABLE 3. Summary of BSI MADCAT Network Traffic (Nov. 2024)\nMetric\nValue\nTotal Log Events\n13,244,068\nUnique Source IPs\n133,429\nAnalysis Period\nNovember 1, 2024 - November 30,\n2024\nMonthly per-IP Frequency (whole month)\nMean per-IP Frequency (month)\n99.26\nMedian per-IP Frequency (month)\n4.0\nDaily per-IP Frequency (by active IPs on that day)\nDay with Highest Daily Mean\n2024-11-07 (per-IP daily mean:\n36.18)\nDay with Lowest Daily Mean\n2024-11-15 (per-IP daily mean:\n19.54)\nNote: The monthly mean is computed as total events divided\nby the number of unique IPs across the whole month. Daily\nmeans are computed per day over the set of IPs active on that\nday. These aggregates are therefore not directly comparable\nand serve different analytical purposes.\nC. REINFORCEMENT LEARNING AGENT DESIGN\nThe reinforcement learning component orchestrates honey-\npot deployments from short sequences of recent events per\nsource IP. This section reflects the current implementation: an\nLSTM-based dueling DQN with experience replay, a target\nnetwork, and asynchronous reward assignment, integrated with\nKubernetes for pod lifecycle and with the Sensor Node for\nper-attacker forwarding.\n1) State Space (S)\nThe state, st ‚ààS, is designed to capture temporal patterns\nin network traffic by representing a sequence of the last N\nobservations from a single source IP address.\n2) Sequence Length and Early Decisions\nThe state is a fixed-length sequence of the most recent N = 10\nobservations. If fewer than N observations are available for\na given IP, the sequence is zero-padded and masked so that\nthe LSTM ignores padded steps. The agent is invoked from\nthe first observation onward; padding permits decisions at\nt ‚àà{1, . . . , N} without waiting for a full sequence window.\nThis choice reflects the empirical median length (‚âà4) and the\nlong tail of higher activity levels.\n3) Observation Features\nEach observation ot is a fixed-length feature vector derived\nfrom a single parsed network event in Elasticsearch, restricted\nto fields that are directly usable by the RL agent in real-\ntime without heavy external enrichment or preprocessing. The\nfeature composition in the current prototype is:\n‚Ä¢ Core numeric features (6): FLOW.duration (s), FL\nOW.bytes_toserver, FLOW.bytes_toclient,\nIP.ttl, TCP.dest_port, TCP.src_port. These\nfields capture timing, data volume, and port targeting,\nprimary indicators for malicious session behavior.\n‚Ä¢ ASN numeric feature (1): src_ip_geoasn.as.n\number. The Autonomous System Number is directly\nused for coarse-grained reputation scoring without re-\nquiring organization-name resolution.\n‚Ä¢ Categorical features with hashed one-hot encoding\n(140 dims total):\n-- src_cc (32 dims) ISO country code of source IP,\nwhen available without enrichment delay.\n-- tcp_flag_pattern (32 dims) compact encod-\ning of observed TCP flag combinations.\n-- FLOW.state (16 dims) protocol-independent con-\nnection state from flow tracking.\n-- event_type (32 dims) parsed event classification\n(e.g., flow, syn_scan).\n-- proto (8 dims) transport protocol category.\n-- port_category (20 dims) fixed mapping for\nwell-known, registered, dynamic, and specific high-\nvalue ports (22, 23, 80, 443, 5060, 123).\nHigh-cardinality text values (e.g., AS names) are ex-\ncluded to avoid unnecessary collisions and enrichment\ncost. Hashed one-hot encoding using xxhash ensures a\nfixed dimensionality with stable mapping for categorical\ndomains of bounded size.\n‚Ä¢ Short-term activity profile (5): Computed over a rolling\n5-minute window per source IP: ev_5m (event count),\nports_5m (unique destination ports), protos_5m\n(unique protocols), targets_5m (unique destination\nIPs), and syn_ratio_5m (ratio of SYN packets to\ntotal TCP packets).\n‚Ä¢ Time features (2): Sine and cosine transforms of the time-\nof-day from @timestamp, scaled to [0, 2œÄ] radians,\nenabling cyclic encoding of diurnal patterns.\n‚Ä¢ Runtime feature (1): time_since_last_min\ncapped minutes since the last event from this source IP,\nproviding a recency signal without storing the full history.\n‚Ä¢ Payload features (8 dims): Four scalar statistics com-\nputed directly on available payloads: total length, byte\nentropy, non-printable character ratio, and LZ77-based\ncompressibility. The latter is derived from the compres-\nsion ratio obtained by applying the Lempel-Ziv 77 al-\ngorithm [127], a lossless dictionary-based scheme that\nreplaces repeated sequences with backward references.\nThis metric serves as a heuristic for payload structure:\nhighly compressible payloads often contain redundant\n21\n\nor patterned data (e.g., repeated commands or cleartext),\nwhereas low-compressibility payloads are more likely to\nbe encrypted or obfuscated. A matching 4-dimensional\nblock encodes the SHA-1 hash of the payload (truncated\nto 32-bit integers for space efficiency). Raw payload\nbytes and strings are not retained; if no payload is present,\nthe payload sub-vector is set to all zeros.\nThis configuration intentionally excludes enrichment-heavy\nfeatures (e.g., full geolocation, OS fingerprinting, organization\nnames) and non-deterministic metadata. The design ensures\nall inputs are available from parsed event fields at ingest time,\nkeeping the observation extraction path bounded in latency\nand reproducible.\n4) Processing and Normalization\nNumeric features are normalized in an online fashion using\nWelford‚Äôs algorithm [128] to incrementally compute mean\nand variance, with hard clipping applied to prevent extreme\nvalues from dominating the feature scale. Running statistics\nare persisted to disk so that scaling remains consistent across\nprocess restarts. Categorical variables are transformed into\nfixed-size indicator vectors via deterministic hashing with\nxxhash [129], enabling constant-time transformation while\nbounding dimensional growth. The time_since_last_\nmin feature is stored in its own dedicated scalar slot rather than\nas part of any hashed indicator vector, ensuring that recency\ninformation remains numerically interpretable and does not\ncollide with categorical encodings.\nSee Appendix A for an analysis of raw MADCAT fields.\nThe exact model input features used by the RL agent are listed\nin Section VIII-C (Observation Features).\n5) Action Space (A)\nThe agent‚Äôs action space is discrete and consists of two possible\nactions. The action at ‚ààA is chosen at each time step t:\n1) wait : The agent takes no action and continues to ob-\nserve events from the source IP. This is the default,\nresource-conserving action.\n2) deploy : The agent initiates the deployment of a high-\ninteraction honeypot tailored to the perceived threat and\nredirects the source IP‚Äôs traffic to it.\n6) Reward Function (R)\nThe reward signal R(st, at) is defined to favor deployments that\nactually yield intelligence. Rewards are sparse and delayed,\nreflecting that utility is only observable after a honeypot‚Äôs\nobservation window.\n7) Current Design (Prototype)\nIf the agent chooses deploy, the reward is proportional to\nthe amount of log data collected from the targeted source\nafter deployment. Let L denote the total number of log events\nattributed to that source during the honeypot‚Äôs lifespan, and ¬ØL a\nnormalization constant (e.g., a rolling median per protocol/port\nor per time-of-day bucket). The deployment reward is:\nRdeploy = Œ± ¬∑ min\n\u0012L\n¬ØL , Lmax\n\u0013\n(3)\nwith Œ± > 0 a scaling factor and Lmax a cap to limit outliers. If\nno logs are collected (L = 0), a mild penalty is assigned to\ndiscourage wasteful deployments:\nRno_logs = ‚àíŒ¥,\nŒ¥ ‚â™1\n(4)\nTo optimize resource utilization and discourage idle deploy-\nments, each high-interaction pod in the cluster is configured\nwith a 20-minute inactivity timeout. If no interactions from\nthe associated adversary are observed within this window, the\npod is automatically terminated. Such premature termination\ntriggers a penalty in the RL agent‚Äôs reward function, reflecting\nthe wasted resources and missed intelligence opportunities.\nThis mechanism incentivizes the agent to escalate only when\nthere is a high likelihood of sustained interaction, aligning\noperational efficiency with intelligence-gathering objectives.\n8) Planned Extension (Quality-Aware Reward)\nThe reward will be augmented with a novelty/anomaly term\nthat reflects the quality of the collected data. Let A denote\nan anomaly score aggregated over the new logs (e.g., mean\nreconstruction error from an autoencoder, or an alternative\ndetector‚Äôs score). The future reward will take the form:\nRfuture\ndeploy = Œ±¬∑min\n\u0012L\n¬ØL , Lmax\n\u0013\n+Œ≤ ¬∑clip(Agg(A), 0, Amax) (5)\nwhere Œ≤ > 0 weights anomaly-driven value, Agg(¬∑) is a\nrobust aggregator (e.g., trimmed mean or percentile), and Amax\ncaps the anomaly contribution. This preserves a conservative\nshaping philosophy: intelligence quantity remains the back-\nbone, while quality signals (novelty/anomaly) enhance learn-\ning without enabling reward gaming. The utilization heuristic\ncontinues to act only as a stabilizer outside the reward to avoid\nstarvation during low-interaction phases.\n9) Learning Algorithm\nThe agent employs a Deep Q-Network (DQN) with an LSTM\nlayer to process the sequential state information.\n10) Neural Network Architecture\nThe network architecture is comprised of the following layers\n(resource-awareness noted where applicable):\n1) Input Layer: Takes the state tensor of shape (10, D),\nwhere D is the feature dimension.\n2) Masking Layer: Handles variable-length sequences by\nignoring padded time steps, ensuring they do not affect\nthe LSTM‚Äôs state.\n22\n\n3) LSTM Layer: A single LSTM layer with 64 units pro-\ncesses the sequence, capturing temporal dependencies\nin the data.\n4) Batch Normalization: Stabilizes learning by normaliz-\ning the activations from the LSTM layer.\n5) Dense Layer: A fully-connected layer with 64 units and\na ReLU activation function. Runtime features (cluster\nutilization, active pods, capacity) are concatenated post-\nLSTM to allow explicit conditioning of Q-values on\nresource pressure.\n6) Dropout Layer: A dropout rate of 0.2 is applied for\nregularization to prevent overfitting.\n7) Dueling Head: Two parallel streams compute (i) the\nstate value and (ii) the action advantages. They are\ncombined into Q-values via Q(s, a) = V(s) + A(s, a) ‚àí\n1\n|A|\nP\na‚Ä≤ A(s, a‚Ä≤). [130] The output comprises two Q-\nvalues, one per action (wait, deploy).\n11) Q-Learning Update Rule\nTo improve the stability of value estimation, the agent com-\nbines two mechanisms from prior work: (i) experience re-\nplay [131] to decorrelate updates by sampling from a replay\nbuffer, and (ii) a target network [131] to reduce non-stationarity\nin the bootstrap target. The target network parameters Œ∏‚Ä≤\nt are\nheld fixed for a number of training steps and then updated\nfrom the online network parameters Œ∏t.\nThe action-value target follows the Double DQN formu-\nlation [132], in which the next action is selected using the\nonline network and evaluated using the target network. For a\ntransition (st, at, Rt+1, st+1, donet+1), the target is:\nyt = Rt+1 + (1 ‚àídonet+1) Œ≥\n¬∑ Q\n\u0010\nst+1, arg max\na\nQ(st+1, a; Œ∏t); Œ∏‚Ä≤\nt\n\u0011\n,\n(6)\nwhere Œ≥ ‚àà[0, 1] is the discount factor. The multiplicative\n(1 ‚àídonet+1) term is not explicitly shown in [132] but is\nstandard in implementations to zero out the bootstrap term\nwhen the next state is terminal.\nFollowing [131], the network parameters Œ∏t are optimized by\nminimizing the Huber loss between the predicted Q(st, at; Œ∏t)\nand the target yt, which is less sensitive to outliers than the\nmean-squared error. This formulation mitigates the overesti-\nmation bias of standard Q-learning [133] while retaining the\nsample efficiency of off-policy learning.\n12) Hyperparameters\nThe key hyperparameters for the learning process are:\n‚Ä¢ Learning Rate (Œ±): 0.001\n‚Ä¢ Discount Factor (Œ≥): 0.95\n‚Ä¢ Initial Epsilon (œµ): 1.0 ‚Üílinear decay to œµmin (for robust\nearly exploration)\n‚Ä¢ Minimum Epsilon (œµmin): 0.01\n‚Ä¢ Epsilon Decay: 0.995\n‚Ä¢ Replay Memory Size: 10,000\n‚Ä¢ Batch Size: 32\n‚Ä¢ Target Network Update Frequency: 1000 training steps\n(hard update)\nThese hyperparameters represent initial starting values for\ntraining and are not guaranteed to be optimal for the target\nenvironment. Determining their effectiveness requires em-\npirical evaluation after system deployment, when sufficient\ninteraction data are available for the RL agent to operate in\na fully online setting. As part of future work, it is planned to\napply automated hyperparameter tuning techniques, such as\nBayesian optimization [134], to identify the configuration that\nmaximizes long-term performance.\nMore broadly, all design elements described in this section,\nincluding feature selection, hashing strategies, normalization\nschemes, and reward shaping, represent the current prototype\nimplementation. They are expected to undergo significant\nrefinement as empirical evidence is gathered, and the final de-\nployed system will likely differ substantially from the present\ndescription (see Section VIII-G1).\nD. DEPLOYMENT AND INFRASTRUCTURE (PROTOTYPE)\nThis section documents the current prototype environment\nand clarifies the handling of cluster utilization. Maintaining\na healthy utilization band improves learning efficiency and\nintelligence yield: if utilization remains too low due to overly\nconservative deployment (as observed in early tests with sparse\nsensor interactions), the agent receives too few meaningful\nrewards; if too high, contention harms fidelity.\n1) Cloud Infrastructure\nThe cloud infrastructure is deployed on Google Cloud Platform\n(GCP), taking advantage of its scalable and flexible computing\nresources. Compute Engine virtual machines (VMs) host the\nsensor, Hive, and cluster nodes, with each instance provisioned\naccording to the specific performance requirements of its\nrole. This right-sizing approach ensures optimal operational\nperformance while controlling costs. Container images for the\ndeployment are stored and versioned in GCP‚Äôs managed Con-\ntainer Registry, providing a secure and centralized repository\nfor maintaining the integrity and traceability of all container-\nized components.\n2) Network Configuration\nThe network configuration ensures secure and efficient com-\nmunication between the different components of the honeynet:\n‚Ä¢ VPC and Subnets: A Virtual Private Cloud (VPC) with\nsubnets for isolating different components of the hon-\neynet.\n‚Ä¢ Firewall Rules: Configured to allow only necessary\ntraffic to and from the honeynet components, following\nthe principle of least privilege.\n‚Ä¢ Routing: Custom routes to manage the traffic flow be-\ntween the sensor, Hive, and cluster nodes.\nE. CONFIGURATION MANAGEMENT\nThe prototype uses infrastructure-as-code for reproducible\ndeployment.\n23\n\n1) Terraform Configuration\nInfrastructure is managed using Terraform [135], providing a\ndeclarative approach to infrastructure provisioning that ensures\nconsistency and reproducibility across different deployment\nenvironments. Resource definitions specify VM instances,\nnetworks, and storage components with precise configurations\nthat can be version-controlled and audited, enabling teams\nto track changes and understand the impact of infrastructure\nmodifications. This approach eliminates configuration drift,\nensuring that all deployments utilize identical infrastructure\nconfigurations.\n2) Docker Compose\nLocal development utilizes Docker Compose to provide a con-\nsistent and reproducible development environment that mirrors\nthe production deployment architecture. Service definitions\nspecify container configurations for all system components,\nensuring that developers can work with the identical software\nversions and configurations that will be deployed in produc-\ntion. This consistency eliminates the \"works on my machine\"\nproblem and enables developers to test their changes in an\nenvironment that closely resembles the actual deployment.\nNetwork configuration establishes inter-service communi-\ncation patterns that replicate the production network topology,\nallowing developers to test component interactions and integra-\ntion points without requiring the whole cloud infrastructure.\nThis local networking setup enables efficient development\nand debugging while maintaining the security and isolation\nrequirements of the honeynet system. Volume management\nprovides persistent data storage for development and testing,\nensuring that valuable test data and configuration informa-\ntion are preserved across development sessions and enabling\nrealistic testing scenarios that require historical data.\nF. TRAFFIC FORWARDING IMPLEMENTATION\nTransparent redirection from the Sensor Node to a deployed\nhoneypot is orchestrated by the event loop after a deploy\ndecision. The Kubernetes manager creates a pod labeled with\nthe attacker‚Äôs source IP and exposes the service ports. The\nevent loop then obtains the pod IP and calls a sensor-side setup\nscript over SSH using a non-interactive command. That script\nconfigures connection tracking and port forwarding (e.g., via\niptables/DNAT) for the specific source IP and target pod\nIP for a configured TTL. This design keeps latency low and\nconfines redirection to the attacker being escalated. Cleanup\nof expired rules and pods is performed periodically by the\nevent loop and the honeypot manager.\nG. LIMITATIONS AND FUTURE ENHANCEMENTS\nThe prototype has several limitations that will be addressed in\nfuture versions.\n1) Current Limitations\nKnown limitations include scale constraints that limit the max-\nimum number of concurrent sessions and pod deployments that\ncan be handled simultaneously. These limitations are primarily\ndetermined by the computational resources available and the\nefficiency of the current implementation, which may restrict\nthe system‚Äôs ability to handle extremely high-volume attack\nscenarios or coordinate large numbers of honeypot instances.\nFeature limitations encompass the restricted range of honeypot\ntypes and detection capabilities currently supported by the\nprototype, which may not cover all potential attack vectors or\nprovide the depth of analysis required for highly sophisticated\nthreats.\nAnother fundamental limitation relates to the nature of the\navailable data. Throughout the thesis work, the reinforcement\nlearning agent was deployed and operated entirely in a live\nenvironment, interacting with real adversary traffic rather than\nstatic offline captures. This approach is essential, as the agent‚Äôs\nreward structure depends on genuine state transitions and\ninformation gain arising from its own deployment actions.\nHowever, due to technical issues in the attacker forwarding\nmechanism, no high-interaction (deep emulation) sessions\nwere successfully recorded. Since such post-escalation data\nare critical for both the anomaly detection pipeline and the en-\nvisioned quality-based reward function, their absence limited\nthe scope of the evaluation to the first-flight decision-making\nstage. While a potential data exchange with Telekom Security‚Äôs\nT-Pot platform was explored together with BSI, the required\norganizational approvals could not be completed within the\nthesis timeline. As a mitigation, a self-operated T-Pot instance\nwas deployed for exploratory collection; however, these data\nare reserved for future work and are not included in the present\nevaluation.\nPerformance limitations arise from real-time processing\nconstraints that affect the system‚Äôs ability to maintain optimal\nresponse times under heavy load conditions. These constraints\nare influenced by the computational complexity of the machine\nlearning models and the overhead associated with container\norchestration and network redirection. Security limitations\nreflect the basic security measures and hardening currently\nimplemented, which may not provide the level of protection\nrequired for deployment in highly sensitive environments or\nagainst sophisticated adversaries who may attempt to compro-\nmise the honeynet infrastructure itself.\n2) Scaling & Security\nFuture enhancements include scalability improvements that\nwill implement horizontal scaling and load balancing capabil-\nities to handle increased traffic volumes and support larger\ndeployments across multiple geographic regions. These im-\nprovements will enable the system to distribute computational\nload across various nodes and automatically scale resources\nbased on demand, ensuring consistent performance even under\nextreme attack scenarios. Advanced machine learning models\nwill be integrated (e.g., transformer-based models) for more\nsophisticated sequence understanding and threat prediction.\nEnhanced security features will incorporate advanced threat\ndetection and response mechanisms, including more sophisti-\ncated anomaly detection algorithms, behavioral analysis ca-\n24\n\npabilities, and automated response systems that can adapt\nto evolving attack techniques. Integration capabilities will be\nexpanded to include seamless connectivity with SIEM systems\nand threat intelligence platforms, enabling the adaptive hon-\neynet to contribute to broader security ecosystems and share\nthreat intelligence with other security tools and platforms.\n3) Clustering & Anomaly Detection\nAt the current stage of development, no definitive solution\nfor the anomaly detection component has been established.\nPreliminary investigations indicate that a single analytical\ntechnique is unlikely to perform optimally across all deploy-\nment scenarios, particularly given the heterogeneity of attack\nbehaviors and the evolving nature of adversary tactics. Instead,\nit is expected that a portfolio of complementary methods will\nneed to be evaluated and potentially combined into a hybrid\ndetection pipeline. Such a pipeline could, for example, em-\nploy lightweight classifiers,such as decision trees or Random\nForest ensembles,for rapid, low-latency triage of incoming\nsessions, followed by more computationally intensive deep\nreinforcement learning (DQN) or recurrent neural network\n(RNN) models for fine-grained resource allocation and esca-\nlation decisions. Other promising avenues include clustering\nalgorithms (e.g., DBSCAN, HDBSCAN, or k-means variants)\nfor unsupervised grouping of session behaviors, autoencoder-\nbased novelty detection for identifying rare or unseen patterns,\nand graph-based learning approaches for correlating activity\nacross multiple sessions and attack chains.\nGiven the scope of these possibilities, the evaluation process\nwill necessarily proceed in multiple phases, beginning with\nexperiments on offline datasets to reduce operational risk and\nallow rapid iteration of models and features. To facilitate this\nprocess and build domain-specific knowledge of the data, a\ncollaborative research initiative between the German Federal\nOffice for Information Security (BSI) and the University of Ap-\nplied Sciences Kiel is planned. Within this framework, student-\nled projects will systematically investigate and benchmark a\nrange of deep learning and machine learning techniques, start-\ning with exploratory clustering to uncover latent structures in\nthe data, progressing to supervised classification methods for\nlabeling and triaging known attack patterns, and culminating in\nanomaly detection methods tailored for real-time deployment.\nThe insights gained from these projects will directly inform the\ndesign of a robust, hybrid anomaly detection strategy capable\nof adapting to the diverse operational contexts in which the\nsystem may be deployed.\nIX. EVALUATION (PLANNED)\nGiven that the reinforcement learning agent‚Äôs reward structure\ndepends on live interaction, a quantitative evaluation on a\nstatic dataset is limited in validity. While Offline RL methods\ncould be explored with logged interactions, they are outside\nthe scope of this work. Due to limited access to sustained live\nattack traffic, no statistically robust field evaluation has been\ncompleted to date. The following, therefore, documents the\nprototype‚Äôs design and intended evaluation protocol rather than\nreporting conclusive empirical results. The planned protocol\nincludes collecting deployment logs and performance metrics\nto compare RL-driven orchestration against non-RL baselines\n(e.g., threshold heuristics and static policies), followed by\niterative refinement of the RL architecture.\nA. EXPERIMENTAL SETUP\nAn initial short-lived deployment was prepared to validate\nintegration and data flows. However, the duration and volume\nof observed traffic were insufficient to derive statistically\nmeaningful conclusions. A future, extended field study is\noutlined to assess detection quality, resource efficiency, and\noperational stability under representative load.\n1) Quantitative Results\nNo quantitative results are reported at this time. Metrics and\nprotocol for future evaluation are defined (precision/recall,\nF1, AUC; deployment efficiency; time-to-redirect; resource\ncost per engagement), with explicit comparison of RL versus\nnon-RL baselines. Measurement is deferred until a sustained\nlive trial is conducted.\nB. DISCUSSION\nThese observations highlight key areas for future work. The\ncurrent RL agent and feature set are an initial operational de-\nsign intended to exercise the orchestration loop. Demonstrating\ndetection performance and selectivity requires an extended\nlive trial with sufficient adversary engagement, which is part\nof the planned research agenda.\nX. CONCLUSION\nThis work addresses the critical limitations of static honeypots\nin countering modern, sophisticated cyber threats. A novel\nadaptive honeynet architecture is proposed that integrates\nreinforcement learning with dynamic container orchestration\nto create an intelligent and responsive cyber-deception system.\nThe primary contribution of this research is the design and\nimplementation of a functional prototype that operational-\nizes the core architectural loop. While the RL agent (DQN\nwith LSTM and dueling head) has been integrated end-to-\nend, empirical validation of detection quality and deployment\nselectivity remains future work pending a sustained live trial.\nAn important operational lesson learned is that a deployment\npipeline based on bespoke Bash scripts was too error-prone for\nrepeatable operations and open-source scalability. As a result,\ndeployment is being migrated to Ansible-based playbooks and\nroles to ensure idempotency, clearer state management, and\nmaintainable contributions. The work provides a foundational\nblueprint and an initial, operational design for how RL can be\nleveraged for infrastructure-level orchestration.\nA significant technical and methodological lesson emerged\nfrom the inability to fully realize the attacker forwarding\nmechanism as planned. As detailed in Section VIII-A, the\nintended WireGuard-based tunneling for secure attacker traffic\nforwarding proved challenging to implement, requiring con-\nsiderable effort without producing a functional result within\n25\n\nthe thesis timeframe. The subsequent availability of a DNAT-\nbased alternative came too late to integrate into the opera-\ntional pipeline, resulting in the absence of high-interaction\n(deep emulation) session data. These post-escalation logs are\nessential for evaluating the anomaly detection pipeline and im-\nplementing the envisioned quality-weighted reward function.\nTheir absence limited the evaluation to first-flight decision-\nmaking and highlighted a broader dependency: in live cyber-\ndefense experimentation, data availability is inseparably tied\nto the readiness and stability of critical infrastructure com-\nponents. Delays or failures in implementing such core data-\npath elements can directly constrain the scope and validity of\nexperimental outcomes.\nThe experience underlines the importance of prioritizing\nessential data collection mechanisms early in the development\nprocess, even before other architectural optimizations. For\nfuture iterations, attacker forwarding and post-escalation data\ncapture will be treated as primary engineering milestones,\nensuring that subsequent model evaluations are grounded in\ncomplete, representative datasets. While the prototype is sub-\nject to these limitations, it nevertheless serves as a crucial first\nstep, proving the feasibility of the core concept and providing\na robust platform for the extensive future work outlined in\nthe next section. The transition to Ansible further reduces\noperational risk and opens the pathway for community-driven,\nreproducible deployments across diverse environments. A\nstructured evaluation plan will collect and analyze data from\ndeployments to compare the RL-driven orchestration loop\nagainst non-RL baselines, iteratively refine the agent architec-\nture, and substantiate claims of superiority where supported\nby evidence. Ultimately, this research paves the way for a\nnew class of proactive, autonomous defense systems capa-\nble of adapting to the ever-evolving threat landscape while\nmaintaining an up-to-date catalog of bot families and versions.\nXI. FUTURE WORK\nA. SECURITY ENHANCEMENTS\nTo further enhance the security of the adaptive honeynet, sev-\neral key areas require attention. These enhancements aim to\nimprove the system‚Äôs resilience against sophisticated attacks\nand ensure robust protection mechanisms.\n1) Advanced Threat Detection\nImplementing advanced threat detection mechanisms will be\ncritical for identifying and mitigating complex attack vectors.\nThis will involve behavioral analysis to detect anomalies and\npotential threats by examining adversary activity patterns,\nsignature-based detection using regularly updated threat intel-\nligence to recognize known malicious activities, and heuristic\nanalysis techniques to uncover previously unknown or zero-\nday threats.\n2) Enhanced Encryption\nSecuring data in transit and at rest is vital to protecting sensitive\ninformation. Planned measures include enforcing Transport\nLayer Security (TLS) for all network communications to guar-\nantee data integrity and confidentiality, as well as encrypting\nstored data with strong cryptographic algorithms to prevent\nunauthorized access.\nFuture efforts will be organized around three core pillars:\nenhancing the AI pipeline, building out advanced intelligence\ncapabilities, and operationalizing the platform.\nB. REALIZING THE ARCHITECTURAL VISION\nA primary focus of future work will be the full implementation\nof the conceptual AI analytics pipeline, including the adaptive\nautoencoder for post-interaction log analysis and the anomaly-\nweighted reward function. This will transition the system from\nits current prototype stage to an intelligent data-gathering\nplatform that prioritizes novel threats. Key research challenges\ninclude designing a robust online training process to counter\nconcept drift [136] and exploring more advanced models like\nTransformers for log analysis. In parallel, a data-driven eval-\nuation campaign will measure detection quality, deployment\nselectivity, time-to-redirect, and cost per engagement under\ncontrolled deployments, explicitly comparing the RL-driven\norchestration to deterministic heuristics and static policies.\nResults will be used to refine the RL architecture (state, reward,\nand hyperparameters) and to determine where RL provides\nstatistically significant advantages.\nFurthermore, development will concentrate on building out\nthe core intelligence capabilities outlined in the architecture,\nsuch as automated attack chain extraction, bot versioning,\nMITRE ATT&CK integration, and incorporating Explainable\nAI (XAI) techniques [137] to ensure analyst trust and utility.\nC. OPERATIONALIZATION AND AUTONOMOUS\nCAPABILITIES\nThe long-term vision is to develop a more autonomous system\nthat reduces the need for constant human oversight. This\nincludes research into self-healing capabilities, where the\nsystem can automatically recover from component failures\nor even direct attacks on the honeynet infrastructure. Further-\nmore, the RL agent‚Äôs reward function and action space will\nbe expanded to enable more complex adaptive deception\nstrategies, where the honeypots themselves can modify their\nbehavior in real-time to maximize intelligence gathering from\nhigh-value targets. Finally, the entire platform will be hardened\nand optimized for robust, scalable deployment in enterprise\nand national security environments. A staged rollout plan will\nintroduce canary evaluations where RL policies are evaluated\nside-by-side with baseline policies to ensure safe, evidence-\nbased progression.\nD. SCALABILITY TO A GLOBAL HONEYNET\nA critical next step is to evolve the prototype into a fully\nscalable, distributed system. This involves several concrete\nengineering efforts:\n‚Ä¢ Multi-Sensor Deployment: Replace ad-hoc bash scripts\nwith Ansible playbooks and roles for reproducible, idem-\npotent provisioning of sensors, Hive, and cluster nodes\n26\n\nacross diverse environments (on-prem and multiple clouds).\nStandardize inventories, variables, and secrets manage-\nment to enable contributors to stand up testbeds reliably.\n‚Ä¢ Hive and Cluster Federation: For very large-scale de-\nployments, the single Hive and Cluster model will be-\ncome a bottleneck. Future research will explore a feder-\nated architecture with multiple, geographically distributed\ncluster nodes, each managed by a regional Hive. These re-\ngional Hives would, in turn, report high-level intelligence\nto a central \"super-Hive\" for global threat correlation.\n‚Ä¢ Load Balancing and High Availability: Implement load\nbalancing for the Hive node‚Äôs data ingestion endpoints\nand ensure high availability for the Elasticsearch cluster\nand RL agent to handle telemetry from a large fleet of\nsensors without data loss or downtime. Integrate Ansible\nwith CI/CD to test HA failover playbooks and configura-\ntion drift remediation.\n‚Ä¢ Optimized Data Telemetry: Investigate and implement\nmore efficient data serialization formats and communi-\ncation protocols (e.g., gRPC with Protocol Buffers) for\nsensor-to-Hive communication to minimize bandwidth\nconsumption, which is critical in a large-scale deploy-\nment.\n‚Ä¢ Open-Source Workflow Enablement: Provide an Ansi-\nble collection with modular roles (sensor, Hive, cluster,\nobservability), plus Molecule tests, so external contribu-\ntors can validate changes locally. Add GitHub Actions\nfor linting (ansible-lint), idempotency checks, and basic\nintegration smoke tests. Include datasets and scripts for\nreproducible evaluation runs to facilitate independent\ncomparison of RL vs. non-RL baselines.\nACKNOWLEDGMENT\nThe author would like to thank Heiko Folkerts and Detlef Nu√ü\nfrom the German Federal Office for Information Security (BSI)\nfor their valuable support and collaboration on this project. The\nauthor is also grateful to Prof. Dr. Stephan Schneider and Prof.\nDr. Christian Kraus from the University of Applied Sciences\nKiel for their insightful guidance and academic supervision.\nThe author further acknowledges the use of generative AI\nfor assistance in refining the language, improving grammatical\nclarity, and supporting LaTeX formatting during the prepa-\nration of this manuscript. All research design, data analysis,\ninterpretations, and conclusions remain entirely the responsi-\nbility of the author.\nEU IA ACT\nThe authors acknowledge that the presented system incorpo-\nrates AI-based decision-making in a cybersecurity context,\nbringing it within the scope of the European Union‚Äôs AI Act\n(Regulation (EU) 2024/1689). [138] While the architecture\ndoes not meet the classification criteria for a\"high-risk\" AI\nsystem as defined in Annex III, its design intentionally aligns\nwith the Act‚Äôs general principles in Articles 10-15, including\ntransparent feature extraction, auditable decision flows, and\nrobust operation, to facilitate future compliance should the\nregulatory scope evolve.\nREFERENCES\n[1] E. U. A. f. C. (ENISA), ‚Äò‚ÄòENISA THREAT LANDSCAPE 2024,‚Äô‚Äô Euro-\npean Union Agency for Cybersecurity (ENISA), Tech. Rep., 9 2024.\n[2] S. Morgan, ‚Äò‚ÄòCybercrime to cost the world $10.5 trillion annually by\n2025,‚Äô‚Äô 2020. [Online]. Available: https://cybersecurityventures.com/cybe\nrcrime-damages-6-trillion-by-2021/\n[3] Mandiant, ‚Äò‚ÄòM-trends 2025,‚Äô‚Äô Tech. Rep., 2025. [Online]. Available:\nhttps://cloud.google.com/security/resources/m-trends?hl=de\n[4] BSI, ‚Äò‚ÄòMADCAT,‚Äô‚Äô 8 2025. [Online]. Available: https://github.com/BSI-B\nund/MADCAT_v2\n[5] Zeit, ‚Äò‚ÄòHinweise auf hackerangriff verdichten sich,‚Äô‚Äô 11 2016. [Online].\nAvailable: https://www.zeit.de/digital/internet/2016-11/internet-deutsch\ne-telekom-stoerung-fernsehen-telefonie-netz\n[6] Spiegel, ‚Äò‚ÄòBSI vermutet weltweiten hackerangriff,‚Äô‚Äô 11 2016. [Online].\nAvailable: https://www.spiegel.de/netzwelt/web/telekom-stoerung-bsi-v\nermutet-weltweiten-hackerangriff-a-1123471.html\n[7] J. Schmidt, ‚Äò‚ÄòGro√üst√∂rung bei der telekom: Was wirklich geschah,‚Äô‚Äô 11\n2016. [Online]. Available: https://www.heise.de/news/Grossstoerung-bei\n-der-Telekom-Was-wirklich-geschah-3520212.html\n[8] C. Zhaojun, ‚Äò‚ÄòCVE-2021-44228,‚Äô‚Äô Tech. Rep., 12 2021. [Online]. Available:\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-44228\n[9] L. Spitzner, Honeypots: Tracking Hackers.\nAddison Wesley, 9 2002.\n[10] H. Project, Know Your Enemy: Learning about Security Threats. Addison-\nWesley, 2004.\n[11] S. Dowling, M. Schukat, and E. Barrett, ‚Äò‚ÄòNew framework for adaptive\nand agile honeypots,‚Äô‚Äô ETRI Journal, vol. 42, no. 6, pp. 965‚Äì975, 2020.\n[12] P. Wang, L. Wu, R. Cunningham, and C. C. Zou, ‚Äò‚ÄòHoneypot detection\nin advanced botnet attacks,‚Äô‚Äô International Journal of Information and\nComputer Security, vol. 4, no. 1, p. 30, 2010.\n[13] G. Wagener, R. State, T. Engel, and A. Dulaunoy, ‚Äò‚ÄòAdaptive and self-\nconfigurable honeypots,‚Äô‚Äô 12th IFIP/IEEE International Symposium on\nIntegrated Network Management (IM 2011) and Workshops, vol. 1, pp.\n345‚Äì352, 2011.\n[14] S. Dowling, M. Schukat, and E. Barrett, ‚Äò‚ÄòImproving adaptive honeypot\nfunctionality with efficient reinforcement learning parameters for auto-\nmated malware,‚Äô‚Äô Journal of Cyber Security Technology, vol. 2, no. 2, pp.\n75‚Äì91, 2018.\n[15] A. Pauna, A.-C. Iacob, and I. Bica, ‚Äò‚ÄòQRASSH - a self-adaptive SSH\nhoneypot driven by q-learning,‚Äô‚Äô 2018 International Conference on Com-\nmunications (COMM), vol. 00, pp. 441‚Äì446, 2018.\n[16] S. Veluchamy and R. S. Kathavarayan, ‚Äò‚ÄòDeep reinforcement learning for\nbuilding honeypots against runtime DoS attack,‚Äô‚Äô International Journal\nof Intelligent Systems, vol. 37, no. 7, pp. 3981‚Äì4007, 2022. [Online].\nAvailable: https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22708\n[17] N. Shone, T. N. Ngoc, V. D. Phai, and Q. Shi, ‚Äò‚ÄòA deep learning approach\nto network intrusion detection,‚Äô‚Äô IEEE Transactions on Emerging Topics\nin Computational Intelligence, vol. 2, no. 1, pp. 41‚Äì50, 2018.\n[18] M. Catillo, A. Pecchia, and U. Villano, ‚Äò‚ÄòAutoLog: Anomaly detection by\ndeep autoencoding of system logs,‚Äô‚Äô Expert Systems with Applications, vol.\n191, p. 116263, 2022.\n[19] S. Park, M. Kim, and S. Lee, ‚Äò‚ÄòAnomaly detection for HTTP using\nconvolutional autoencoders,‚Äô‚Äô IEEE Access, vol. 6, pp. 70 884‚Äì70 901,\n2018.\n[20] A. M. Vartouni, S. S. Kashi, and M. Teshnehlab, ‚Äò‚ÄòAn anomaly detection\nmethod to detect web attacks using stacked auto-encoder,‚Äô‚Äô 2018 6th\nIranian Joint Congress on Fuzzy and Intelligent Systems (CFIS), pp. 131‚Äì\n134, 2018.\n[21] I. Boureanu, S. Schneider, B. Reaves, N. O. Tippenhauer, C. Guan, H. Liu,\nG. Cao, S. Zhu, and T. L. Porta, ‚Äò‚ÄòHoneyIoT: Adaptive high-interaction\nhoneypot for IoT devices through reinforcement learning,‚Äô‚Äô in Proceedings\nof the 16th ACM Conference on Security and Privacy in Wireless and\nMobile Networks, ser. Proceedings of the 16th ACM Conference on\nSecurity and Privacy in Wireless and Mobile Networks.\nNew York, NY,\nUSA: Association for Computing Machinery, 2023, pp. 49‚Äì59. [Online].\nAvailable: https://doi.org/10.1145/3558482.3590195\n[22] E. Limouchi and I. Mahgoub, ‚Äò‚ÄòReinforcement learning-assisted threshold\noptimization for dynamic honeypot adaptation to enhance IoBT networks\nsecurity,‚Äô‚Äô 2021 IEEE Symposium Series on Computational Intelligence\n(SSCI), vol. 00, pp. 1‚Äì7, 2021.\n27\n\n[23] A. Pauna, I. Bica, F. Pop, and A. Castiglione, ‚Äò‚ÄòOn the rewards of self-\nadaptive IoT honeypots,‚Äô‚Äô Annals of Telecommunications, vol. 74, no. 7-8,\npp. 501‚Äì515, 2019.\n[24] M. Verkerken, L. D‚Äôhooge, T. Wauters, B. Volckaert, and F. D. Turck,\n‚Äò‚ÄòUnsupervised machine learning techniques for network intrusion detec-\ntion on modern data,‚Äô‚Äô 2020 4th Cyber Security in Networking Conference\n(CSNet), vol. 00, pp. 1‚Äì8, 2020.\n[25] N. Jadav, N. Dutta, H. K. D. Sarma, E. Pricop, and S. Tanwar, ‚Äò‚ÄòA machine\nlearning approach to classify network traffic,‚Äô‚Äô 2021 13th International\nConference on Electronics, Computers and Artificial Intelligence (ECAI),\nvol. 00, pp. 1‚Äì6, 2021.\n[26] Q. H. Nguyen, S. Hore, A. Shah, T. Le, and N. D. Bastian, ‚Äò‚ÄòFedNIDS: A\nfederated learning framework for packet-based network intrusion detection\nsystem,‚Äô‚Äô Digital Threats: Research and Practice, vol. 6, no. 1, pp. 1‚Äì23,\n2025.\n[27] R.-H. Hwang, M.-C. Peng, V.-L. Nguyen, and Y.-L. Chang, ‚Äò‚ÄòAn LSTM-\nbased deep learning approach for classifying malicious traffic at the packet\nlevel,‚Äô‚Äô Applied Sciences, vol. 9, no. 16, p. 3414, 2019.\n[28] M. A. Kristyanto, H. Studiawan, and B. A. Pratomo, ‚Äò‚ÄòEvaluation of\nreinforcement learning algorithm on SSH honeypot,‚Äô‚Äô 2022 6th Interna-\ntional Conference on Information Technology, Information Systems and\nElectrical Engineering (ICITISEE), vol. 00, pp. 346‚Äì350, 2022.\n[29] N. Innab, E. Alomairy, and L. Alsheddi, ‚Äò‚ÄòHybrid system between anomaly\nbased detection system and honeypot to detect zero day attack,‚Äô‚Äô 2018 21st\nSaudi Computer Society National Computer Conference (NCC), vol. 00,\npp. 1‚Äì5, 2018.\n[30] S. Touch and J.-N. Colin, ‚Äò‚ÄòA comparison of an adaptive self-guarded\nhoneypot with conventional honeypots,‚Äô‚Äô Applied Sciences, vol. 12, no. 10,\np. 5224, 2022.\n[31] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction.\nThe MIT Press, 2014.\n[32] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra,\nand M. Riedmiller, ‚Äò‚ÄòPlaying atari with deep reinforcement learning,‚Äô‚Äô\narXiv, 2013, basic first Introduction DQN.\n[33] P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P.-A. Manzagol,\n‚Äò‚ÄòStacked denoising autoencoders: Learning useful representations in a\ndeep network with a local denoising criterion,‚Äô‚Äô J. Mach. Learn. Res.,\nvol. 11, p. 3371‚Äì3408, 2010.\n[34] D. Merkel, ‚Äò‚ÄòDocker: lightweight linux containers for consistent develop-\nment and deployment,‚Äô‚Äô Linux J., 2014.\n[35] D. Bernstein, ‚Äò‚ÄòContainers and cloud: From LXC to docker to kubernetes,‚Äô‚Äô\nIEEE Cloud Computing, vol. 1, no. 3, pp. 81‚Äì84, 2014.\n[36] R.-H. Hwang, M.-C. Peng, C.-W. Huang, P.-C. Lin, and V.-L. Nguyen,\n‚Äò‚ÄòAn unsupervised deep learning model for early network traffic anomaly\ndetection,‚Äô‚Äô IEEE Access, vol. 8, pp. 30 387‚Äì30 399, 2020.\n[37] I. S. I. U. o. S. California, ‚Äò‚ÄòInternet protocol - DARPA internet\nprogram protocol specification,‚Äô‚Äô 1981. [Online]. Available: https:\n//tools.ietf.org/html/rfc791\n[38] E. Hutchins, M. Cloppert, and R. Armin, ‚Äò‚ÄòIntelligence-driven computer\nnetwork defense informed by analysis of adversary campaigns and\nintrusion kill chains,‚Äô‚Äô Leading Issues in Information Warfare & Security\nResearch, 2011.\n[39] C. Johnson, L. Badger, D. Waltermire, J. Snyder, and C. Skorupka,\n‚Äò‚ÄòGuide to cyber threat information sharing.‚Äô‚Äô [Online]. Available:\nhttp://dx.doi.org/10.6028/NIST.SP.800-150\n[40] T. Fawcett, ‚Äò‚ÄòAn introduction to ROC analysis,‚Äô‚Äô Pattern Recognition\nLetters, vol. 27, no. 8, pp. 861‚Äì874, 2006, ROC Analysis in Pattern\nRecognition. [Online]. Available: https://www.sciencedirect.com/science/\narticle/pii/S016786550500303X\n[41] M. Armbrust, A. Fox, R. Griffith, A. D. Joseph, R. Katz, A. Konwinski,\nG. Lee, D. Patterson, A. Rabkin, I. Stoica, and M. Zaharia, ‚Äò‚ÄòA view of\ncloud computing,‚Äô‚Äô Communications of the ACM, vol. 53, no. 4, pp. 50‚Äì58,\n2010. [Online]. Available: https://doi.org/10.1145/1721654.1721672\n[42] B. Shneiderman, M. Cohen, S. Jacobs, C. Plaisant, N. Diakopoulos,\nand N. Elmqvist, Designing the User Interface Strategies for Effective\nHuman-Computer Interaction, Global Edition.\nPearson Deutschland,\n2017. [Online]. Available: https://elibrary.pearson.de/book/99.150005/9\n781292153926\n[43] K. Scarfone and P. Mell, ‚Äò‚ÄòGuide to intrusion detection and prevention\nsystems (IDPS).‚Äô‚Äô [Online]. Available: https://nvlpubs.nist.gov/nistpubs/le\ngacy/sp/nistspecialpublication800-94.pdf\n[44] A. Pauna and I. Bica, ‚Äò‚ÄòRASSH - reinforced adaptive SSH honeypot,‚Äô‚Äô\n2014 10th International Conference on Communications (COMM), pp.\n1‚Äì6, 2014.\n[45] J. SONG, H. TAKAKURA, Y. OKABE, D. INOUE, M. ETO, and\nK. NAKAO, ‚Äò‚ÄòA comparative study of unsupervised anomaly detection\ntechniques using honeypot data,‚Äô‚Äô IEICE Transactions on Information and\nSystems, vol. E93.D, no. 9, pp. 2544‚Äì2554, 2010.\n[46] S. Touch and J.-N. Colin, ‚Äò‚ÄòAsguard: Adaptive self-guarded honeypot,‚Äô‚Äô\nProceedings of the 17th International Conference on Web Information\nSystems and Technologies, pp. 565‚Äì574, 2021.\n[47] P. Prasad, N. Girish, V. Sarasvathi, A. Vh, and K. S. Prem, ‚Äò‚ÄòGenerative\nAI SSH honeypot with reinforcement learning,‚Äô‚Äô pp. 770‚Äì775, 2025.\n[48] F. Bao, S. Miller, J. Zhou, G.-J. Ahn, and P. Owezarski, ‚Äò‚ÄòA near real-time\nalgorithm for autonomous identification and characterization of honeypot\nattacks,‚Äô‚Äô Proceedings of the 10th ACM Symposium on Information,\nComputer and Communications Security, pp. 531‚Äì542, 2015.\n[49] C. Yin, Y. Zhu, J. Fei, and X. He, ‚Äò‚ÄòA deep learning approach for intrusion\ndetection using recurrent neural networks,‚Äô‚Äô IEEE Access, vol. 5, pp.\n21 954‚Äì21 961, 2017.\n[50] N. Sharan, T. Quig, E. Goodman, Y. R. Choe, and D. Brucker-Hahn,\n‚Äò‚ÄòRaw packet data ingestion with transformers for malicious activity\nclassifications,‚Äô‚Äô 2023 International Conference on Machine Learning\nand Applications (ICMLA), vol. 00, pp. 2188‚Äì2193, 2023.\n[51] C. Stoll, The cuckoo‚Äôs egg: Tracking a spy through the maze of computer\nespionage.\nDoubleday, 1989.\n[52] C. D. Team, ‚Äò‚ÄòCowrie.‚Äô‚Äô [Online]. Available: https://docs.cowrie.org/en/lat\nest/\n[53] ‚Äò‚ÄòT-pot - the all in one multi honeypot platform.‚Äô‚Äô [Online]. Available:\nhttps://github.com/telekom-security/tpotce\n[54] S. Dowling, M. Schukat, and E. Barrett, ‚Äò‚ÄòMachine learning and knowledge\ndiscovery in databases, european conference, ECML PKDD 2018, dublin,\nireland, september 10‚Äì14, 2018, proceedings, part III,‚Äô‚Äô Lecture Notes in\nComputer Science, pp. 341‚Äì355, 2019.\n[55] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning.\nMIT Press,\n2016.\n[56] B. Thuraisingham, D. Evans, T. Malkin, D. Xu, M. Du, F. Li, G. Zheng,\nand V. Srikumar, ‚Äò‚ÄòDeepLog: Anomaly detection and diagnosis from\nsystem logs through deep learning,‚Äô‚Äô in Proceedings of the 2017 ACM\nSIGSAC Conference on Computer and Communications Security, ser.\nProceedings of the 2017 ACM SIGSAC Conference on Computer\nand Communications Security.\nNew York, NY, USA: Association\nfor Computing Machinery, 2017, pp. 1285‚Äì1298. [Online]. Available:\nhttps://doi.org/10.1145/3133956.3134015\n[57] J. T. F. T. Initiative, ‚Äò‚ÄòManaging information security risk: Organization,\nmission, and information system view,‚Äô‚Äô 2011. [Online]. Available:\nhttps://csrc.nist.gov/pubs/sp/800/39/final\n[58] C. . I. Agency, ‚Äò‚ÄòNation-state threats,‚Äô‚Äô 2025. [Online]. Available:\nhttps://www.cisa.gov/topics/cyber-threats-and-advisories/nation-state-c\nyber-actors\n[59] Crowdstrike, ‚Äò‚ÄòCrowdStrike 2025 global threat report,‚Äô‚Äô 2025. [Online].\nAvailable: https://www.crowdstrike.com/en-us/global-threat-report/\n[60] Verizon, ‚Äò‚Äò2024 data breach investigations report,‚Äô‚Äô 2024. [Online].\nAvailable: https://www.verizon.com/business/resources/reports/2024-d\nbir-data-breach-investigations-report.pdf\n[61] Chainanalysis, ‚Äò‚ÄòThe 2025 crypto crime report,‚Äô‚Äô 2025. [Online]. Available:\nhttps://go.chainalysis.com/2025-Crypto-Crime-Report.html\n[62] Europol, Internet Organised Crime Threat Assessment (IOCTA) 2025.\nEuropol, 2025.\n[63] Agency,\nCybersecurity\nand\nInfrastructure\nSecurity,\n‚Äò‚ÄòDarkSide\nransomware:\nBest\npractices\nfor\npreventing\nbusiness\ndisruption\nfrom\nransomware\nattacks,‚Äô‚Äô\nCybersecurity\nand\nInfrastructure\nSecurity\nAgency,\nTech.\nRep.,\n7\n2021.\n[Online].\nAvailable:\nhttps://www.cisa.gov/news-events/cybersecurity-advisories/aa21-131a\n[64] SecurityScorecard, ‚Äò‚ÄòJBS ransomware attack started in march and much\nlarger in scope than previously identified,‚Äô‚Äô 6 2021. [Online]. Available:\nhttps://securityscorecard.com/blog/jbs-ransomware-attack-started-in-m\narch/?utm_source=chatgpt.com\n[65] J. Nguyen-Duy, ‚Äò‚ÄòNew supply chain ransomware attack targets kaseya\nplatform,‚Äô‚Äô Fortinet, Tech. Rep., 7 2021. [Online]. Available: https:\n//www.fortinet.com/blog/threat-research/new-supply-chain-ransomwar\ne-attack-targets-kaseya-platform\n[66] FireEye, ‚Äò‚ÄòHighly evasive attacker leverages SolarWinds supply chain\nto compromise multiple global victims with SUNBURST backdoor,‚Äô‚Äô\nMandiant, Tech. Rep., 9 2020. [Online]. Available: https://cloud.google.c\nom/blog/topics/threat-intelligence/evasive-attacker-leverages-solarwind\ns-supply-chain-compromises-with-sunburst-backdoor?hl=en\n28\n\n[67] Codecov, ‚Äò‚ÄòPost-mortem / root cause analysis,‚Äô‚Äô 2021. [Online]. Available:\nhttps://about.codecov.io/apr-2021-post-mortem/\n[68] B. f. S. i. d. Informationstechnik, ‚Äò‚ÄòKritische backdoor in XZ f√ºr\nlinux,‚Äô‚Äô Tech. Rep. 2024-223608-1132, 4 2024. [Online]. Available:\nhttps://www.bsi.bund.de/SharedDocs/Cybersicherheitswarnungen/DE/\n2024/2024-223608-1032.pdf?__blob=publicationFile\n[69] C. . I. Agency, ‚Äò‚ÄòPRC state-sponsored actors compromise and maintain\npersistent access to u.s. critical infrastructure,‚Äô‚Äô 2 2024. [Online]. Available:\nhttps://www.cisa.gov/news-events/cybersecurity-advisories/aa24-038a\n[70] Bundeskriminalamt, ‚Äò‚ÄòHACKTIVISTS,‚Äô‚Äô 2016. [Online]. Available:\nfile:///C:/Users/lukas/Downloads/summaryHacktivists.pdf\n[71] D. Cappelli, A. Moore, and R. Trzeciak, The CERT Guide to Insider\nThreats: How to Prevent, Detect, and Respond to Information Technology\nCrimes (Theft, Sabotage, Fraud).\nAddison-Wesley, 2012.\n[72] ‚Äò‚ÄòMITRE ATT&CK framework.‚Äô‚Äô [Online]. Available: https://attack.mitre\n.org\n[73] cloudsecurityalliance, ‚Äò‚ÄòTop threats to cloud computing 2024,‚Äô‚Äô Tech. Rep.,\n8 2024. [Online]. Available: https://cloudsecurityalliance.org/artifacts/to\np-threats-to-cloud-computing-2024\n[74] S. Rose, O. Borchert, S. Mitchell, and S. Connelly, ‚Äò‚ÄòZero trust architec-\nture,‚Äô‚Äô 2020.\n[75] OWASP, ‚Äò‚ÄòOWASP top ten,‚Äô‚Äô 2021. [Online]. Available: https://owasp.org/\nTop10/\n[76] H. Myrbakken and R. Colomo-Palacios, ‚Äò‚ÄòDevSecOps: A multivocal\nliterature review,‚Äô‚Äô in Software Process Improvement and Capability\nDetermination.\nSpringer International Publishing, 2017, pp. 17‚Äì29.\n[77] OWASP, ‚Äò‚ÄòOWASP top 10 API security risks,‚Äô‚Äô 2023. [Online]. Available:\nhttps://owasp.org/API-Security/editions/2023/en/0x11-t10/\n[78] K. Mitnick and W. Simon, The art of deception: Controlling the human\nelement of security.\nJohn Wiley & Sons, 2003.\n[79] Z. Alkhalil, C. Hewage, L. Nawaf, and I. Khan, ‚Äò‚ÄòPhishing attacks: A recent\ncomprehensive study and a new anatomy,‚Äô‚Äô Frontiers in Computer Science,\nvol. 3, p. 563060, 2021.\n[80] F. B. o. Investigation, ‚Äò‚ÄòInternet crime report 2024,‚Äô‚Äô Federal Bureau of\nInvestigation, Tech. Rep., 2024. [Online]. Available: https://www.ic3.gov/\nAnnualReport/Reports/2024_IC3Report.pdf\n[81] O. Ogwo-Ude, ‚Äò‚ÄòBusiness email compromise challenges to medium and\nlarge-scale firms in USA: An analysis,‚Äô‚Äô Open Journal of Applied Sciences,\nvol. 13, no. 06, pp. 803‚Äì812, 2023.\n[82] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bac≈üar, and J.-P. Hubaux, ‚Äò‚ÄòGame\ntheory meets network security and privacy,‚Äô‚Äô ACM Computing Surveys\n(CSUR), vol. 45, no. 3, pp. 1‚Äì39, 2013.\n[83] M. Brundage, S. Avin, J. Clark, H. Toner, P. Eckersley, B. Garfinkel,\nA. Dafoe, P. Scharre, T. Zeitzoff, B. Filar, H. Anderson, H. Roff, G. C.\nAllen, J. Steinhardt, C. Flynn, S. Beard, H. Belfield, S. Farquhar, C. Lyle,\nR. Crootof, O. Evans, M. Page, J. Bryson, R. Yampolskiy, and D. Amodei,\n‚Äò‚ÄòThe malicious use of artificial intelligence: Forecasting, prevention, and\nmitigation,‚Äô‚Äô 2018. [Online]. Available: https://arxiv.org/abs/1802.07228\n[84] E. U. A. f. C. (ENISA), ‚Äò‚ÄòENISA foresight cybersecurity threats for 2030,‚Äô‚Äô\nEuropean Union Agency for Cybersecurity (ENISA), Tech. Rep., 3 2023.\n[Online]. Available: https://www.enisa.europa.eu/publications/enisa-fores\night-cybersecurity-threats-for-2030\n[85] N. S. A. Cybersecurity and I. S. Agency, ‚Äò‚ÄòKubernetes hardening guide,‚Äô‚Äô\n8 2022. [Online]. Available: https://media.defense.gov/2022/Aug/29/2003\n066362/-1/-1/0/CTR_KUBERNETES_HARDENING_GUIDANCE_1\n.2_20220829.PDF\n[86] ‚Äò‚ÄòKubernetes documentation.‚Äô‚Äô [Online]. Available: https://kubernetes.io/\ndocs/concepts/services-networking/\n[87] N. Neshenko, E. Bou-Harb, J. Crichigno, G. Kaddoum, and N. Ghani,\n‚Äò‚ÄòDemystifying IoT security: An exhaustive survey on IoT vulnerabilities\nand a first empirical look on internet-scale IoT exploitations,‚Äô‚Äô IEEE\nCommunications Surveys & Tutorials, vol. 21, no. 3, pp. 2702‚Äì2733, 2019.\n[88] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein, J. Cochran,\nZ. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis, D. Kumar,\nC. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman, N. Sullivan,\nK. Thomas, and Y. Zhou, ‚Äò‚ÄòUnderstanding the mirai botnet,‚Äô‚Äô in Proceedings\nof the 26th USENIX Conference on Security Symposium, ser. SEC‚Äô17.\nUSENIX Association, 2017, p. 1093‚Äì1110.\n[89] Y. Xiao, Y. Jia, C. Liu, X. Cheng, J. Yu, and W. Lv, ‚Äò‚ÄòEdge\ncomputing security: State of the art and challenges,‚Äô‚Äô Proceedings\nof the IEEE, vol. 107, pp. 1608‚Äì1631, 2019. [Online]. Available:\nhttps://api.semanticscholar.org/CorpusID:196173948\n[90] IBM, ‚Äò‚ÄòCost of a data breach report 2025,‚Äô‚Äô 2025. [Online]. Available:\nhttps://www.ibm.com/reports/data-breach\n[91] S. Ferguson and D. Olenick, ‚Äò‚ÄòFBI: DarkSide ransomware used\nin colonial pipeline attack,‚Äô‚Äô 5 2021. [Online]. Available: https:\n//www.bankinfosecurity.com/fbi-darkside-ransomware-used-in-colonia\nl-pipeline-attack-a-16555\n[92] E. Parliament, ‚Äò‚ÄòREGULATION (EU) 2016/679 OF THE EUROPEAN\nPARLIAMENT AND OF THE COUNCIL of 27 april 2016 on the\nprotection of natural persons with regard to the processing of personal data\nand on the free movement of such data, and repealing directive 95/46/EC\n(general data protection regulation),‚Äô‚Äô 4 2016. [Online]. Available:\nhttp://data.europa.eu/eli/reg/2016/679/oj\n[93] S. o. California, ‚Äò‚ÄòAssembly bill no. 375,‚Äô‚Äô 2018. [Online]. Available:\nhttps://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=20\n1720180AB375\n[94] F. T. Comission, ‚Äò‚ÄòFTC takes action against marriott and starwood\nover multiple data breaches,‚Äô‚Äô 10 2024. [Online]. Available: https:\n//www.ftc.gov/news-events/news/press-releases/2024/10/ftc-takes-actio\nn-against-marriott-starwood-over-multiple-data-breaches\n[95] ‚Äî‚Äî, ‚Äò‚ÄòEquifax data breach settlement,‚Äô‚Äô 2024. [Online]. Available: https:\n//www.ftc.gov/enforcement/refunds/equifax-data-breach-settlement\n[96] T. Holz and F. Raynal, ‚Äò‚ÄòDetecting honeypots and other suspicious envi-\nronments,‚Äô‚Äô in Proceedings from the Sixth Annual IEEE SMC Information\nAssurance Workshop, 2005, pp. 29‚Äì36.\n[97] M. M. R√∂hling, M. Grimmer, D. Kreubel, J. Hoffmann, and B. Franczyk,\n‚Äò‚ÄòStandardized container virtualization approach for collecting host intru-\nsion detection data,‚Äô‚Äô in 2019 Federated Conference on Computer Science\nand Information Systems (FedCSIS), 2019, pp. 459‚Äì463.\n[98] K. Papazis and N. Chilamkurti, ‚Äò‚ÄòDetecting indicators of deception\nin emulated monitoring systems,‚Äô‚Äô Service Oriented Computing and\nApplications, vol. 13, no. 1, pp. 17‚Äì29, 03 2019. [Online]. Available:\nhttps://doi.org/10.1007/s11761-018-0252-2\n[99] S. Srinivasa, J. M. Pedersen, and E. Vasilomanolakis, ‚Äò‚ÄòGotta catch ‚Äôem\nall: A multistage framework for honeypot fingerprinting,‚Äô‚Äô Digital Threats,\nvol. 4, no. 3, 2023. [Online]. Available: https://doi.org/10.1145/3584976\n[100] G. Portokalidis, A. Slowinska, and H. Bos, ‚Äò‚ÄòArgos: an emulator for\nfingerprinting zero-day attacks for advertised honeypots with automatic\nsignature generation,‚Äô‚Äô SIGOPS Oper. Syst. Rev., vol. 40, no. 4, p. 15‚Äì27,\n2006. [Online]. Available: https://doi.org/10.1145/1218063.1217938\n[101] J. Gama, I. Zliobaite, A. Bifet, M. Pechenizkiy, and A. Bouchachia, ‚Äò‚ÄòA\nsurvey on concept drift adaptation,‚Äô‚Äô ACM Comput. Surv., vol. 46, no. 4,\n2014. [Online]. Available: https://doi.org/10.1145/2523813\n[102] J. Lu, A. Liu, F. Dong, F. Gu, J. Gama, and G. Zhang, ‚Äò‚ÄòLearning\nunder concept drift: A review,‚Äô‚Äô IEEE Transactions on Knowledge\nand Data Engineering, p. 1‚Äì1, 2018. [Online]. Available: http:\n//dx.doi.org/10.1109/TKDE.2018.2876857\n[103] J. Zhou, G. Cui, S. Hu, Z. Zhang, C. Yang, Z. Liu, L. Wang, C. Li,\nand M. Sun, ‚Äò‚ÄòGraph neural networks: A review of methods and\napplications,‚Äô‚Äô AI Open, vol. 1, pp. 57‚Äì81, 2020. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S2666651021000012\n[104] O. Open, ‚Äò‚ÄòSTIX‚Ñ¢version 2.1.‚Äô‚Äô 2021. [Online]. Available: https:\n//www.oasis-open.org/standard/6426/\n[105] K. Kent and M. Souppaya, ‚Äò‚ÄòGuide to computer security log management,‚Äô‚Äô\n2006.\n[106] mushorg, ‚Äò‚Äòconpot.‚Äô‚Äô [Online]. Available: https://github.com/mushorg/con\npot\n[107] DinoTools, ‚Äò‚Äòdinoaea.‚Äô‚Äô [Online]. Available: https://github.com/DinoTools\n/dionaea\n[108] mushorg, ‚Äò‚Äòglastopf.‚Äô‚Äô [Online]. Available: https://github.com/mushorg/gla\nstopf\n[109] johnnykv, ‚Äò‚Äòheralding,‚Äô‚Äô 8 2025. [Online]. Available: https://github.com/j\nohnnykv/heralding\n[110] honeytrap, 8 2025. [Online]. Available: https://github.com/honeytrap/hon\neytrap\n[111] J. Wright, ‚Äò‚Äòelastichoney,‚Äô‚Äô 8 2025. [Online]. Available: https://github.com\n/jordan-wright/elastichoney\n[112] gbrindisi, ‚Äò‚Äòwordpot,‚Äô‚Äô 8 2025. [Online]. Available: https://github.com/gbr\nindisi/wordpot\n[113] Y. M. P. Pa, S. Suzuki, K. Yoshioka, T. Matsumoto, T. Kasama, and\nC. Rossow, ‚Äò‚ÄòIoTPOT: Analysing the rise of IoT compromises,‚Äô‚Äô in 9th\nUSENIX Workshop on Offensive Technologies (WOOT 15).\nWashington,\nD.C.: USENIX Association, 2015. [Online]. Available: https://www.usen\nix.org/conference/woot15/workshop-program/presentation/pa\n[114] zeroq, ‚Äò‚Äòamun,‚Äô‚Äô 8 2025. [Online]. Available: https://github.com/zeroq/a\nmun\n[115] ‚Äò‚ÄòKibana.‚Äô‚Äô [Online]. Available: https://www.elastic.co/kibana\n29\n\n[116] ‚Äò‚ÄòGrafana documentation.‚Äô‚Äô [Online]. Available: https://grafana.com/docs\n/grafana/latest/\n[117] ‚Äò‚ÄòPrometheus documentation.‚Äô‚Äô [Online]. Available: https://prometheus.io/\ndocs/introduction/overview/\n[118] B. Rabenstein and J. Volz, ‚Äò‚ÄòPrometheus: A next-generation monitoring\nsystem (talk),‚Äô‚Äô in SREcon16.\nUSENIX Association, 2015.\n[119] ‚Äò‚ÄòOpenTelemetry documentation.‚Äô‚Äô [Online]. Available: https://openteleme\ntry.io/docs/\n[120] W. E. Ed., ‚Äò‚ÄòTransmission control protocol,‚Äô‚Äô 2022. [Online]. Available:\nhttps://datatracker.ietf.org/doc/html/rfc9293\n[121] J. Postel, ‚Äò‚ÄòUser datagram protocol,‚Äô‚Äô 8 1980. [Online]. Available:\nhttps://www.rfc-editor.org/rfc/rfc768\n[122] Elastic, ‚Äò‚ÄòElastic stack.‚Äô‚Äô [Online]. Available: https://www.elastic.co/elast\nic-stack\n[123] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S.\nCorrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow,\nA. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur,\nJ. Levenberg, D. Mane, R. Monga, S. Moore, D. Murray, C. Olah, M. Schus-\nter, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke,\nV. Vasudevan, F. Viegas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke,\nY. Yu, and X. Zheng, ‚Äò‚ÄòTensorFlow: Large-scale machine learning on\nheterogeneous distributed systems,‚Äô‚Äô arXiv, 2016.\n[124] ‚Äò‚ÄòLightweight kubernetes.‚Äô‚Äô [Online]. Available: https://k3s.io/\n[125] Cisco, ‚Äò‚ÄòSnort.‚Äô‚Äô [Online]. Available: https://www.snort.org/\n[126] J. A. Donenfeld, ‚Äò‚ÄòWireGuard: Next generation kernel network tunnel,‚Äô‚Äô in\nNetwork and Distributed System Security Symposium. [Online]. Available:\nhttps://api.semanticscholar.org/CorpusID:2590070\n[127] J. Ziv and A. Lempel, ‚Äò‚ÄòA universal algorithm for sequential data com-\npression,‚Äô‚Äô IEEE Transactions on Information Theory, vol. 23, no. 3, pp.\n337‚Äì343, 1977.\n[128] B. P. Welford, ‚Äò‚ÄòNote on a method for calculating corrected sums of\nsquares and products,‚Äô‚Äô Technometrics, vol. 4, no. 3, pp. 419‚Äì420, 1962.\n[Online]. Available: https://www.tandfonline.com/doi/abs/10.1080/0040\n1706.1962.10490022\n[129] Cyan4973, ‚Äò‚ÄòxxHash.‚Äô‚Äô [Online]. Available: https://xxhash.com/\n[130] Z. Wang, T. Schaul, M. Hessel, H. V. Hasselt, M. Lanctot, and N. D.\nFreitas, ‚Äò‚ÄòDueling network architectures for deep reinforcement learning,‚Äô‚Äô\nin Proceedings of the 33rd International Conference on International\nConference on Machine Learning - Volume 48, ser. ICML‚Äô16.\nJMLR.org,\n2016, p. 1995‚Äì2003.\n[131] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.\nBellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski,\nS. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran,\nD. Wierstra, S. Legg, and D. Hassabis, ‚Äò‚ÄòHuman-level control through deep\nreinforcement learning,‚Äô‚Äô Nature, vol. 518, no. 7540, pp. 529‚Äì533, 2015.\n[132] H. v. Hasselt, A. Guez, and D. Silver, ‚Äò‚ÄòDeep reinforcement learning with\ndouble q-learning,‚Äô‚Äô in Proceedings of the Thirtieth AAAI Conference on\nArtificial Intelligence, ser. AAAI‚Äô16.\nAAAI Press, 2016, p. 2094‚Äì2100.\n[133] C. J. C. H. Watkins and P. Dayan, ‚Äò‚ÄòQ-learning,‚Äô‚Äô Machine Learning, vol. 8,\nno. 3-4, pp. 279‚Äì292, 1992.\n[134] J. Snoek, H. Larochelle, and R. P. Adams, ‚Äò‚ÄòPractical bayesian\noptimization of machine learning algorithms,‚Äô‚Äô 2012. [Online]. Available:\nhttps://arxiv.org/abs/1206.2944\n[135] Hashicorp, ‚Äò‚ÄòTerraform.‚Äô‚Äô [Online]. Available: https://developer.hashicorp.\ncom/terraform/docs\n[136] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins,\nA. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, D. Hass-\nabis, C. Clopath, D. Kumaran, and R. Hadsell, ‚Äò‚ÄòOvercoming catastrophic\nforgetting in neural networks,‚Äô‚Äô Proceedings of the National Academy of\nSciences, vol. 114, 2016.\n[137] A. B. Arrieta, N. D√≠az-Rodr√≠guez, J. D. Ser, A. Bennetot, S. Tabik,\nA. Barbado, S. Garcia, S. Gil-Lopez, D. Molina, R. Benjamins,\nR. Chatila, and F. Herrera, ‚Äò‚ÄòExplainable artificial intelligence (XAI):\nConcepts, taxonomies, opportunities and challenges toward responsible\nAI,‚Äô‚Äô Information Fusion, vol. 58, pp. 82‚Äì115, 2020. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S1566253519308103\n[138] European-Union, ‚Äò‚ÄòAI act,‚Äô‚Äô 6 2024. [Online]. Available: https://artificiali\nntelligenceact.eu/ai-act-explorer/\nLUKAS JOHANNES M√ñLLER is currently a gradu-\nate student with the Georgia Institute of Technology,\ncollaborating with the German Federal Office for\nInformation Security (BSI) on adaptive honeynet\nand moving-target defense projects. His research\ninterests include adaptive honeynets, reinforcement-\nlearning-driven container orchestration, unsuper-\nvised anomaly detection, and vulnerability research.\n30\n\nAPPENDIX A DETAILED FEATURE ANALYSIS OF THE MADCAT SENSOR DATA\nFeature\nData Type\nRelevant\nJustification\n_index\nobject\nNo\nInternal Elasticsearch metadata with no relation to session behav-\nior.\n_id\nobject\nNo\nUnique document identifier not related to network behavior.\n_score\nobject\nNo\nSearch relevance score unrelated to traffic features.\n_ignored\nobject\nNo\nField ingestion metadata unrelated to network behavior.\nsort\nobject\nNo\nElasticsearch sort field not related to network features.\nsrc_ip\nobject\nYes\nDirect source address is essential for identifying the origin of\ntraffic in RL decisions.\ndest_ip_-\ngeoip.geo.city_name\nobject\nNo\nCity-level geolocation requires enrichment and is not reliable\nenough for direct RL scoring.\ndest_ip_-\ngeoip.geo.region_-\nname\nobject\nNo\nRegion-level geolocation is enrichment data not directly usable\nin real-time RL decisions.\ndest_ip_-\ngeoip.geo.location.lat\nfloat64\nNo\nLatitude requires enrichment and is not used directly in RL\ndecision-making.\ndest_ip_-\ngeoip.geo.location.lon\nfloat64\nNo\nLongitude requires enrichment and is not used directly in RL\ndecision-making.\ndest_ip_-\ngeoip.geo.continent_-\ncode\nobject\nNo\nContinent code is enrichment data and not necessary for RL\nscoring.\ndest_ip_-\ngeoip.geo.country_-\niso_code\nobject\nNo\nCountry code requires enrichment and is not used in the RL\nscoring loop.\ndest_ip_-\ngeoip.geo.postal_-\ncode\nobject\nNo\nPostal code is unreliable and irrelevant for RL scoring.\ndest_ip_-\ngeoip.geo.country_-\nname\nobject\nNo\nHuman-readable country name is redundant and not needed for\nRL logic.\ndest_ip_-\ngeoip.geo.timezone\nobject\nNo\nTimezone is enrichment metadata and not a real-time RL feature.\nTCP.res1\nfloat64\nNo\nReserved header field with no behavioral value.\nTCP.ack\nobject\nYes\nACK flag is directly usable for detecting connection state anoma-\nlies in RL.\nTCP.syn\nobject\nYes\nSYN flag is directly usable for detecting scans and session\ninitiation patterns.\nTCP.psh\nobject\nNo\nPSH flag requires deep interpretation and is not a primary RL\ntrigger.\nTCP.urg\nobject\nNo\nURG flag is rarely set and has no consistent RL scoring value.\nTCP.rst\nobject\nYes\nRST flag is directly usable for identifying scanning or forced\nconnection termination.\nTCP.src_port\nfloat64\nYes\nSource port is a fundamental feature for identifying service\npatterns.\nTCP.tcp_flags\nobject\nYes\nCombined flags are directly usable for RL pattern matching.\nTCP.ack_seq\nfloat64\nNo\nAcknowledgment sequence number requires session tracking\nbeyond RL‚Äôs real-time scope.\nTCP.tcp_op-\ntions.tained\nobject\nNo\nTool-specific metadata unrelated to RL scoring.\nTCP.tcp_op-\ntions.timestamp\nobject\nNo\nTCP timestamp is enrichment-level fingerprinting, not used in\nRL.\nTCP.tcp_op-\ntions.sack_perm\nobject\nNo\nSACK permission is fingerprinting data, not used in RL scoring.\n31\n\nFeature\nData Type\nRelevant\nJustification\nTCP.tcp_op-\ntions.padding_hex\nobject\nNo\nPadding content is irrelevant for RL scoring.\nTCP.tcp_options.nop\nobject\nNo\nNo-Operation option has no RL scoring value.\nTCP.tcp_op-\ntions.window\nobject\nNo\nTCP window option requires enrichment and is not used in RL\ndirectly.\nTCP.tcp_options.mss\nobject\nNo\nMSS is passive fingerprinting, not a real-time RL feature.\nTCP.window\nfloat64\nNo\nWindow size is passive fingerprinting, not used in RL scoring.\nTCP.cwr\nobject\nNo\nCongestion flag is rare and irrelevant for RL.\nTCP.urg_ptr\nobject\nNo\nUrgent pointer has no consistent RL scoring impact.\nTCP.fin\nobject\nYes\nFIN flag is directly usable for detecting unusual connection\ntermination patterns.\nTCP.dest_port\nfloat64\nYes\nDestination port is a fundamental RL decision variable.\nTCP.hdr_len\nfloat64\nNo\nTCP header length is fingerprinting data, not used in RL decisions.\nTCP.ecn\nobject\nNo\nECN flag is not a primary RL decision feature.\nTCP.checksum\nobject\nNo\nChecksum validity is handled at transport level, not used in RL\nscoring.\nTCP.seq\nfloat64\nNo\nSequence number analysis is beyond the RL decision window.\nsrc_port\nfloat64\nYes\nSource port at root level is usable for RL scoring if protocol-\nspecific fields are missing.\nFLOW.proxy_ip\nobject\nNo\nProxy IP is enrichment data not available in real-time RL context.\nFLOW.end\nobject\nYes\nFlow end time is usable for session duration calculation in RL.\nFLOW.start\nobject\nYes\nFlow start time is directly usable for session duration in RL.\nFLOW.bytes_to-\nclient\nfloat64\nYes\nBytes to client is directly usable for detecting exfiltration patterns\nin RL.\nFLOW.backend_ip\nobject\nNo\nBackend IP requires enrichment and is not directly usable in RL\nscoring.\nFLOW.proxy_port\nfloat64\nNo\nProxy port is enrichment detail not used in RL scoring.\nFLOW.duration\nfloat64\nYes\nFlow duration is directly usable for RL attack behavior classifica-\ntion.\nFLOW.bytes_-\ntoserver\nfloat64\nYes\nBytes to server is directly usable for detecting suspicious uploads\nin RL.\nFLOW.backend_port\nfloat64\nNo\nBackend port requires enrichment, not directly used in RL.\nFLOW.reason\nobject\nNo\nFlow termination reason is enrichment-level context, not a direct\nRL signal.\nFLOW.min_rtt\nfloat64\nNo\nRTT measurement requires enrichment and is not part of RL\nscoring.\nFLOW.state\nobject\nYes\nFlow state is a direct RL decision feature.\nsrc_ip_-\ngeoasn.as.number\nfloat64\nYes\nASN number of source IP is directly usable for RL reputation\nscoring.\nsrc_ip_-\ngeoasn.as.organization.name\nobject\nNo\nASN organization name is enrichment data, not a direct RL\nvariable.\nlog.offset\nint64\nNo\nLog offset is ingestion metadata, irrelevant to RL.\nlog.file.path\nobject\nNo\nLog file path is ingestion metadata, irrelevant to RL.\ndest_port\nfloat64\nYes\nDestination port at root level is usable for RL scoring.\nproto\nobject\nYes\nProtocol type is a fundamental RL decision feature.\ndest_ip\nobject\nYes\nDestination IP is directly usable for RL scoring.\necs.version\nobject\nNo\nECS version is logging metadata.\nobserver.product\nobject\nNo\nObserver product is logging metadata.\nobserver.version\nobject\nNo\nObserver version is logging metadata.\nobserver.type\nobject\nNo\nObserver type is logging metadata.\nobserver.hostname\nobject\nYes\nSensor hostname is usable for RL asset targeting logic.\nxlog_origin\nobject\nNo\nOrigin tag is metadata unrelated to RL scoring.\nIP.version\nfloat64\nYes\nIP version is directly usable for RL decisions.\nIP.tot_len\nfloat64\nYes\nTotal packet length is directly usable for RL anomaly scoring.\n32\n\nFeature\nData Type\nRelevant\nJustification\nIP.tos\nobject\nNo\nType of Service is enrichment-level fingerprinting, not used in\nRL.\nIP.dest_addr\nobject\nYes\nDestination address is directly usable for RL decisions.\nIP.src_addr\nobject\nYes\nSource address is directly usable for RL decisions.\nIP.id\nobject\nNo\nIP ID is fingerprinting data, not used in RL scoring.\nIP.hdr_len\nfloat64\nNo\nIP header length is fingerprinting data, not used in RL scoring.\nIP.ttl\nfloat64\nYes\nTTL is directly usable for RL OS/liveness detection.\nIP.protocol\nfloat64\nYes\nProtocol number is a fundamental RL decision feature.\nIP.checksum\nobject\nNo\nIP checksum is validation metadata, not a RL feature.\nIP.flags\nobject\nNo\nIP flags require enrichment to interpret and are not used directly\nin RL.\ntimestamp\nobject\nYes\nEvent timestamp is directly usable for RL decision timing.\ntimestamp_pro-\ncessed\nobject\nNo\nProcessing timestamp is ingestion metadata.\nbackend_id\nobject\nNo\nBackend ID is infrastructure metadata.\nSPLIT.split\nobject\nNo\nLog splitting flag is ingestion metadata.\nevent.original\nobject\nNo\nRaw log text is not parsed for direct RL use.\nsrc_ip_-\ngeoip.geo.country_-\nname\nobject\nNo\nSource country name is enrichment data not used directly in RL.\nsrc_ip_-\ngeoip.geo.location.lat\nfloat64\nNo\nSource latitude is enrichment data, not a RL feature.\nsrc_ip_-\ngeoip.geo.location.lon\nfloat64\nNo\nSource longitude is enrichment data, not a RL feature.\nsrc_ip_-\ngeoip.geo.continent_-\ncode\nobject\nNo\nContinent code is enrichment data, not used in RL scoring.\nsrc_ip_-\ngeoip.geo.country_-\niso_code\nobject\nNo\nCountry code is enrichment data, not used in RL scoring.\nsrc_ip_-\ngeoip.geo.timezone\nobject\nNo\nTimezone is enrichment data, not used in RL scoring.\n@version\nobject\nNo\nLogstash metadata.\norigin\nobject\nNo\nLog origin metadata.\nhost.containerized\nbool\nYes\nContainerization state is directly usable for RL targeting logic.\nhost.mac\nobject\nNo\nMAC address is not visible for most remote sessions.\nhost.name\nobject\nYes\nHostname is directly usable for RL targeting logic.\nhost.architecture\nobject\nNo\nCPU architecture requires enrichment, not used in RL scoring.\nhost.ip\nobject\nYes\nHost IP is directly usable for RL targeting logic.\nhost.id\nobject\nNo\nHost ID is internal metadata.\nhost.os.version\nobject\nNo\nOS version is enrichment data, not used in RL scoring.\nhost.os.kernel\nobject\nNo\nKernel version is enrichment data, not used in RL scoring.\nhost.os.family\nobject\nNo\nOS family is enrichment data, not used in RL scoring.\nhost.os.name\nobject\nNo\nOS name is enrichment data, not used in RL scoring.\nhost.os.codename\nobject\nNo\nOS codename is enrichment data, not used in RL scoring.\nhost.os.platform\nobject\nNo\nOS platform is enrichment data, not used in RL scoring.\nhost.os.hostname\nobject\nYes\nOS hostname is directly usable for RL targeting logic.\ninput.type\nobject\nNo\nInput type is ingestion metadata.\nct_status\nobject\nYes\nThreat intelligence status is directly usable for RL blocking logic.\nunixtime\nfloat64\nYes\nUnix timestamp is directly usable for RL timing logic.\n@timestamp\nobject\nYes\nEvent timestamp is directly usable for RL decisions.\nevent_type\nobject\nYes\nEvent type is directly usable for RL decision-making.\nagent.version\nobject\nNo\nAgent version is metadata.\nagent.name\nobject\nNo\nAgent name is metadata.\n33\n\nFeature\nData Type\nRelevant\nJustification\nagent.id\nobject\nNo\nAgent ID is metadata.\nagent.type\nobject\nNo\nAgent type is metadata.\nagent.hostname\nobject\nNo\nAgent hostname is redundant metadata.\nagent.ephemeral_id\nobject\nNo\nAgent ephemeral ID is metadata.\ntags\nobject\nNo\nTags require enrichment parsing, not direct RL use.\ndest_ip_-\ngeoasn.as.number\nfloat64\nYes\nDestination ASN number is directly usable for RL reputation\nscoring.\ndest_ip_-\ngeoasn.as.organization.name\nobject\nNo\nDestination ASN org name is enrichment data.\nFLOW.payload_hd\nobject\nNo\nHex payload dump is not parsed in real-time RL.\nFLOW.payload_str\nobject\nNo\nString payload is not parsed in real-time RL.\nFLOW.payload_sha1\nobject\nYes\nPayload hash is directly usable for RL matching to known threats.\nhost.os.type\nobject\nNo\nOS type is enrichment data, not used in RL scoring.\nsrc_ip_-\ngeoip.mmdb.dma_-\ncode\nfloat64\nNo\nDMA code is irrelevant for RL scoring.\nsrc_ip_-\ngeoip.geo.city_name\nobject\nNo\nCity name is enrichment data, not used in RL scoring.\nsrc_ip_-\ngeoip.geo.postal_-\ncode\nobject\nNo\nPostal code is unreliable and irrelevant for RL scoring.\nsrc_ip_-\ngeoip.geo.region_-\nname\nobject\nNo\nRegion name is enrichment data, not used in RL scoring.\nTCP.payload_hd\nobject\nNo\nHex TCP payload is not parsed for RL.\nTCP.payload_sha1\nobject\nYes\nTCP payload hash is directly usable for RL threat matching.\nTCP.payload_str\nobject\nNo\nString TCP payload is not parsed for RL.\nTCP.tcp_options.eol\nobject\nNo\nEnd of Option List is irrelevant to RL scoring.\nicmp_code\nfloat64\nYes\nICMP code is directly usable for RL anomaly detection.\nICMP.type_str\nobject\nYes\nICMP type string is directly usable for RL scoring.\nICMP.id\nobject\nNo\nICMP ID is not a primary RL feature.\nICMP.checksum\nobject\nNo\nICMP checksum is irrelevant to RL scoring.\nICMP.code\nfloat64\nYes\nICMP code is directly usable for RL scoring.\nICMP.tainted\nobject\nNo\nTool-specific metadata irrelevant to RL.\nICMP.type\nfloat64\nYes\nICMP type is directly usable for RL anomaly scoring.\nICMP.seq\nobject\nNo\nICMP sequence number is not a primary RL feature.\nicmp_type\nfloat64\nYes\nICMP type number is directly usable for RL scoring.\nhttp.version\nobject\nNo\nHTTP version is enrichment-level metadata.\nhttp.request.method\nobject\nYes\nHTTP method is directly usable for RL web attack detection.\nuser_agent.original\nobject\nNo\nFull user agent string requires parsing, not direct RL use.\nuser_agent.os.full\nobject\nNo\nOS info from UA is enrichment data, not RL-direct.\nuser_agent.os.name\nobject\nNo\nOS name from UA is enrichment data.\nuser_agent.name\nobject\nNo\nUA name is enrichment data.\nuser_-\nagent.device.name\nobject\nNo\nUA device type is enrichment data.\nUDP.len\nfloat64\nYes\nUDP length is directly usable for RL anomaly scoring.\nUDP.src_port\nfloat64\nYes\nUDP source port is directly usable for RL scoring.\nUDP.checksum\nfloat64\nNo\nUDP checksum is irrelevant to RL scoring.\nUDP.dest_port\nfloat64\nYes\nUDP destination port is directly usable for RL scoring.\nurl.original\nobject\nYes\nFull URL is directly usable for RL web attack detection.\nuser_agent.version\nobject\nNo\nUA version is enrichment data.\nRAW.ether_type\nobject\nNo\nEtherType is L2 metadata irrelevant to RL scoring.\nRAW.pcap_filter\nobject\nNo\nCapture filter is collection metadata.\ntainted\nobject\nNo\nGeneric taint flag is irrelevant to RL.\n34\n\nFeature\nData Type\nRelevant\nJustification\nSPLIT.part\nfloat64\nNo\nSplit part number is ingestion metadata.\nSPLIT.total\nfloat64\nNo\nSplit total is ingestion metadata.\nSPLIT.tag\nobject\nNo\nSplit tag is ingestion metadata.\nICMP.IP.version\nfloat64\nNo\nEncapsulated IP version is enrichment detail.\nICMP.IP.tos\nobject\nNo\nEncapsulated TOS is enrichment detail.\nICMP.IP.tot_len\nfloat64\nNo\nEncapsulated total length is enrichment detail.\nICMP.IP.dest_addr\nobject\nNo\nEncapsulated dest address is enrichment detail.\nICMP.IP.src_addr\nobject\nNo\nEncapsulated source address is enrichment detail.\nICMP.IP.id\nobject\nNo\nEncapsulated IP ID is enrichment detail.\nICMP.IP.hdr_len\nfloat64\nNo\nEncapsulated header length is enrichment detail.\nICMP.IP.ttl\nfloat64\nNo\nEncapsulated TTL is enrichment detail.\nICMP.IP.protocol\nfloat64\nNo\nEncapsulated protocol is enrichment detail.\nICMP.IP.flags\nobject\nNo\nEncapsulated flags are enrichment detail.\nICMP.IP.checksum\nobject\nNo\nEncapsulated checksum is irrelevant.\nICMP.TCP.res1\nfloat64\nNo\nReserved encapsulated TCP field is irrelevant.\nICMP.TCP.ack\nobject\nNo\nEncapsulated ACK is enrichment detail.\nICMP.TCP.psh\nobject\nNo\nEncapsulated PSH is enrichment detail.\nICMP.TCP.syn\nobject\nNo\nEncapsulated SYN is enrichment detail.\nICMP.TCP.urg\nobject\nNo\nEncapsulated URG is enrichment detail.\nICMP.TCP.src_port\nfloat64\nNo\nEncapsulated source port is enrichment detail.\nICMP.TCP.tcp_flags\nobject\nNo\nEncapsulated flags are enrichment detail.\nICMP.TCP.rst\nobject\nNo\nEncapsulated RST is enrichment detail.\nICMP.TCP.ack_seq\nfloat64\nNo\nEncapsulated ACK seq is enrichment detail.\nICMP.TCP.window\nfloat64\nNo\nEncapsulated window is enrichment detail.\nICMP.TCP.cwr\nobject\nNo\nEncapsulated CWR is enrichment detail.\nICMP.TCP.urg_ptr\nobject\nNo\nEncapsulated urgent pointer is enrichment detail.\nICMP.TCP.fin\nobject\nNo\nEncapsulated FIN is enrichment detail.\nICMP.TCP.dest_port\nfloat64\nNo\nEncapsulated destination port is enrichment detail.\nICMP.TCP.hdr_len\nfloat64\nNo\nEncapsulated header length is enrichment detail.\nICMP.TCP.ecn\nobject\nNo\nEncapsulated ECN is enrichment detail.\nICMP.TCP.checksum\nobject\nNo\nEncapsulated checksum is irrelevant.\nICMP.TCP.seq\nfloat64\nNo\nEncapsulated sequence number is enrichment detail.\nICMP.unused\nobject\nNo\nICMP unused field is irrelevant.\nICMP.code_str\nobject\nYes\nHuman-readable ICMP code is directly usable in RL scoring.\nICMP.TCP.tcp_op-\ntions.tained\nobject\nNo\nTool-specific encapsulated metadata is irrelevant.\nICMP.TCP.tcp_op-\ntions.mss\nobject\nNo\nEncapsulated MSS is enrichment detail.\nICMP.TCP.tcp_op-\ntions.padding_hex\nobject\nNo\nEncapsulated padding is irrelevant.\nhttp.request.referrer\nobject\nNo\nHTTP referrer is enrichment-level data, not a direct RL feature.\nICMP.TCP.tcp_op-\ntions.nop\nobject\nNo\nEncapsulated NOP is irrelevant.\nICMP.TCP.tcp_op-\ntions.timestamp\nobject\nNo\nEncapsulated TCP timestamp is enrichment detail.\n35\n",
    "figure_captions": [
      "Figure 2 and with its data flow detailed in Figure 3, is a modu-",
      "Figure 4, which illustrates the integration between the RL"
    ]
  },
  {
    "arxiv_id": "2512.07820v1",
    "title": "Graph-Based Learning of Spectro-Topographical EEG Representations with Gradient Alignment for Brain-Computer Interfaces",
    "abstract": "We present a novel graph-based learning of EEG representations with gradient alignment (GEEGA) that leverages multi-domain information to learn EEG representations for brain-computer interfaces. Our model leverages graph convolutional networks to fuse embeddings from frequency-based topographical maps and time-frequency spectrograms, capturing inter-domain relationships. GEEGA addresses the challenge of achieving high inter-class separability, which arises from the temporally dynamic and subject-sensitive nature of EEG signals by incorporating the center loss and pairwise difference loss. Additionally, GEEGA incorporates a gradient alignment strategy to resolve conflicts between gradients from different domains and the fused embeddings, ensuring that discrepancies, where gradients point in conflicting directions, are aligned toward a unified optimization direction. We validate the efficacy of our method through extensive experiments on three publicly available EEG datasets: BCI-2a, CL-Drive and CLARE. Comprehensive ablation studies further highlight the impact of various components of our model.",
    "text": "GRAPH-BASED LEARNING OF SPECTRO-TOPOGRAPHICAL EEG REPRESENTATIONS\nWITH GRADIENT ALIGNMENT FOR BRAIN-COMPUTER INTERFACES\nPrithila Angkan1,2, Amin Jalali1,2, Paul Hungler1,3, Ali Etemad1,2\n1Ingenuity Labs Research Institute\n2 Department of Electrical and Computer Engineering\n3Department of Chemical Engineering\nQueen‚Äôs University, Kingston, Canada\n{prithila.angkan, amin.jalali, paul.hungler, ali.etemad}@queensu.ca\nABSTRACT\nWe present a novel graph-based learning of EEG representa-\ntions with gradient alignment (GEEGA) that leverages multi-\ndomain information to learn EEG representations for brain-\ncomputer interfaces.\nOur model leverages graph convolu-\ntional networks to fuse embeddings from frequency-based to-\npographical maps and time-frequency spectrograms, captur-\ning inter-domain relationships. GEEGA addresses the chal-\nlenge of achieving high inter-class separability, which arises\nfrom the temporally dynamic and subject-sensitive nature of\nEEG signals by incorporating the center loss and pairwise\ndifference loss. Additionally, GEEGA incorporates a gradi-\nent alignment strategy to resolve conflicts between gradients\nfrom different domains and the fused embeddings, ensuring\nthat discrepancies, where gradients point in conflicting direc-\ntions, are aligned toward a unified optimization direction. We\nvalidate the efficacy of our method through extensive experi-\nments on three publicly available EEG datasets: BCI-2a, CL-\nDrive and CLARE. Comprehensive ablation studies further\nhighlight the impact of various components of our model.\nIndex Terms‚Äî EEG, BCI, Graph, Gradient alignment\n1. INTRODUCTION\nElectroencephalography (EEG) is a non-invasive technique\nthat captures the electrical activity of the brain.\nIts cost-\neffectiveness and high temporal resolution make it widely\nused for brain-computer interfaces (BCI) in various research\nareas [1‚Äì3]. However, EEG presents challenges due to its low\nsignal-to-noise ratio, subject-dependency, and low spatial\nresolution [4]. Prior EEG studies leverage information from\nvarious domains such as time, frequency, and topographical\nmapping to enhance representations [5,6]. However, learning\neffective multi-domain representations from EEG poses two\nnuanced challenges.\nFirst, obtaining distinct class-specific\nclusters with large inter-class separation has proven chal-\nlenging, especially in multi-domain setups [7]. Second, to\nlearn multi-domain information, gradient conflicts can arise,\nresulting in suboptimal training [8].\nTo address these challenges, we propose a novel ap-\nproach using Graph-based learning of spectro-topographical\nEEG representations with Gradient Alignment (GEEGA).\nGEEGA encodes EEG from frequency-based topography\nmaps and time-frequency spectrograms, maps embeddings\nonto a shared feature space using graph convolutional net-\nworks, and aligns gradients to reduce domain conflicts. Our\nmethod calculates class centers and pulls positive pairs to-\nward them while pushing negatives apart for maximum inter-\nclass separation. We evaluate our method on three publicly\navailable EEG datasets, CLARE [9], CL-Drive [10], and BCI-\n2a [11]. Our approach achieves state-of-the-art performance\nacross all three benchmarks.\nThe contributions in this work are summarized as follows.\n(1) We propose a new model, GEEGA, for EEG representa-\ntion learning. Our model successfully learns multi-domain\nspectro-topographical information from EEG through graph-\nbased fusion. (2) Our model effectively resolves gradient con-\nflicts by aligning the gradients of the fused embeddings, en-\nsuring that discrepancies, where gradients from each domain\npoint in different directions, are addressed and guided toward\na unified direction. This ensures balanced optimization across\nall domains causing the fused embeddings effectively capture\ncomplementary information from different domains, leading\nto enhanced performance. To the best of our knowledge, this\nis the first attempt to resolve gradient conflicts in the context\nof BCI as well as the first effort toward addressing such con-\nflicts in a multi-domain setting in any context. (3) Moreover,\nour model incorporates class centers, enhancing inter-class\nseparability by pulling positive pairs toward their respective\nclass centers while pushing negative pairs apart. (4) GEEGA\nshows strong performances across several datasets and out-\nperforms prior works. Detailed ablation studies demonstrate\nthe positive impact of different components of our method.\narXiv:2512.07820v1  [cs.HC]  8 Dec 2025\n\n2. RELATED WORK\nTransformers have recently become popular in EEG repre-\nsentation learning. In [2], EEG-Deformer was proposed com-\nbining CNNs with transformers to capture coarse and fine-\ngrained temporal dynamics. In [6] parallel transformers were\nused for spatial-temporal feature extraction with CNN inte-\ngration, while [12] employed CNNs for channel-wise feature\nextraction followed by transformer processing. EEG channel-\nattention with Swin Transformer for motor imagery was inte-\ngrated in [13] and [14] and utilized multi-dimensional global\nattention for spectral-spatial-temporal features. In [15] self-\nsupervised masked autoencoders for cognitive load classifi-\ncation were applied, while [16] implemented Bayesian trans-\nformers for sleep staging.\nGraph-based architectures have gained traction for EEG\nclassification. GCN was used in [17] for sleep stage clas-\nsification to learn intrinsic channel connections.\nIn [18],\ngraph and 1D convolutions were combined for intra- and\ninter-channel interactions, while [19] integrated GCNs with\nLSTMs for emotion classification. GCN and attention mech-\nanisms were fused in [20] for structural relationships and\nlong-range dependencies. Another graph-based network was\nused in [21], leveraging the spatial and temporal dependencies\nof EEG for emotion recognition. Finally [22] dynamically\nadjusted graph connections per instance using multi-level\ngraph convolutions and coarsening.\n3. METHOD\n3.1. Problem Statement\nGiven a set of EEG signals, X = [X1, X2, ¬∑ ¬∑ ¬∑ , Xc] ‚ààRc\nwith c channels, we aim to extract complementary represen-\ntations: frequency domain Efreq ‚ààRM1 and time-frequency\ndomain Etime-freq ‚ààRM2, where M1 and M2 are the size of\nthe embeddings. Training a unified multi-domain model faces\nthe challenge of misaligned gradients. Specifically, the gradi-\nents measured by the loss function over a mini-batch B for\nthe frequency domain (‚àáfreq\nB ), for the time-frequency domain\n(‚àátime-freq\nB\n), and the fused domain (‚àájoint\nB\n), often point to con-\nflicting directions, hindering effective training. Our goal is to\nalign these gradients for unified optimization while achieving\nhigh inter-class separability.\n3.2. Our Approach\nMulti-domain encoding.\nWe encode the pre-processed\nEEG signals X into multi-spectral topography maps Xtopo ‚àà\nRB√ók√óh√ów (frequency domain) and spectrograms Xspectro ‚àà\nRB√óc√óh√ów (time-frequency domain), where B, k, c, h, w\ndenote batch size, frequency bands, channels, height, and\nwidth respectively. Both inputs are flattened, linearly pro-\njected into token sequences [23], and positional encoding is\nadded. The tokens are then fed to their respective transformer\nbranches:\nTtopo (frequency domain encoding) and Tspectro\n(time-frequency domain encoding). Producing embeddings\nEfreq ‚ààRM1 (frequency domain) and Etime-freq ‚ààRM2 (time-\nfrequency domain), where M1 and M2 denote the size of the\nembeddings (see Fig. 1 (a)).\nGraph-based embedding fusion. We fuse the embeddings\nEfreq and Etime-freq using a GCN module Œ¶. The concatenated\nembedding Econcat ‚ààRB√óG1 is projected to ÀúEconcat ‚ààRB√óG2\nwhere B is the batch size, G1 is the initial embedding dimen-\nsion, and G2 is dimension of the higher-dimensional space,\nwhich is defined as G2 = N √ó F, where N is the number\nof nodes in the graph with F being the feature dimension of\neach node. ÀúEconcat is reshaped into ÀúEnode ‚ààRB√óN√óF to form\na graph structure.\nIn the first GCN layer, the learnable weight matrix W1 ‚àà\nRF √óF transforms the node features as:\nOGCN1 = ÀúEnodeW1,\nOGCN1 ‚ààRB√óN√óF ,\n(1)\nwhere OGCN1 is the output from the first GCN layer. Node\nfeatures are updated by aggregating neighboring information\nvia adjacency matrix A ‚ààRN√óN, forming a fully connected\ngraph in our case as:\nÀúEnode-update = A ¬∑ OGCN1.\n(2)\nThis process is repeated for the second GCN layer, followed\nby flattening and a linear transformation to produce the final\nfeature vector of size H. A ReLU activation function is ap-\nplied after each GCN layer to introduce non-linearity.\nTo train Ttopo, Tspectro, and the GCN, we use binary cross-\nentropy loss LBCE and Git loss [24]. Git loss is defined as:\nLGit = 1\n2\nn\nX\ni=1\n‚à•Ei ‚àíci\ny‚à•2\n2 +\nm\nX\ni,j=1,iÃ∏=j\n1\n1 + ‚à•Ei ‚àícj\ny‚à•2\n2\n, (3)\nwhere Ei is the feature vector of the ith sample, and ci\ny is the\ncenter of the class to which Ei belongs. n and m are the to-\ntal number of samples for the two classes, respectively. This\nloss combines center loss (first term of the equation) which re-\nduces intra-class distances with pairwise difference loss (sec-\nond part of the equation) which increases inter-class distances\nto enhance class separability as shown in Fig.1 (b).\nGradient alignment.\nMultiple domains in a single latent\nspace can face the gradient conflict problem where the gra-\ndients from different domains may point at conflicting direc-\ntions [8, 25] (see Fig.1(c)). This can result in sub-optimal\ntraining of the model and degrading of downstream perfor-\nmance. We align the two domains with respect to the fused\ndomain rather than directly aligning the individual domains\nwith each other as non-linear fusion reveals complex cross-\ndomain interactions that remain hidden when domains are\nconsidered in isolation [26].\nWe define the gradients of losses computed over a mini-\nbatch B as ‚àáBLBCE(topo), ‚àáBLBCE(spectro), and ‚àáBLBCE(GCN).\n\n(a) Proposed model.\n(b) Git loss.\nConflicting gradient\nNon-conflicting gradient\nùêøBCE(spectro)  gradient\nùêøBCE (GCN)  gradient\nùêøAlign(GCN-spectro) gradient\n(c) Gradient alignment.\nFig. 1: (a) The overview of our proposed network is depicted. (b) The concept of the Git loss is presented where we aim to\nminimize intra-class distances d1 and maximize inter-class distances d2. (c) The concept of gradient alignment is presented.\nWhen cosine similarity between gradients is negative (cos Œ≤ ‚â§\n0, where Œ≤ represents the angle between the gradients from\ndifferent domains), conflicts exist. To resolve this, we use\nthe Pareto optimization method that assigns weights Œ±topo,\nŒ±spectro, and Œ±GCN via a closed-form solution. The optimiza-\ntion problem for aligned gradient LAlign(GCN-topo) is\nmin\nŒ±GCN,Œ±topo‚ààR\n\r\rŒ±GCN‚àáBLGCN + Œ±topo‚àáBLtopo\n\r\r2 ,\n(4)\nsubject to the constraints that Œ±GCN, Œ±topo ‚â•0 and Œ±GCN +\nŒ±topo = 1.\nHere, Eq.\n4 minimizes the L2-norm of the\ngradients within the convex hull of the gradient vectors\n{‚àáBLi}i‚àà{GCN,topo} [27]. The aligned gradient is:\nhalign\nGCN-topo(Œ∏) = 2Œ±GCN‚àáBLGCN(Œ∏)+2Œ±topo‚àáBLtopo(Œ∏), (5)\nwhere the resulting weights 2Œ±GCN and 2Œ±topo maintain the\nsame weight summation (i.e., 2Œ±GCN + 2Œ±topo = 2) and the\nmodel parameters Œ∏ are updated as\nŒ∏(t + 1) = Œ∏(t) ‚àíŒ∑halign\nGCN-topo(Œ∏(t)).\n(6)\nSimilar operations are performed for LAlign(GCN-spectro) to align\nGCN and spectrogram gradients.\nFinally, we define the total loss of GEEGA as:\nLT otal =LGit(topo) + LGit(spectro) + LGit(GCN)\n+ LBCE(topo) + LBCE(spectro) + LBCE(GCN)\n+ LAlign(GCN-topo) + LAlign(GCN-spectro).\n(7)\n4. EXPERIMENT SETUP\nDatasets.\nWe use three publicly available EEG datasets,\nnamely BCI-2a [11], CL-Drive [10] and CLARE [9] for our\nwork. We use leave-one-subject-out (LOSO) evaluation. For\nBCI-2a, feet and tongue movement are used for binary clas-\nsification, while for CL-Drive and CLARE, the subjective\nscores are binarized into low (1-5) and high (6-9) categories.\nData preprocessing. For BCI-2a, we use pre-processed data\nwith each trial as an individual segment. For the other two\ndatasets, we apply Butterworth bandpass filtering (1-75 Hz)\nand notch filtering following [10], then segment the signals\ninto 10-second intervals. We generate multi-spectral topogra-\nphy maps and spectrograms from the segmented data.\nMulti-spectral topography maps. To generate multi-spectral\ntopography maps, we compute power spectral density (PSD)\nfor each channel and five frequency bands: Delta, Theta,\nAlpha, Beta, and Gamma, following standard EEG prac-\ntice [10, 28, 29].\nUsing Simpson‚Äôs rule [30], we compute\neach band‚Äôs power across all channels. These values are spa-\ntially mapped onto 2D grids using the international 10-20\nelectrode system with radial basis function (RBF) inter-\npolation [31], creating multi-spectral topography maps of\ndimensions 32 √ó 32 √ó 1 for all datasets.\nSpectrograms.\nWhile PSD captures power distribution\nacross frequency bands, it fails to capture temporal de-\npendencies.\nWe address this using spectrograms contain-\ning time-frequency information. We compute Fast Fourier\nTransform (FFT) with non-overlapping 256-point windows,\ncreating matrices where columns represent frequencies and\nrows represent time intervals. Spectrograms are generated for\n4 channels (cognitive load datasets) or 22 channels (motor\nimagery dataset), each with dimensions 32 √ó 32 √ó 1\nImplementation details. We use a batch size B of 32 and\nthe Adam optimizer [34] (learning rate 0.0001, weight decay\n0.00001). Training employs a Plateau scheduler (decay factor\n\nTable 1: Performance compared to state-of-the-art solutions.\nBCI-2a\nCL-Drive\nCLARE\nModel\nAccuracy\nF1\nAccuracy\nF1\nAccuracy\nF1\nDGCNN [28]\n65.29(9.26)\n64.74(11.82) 65.77(4.71)\n57.06(5.30)\n61.84(3.96)\n51.05(7.70)\nBiHDM [32]\n67.86(9.29)\n67.27(10.57) 62.01(15.57) 57.92(11.66) 68.14(16.43) 52.17(16.54)\nConformer [33] 68.12(9.43)\n67.53(11.25) 69.38(8.72)\n63.29(9.29)\n70.42(16.02) 58.28(12.00)\nMAE [15]\n65.76(10.24) 65.98(10.92) 67.88(14.67) 61.25(13.18) 62.48(10.71) 57.51(7.29)\nVGG-style [10] 69.48(10.67) 69.73(10.24) 70.28(10.87) 63.12(9.39)\n70.29(16.03) 60.24(13.16)\nDMMR [29]\n65.57(10.23) 64.97(10.20) 61.15(13.74) 52.40(8.28)\n69.02(22.07) 52.95(14.71)\nGEEGA (our) 73.54(8.66)\n72.86(8.04)\n74.64(7.56)\n64.53(8.24)\n73.29(16.23) 60.68(14.42)\nTable 2: Ablation experiments demonstrating the impact of\neach module within our proposed model. MS: multi-spectral\ntopography maps, S: spectrograms, A: alignment.\nBCI-2a\nCL-Drive\nCLARE\nMS S LGit A Accuracy\nF1\nAccuracy\nF1\nAccuracy\nF1\n‚úì‚úì\n‚úì\n‚úì73.54(8.66) 72.86(8.04) 74.64(7.56)\n64.53(8.24) 73.29(16.23) 60.68(14.42)\n‚úì‚úì\n‚úó\n‚úì70.85(9.24) 69.20(9.83) 69.30(10.38) 60.07(7.72) 69.41(15.84) 54.28(12.30)\n‚úì‚úì\n‚úì\n‚úó70.90(9.45) 69.87(9.73) 72.70(8.47)\n62.65(6.81) 71.05(16.50) 56.39(14.00)\n‚úì‚úì\n‚úó\n‚úó69.48(8.29) 68.21(8.84) 70.20(8.99)\n60.29(6.43) 70.07(16.50) 56.40(14.00)\n‚úì\n‚úó\n‚úó\n‚úó66.00(9.41) 65.15(9.38) 67.52(9.29)\n60.23(7.25) 66.82(17.24) 54.52(14.69)\n‚úó\n‚úì\n‚úó\n‚úó66.43(9.36) 64.92(8.25) 67.46(8.57)\n59.43(7.34) 70.50(15.38) 52.47(17.16)\n0.1, patience 5) and warmup LambdaLR for first 5 epochs.\nModel is trained for 25 epochs on NVIDIA 2080 Ti using\nPyTorch. Both encoders Ttopo and Tspectro use 3 transformer\nblocks with 8 attention heads, embedding dimension 512, and\nMLP hidden dimension 1024. The GCN module parameters\nare: G1 = 1024, G2 = 1536, N = 6 nodes, F = 256 and H =\n512. This connects to FC layers (128, 1) with ReLU activa-\ntion and 0.25 dropout. The FC layers after Efreq and Etime-freq\nuse identical configurations. Dropout rates of 0.1 and 0.25\nare applied to transformer/GCN blocks and FC layers respec-\ntively for regularization.\nBaseline methods. We compare our proposed method with\nother popular and state-of-the-art recent works in EEG-based\nclassification, and exclude methods requiring large-scale pre-\ntraining (EEGPT [35], BENDR [36]) following [21,37].\n5. RESULTS\nPerformance.\nWe present the overall performance of our\nmethod in comparison to prior works in Table 1, where we\nobserve that GEEGA achieves the best result across all three\ndatasets.\nNotably, we observe that our method achieves\nhigher accuracy and F1 scores than the two competing meth-\nods, the VGG-style CNN [10] and Conformer [33], by consid-\nerable margins. For instance, GEEGA outperforms the VGG\nby accuracy and F1 values of 4.06% and 3.13% respectively\non the BCI-2a dataset, 4.36% and 1.41% on the CL-Drive\ndataset, and 3.00% and 0.44% on the CLARE dataset. Sim-\nilarly, our method outperforms the widely used Conformer\nmodel by accuracy and F1 values of 5.42% and 5.33% on\nBCI-2a dataset, 5.26% and 1.24% on CL-Drive, and 2.87%\n0\n500\n1000\n1500\n2000\nIteration\n0.3\n0.2\n0.1\n0.0\n0.1\n0.2\n0.3\n0.4\nCosine Similarity\n0\n500\n1000\n1500\n2000\nIteration\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\n0.8\nCosine Similarity\n0\n500\n1000\n1500\n2000\nIteration\n0.4\n0.2\n0.0\n0.2\n0.4\nCosine Similarity\n(a) w/o gradient alignment\n0\n500\n1000\n1500\n2000\nIteration\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\n0.8\nCosine Similarity\n(b) w/ gradient alignment\nFig. 2: The first row shows cosine similarities between multi-\nspectral topography maps and the fused domain, while the\nsecond row shows the same for spectrograms. Blue (values\n<0) indicates gradient conflicts, while red (values >0) indi-\ncates no conflict.\nand 2.40% on CLARE. The results show that performance\ndoes not always correlate with the number of parameters, for\ninstance, simpler models like VGG can still perform well.\nGradient alignment. Our key contribution is gradient align-\nment across domains to minimize conflicts and improve train-\ning. Fig. 2(a) shows misaligned gradients (positive (red) and\nnegative (blue)) throughout training w/o our alignment pro-\ncess. Fig. 2 (b) demonstrates reduced misaligned gradients as\ntraining progresses, confirming our alignment strategy‚Äôs ef-\nfectiveness for both frequency and time-frequency domains.\nAblation. In Table 2, we present the results of detailed abla-\ntion experiments conducted to evaluate the impact of individ-\nual components in our method. We remove key components,\nincluding multi-spectral topography maps, spectrograms, the\ngit loss (LGit), and the alignment mechanism, and compare\nthe results. We observe that our proposed GEEGA method\nwith all the components achieves the best results compared\nto the other ablated combinations. Specifically, we observe\nthat removing the git loss or the alignment step individually\nresults in considerable drops in performance.\n6. CONCLUSION\nWe propose GEEGA for EEG representation learning by inte-\ngrating frequency and time-frequency domains using parallel\ntransformer encoders and graph-based fusion. Our method\naddresses gradient conflicts through alignment strategies and\nenhances class separability using center loss with pairwise\ndifference loss. Results on three benchmark datasets demon-\nstrate superior performance over existing methods. In the fu-\nture cross-task transferability and real-time applications can\nbe explored.\n\n7. REFERENCES\n[1] Shitao Zheng and Dongrui Wu, ‚ÄúSemi-supervised domain adaptation\nfor eeg-based sleep stage classification,‚Äù in ICASSP, 2024, pp. 1776‚Äì\n1780.\n[2] Yi Ding, Yong Li, Hao Sun, Rui Liu, Chengxuan Tong, Chenyu Liu,\nXinliang Zhou, and Cuntai Guan, ‚ÄúEeg-deformer: A dense convolu-\ntional transformer for brain-computer interfaces,‚Äù IEEE JBHI, 2024.\n[3] Shivam Grover, Amin Jalali, and Ali Etemad, ‚ÄúSegment, shuffle, and\nstitch: A simple layer for improving time-series representations,‚Äù in\nNeurIPS, 2024.\n[4] He He and Dongrui Wu, ‚ÄúTransfer learning for brain‚Äìcomputer inter-\nfaces: A euclidean space data alignment approach,‚Äù IEEE TBME, vol.\n67, no. 2, pp. 399‚Äì410, 2019.\n[5] Rui Li, Yiting Wang, and Bao-Liang Lu, ‚ÄúA multi-domain adaptive\ngraph convolutional network for eeg-based emotion recognition,‚Äù in\nACMMM, 2021, pp. 5565‚Äì5573.\n[6] Xiuzhen Yao, Tianwen Li, Peng Ding, Fan Wang, Lei Zhao, Anmin\nGong, Wenya Nan, and Yunfa Fu, ‚ÄúEmotion classification based on\ntransformer and cnn for eeg spatial‚Äìtemporal feature learning,‚Äù Brain\nsciences, vol. 14, no. 3, pp. 268, 2024.\n[7] Maria Sayu Yamamoto, Khadijeh Sadatnejad, Toshihisa Tanaka,\nMd Rabiul Islam, Fr¬¥ed¬¥eric Dehais, Yuichi Tanaka, and Fabien Lotte,\n‚ÄúModeling complex eeg data distribution on the riemannian manifold\ntoward outlier detection and multimodal classification,‚Äù IEEE TBME,\n2023.\n[8] Yake Wei and Di Hu, ‚ÄúMmpareto: Boosting multimodal learning with\ninnocent unimodal assistance,‚Äù ICML, 2024.\n[9] Anubhav Bhatti, Prithila Angkan, Behnam Behinaein, Zunayed Mah-\nmud, Dirk Rodenburg, Heather Braund, P. James Mclellan, Aaron Ru-\nberto, Geoffery Harrison, Daryl Wilson, Adam Szulewski, Dan Howes,\nAli Etemad, and Paul Hungler, ‚ÄúClare: Cognitive load assessment in\nrealtime with multimodal data,‚Äù 2024.\n[10] Prithila Angkan, Behnam Behinaein, Zunayed Mahmud, Anubhav\nBhatti, Dirk Rodenburg, Paul Hungler, and Ali Etemad, ‚ÄúMultimodal\nbrain‚Äìcomputer interface for in-vehicle driver cognitive load measure-\nment: Dataset and baselines,‚Äù IEEE T-ITS, 2024.\n[11] Clemens Brunner, Robert Leeb, Gernot M¬®uller-Putz, Alois Schl¬®ogl, and\nGert Pfurtscheller, ‚ÄúBci competition 2008‚Äìgraz data set a,‚Äù Institute for\nknowledge discovery (laboratory of brain-computer interfaces), Graz\nUniversity of Technology, vol. 16, pp. 1‚Äì6, 2008.\n[12] Zhijiang Wan, Manyu Li, Shichang Liu, Jiajin Huang, Hai Tan, and\nWenfeng Duan, ‚ÄúEegformer: A transformer‚Äìbased brain activity clas-\nsification method using eeg signal,‚Äù\nFront. Neurosci., vol. 17, pp.\n1148855, 2023.\n[13] Han Wang, Lei Cao, Chenxi Huang, Jie Jia, Yilin Dong, Chunjiang\nFan, and Victor Hugo C De Albuquerque, ‚ÄúA novel algorithmic struc-\nture of eeg channel attention combined with swin transformer for motor\npatterns classification,‚Äù IEEE TNSRE, 2023.\n[14] Yongling Xu, Yang Du, Ling Li, Honghao Lai, Jing Zou, Tianying\nZhou, Lushan Xiao, Li Liu, and Pengcheng Ma, ‚ÄúAmdet: Attention\nbased multiple dimensions eeg transformer for emotion recognition,‚Äù\nIEEE Trans. Affect. Comput., 2023.\n[15] Dustin Pulver, Prithila Angkan, Paul Hungler, and Ali Etemad, ‚ÄúEeg-\nbased cognitive load classification using feature masked autoencoding\nand emotion transfer learning,‚Äù in ICMI, 2023, pp. 190‚Äì197.\n[16] Yuchen Liu and Ziyu Jia, ‚ÄúBstt: A bayesian spatial-temporal trans-\nformer for sleep staging,‚Äù in ICLR, 2023.\n[17] Ziyu Jia, Youfang Lin, Jing Wang, Ronghao Zhou, Xiaojun Ning, Yuan-\nlai He, and Yaoshuai Zhao, ‚ÄúGraphsleepnet: Adaptive spatial-temporal\ngraph convolutional networks for sleep stage classification.,‚Äù in IJCAI,\n2020, vol. 2021, pp. 1324‚Äì1330.\n[18] Xuefen Lin, Jielin Chen, Weifeng Ma, Wei Tang, and Yuchen Wang,\n‚ÄúEeg emotion recognition using improved graph neural network with\nchannel selection,‚Äù Comput. Methods Programs Biomed., vol. 231, pp.\n107380, 2023.\n[19] Yun Gu, Xinyue Zhong, Cheng Qu, Chuanjun Liu, and Bin Chen, ‚ÄúA\ndomain generative graph network for eeg-based emotion recognition,‚Äù\nIEEE JBHI, vol. 27, no. 5, pp. 2377‚Äì2386, 2023.\n[20] Ming Jin, Changde Du, Huiguang He, Ting Cai, and Jinpeng Li, ‚ÄúPgcn:\nPyramidal graph convolutional network for eeg emotion recognition,‚Äù\nIEEE TMM, 2024.\n[21] Chenyu Liu, Xinliang Zhou, Jiaping Xiao, Zhengri Zhu, Liming Zhai,\nZiyu Jia, and Yang Liu, ‚ÄúVsgt: variational spatial and gaussian tempo-\nral graph models for eeg-based emotion recognition,‚Äù in IJCAI, 2024,\npp. 3078‚Äì3086.\n[22] Tengfei Song, Suyuan Liu, Wenming Zheng, Yuan Zong, and Zhen Cui,\n‚ÄúInstance-adaptive graph for eeg emotion recognition,‚Äù in AAAI, 2020,\nvol. 34, pp. 2701‚Äì2708.\n[23] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weis-\nsenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani,\nMatthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit,\nand Neil Houlsby, ‚ÄúAn image is worth 16x16 words: Transformers\nfor image recognition at scale,‚Äù in ICLR, 2021.\n[24] Alessandro Calefati, Muhammad Kamran Janjua, Shah Nawaz, and\nIgnazio Gallo, ‚ÄúGit loss for deep face recognition,‚Äù arXiv preprint\narXiv:1807.08512, 2018.\n[25] Xiaokang Peng, Yake Wei, Andong Deng, Dong Wang, and Di Hu,\n‚ÄúBalanced multimodal learning via on-the-fly gradient modulation,‚Äù in\nCVPR, 2022, pp. 8238‚Äì8247.\n[26] Marcus Ghosh, Gabriel B¬¥ena, Volker Bormuth, and Dan FM Goodman,\n‚ÄúNonlinear fusion is optimal for a wide class of multisensory tasks,‚Äù\nPLoS Comput. Biol., vol. 20, no. 7, pp. e1012246, 2024.\n[27] Jean-Antoine D¬¥esid¬¥eri, ‚ÄúMultiple-gradient descent algorithm (mgda)\nfor multiobjective optimization,‚Äù C. R. Math., vol. 350, no. 5-6, pp.\n313‚Äì318, 2012.\n[28] Tengfei Song, Wenming Zheng, Peng Song, and Zhen Cui, ‚ÄúEeg emo-\ntion recognition using dynamical graph convolutional neural networks,‚Äù\nIEEE Trans. Affect. Comput., vol. 11, no. 3, pp. 532‚Äì541, 2018.\n[29] Yiming Wang, Bin Zhang, and Yujiao Tang, ‚ÄúDmmr: Cross-subject\ndomain generalization for eeg-based emotion recognition via denoising\nmixed mutual reconstruction,‚Äù in AAAI, 2024, vol. 38, pp. 628‚Äì636.\n[30] Daniel J Velleman, ‚ÄúThe generalized simpson‚Äôs rule,‚Äù Am. Math. Mon.,\nvol. 112, no. 4, pp. 342‚Äì350, 2005.\n[31] Felix Havugimana, Kazi Ashraf Moinudin, and Mohammed Yeasin,\n‚ÄúDeep learning framework for modeling cognitive load from small and\nnoisy eeg data,‚Äù IEEE TCDS, 2023.\n[32] Yang Li, Lei Wang, Wenming Zheng, Yuan Zong, Lei Qi, Zhen Cui,\nTong Zhang, and Tengfei Song, ‚ÄúA novel bi-hemispheric discrepancy\nmodel for eeg emotion recognition,‚Äù IEEE TCDS, vol. 13, no. 2, pp.\n354‚Äì367, 2020.\n[33] Yonghao Song, Qingqing Zheng, Bingchuan Liu, and Xiaorong Gao,\n‚ÄúEeg conformer: Convolutional transformer for eeg decoding and visu-\nalization,‚Äù IEEE TNSRE, vol. 31, pp. 710‚Äì719, 2022.\n[34] Diederik P. Kingma and Jimmy Ba, ‚ÄúAdam: A method for stochastic\noptimization,‚Äù ICLR, vol. abs/1412.6980, 2014.\n[35] Guangyu Wang, Wenchao Liu, Yuhong He, Cong Xu, Lin Ma, and\nHaifeng Li, ‚ÄúEEGPT: Pretrained transformer for universal and reliable\nrepresentation of EEG signals,‚Äù in NeuIPS, 2024.\n[36] Demetres Kostas, Stephane Aroca-Ouellette, and Frank Rudzicz,\n‚ÄúBendr: Using transformers and a contrastive self-supervised learning\ntask to learn from massive amounts of eeg data,‚Äù Front. Hum. Neurosci.,\nvol. 15, pp. 653659, 2021.\n[37] Qinke Ni, Hongyu Zhang, Cunhang Fan, Shengbing Pei, Chang Zhou,\nand Zhao Lv, ‚ÄúDbpnet: Dual-branch parallel network with temporal-\nfrequency fusion for auditory attention detection,‚Äù in IJCAI, 2024.\n",
    "figure_captions": [
      "Fig. 1: (a) The overview of our proposed network is depicted. (b) The concept of the Git loss is presented where we aim to",
      "Fig. 2: The first row shows cosine similarities between multi-"
    ]
  },
  {
    "arxiv_id": "2512.07818v1",
    "title": "Provable Long-Range Benefits of Next-Token Prediction",
    "abstract": "Why do modern language models, trained to do well on next-word prediction, appear to generate coherent documents and capture long-range structure? Here we show that next-token prediction is provably powerful for learning longer-range structure, even with common neural network architectures. Specifically, we prove that optimizing next-token prediction over a Recurrent Neural Network (RNN) yields a model that closely approximates the training distribution: for held-out documents sampled from the training distribution, no algorithm of bounded description length limited to examining the next $k$ tokens, for any $k$, can distinguish between $k$ consecutive tokens of such documents and $k$ tokens generated by the learned language model following the same prefix. We provide polynomial bounds (in $k$, independent of the document length) on the model size needed to achieve such $k$-token indistinguishability, offering a complexity-theoretic explanation for the long-range coherence observed in practice.",
    "text": "Provable Long-Range Benefits of Next-Token Prediction\nXinyuan Cao\nGeorgia Tech\nxcao78@gatech.edu\nSantosh S. Vempala\nGeorgia Tech\nvempala@gatech.edu\nAbstract\nWhy do modern language models, trained to do well on next-word prediction, appear to\ngenerate coherent documents and capture long-range structure?\nHere we show that next-\ntoken prediction is provably powerful for learning longer-range structure, even with common\nneural network architectures. Specifically, we prove that optimizing next-token prediction over\na Recurrent Neural Network (RNN) yields a model that closely approximates the training\ndistribution: for held-out documents sampled from the training distribution, no algorithm of\nbounded description length limited to examining the next k tokens, for any k, can distinguish\nbetween k consecutive tokens of such documents and k tokens generated by the learned language\nmodel following the same prefix. We provide polynomial bounds (in k, independent of the\ndocument length) on the model size needed to achieve such k-token indistinguishability, offering\na complexity-theoretic explanation for the long-range coherence observed in practice.\nContents\n1\nIntroduction\n1\n1.1\nLanguage models and distinguishers\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.2\nMain result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.3\nTechnical overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.4\nRelated work\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n1.5\nPreliminaries\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2\nBoosting an RNN\n14\n2.1\nA simple construction\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n2.2\nAn efficient construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n2.3\nSynchronized enumeration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n2.4\nProofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3\nProof of the Main Theorem\n42\n3.1\nBounding the bit size . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\nA Indistinguishability and KL divergence\n59\nB Computational Limitations of Autoregressive LLMs\n62\nC Common Transition Functions\n63\narXiv:2512.07818v1  [cs.LG]  8 Dec 2025\n\n1\nIntroduction\nLarge Language Models (LLMs) exhibit surprising learning properties across a variety of different\ntasks. Most publicly released LLMs are autoregressive, meaning that those LLMs are trained to\ngenerate text sequentially, learning to predict a single token at a time conditioned on the preceding\ntokens. The training process optimizes the parameters of a model on a corpus of sequential data by\nminimizing the expected log loss of next-token prediction. Once trained, LLMs are used to generate\nthe documents (strings) given prompts (prefixes) by repeatedly generating the next token.\nGenerating a document by repeatedly predicting the next token is statistically equivalent to full\ndocument generation. Any distribution over documents can also be represented by the conditional\ndistribution over the next token or by the probabilities of entire documents (see Def. 1). Thus,\nfrom an information-theoretic point of view, i.e., ignoring computation, maximizing next-token\nlog likelihood is equivalent to maximizing whole-document log likelihood (see Lemma 5). This\nequivalence further implies that a language model (LM) can be used to ‚Äúcomplete any thought,‚Äù i.e.,\ngiven an arbitrary text prompt, one can repeatedly sample the next tokens conditioned on previously\ngenerated tokens, progressively extending the prompt to a full document.\nThis equivalence no longer holds when one considers computational efficiency. For instance,\naccurately completing prompts like ‚ÄúThe prime factors of 49990139543 are . . . ‚Äù requires the ability\nto factor large integers, which is often assumed to be intractable for numbers that are the product\nof two large random primes. While a non-autoregressive polynomial-time generator exists for such\nstrings [Kal03], by first picking random primes, multiplying them, then outputting the corresponding\ndocument, autoregressive LLMs will fail to complete these prompts once the integers exceed a certain\nthreshold (see Appendix B for a simple proof).\nThis computational limitation, which depends on model size, training complexity, etc., potentially\nleads to not capturing the essential structure of the training distribution (e.g., rules of a context-free\ngrammar [DRGM+22] or logical reasoning [QWL+22, MAS+24]). It is remarkable that interesting\nlong-range structure is effectively learned by autoregressive LLMs. For example, GPT4 rarely\ngenerates grammatically incorrect sentences [FYL+23]. The main motivation of this paper is to\ninvestigate the long-range implications of next-token prediction. We aim to rigorously explain the\neffectiveness of next-token prediction for document generation.\nMore precisely, let us assume that we have a model with small expected log loss for next-token\nprediction on some training distribution. Without a priori knowing the ‚Äústructure‚Äù of the input\ndistribution, can we say something meaningful about the model having learned latent structure? As\na concrete step towards this goal, here we consider next-k-token generation:\nHow accurately can a model trained on next-token prediction generate the next k tokens?\nAlternatively, could there exist a way to distinguish the output of the model from the training\ndistribution by looking at k output tokens at a time, given that looking at only one token gives no\nstatistical distinction? Such distinguishers are quite natural ‚Äî e.g., looking at k = 4 or more tokens\nin trigram models would easily distinguish them from training distributions of grammatically correct\ntext. The same idea extends to modern LLM evaluation. Many current tasks measure performance\nusing various functions such as correctness [HBB+20, HBK+21], factuality [ZZC+23], or logical\ncoherence [QML+25]. These functions can be viewed as distinguishers ‚Äî they evaluate whether a\nbounded window of tokens (a given prefix and generated text for the specific task) satisfies a specific\nproperty satisfied by the training distribution.\nWe use the following notion of a distinguisher: a Boolean function that determines if the sequence\ngenerated from an LM satisfies some (fixed) property of the training distribution (see Def. 2). This\n1\n\nverification task is often significantly more computationally efficient than text generation. For\nexample, consider the generation task of the Boolean satisfiability (SAT) problem, where the prompt\nis a Boolean formula in Conjunctive Normal Form, and the generated tokens are an assignment of\nvariables to make the formula true. Although finding such an assignment is NP-hard, an efficient\ndistinguisher exists that simply verifies whether the proposed solution makes the formula true. The\ngoal of a training algorithm is to produce an LM that cannot be distinguished from the training\ndistribution.\nThe main finding of this paper (Theorem 1) is that an LLM obtained by simply minimizing\nthe next-token log loss generates output that is indistinguishable from the training distribution.\nSpecifically, given the same prompts, no distinguisher of up to a given size can distinguish the learned\nmodel from the training distribution, even when examining k tokens at a time. We show this result\nfor Recurrent Neural Networks (RNNs), a standard family of neural network architectures that is\nnatural for sequential generation tasks and computationally quite general.\nOur main theorem can be viewed as a complexity-theoretic treatment of LMs and loss minimization.\nYao‚Äôs classical theorem relates distinguishers and next-bit predictors [Yao82]: the existence of a k-bit\ndistinguisher, i.e., a circuit that can distinguish a given distribution from the uniform distribution\nover k-bit sequences, implies the existence of a next-bit predictor with nontrivial success probability.\nIn the setting of LMs, we show that the existence of distinguishers implies that next-token log loss\ncan be reduced, thereby improving next-token prediction.\nWe argue that even if the training loss is not zero, simply minimizing it (approximately) ensures\nthat the output LM cannot be distinguished from the training data by any bounded-size RNN over\na generation window of size k.\nTo state our main results precisely, we first introduce some definitions.\n1.1\nLanguage models and distinguishers\nWe consider language models that generate strings of length n over a finite alphabet Œ£ of tokens.\nLet S := Œ£<n be all possible prefixes. For a string s, we denote its length as |s|, and its i-th token\nas si. We denote its substrings si:j = sisi+1 ¬∑ ¬∑ ¬∑ sj‚àí1, si: = si:|s|+1, s:i = s1:i.\nDefinition 1 (Language Model). An autoregressive Language Model (LM) p is a function that\noutputs next-token probabilities of a distribution over strings, i.e., it maps a string s and a token y\nto the probability that y is the next token after s: p : (Œ£ ‚à™{‚àÖ}) √ó S ‚Üí[0, 1]. We write p(y | s) for\nthe probability of token y following the prefix s.\nEvery LM p corresponds to a text distribution ¬Øp : |Œ£|n ‚Üí[0, 1], such that P\nx‚ààŒ£n ¬Øp(x) = 1, that\nassigns probability ¬Øp(x) to each text x = x1x2 ¬∑ ¬∑ ¬∑ xn. In terms of conditional probability, each LM\ncorresponds to a text distribution: ¬Øp(x) = Qn\ni=1 p(xi | x:i).\nLet ‚àÜ(Œ£n) be all LMs over Œ£n. We assume that p represents the training next-token distribution,\ni.e., the distribution that generates the training documents, and that q denotes the learned LM. Let\n¬Øp and ¬Øq be the corresponding text distributions. The goal is to learn an LM q using data drawn\nfrom p.\nThe training objective is the standard next-token loss, defined as\nL(q) = ‚àíE\nx‚àº¬Øp\n\"\n1\nn\nn\nX\ni=1\nlog q(xi | x:i)\n#\n(1.1)\nGiven some prefix s, the task of an LM is to complete s to a full document (string of length n)\nby sequentially generating new tokens, where each token is conditioned on the concatenation of s\nand all tokens generated so far.\n2\n\nA distinguisher d operates on a full document, and di(x) is meant to distinguish whether the\ngiven completion of x:i, namely xi: is from the underlying next-k-token distribution or not.\nDefinition 2 (Next-k-token Distinguisher). A next-k-token distinguisher is a function d : [n]√óŒ£n ‚Üí\n{0, 1}. We require that di(x) := d(i, x) depends only on the prefix x:i and the k-token window xi:i+k,\ni.e., d(i, x) = d(i, x:i+k) for all i ‚àà[n], x ‚ààŒ£n. The advantage of d in distinguishing between two\ntext distributions ¬Øp and ¬Øq is defined as\na(d, ¬Øp, ¬Øq) := E\ny‚àº¬Øp\n\"\n1\nn\nn\nX\ni=1\n\u0012\nE\nx‚àº¬Øq [di(x) | x:i = y:i] ‚àídi(y)\n\u0013#\n.\n(1.2)\nTwo text distributions ¬Øp and ¬Øq are œµ-indistinguishable by a next-k-token distinguisher d if its\nadvantage‚Äôs absolute value |a(d, ¬Øp, ¬Øq)| ‚â§œµ. We say that ¬Øp and ¬Øq are Œµ-indistinguishable to next-k-token\ndistinguishers of size d if\nsup\nd:|d|‚â§d\n|a(d, ¬Øp, ¬Øq)| ‚â§Œµ,\nwhere the supremum ranges over all next-k-token distinguishers d of size at most d.\nThis definition of ‚Äòadvantage‚Äô quantifies the distinguisher‚Äôs ability to capture differences between\nthe training distribution ¬Øp and the learned LM ¬Øq. Consider any distinguisher that assigns 0 to valid\n(prefix, k-token) pairs, in particular to such pairs from the training distribution, and assigns 1 when\nsome implicit pattern or rule is violated. Then, for a given prefix y:i sampled from the training\ndistribution ¬Øp, the inner term compares the distinguisher‚Äôs value [di(x) | x:i = y:i] on the learned\nLM ¬Øq‚Äôs k-token completion, with di(y) the training distribution ¬Øp‚Äôs k-token completion. Thus, a\npositive advantage measures the difference of a particular function between the learned LM and the\ntraining distribution over a k-token window, averaged over all prefixes from the true data. We can\nassume that the advantage is nonnegative without loss of generality; if not, we can simply consider\nthe distinguisher with all outputs complemented.\nWe note that being sufficiently close in KL divergence implies there is no œµ-distinguisher. Since a\ndistinguisher is a binary function of a prefix and a k-token string, its advantage, i.e., the difference\nbetween expectations under ¬Øp and ¬Øq, is the difference in probability that ¬Øp and ¬Øq assign to that\n(prefix, k-token) pair. This gap is at most the total variation distance between the prefix-conditioned\ndistributions, and using Pinsker‚Äôs Inequality, one can show the following (see Appendix A for a\nrigorous derivation): for any next-k-token distinguisher d and text distributions ¬Øp, ¬Øq,\na(d, ¬Øp, ¬Øq) ‚â§\nr\nk\n2nDKL(¬Øp‚à•¬Øq).\n1.2\nMain result\nWe consider the class of LMs representable by Recurrent Neural Networks (formally defined in\nDef. 3), where recurrent connections allow information to persist over time steps. An RNN maintains\na hidden node set, a subset of nodes that serves as the ‚Äòworking memory‚Äô, in that the network‚Äôs\nfuture outputs can be computed from the current values of the hidden node set and the subsequent\ninputs, without revisiting the past input sequence.\nThe size of the RNN refers to the total number of nodes, while the hidden node set size refers\nspecifically to the number of nodes in the hidden node set. The RNN-time corresponds to the\nnumber of steps during which node values are actively updated. For an RNN Q, we denote its size\nas |Q|, its hidden node set size as |HQ|, and RNN-time as TQ.\n3\n\nA priori, it is unclear whether there exists a bounded-size RNN whose output is indistinguishable\nfrom a given training distribution. Even if an indistinguishable RNN exists, it is conceivable that\nfinding one might be intractable. In practice, one simply uses Gradient Descent to minimize the\nnext-token loss over a small set of model architectures. For instance, Llama 3 includes LMs with 8B,\n70B, and 405B parameters [DJP+24], each trained separately by optimizing the next-token loss.\nOur main result shows that minimizing next-token log loss yields an indistinguishable language\nmodel. Specifically, we first select a size parameter j0 uniformly from a large enough range, and\ndefine the network (RNN) size as N1 = c1 ¬∑ j2\n0 and the hidden node set size as H1 = c2 ¬∑ j0 for fixed\nconstants c1, c2 ‚ààN. We then train an LM q1 of size N1 and hidden node set size H1 by minimizing\nthe next-token loss. Next, we consider a slightly larger model with network size N2 = c1 ¬∑ (j0 + 1)2\nand hidden node set size H2 = c2 ¬∑ (j0 + 1), and train an LM q2 by minimizing the next-token loss.\nIf the loss for q2 does not decrease by at least œµ2/4k, we output LM q1. Otherwise, we repeat the\nprocess with incrementally larger sizes, until the decrease in loss is less than œµ2/4k. The procedure is\nformally stated in Algorithm 1; with large probability, we only need to try two models.\nTheorem 1 (Minimizing Next-token Loss Yields an Indistinguishable LM). For any 0 < œµ <\n1, k, œÑ, d ‚ààN, for alphabet size |Œ£| = O(1), with probability at least 0.9, by trying only two model\nsizes and minimizing next-token loss, we can output an LM q with the following properties:\n1. The model q is œµ-indistinguishable from the training distribution p for any next-k-token distin-\nguisher d : [n] √ó Œ£n ‚Üí{0, 1} realized by an RNN of size |d| ‚â§d and RNN-time T(d) ‚â§œÑ.\n2. The model q has size O\n\u0010\nk2\nœµ4 (d + k)\n\u0011\nand RNN-time œÑ ¬∑ (k2k)O\n\u0010\nk\nœµ2\n\u0011\n.\nThese guarantees naturally extend to arbitrary alphabet sizes, as shown in the proof in Section 3.\nIn words, the theorem says that the standard training scheme ‚Äî fix a model architecture and\nminimize next-token loss ‚Äî reaches a model that is guaranteed to be indistinguishable from the\ntraining distribution. The model‚Äôs size is polynomial in k, the distinguisher window length, d,\nthe distinguisher size bound and 1/œµ, the inverse of the distinguisher advantage, while remaining\nindependent of the document length n; as long as our distinguisher has bounded window size, the LM\nremains indistinguishable regardless of the length of the generated document. This result addresses\nthe issue of accumulated error [RCAZ15, BVJS15, AABC22], which can increase with the length of\nthe generated document due to suboptimal next-token loss.\nAn important point that we emphasize here is that our result for loss minimization does not require\nknowledge of any distinguisher ‚Äî the guarantee relies only on the existence of the distinguisher.\nTo illustrate the theorem, consider training data consisting of mathematical computations, such\nas multi-step arithmetic, algebraic simplifications or logical deductions, whose correctness can be\nchecked by a small RNN and thus correct and incorrect derivations can be distinguished. In this\nsetting, Theorem 1 implies that simply minimizing the next-token loss with a model of size cubic in\nk and linear in the distinguisher size d suffices to yield an LM that can generate correct derivations\n(i.e., indistinguishable by any distinguisher of size d) for any output of length at most k tokens.\nThis indicates how statistically trained next-token prediction can reliably reproduce structured\nmulti-step reasoning. It also suggests the benefits of scaling up model sizes ‚Äî to make the learned\nLM indistinguishable from the training distribution on larger windows.\nBit Size.\nTo ensure that our constructions do not implicitly use very large computations, e.g.,\nby requiring the maintenance of numbers whose lengths grow as functions of the input size, we\nalso bound the memory required per node in Theorem 2. Specifically, we show that next-token loss\nminimization yields an œµ-indistinguishable language model of polynomial size with the number of bits\n4\n\nmaintained at each node bounded by O\n\u0010\nbD + k3\nœµ4 + k\nœµ2 log œÑ\n\u0011\n, where œÑ is the distinguisher RNN-time\nbound and bD is a bound on the number of bits used by distinguisher RNNs.\n1.3\nTechnical overview\nOur proof is based on two main conceptual ideas. The first is that, given a next-k-token distinguisher\nd with some advantage for an LM q, one can boost q, i.e., modify it, so that the KL divergence\nbetween ¬Øp and ¬Øq decreases by at least a2(d, ¬Øp, ¬Øq)n/(4k). We first prove this for general LMs and\ndistinguishers in Lemma 1. We then show that such a boosting step can also be done for LMs and\ndistinguishers implemented by RNNs in Lemma 3.\nThe second idea connects one-step boosting to indistinguishability through loss minimization.\nSpecifically, Lemma 4 shows that if a model‚Äôs loss can be reduced via distinguisher-based boosting,\nthen the model obtained by minimizing log loss under size constraints must already be indistin-\nguishable from the training distribution. We call this ‚Äòself-boosting‚Äô, since it is achieved by pure loss\nminimization, without explicit knowledge of a distinguisher.\nImproving the next-token loss is equivalent to improving the KL divergence, DKL(¬Øp||¬Øq) =\nE\nx‚àº¬Øp log ¬Øp(x)\n¬Øq(x). Specifically, for any LMs q, q‚Ä≤ ‚àà‚àÜ(Œ£n), Lemma 6 implies that\nDKL(¬Øp‚à•¬Øq) ‚àíDKL(¬Øp‚à•¬Øq‚Ä≤) = n\n\u0000L(q) ‚àíL(q‚Ä≤)\n\u0001\n.\nBoosting using distinguishers.\nThe idea for improving a model using a distinguisher is to\napply a reweighting step based on a next-k-token distinguisher with non-negligible advantage. The\nadvantage of a distinguisher defined in Equation (1.2) is computed as the average advantage over all\nlength-k blocks. However, we cannot reweight all length-k blocks simultaneously because of their\noverlaps. Conversely, reweighting only the single best block would yield an insufficient improvement\nin the KL divergence, making the number of boosting steps depend on the document length. So\ninstead we group all length-k blocks into k disjoint sets based on their starting offset in [0, k ‚àí1].\nWe then identify the most advantageous set of disjoint blocks among these k options, indexed by\nthe offset i‚àó\n0 ‚àà[0, k ‚àí1], and apply an update to each length-k block in that set, as illustrated in\nFigure 1.1. As we will see shortly, the resulting improvement in KL divergence allows us to bound\nthe total number of boosting steps in the proof of the main theorem.\nLemma 1 (Boosted Text Distribution). Let k ‚àà[n], ¬Øp, ¬Øq ‚àà¬Ø‚àÜ(Œ£n), and d be a next-k-token\ndistinguisher with advantage Œ± := a(d, ¬Øp, ¬Øq). Then there exists i‚àó\n0 ‚àà[0, k ‚àí1] such that the text\ndistribution ¬Øq‚Ä≤ defined below satisfies:\nDKL(¬Øp‚à•¬Øq‚Ä≤) ‚â§DKL(¬Øp‚à•¬Øq) ‚àíŒ±2n\n4k .\nThe text distribution ¬Øq‚Ä≤ ‚àà¬Ø‚àÜ(Œ£n) is defined as:\n¬Øq‚Ä≤(x) = q‚Ä≤(x:i‚àó\n0+1)\nY\ni‚ààI\nq‚Ä≤(xi+1:i+k+1 | x:i+1),\nwhere I := {i ‚àà[n] | i ‚â°i‚àó\n0 (mod k)} and q‚Ä≤ is\nq‚Ä≤(x:i‚àó\n0+1) := q(x:i‚àó\n0+1);\n‚àÄi ‚ààI :\nq‚Ä≤(xi+1:i+k+1 | x:i+1) ‚àùq(xi+1:i+k+1 | x:i+1)e‚àíŒ±di+1(x).\n(1.3)\nFor all i ‚ààI, the normalization constants of q‚Ä≤ are:\nZ(s) := E\nx‚àº¬Øq\nh\ne‚àíŒ±d|s|+1(x) | x:|s|+1 = s\ni\nwith q‚Ä≤(xi+1:i+k+1 | x:i+1) := q(xi+1:i+k+1 | x:i+1)e‚àíŒ±di+1(x)\nZ(x:i+1)\n.\n5\n\nq\nqe‚àíŒ±d/Z\nqe‚àíŒ±d/Z\nqe‚àíŒ±d/Z\n¬∑ ¬∑ ¬∑ ¬∑ ¬∑ ¬∑\n1\nk\n2k\n3k\ni‚àó\n0\ni‚àó\n0 + k\ni‚àó\n0 + 2k\ni‚àó\n0 + 3k\nFigure 1.1: Illustration of the boosting construction for q‚Ä≤ in Lemma 1. The axis is the index of the\ntext, ranging from 1 to n. The new model q‚Ä≤ behaves identically to the original q until i‚àó\n0. After that,\nit repeatedly applies a reweighting qe‚àíŒ±d/Z over subsequent length-k blocks, starting at i‚àó\n0 + 1.\nThis lemma shows that a distinguisher with non-negligible advantage can be used to improve an\nLM, making the updated distribution over documents closer to the true distribution in KL divergence.\nIts proof is inspired by [AMGK22], who considered next-token prediction; we consider next-k-token\ndistinguishers rather than next-token distinguishers.\nThe boosted full-document model in Lemma 1 also implies a boosted next-token model, which\nwe describe next. Its proof is in Section 2.4.\nFor any two strings s, x ‚ààŒ£‚àó, we use s ¬∑ x to denote their concatenation, and write q(s | x) =\nQ|s|\ni=1 q(si | x ¬∑ s:i) for the conditional probability of the string s given the prefix x.\nLemma 2 (Boosted Next-token Probability). Let k ‚àà[n], p, q ‚àà‚àÜ(Œ£n), and d be a next-k-token\ndistinguisher with advantage Œ± := a(d, ¬Øp, ¬Øq). Then there exists i‚àó\n0 ‚àà[0, k ‚àí1] such that the model q‚Ä≤\nhas next-token conditional probability satisfying:\nDKL(¬Øp‚à•¬Øq‚Ä≤) ‚â§DKL(¬Øp‚à•¬Øq) ‚àíŒ±2n\n4k .\nThe model q‚Ä≤ ‚àà‚àÜ(Œ£n) is defined as follows:\nq‚Ä≤(xi | x:i) =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nq(xi | x:i)\nif i ‚â§i‚àó\n0;\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s)) ¬∑ 1 (s:i‚àíi0+1 = xi0+1:i+1)\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s)) ¬∑ 1 (s:i‚àíi0 = xi0+1:i)\nif i = i0 + r0,\ni0 ‚ààI,\n1 ‚â§r0 ‚â§k,\n(1.4)\nwhere I := {i ‚àà[n] | i ‚â°i‚àó\n0 (mod k)}.\nRNN implementation of boosting.\nNow we turn to how such a boosted model could be\nimplemented. For this, we consider a family of sufficiently powerful model architectures and ensure\nthat the boosted model is not much larger than the original while remaining in the same family.\nIntuitively, each boosting step incorporates information from the distinguisher and can therefore\nincrease the model size. Roughly speaking, as long as the number of boosting steps is bounded and\nthe model size grows slowly, this procedure should yield an indistinguishable LM that is not too\nlarge.\nWhen we restrict to a natural family of architectures, in our case RNNs, we have to compute the\nprobability update defined in Equation (1.4) with an RNN. For a prefix x:i0+1, we can enumerate\nand sum over all length-k strings s ‚ààŒ£k. The difficulty is to compute the next-token probability for\neach candidate s ‚ààŒ£k, without overwriting the RNN‚Äôs internal state, which we need for each string\nin the enumeration.\nTo build the RNN that realizes q‚Ä≤, we break down the boosted next-token probability (1.4) into\nsimpler components that can be implemented by RNNs.\n6\n\nFor any i ‚àà[n], define i0(i) as the greatest element in I that is less than or equal to i. For any\nlength-k string s ‚ààŒ£k, define the functions\nf1(s, i) = q\n\u0000s | x:i0(i)+1\n\u0001\n,\nf2(s, i) = exp\n\u0000‚àíŒ±di0(i)+1\n\u0000x:i0(i)+1 ¬∑ s\n\u0001\u0001\n,\ng1(s, i) = 1\n\u0000s:i‚àíi0(i)+1 = xi0(i)+1:i+1\n\u0001\n,\ng2(s, i) = 1\n\u0000s:i‚àíi0(i) = xi0(i)+1:i\n\u0001\n.\nThen the next-token probability q‚Ä≤ can be rewritten as\nq‚Ä≤(xi | x:i) =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\nq(xi | x:i)\nif i ‚â§i‚àó\n0;\nP\ns‚ààŒ£k f1(s, i)f2(s, i)g1(s, i)\nP\ns‚ààŒ£k f1(s, i)f2(s, i)g2(s, i)\nif i ‚â•i‚àó\n0 + 1.\n(1.5)\nThe RNN implementation of q‚Ä≤ is nontrivial, as it requires enumerating all length-k strings and\nsynchronizing the computation of four functions f1, f2, g1, g2 across time steps. Each step in this\niteration needs to use the internal state of the RNN implementing q after seeing x:i0(i)+1.\nOur first, conceptually simpler, solution to address the internal state maintenance problem is\ndescribed in Section 2.1. Here, the boosted model replicates the original model so that one copy\nmaintains the RNN state after processing a prefix x:i+1 and the other copy iteratively processes\neach length-k continuation s. This approach roughly doubles the model size at each boosting step,\nleading to an exponential growth in the model size with the number of boosting steps.\nTo get an efficient construction, we leverage the hidden node set of an RNN, which captures all\nthe state information needed to process the remaining input string. Instead of having two copies of\nthe original RNN, we use two copies of the hidden node set. The first copy maintains the state after\nprocessing a prefix x:i0(i)+1. The second is used as ‚Äúscratch space‚Äù ‚Äî we copy the state of the first\nhidden node set, then process a length-k continuation token by token. The first copy of the hidden\nnode set and the Œò(k) nodes needed for the enumeration of length-k strings constitute the hidden\nnode set of the boosted RNN (it does not double!). Lemma 3 shows that in each boosting step using\nthe distinguisher D, the hidden node set size increases by only Œò(k) + |HD|, and the model size\nincreases by Œò(k) + |HQ| + |HD| + |D|. Consequently, the hidden node set grows linearly and the\nmodel size grows quadratically with the number of boosting steps.\nLemma 3 (RNN Boosting). For any language model q representable by an RNN Q, if there exists a\nnext-k-token distinguisher di(x) with advantage Œ±, representable by an RNN D, then there exists a\nlanguage model q‚Ä≤, representable by an RNN Q‚Ä≤, with size |Q‚Ä≤| = |Q|+|HQ|+|D|+|HD|+7k+25, hidden\nnode set size |HQ‚Ä≤| = |HQ| + |HD| + 6k + 17 and RNN-time T = TQ‚Ä≤ = (|Œ£|k + 1)k(max{TQ, TD} + 4)\nsuch that the next-token loss decreases by at least Œ±2/4k, i.e., L(q‚Ä≤) ‚àíL(q) ‚â§‚àíŒ±2/4k.\nThe proof of Lemma 3, in Section 2.4.5, builds on the structural flexibility of RNNs, enabling\nefficient synchronization of multiple RNNs and systematic enumeration of candidate continuations\nwhile preserving a compact hidden node set, as we specify in Section 2.3.\nSelf-boosting by loss minimization.\nLemma 3 establishes that if a model can be distinguished,\nit can be boosted to improve loss. However, the boosting step requires explicit knowledge of the\ndistinguisher to build the new model and it is unclear how to find a distinguisher or determine\nwhether one exists. To address this, we argue that it suffices to simply minimize the next-token\nloss. If the loss of the model cannot be reduced with a modest increase in its size, then there is no\ndistinguisher (of size up to a desired bound) that has a significant advantage.\nTo avoid having to know a distinguisher, we formulate a more general ‚Äúself-boosting‚Äù principle in\nLemma 4. This lemma abstracts the role of the distinguisher by introducing a function c(q) : Q ‚Üí\n7\n\nR+\nS{0}, which measures the effective loss improvement obtainable from boosting a model q ‚ààQ. It\nconnects this generalized boosting to loss minimization: if a model can be boosted to achieve smaller\nloss at the cost of controlled increases in size, time and auxiliary parameters (e.g., hidden node set\nsize), then we can construct a sequence of hyperparameter settings so that for all but a small subset\nof these settings, simply minimizing the loss under the hyperparameter constraints guarantees that\nthe minimizer ÀÜq satisfies c(ÀÜq) ‚â§œµ for any c. This implies œµ-indistinguishability for our setting.\nLemma 4 (Model Self-boosting and Loss Minimization). Let Q be a set of models, where each q ‚ààQ\nhas size |q| ‚ààN, time T(q) ‚ààN and a value h(q) ‚ààR. There exists a q1 ‚ààQ with |q1| = 1, T(q1) = 1\nand h(q1) = h0 for some h0 ‚ààR. Let C be a set of functions c : Q ‚ÜíR+ ‚à™{0} and Œ≤, Œ≥, Œ¥, Œ∏, Œ∂ ‚â•0.\nSuppose there is a loss function L : Q ‚ÜíR+ ‚à™{0} such that, for every q ‚ààQ, c ‚ààC, there exists an\nq‚Ä≤ ‚ààQ with\n|q‚Ä≤| ‚â§|q| + h(q) + Œ≤,\nT(q‚Ä≤) ‚â§Œ≥T(q) + Œ¥,\nh(q‚Ä≤) ‚â§Œ∏h(q) + Œ∂,\nL(q‚Ä≤) ‚â§L(q) ‚àíc(q).\nDefine three sequences {Ni}i‚â•1, {Ti}i‚â•1, {Hi}i‚â•1 as follows.\nN1 = 1, Ni+1 = Ni + Hi + Œ≤;\n(1.6)\nT1 = 1, Ti+1 = Œ≥Ti + Œ¥;\n(1.7)\nH1 = 1, Hi+1 = Œ∏Hi + Œ∂.\n(1.8)\nThen there exists a set Bœµ ‚äÇ{Ni}i‚â•1, such that for any œµ > 0, for all Nj ‚àà{Ni}i‚â•1 \\ Bœµ, every ÀÜq ‚ààQ\nwhich minimizes L(q) over Cj := {q ‚ààQ | |q| ‚â§Nj, T(q) ‚â§Tj, h(q) ‚â§Hj} satisfies\nmax\nx‚ààC c(ÀÜq) ‚â§œµ.\nSpecifically, Bœµ := {Nj ‚àà{Ni}i‚â•1 | Lj+1 < Lj ‚àíœµ} for Lj := min\nq‚ààCj L(q). Also, |Bœµ| ‚â§L(q1)/œµ.\nIn the context of RNN-based LMs, Lemma 4 can be applied with |q| denoting the RNN size, T(q)\nthe RNN-time, and h(q) the hidden node set size. The function c(q) corresponds to the effective\nKL divergence reduction achievable by the next-k-token distinguisher. Based on Lemma 3, we\nset c(q) = Œ±2n/4k when there is a distinguisher with advantage Œ±. Lemma 3 also specifies the\nparameters Œ≤, Œ≥, Œ¥, Œ∏, Œ∂ to achieve a KL improvement of c(q). As a result, Lemma 4 guarantees\nthat, apart from a small set of hyperparameter choices (those for which the KL decreases by more\nthan œµ2n/4k when moving to the next hyperparameter choice), minimizing the next-token loss, or\nequivalently minimizing KL divergence, under hyperparameter constraints yields a model ÀÜq satisfying\nmaxc c(ÀÜq) ‚â§œµ2n/4k. Equivalently, the advantage Œ± is at most œµ.\nWe then show that the number of ‚Äúbad‚Äù hyperparameter choices is small. The algorithm increases\nthe hyperparameters until the KL divergence reduces by less than œµ2n/4k. The initial KL-divergence\nof the trivial one-node RNN that outputs a uniform distribution is DKL(¬Øp, ¬Øq1) = n log |Œ£|. Thus,\nthe number of hyperparameter choices where the loss decreases by more than œµ2n/4k is bounded\nby DKL(¬Øp, ¬Øq1)/(œµ2n/4k) = 4k log |Œ£|/œµ2. Since we select the first set of hyperparameters uniformly\nfrom a much larger set (of size 40k log |Œ£|/œµ2), with probability at least 0.9, purely minimizing loss\nunder the hyperparameter constraint is sufficient to find an indistinguishable model. We achieve\nthis guarantee without ever needing to know, construct, or apply an explicit distinguisher.\nThe proofs of Lemma 4 and Theorem 1 are in Section 3.\n8\n\nBounded bit size.\nOur main result establishes indistinguishability guarantees with bounded\nmodel size, but does not address the sizes of numbers used in the RNN computation. Real-world\nneural networks have to operate with space constraints, such as bounded bit size at each node. It is\nconceivable that the complexity of processing long inputs is being transferred to the sizes of numbers\nneeded for the RNN‚Äôs execution. To ensure that loss minimization gives us truly bounded-space\nconstructions, we extend our analysis to quantify how limited precision in computations affects\nindistinguishability. We define the bit size of an RNN as the maximum number of bits required\nto represent each node‚Äôs value in fixed-point arithmetic. We prove that the œµ-indistinguishability\nachieved by minimizing next-token loss also holds with bounded bit size.\nTheorem 2 shows that, with bit size polynomial in the window size k and the bit size bound\nof the distinguisher family considered (and 1/œµ), one can still obtain an œµ-indistinguishable LM.\nNotably, the bit size also does not depend on the document length. The proof closely parallels that\nof Theorem 1: we construct a boosted model with improved loss and controlled increases in model\nsize and bit size, formalized in Lemma 12 ‚Äî an analog of Lemma 3. Lemma 4 can be applied again\nand ensures that loss minimization alone suffices to recover indistinguishability under model and\nbit-size constraints.\nFuture directions.\nWhile our main theorem provides a polynomial bound on the size of an\nindistinguishable RNN, the RNN-time can be exponentially high. This limitation appears to be\ninevitable for certain hard distributions. For example, going back to the factoring example, consider\ntexts of the form ‚Äòm = p1p2 ¬∑ ¬∑ ¬∑ ps‚Äô, where m is a uniformly random n-bit positive integer, followed by\nits prime factorization in decreasing order. A polynomial-sized distinguisher can verify correctness by\nverifying primality of the proposed factors and multiplying them. However, the completion problem\nof generating the factorization given the prefix ‚Äòm =‚Äô is believed to be computationally intractable.\nOn the other hand, there are problems for which the ‚Äúcounting‚Äù step in the self-boosting can be done\nefficiently (without full enumeration, e.g., by Dynamic Programming or MCMC methods) and thus\npotentially result in smaller RNN-times for suitably structured classes of training distributions.\nIt would also be interesting to analyze the sample complexity of training distributions for learning\nvia loss minimization. One could derive bounds based on the VC dimension of models of bounded\nsize; however, directly using the structure of the training distribution might lead to tighter bounds.\n1.4\nRelated work\nNext-Token Prediction.\nLong after its inception in Shannon‚Äôs pioneering work on the statistical\nstructure of language [Sha48, Sha51], next-token prediction has been central to the design and\ntraining of modern LLMs, which are typically trained to minimize the next-token log loss on massive\ntraining corpora [BMR+20, AAA+23]. This approach has been shown to be highly effective not only\nin natural language processing [SRCM22], but also in multimodal domains [ZZL+23, WZL+24].\nDespite these successes, empirical studies document snowballing failure models [RCAZ15,\nBVJS15], in which small prediction errors at each step accumulate, producing globally incoherent\noutputs. These phenomena are observed in compositional tasks [DLS+24], path-finding [MHVF+24],\narithmetic, and story generation [BCE+23], and are exacerbated by limitations of the teacher-forcing\ntraining scheme [BN24] in a path-star graph.\nMotivated by these challenges, there has been growing theoretical interest in understanding the\nexpressive power of next-token predictors implemented by RNNs and transformers. [Mal23] showed\nthat next-token predictors can approximate any efficiently computable function by a Turing machine.\nFrom a statistical perspective, recent work provides generalization guarantees for transformer-based\nlanguage models trained with next-token prediction [LJL+]. From a computational perspective,\n9\n\nrelated work also investigates when neural architectures can implement nontrivial algorithmic\ncomputations; for example, recurrent convolutional networks have been shown to be able to represent\nsuccinct algorithms [GKKZ22].\nDistinguishability.\nDistinguishability is a well-studied notion in theoretical computer science,\nparticularly in cryptography [KM05, G+05] and the theory of pseudorandomness [Yao82, NW94].\nIn these settings, a distinguisher is an algorithm that attempts to tell two distributions apart, and\nindistinguishability under a class of distinguishers defines the notion of computational equivalence\nbetween distributions. Yao‚Äôs classic theorem [Yao82] connects this definition to prediction by showing\nthat the existence of a k-bit distinguisher (from the uniform distribution) implies a next-bit predictor\nwith nontrivial success probability. Our work adopts this complexity-theoretic viewpoint, using\ncomputationally bounded distinguishers to formalize the proximity of language models.\nIn machine learning, distinguishers are widely used to assess and guide model behaviors in fields\nsuch as generative models [GPAM+20], adversarial robustness [FFF18], language models [AMGK22],\nand reinforcement learning [HE16, OWJ+22]. For instance, in GANs [GPAM+20], a ‚Äòdiscriminator‚Äô\nnetwork is trained to distinguish between real and generated samples, thereby driving the generator\nto produce more realistic outputs. Similarly, in Reinforcement Learning (RL) frameworks like\nGAIL [HE16] and RLHF [OWJ+22], a discriminator or reward model is trained to distinguish\n‚Äòexpert‚Äô (human-preferred) outputs from the agent‚Äôs generated outputs. The resulting signal ‚Äî how\n‚Äòdistinguishable the agent‚Äôs policy is ‚Äî is then used as a reward to update the policy. Closer to our\nsetting, [AMGK22] gave a polynomial-time reduction from likelihood maximization to next-token\ndistinguishability for n-gram models and neural networks with a softmax output layer. In contrast,\nour work focuses on the more general case of next-k-token distinguishability in LMs implemented by\nRNNs. Crucially, while previous work relies on explicitly training distinguishers, our main result\n(Theorem 1) demonstrates a ‚Äòself-boosting‚Äô property (Lemma 4), showing that simply minimizing\nthe next-token loss is, by itself, sufficient to drive down the advantage of a distinguisher, yielding an\nindistinguishable model without ever needing to explicitly train or know a distinguisher.\nBenefits of Loss Minimization.\nLoss minimization is the standard framework for training\nmachine learning models. The idea of connecting model boosting to loss minimization or likelihood\nmaximization originated in [FHT00, LL01]. Since then, several theoretical results have shown that\nloss minimization yields desirable statistical properties. For example, minimizing discrimination\nerror is directly related to the total variation distance [HZL19], and minimizing loss leads to\nmulticalibrated models [HJKRR18, GJRR24, BGH+23]. Our work builds on this foundation by\nshowing that minimizing next-token loss leads to statistically indistinguishabe models.\n1.5\nPreliminaries\nLanguage Models.\nFor m ‚ààN, we denote the sets of strings,\nŒ£‚àó=\n‚àû\n[\ni=0\nŒ£i,\nŒ£<m :=\nm‚àí1\n[\ni=0\nŒ£i,\nŒ£‚â§m :=\nm\n[\ni=0\nŒ£i\nWe use s ¬∑ z to denote the concatenation of two strings s, z ‚ààŒ£‚àó.\nLet ¬Ø‚àÜ(Œ£n) be all text distributions over Œ£n, i.e., joint distributions over length-n strings. Let\n‚àÜ(Œ£n) be all LMs over Œ£n assigning conditional next-token probabilities. Every LM q ‚àà‚àÜ(Œ£n)\ncorresponds to a text distribution ¬Øq : Œ£n ‚Üí[0, 1], such that P\nx‚ààŒ£n ¬Øq(x) = 1, that assigns probability\n10\n\n¬Øq(x) to each string (text) x = x1x2 ¬∑ ¬∑ ¬∑ xn:\n¬Øq(x) := q(x1 | œµ) ¬∑ q(x2 | x1) ¬∑ q(x3 | x1x2) ¬∑ ¬∑ ¬∑ q(xn | x1x2 ¬∑ ¬∑ ¬∑ xn‚àí1),\nwhere œµ is the empty string. Conversely, one can compute the next-token probabilities using text\nprobabilities in general. However, this requires an infinite sum (or exponentially large sum of |Œ£|n if\nthe texts are bounded to length n). Specifically, for y ‚ààŒ£ and s ‚ààS:\nq(y | s) =\nP\nt‚ààŒ£n‚àí|s|‚àí1 ¬Øq(s ¬∑ y ¬∑ t)\nP\nt‚ààŒ£n‚àí|s| ¬Øq(s ¬∑ t)\n.\nFor any LM q and its corresponding text distribution ¬Øq, we might use q and ¬Øq interchangeably as\nthey have a one-to-one correspondence.\nGenerally, for any s ‚ààŒ£‚â§n, we write the marginal probability\n¬Øq(s) :=\nX\nz‚ààŒ£n‚àí|s|\n¬Øq(s ¬∑ z).\nGiven s, z ‚ààŒ£‚â§n with |s| + |z| ‚â§n, we denote the conditional probability\nq(z|s) :=\n|z|\nY\ni=1\nq(zi | s ¬∑ z:i) = Px‚àº¬Øq\n\u0000x|s|+1:|s|+|z|+1 = z | x:|s|+1 = s\n\u0001\n=\nP\nz‚Ä≤‚ààŒ£n‚àí|s|‚àí|z| ¬Øq(s ¬∑ z ¬∑ z‚Ä≤)\nP\nz‚Ä≤‚ààŒ£n‚àí|s| ¬Øq(s ¬∑ z‚Ä≤)\n.\nLoss Functions.\nWe first show that minimizing the next-token loss is equivalent to maximizing\nthe log-likelihood of the data.\nLemma 5 (Next-token Loss and Maximum Log-Likelihood). For a fixed distribution ¬Øp, the document\nlength times next-token loss of ¬Øq is the negative of its log likelihood. That is,\nnL(q) = ‚àíE\nx‚àº¬Øp [log ¬Øq(x)] .\nProof. By definition,\nnL(q) = ‚àí\nZ\n¬Øp(x) ¬∑\nn\nX\ni=1\nlog q(xi | x:i) dx = ‚àí\nZ\n¬Øp(x) log ¬Øq(x) dx = ‚àíE\nx‚àº¬Øp [log ¬Øq(x)] .\nTo further analyze this object, we can re-express it using Shannon entropy and the KL divergence.\nSpecifically, For a distribution ¬Øp, its entropy H(¬Øp) is defined as\nH(¬Øp) = ‚àíE\nx‚àº¬Øp log ¬Øp(x).\nLemma 6 (Next-token Loss and KL Divergence). For a fixed distribution ¬Øp, the document length\ntimes next-token loss of ¬Øq and the KL divergence between ¬Øp and ¬Øq differ by the entropy of ¬Øp. That is,\nnL(q) ‚àíDKL(¬Øp||¬Øq) = H(¬Øp)\nProof.\nnL(q) ‚àíDKL(¬Øp||¬Øq) = ‚àíE\nx‚àº¬Øp [log ¬Øq(x)] ‚àíE\nx‚àº¬Øp log ¬Øp(x)\n¬Øq(x) = ‚àíE\nx‚àº¬Øp [log ¬Øp(x)] = H(¬Øp)\n11\n\nRecurrent Neural Networks.\nA Recurrent Neural Network (RNN) is a type of neural network\n(NN) designed for processing sequential data, characterized by a recurrent architecture where each\nnode maintains a value at each time step. This cyclic and stateful process contrasts with feed-forward\nnetworks, such as Multi-Layer Perceptrons (MLPs), which process data in a single forward pass,\nwith each node computing a value based on the values of nodes in the previous layer. An RNN\nachieves recurrence by sharing parameters (weights) across time steps, updating each node‚Äôs value\nbased on the values of its connected nodes from the previous step. The total number of time steps\nfor a computation is the RNN‚Äôs RNN-time, denoted as T. Thus, the computation of an RNN over T\ntime steps is that of an MLP with T layers, where layers share the same weights and the number of\nnodes in each layer is the number of RNN nodes (see Fig. 1.2).\nAn RNN processes an input stream x1, x2, ¬∑ ¬∑ ¬∑ , xn sequentially. The hidden node set is a subset\nof nodes whose values are determined solely by the past input sequence and their own previous\nvalues. The values of the hidden node set, together with the future input sequence, are sufficient to\ncompute the output of the RNN.\nNotation.\nWe use uppercase letters to denote RNNs and sets of nodes, and lowercase letters to\ndenote individual nodes in the network. The value of a node v at time t is denoted by vt, and the set\nof values of a set of nodes V at time t is denoted by V t. We use lowercase letters to denote individual\nfunctions, and bold lowercase letters to denote sets of functions. The incoming neighbors of a node\nv, denoted as N(v), are the set of vertices u ‚ààV with edges to v: N(v) = {u ‚ààV | (u, v) ‚ààE}. This\nincludes any self-loop (v, v) if it exists.\nTransition Functions.\nRNN computation is based on transition functions.\nEach function\nf : Rn ‚ÜíR maps a set of node values {x1, ¬∑ ¬∑ ¬∑ xn} to a single node value y. Given input x =\n(x1, x2, ¬∑ ¬∑ ¬∑ xn)‚ä§‚ààRn and a vector w ‚ààRn, transition functions are compositions of a constant\nnumber of the following elementary functions:\n1. ReLU: œÉ(x; w) = max(0, w‚ä§x)\n2. Product: œï(x) = Qn\ni=1 xi\n3. Reciprocal: œà(x; w) = 1/w‚ä§x where the denominator must be nonzero.\nWe show formally in Appendix C that common functions such as the indicator function and Boolean\nlogic operations are transition functions.\nDefinition 3 (Recurrent Neural Network (RNN)). An RNN Q is described by a tuple:\n(GQ = (VQ, EQ) , VQ,in, vQ,out, fQ, TQ, gQ, (HQ, fQ,H, œàQ,H)) .\n1. A directed graph GQ = (VQ, EQ), where each node v ‚ààVQ is associated with a real-valued\nstate that evolves over time.\n2. Size: The size of the RNN is the number of nodes in the graph GQ, denoted by |Q| = |VQ|.\n3. Bit-size: The bit-size of the RNN is the maximum number of bits needed to encode the value\nstored in each node at any time step, denoted by ‚ü®Q‚ü©= 1 + ‚ü®Q‚ü©I + ‚ü®Q‚ü©F . Formally, we fix\na signed fixed-point representation with one sign bit, ‚ü®Q‚ü©I integer bits, and ‚ü®Q‚ü©F fractional\nbits. Each real number r stored in a node is represented as r = sign(r) (rI + rF ), where\nsign(r) ‚àà{+1, ‚àí1} is the sign of r, rI is its integer part in the range [1, 2‚ü®Q‚ü©I], and rF ‚àà[0, 1),\nits fractional part, is a multiple of 2‚àí‚ü®Q‚ü©F .\n12\n\nùíóin\nùíâ\nùíóout\ninput\noutput\ninput stream \nùë•1 ‚ãØ ùë•ùëñ ‚ãØ‚ãØ\nùíó\nùíóin\nùíâ\nùíóout\ninput\noutput\ninput stream\nùë•1 ‚ãØ ùë•ùëñ ‚ãØ‚ãØ\nùíóin\nùíâ\nùíóout\nùíôùüè\nùíâùüé\nùíöùüé\ntime\n1\n2\n3\nùíä\nùíôùüê\nùíâùüè\nùíöùüé\nùíôùüë\nùíâùüê\nùíöùüè\nùíôùíä\nùíâùíä‚àíùüè\nùíöùíä‚àíùüê\nùíä+ ùüè\nùíôùíä+ùüè\nùíâùíä\nùíöùíä‚àíùüè\nùíä+ ùüê\nùíôùíä+ùüê\nùíâùíä+ùüè\nùíöùíä\n4\nùíôùüí\nùíâùüë\nùíöùüê\n{0,1,2}\nRNN a\nUnrolled RNN a\nùíóin\nùíâ\nùíóout\nùíôùüè\nùíâùüè\nùíöùüé\ntime\n1\n2\n3\nùüëùíä+ ùüè\nùíôùüè\nùíâùüè\nùíöùüè\nùíôùüè\nùíâùüè\nùíöùüè\nùíôùíä\nùíâùíä\nùíöùüé\nùüëùíä+ ùüê\nùíôùíä\nùíâùíä\nùíöùíä\nùüëùíä+ ùüë\nùíôùíä\nùíâùíä\nùíöùíä\n4\nùíôùüê\nùíâùüê\nùíöùüé\nùíó\nùüé\nùüè\nùüê\nùüé\nùüé\nùüè\nùüê\nRNN b\nUnrolled RNN b\nFigure 1.2: Two examples of RNNs, and their corresponding unrolled feedforward networks. In both\nRNNs, h is the hidden node set. The subscript indicates the input index. RNN a receives a new input\nxi at each time step i. Thus, the output corresponding to the input x:i+1 is computed at time i + 2.\nRNN b receives a new input xi and holds it for three consecutive time steps (t = 3i, 3i + 1, 3i + 2).\nThis is managed by a control node v ‚àà{0, 1, 2}. Thus, the output corresponding to the input x:i+1\nis computed at time 3i + 3.\n4. Input node set VQ,in ‚äÇVQ: A subset of nodes whose values are set externally by an input\nsequence. The input sequence is indexed by a pointer that can be advanced by the RNN.\n5. Output node vQ,out ‚ààVQ: A designated node whose value is the output of the RNN.\n6. Transition functions fQ = {fv}v‚ààVQ\\Vin. At each time step t, the value of a non-input node\nv is updated based on the values of its incoming neighbors at time t ‚àí1.\nvt = fv({ut‚àí1 | u ‚ààN(v)}) where fv is a transition function.\n7. RNN-time TQ ‚ààN: The number of time steps for which the RNN is computed, i.e., nodes\nare updated.\n8. RNN function gQ :\n\u0000R|Vin|\u0001‚àó‚ÜíR: The function computed by the RNN, mapping the input\nsequence to the output node. That is, for any t ‚â•1, vt+TQ\nout\n= gQ(V 1\nin, V 2\nin, ¬∑ ¬∑ ¬∑ , V t\nin).\n9. Hidden node set (HQ, fQ,H, œàQ,H): A subset of nodes HQ = {h1, h2, ¬∑ ¬∑ ¬∑ , h|HQ|} ‚äÇVQ\ndefined by two properties:\n‚Ä¢ Each hidden node set value ht is computed using a transition function fQ,Hj : R|Vin|+|HQ| ‚Üí\nR of only the input node values V t‚àí1\nin\nand the hidden node set Ht‚àí1 and not the rest of\nthe RNN nodes.\nht = fQ,Hj(V t‚àí1\nin\n, Ht‚àí1\nQ ),\n‚àÄh ‚ààHQ.\n13\n\n‚Ä¢ At any time t, the RNN output can be computed from just its hidden node set values\nat time t and the remaining input sequence V t:n+1\nin\n. That is, there exists a function\nœàQ,H :\n\u0000R|Vin|\u0001‚àó√ó R|HQ| ‚ÜíR such that\nœàQ,H(V t:n+1\nin\n, Ht\nQ) = gQ(V 1\nin, V 2\nin, ¬∑ ¬∑ ¬∑ , V n\nin).\n(1.9)\nTo optimize the parameters of an RNN, the network is unrolled for T steps, effectively transforming\nit into a feedforward network with T + 1 layers. This unrolled form allows for the use of standard\nbackpropagation techniques to compute gradients and update parameters across time steps (a\nprocedure known as backpropagation through time (BPTT) [Wer02]).\nIn this work, we focus on the class of next-k-token distinguishers (Definition 2) that are imple-\nmented by RNNs. We refer to such a model as a Distinguisher RNN. This model is an RNN that\ntakes an index i and a string x as input and outputs di(x) ‚àà{0, 1}.\n2\nBoosting an RNN\nThe main goal of this section is to prove Lemma 3, which provides an efficient construction of a\nboosted LM based on RNNs.\nWe begin with a simpler construction of the boosting RNN in Section 2.1, which results in an\nexponential increase in model size with the number of boosting steps (roughly doubling with each\nboosting). We then present a more efficient construction in Section 2.2. The efficient construction\nrelies on synchronized enumeration within an RNN, described in Section 2.3. The proofs of lemmas for\nboosted next-token probability and its components, including Lemma 3, are deferred to Section 2.4.\n2.1\nA simple construction\nTo implement the boosted next-token conditional distribution in Equation (1.5), we need to construct\nRNN components that realize f1, f2, g1, g2. For the indicator functions g1, g2, we use k nodes to\nstore the string xi0(i)+1:i+1, and another k nodes to enumerate length-k strings (Lemma 18). Since\nindicator functions are themselves transition functions by Lemma 18, we can construct an RNN of\nsize O(k) to implement g1 and g2.\nNext, we consider the functions f1 and f2:\nf1(s, i) = q(s | x:i0(i)+1) =\nk\nY\nr=1\nq(sr | x:i0(i)+1 ¬∑ s:r),\nf2(s, i) = exp(‚àíŒ±d(i0(i) + 1, x:i0(i)+1 ¬∑ s)).\nBy Lemma 18, product and exponential are transition functions. Let q and d be implemented by\nRNNs Q and D. For a fixed string s ‚ààŒ£k and index i ‚àà[1, n], an RNN can compute f2. To\ncompute f1, we can use an RNN to compute the k conditional probabilities q(sr | x:i0(i)+1 ¬∑ s:r)\nby sequentially processing the tokens of s. The core difficulty, however, is that this sequential\ncomputation must be performed for all |Œ£|k possible strings s ‚ààŒ£k. Let s(j) denote the j-th string\nin Œ£k for 1 ‚â§j ‚â§|Œ£|k. We need to compute all conditional probabilities in Table 1, row by row.\nThis computation order highlights a key computational challenge: each row j must be computed\nby processing s(j) independently, starting from the same prefix x:i0(i)+1. When switching from the\nstring s(j) to s(j+1), the computation must restart from the state corresponding to the prefix x:i0(i)+1,\nnot from a state ‚Äúcontaminated‚Äù by the suffix s(j). Therefore, we must preserve the hidden state of\nthe RNN Q after processing the prefix x:i0(i)+1 and reuse it as the starting point for each of the |Œ£|k\nsuffix computations. A straightforward solution is an RNN that contains two copies of the RNN Q:\n14\n\ns(j)\nr = 1\nr = 2\n¬∑ ¬∑ ¬∑\nr = k\ns(1)\nq(s(1)\n1\n| x:i0(i)+1)\nq(s(1)\n2\n| x:i0(i)+1 ¬∑ s(1)\n:2 )\n¬∑ ¬∑ ¬∑\nq(s(1)\nk\n| x:i0(i)+1 ¬∑ s(1)\n:k )\ns(2)\nq(s(2)\n1\n| x:i0(i)+1)\nq(s(2)\n2\n| x:i0(i)+1 ¬∑ s(2)\n:2 )\n¬∑ ¬∑ ¬∑\nq(s(2)\nk\n| x:i0(i)+1 ¬∑ s(2)\n:k )\n...\n...\n...\n¬∑ ¬∑ ¬∑\n...\nTable 1: Conditional probabilities for each sequence s(j) and each string index r.\n‚Ä¢ One copy serves as memory, storing the hidden state ÀúHQ after processing the prefix x:i0(i)+1.\n‚Ä¢ The other copy loads the state ÀúHQ and uses it to sequentially process the tokens of s, computing\nq\n\u0000sr | x:i0(i)+1 ¬∑ s:r\n\u0001\nfor r = 1, 2, ¬∑ ¬∑ ¬∑ , k.\nThe same strategy can be applied when computing f2 for all |Œ£|k strings. We can then sum\nup the products f1(s, i)f2(s, i)g1(s, i) and f1(s, i)f2(s, i)g2(s, i) over all possible strings s ‚ààŒ£k, and\ntheir ratio yields the updated next-token conditional probability according to Equation (1.5).\nThe constructed RNN Q‚Ä≤ has size |Q‚Ä≤| = 2|Q|+2|D|+O(k), roughly doubling with each boosting\nstep.\n2.2\nAn efficient construction\nThere are two main hurdles to constructing an RNN more efficiently:\n‚Ä¢ Model size. To keep the model size smaller, we copy only the hidden node set of the RNN\nQ, rather than the entire RNN. This captures the necessary state information while avoiding\nexponential growth in model size. By itself, this is not enough ‚Äî if we double the size of the\nhidden node set, the RNN size will still grow exponentially. To avoid this, we must ensure\nthat the hidden node set of the constructed RNN Q‚Ä≤ remains sufficiently small and not double,\nso that the overall size of Q‚Ä≤ scales polynomially with the number of boosting steps.\n‚Ä¢ Synchonization of RNN components. In Equation (1.5), the updated distribution involves\nsumming over all strings s, combining the outputs of the functions f1, f2, g1, and g2. Since\nthese functions are computed by separate RNN modules, we must carefully synchronize their\ncomputations to ensure that all four RNNs evaluate their respective function on the same\nstring s at the same time step.\nTo do this, we keep track of the maximum of the RNN-times for computing f1, f2, g1, and\ng2, denoted as T, and each component that finishes early holds its state until T time steps\nare reached. We will use counters (Claim 1) for tracking, which are also RNNs. We show in\nLemma 10 that the flexibility of RNNs enables precise, step-by-step control of when to ‚Äúload‚Äù\na new state, compute its transition function and update state, or hold its state to be the same\nas at the previous time step.\nThe RNN receives one new token xi from the input stream every T steps. We are only\nconcerned with the output at time steps that are multiples of T. Specifically, we require that\nthe output node vT¬∑i\nout = g(x:i+1) for each i ‚ààN. We also relax the second requirement of its\nhidden state set H. We need the hidden node set sufficiency property (1.9) not in all time\nsteps, but only for the times that are multipliers of T. Formally, we require the existence of a\nfunction œàH :\n\u0000R|Vin|\u0001‚àó√ó R|H| ‚ÜíR such that for any i ‚àà[1, n],\nœàH\n\u0010\nxi:n+1, H(T‚àí1)¬∑i+1\u0011\n= g (x:n+1) .\n15\n\nNote that this still conforms to the definition of RNNs (Definition 3).\nConstruction Plan.\n‚Ä¢ We construct RNNs that compute the functions f1(s, i), f2(s, i), g1(s, i) and g2(s, i), synchro-\nnizing output for each input index i ‚àà[1, n] and each string s ‚ààŒ£k (Lemma 7, Lemma 8 and\nLemma 9).\n‚Ä¢ We compute q‚Ä≤(xi | x:i) by summing the products f1(s, i)f2(s, i)g1(s, i) and f1(s, i)f2(s, i)g2(s, i)\nfor each string s, and then take the ratio of these two products.\nWe will show that the size of the hidden state of Q‚Ä≤ is bounded. Specifically, |HQ‚Ä≤| ‚â§|HQ| +\n|HD| + 6k + 17. This will lead to an efficient construction of the RNN Q. For convenience, we\nconsider k-digit binary strings instead of k-digit base-|Œ£| strings. Let z(j), 1 ‚â§j ‚â§2k denote k-digit\nbinary strings in increasing order.\nThe following lemmas compute the functions f1, f2, g1 and g2 respectively.\nLemma 7 (Computing k-token Probability f1). Let n ‚ààN be the document length, k, i‚àó\n0 ‚ààN with\ni‚àó\n0 ‚àà[0, k ‚àí1]. Let Q be an RNN for language model q, which receives a new input token from the\ninput stream every T steps. That is, for any input stream x1, x2, ¬∑ ¬∑ ¬∑ , xn, for any 1 ‚â§i ‚â§n, the\noutput node viTQ\nQ,out = q(xi | x:i). Let œÑ ‚ààN be an integer such that œÑ ‚â•TQ + 4. Then there exists an\nRNN U with RNN-time TU = (2k + 1)kœÑ such that\n‚Ä¢ For input index 1 ‚â§i ‚â§i‚àó\n0, it outputs the same next-token conditional probability as q,\nviTU‚àí1\nU,out = q(xi | x:i).\n‚Ä¢ For input index i > i‚àó\n0, its output node computes the conditional probability q over all possible\nlength k binary strings, conditioned on the input prefix x:i0(i). That is, for 1 ‚â§j ‚â§2k,\nv(i‚àí1)TU+jkœÑ‚àí1\nU,out\n= q(z(j) | x:i0(i)+1).\nThe RNN U has a size of |U| = |Q|+|HQ|+2k+7 and a hidden node set size of |HU| = |HQ|+2k+6.\nLemma 8 (Computing Exponential of Weighted Distinguisher f2). Let n ‚ààN be the document\nlength and k, i‚àó\n0 ‚ààN with i‚àó\n0 ‚àà[0, k ‚àí1]. Let d : [n] √ó Œ£n ‚Üí{0, 1} be a next-k-token distinguisher\nimplemented by an RNN D. Let œÑ ‚ààN be an integer such that œÑ ‚â•TD + 2. Let x1, x2, ¬∑ ¬∑ ¬∑ , xn be\nthe input stream. Then there exists an RNN W with RNN-time TW = (2k + 1)kœÑ such that for any\ni‚àó\n0 < i ‚â§n,\nv(i‚àí1)TW +jkœÑ‚àí1\nW,out\n= exp\n\u0010\n‚àíŒ±d\n\u0010\ni0(i) + 1, x:i0(i) ¬∑ z(j)\u0011\u0011\n.\nThe RNN W has a size of |W| = |D|+|HD|+2k+7 and a hidden node set size of |HW | = |HD|+2k+6.\nLemma 9 (Computing Indicator Functions g1 and g2). Let n ‚ààN be the document length. Let œÑ ‚â•4\nbe an integer. Let x1, x2, ¬∑ ¬∑ ¬∑ , xn be the input stream. Then there exists an RNN O with RNN-time\nTO = (2k + 1)kœÑ such that for any i‚àó\n0 < i ‚â§n, there exists two nodes v1, v2 such that\nv(i‚àí1)TO+jkœÑ‚àí1\n1\n= 1\n\u0010\nz(j)\n:i‚àíi0(i)+1 = xi0(i)+1:i+1\n\u0011\n,\nv(i‚àí1)TO+jkœÑ‚àí1\n2\n= 1\n\u0010\nz(j)\n:i‚àíi0(i) = xi0(i)+1:i\n\u0011\n.\nThe size |O| = 3k + 8 and its hidden node set size |HO| = 2k + 5.\n16\n\nThe proofs for Lemma 7, Lemma 8 and Lemma 9 are in Section 2.4.4.\nWe can now construct an RNN that implements the boosted next-token conditional distribution\nin Equation (1.5) by combining these RNN components, using the fact that product and reciprocal\nare transition functions. This construction, which we formalize in Lemma 3, yields an RNN of size\n|Q| + |HQ| + |D| + |HD| + O (k) and hidden node set size |HQ| + |HD| + O (k). The proof is in\nSection 2.4.5.\n2.3\nSynchronized enumeration\nThe main task of the boosted LM is to compute the four functions f1, f2, g1, g2 in Equation (1.5) for all\npossible extensions of an input prefix, keeping the computations synchronized. These computations\nrequire both enumerating the extensions and synchronizing the outputs of all functions so that they\ncan be combined. Lemma 11 shows that for any given RNN, we can construct a new RNN that\niterates over all possible extensions of a given input prefix with length-k strings. The latter RNN\nenumerates strings and tokens within them, producing the corresponding outputs at predetermined\ntime steps. This lemma serves as the foundation for Lemma 7 and Lemma 8.\nThe construction in Lemma 11 requires a mechanism for precise, step-by-step control over RNNs.\nWe first establish this tool in Lemma 10. This lemma provides a general method to augment any\nRNN, enabling it to dynamically, at any time step, load a new state from an external source, run its\noriginal transition function, or hold its state constant. This gated control is the essential building\nblock for constructing the enumerating RNN in Lemma 11.\nLemma 10 (RNN Augmentation for Gated State Updates). Let Q be an RNN with a node set\nS ‚äÜVQ. Suppose we are given:\n(i) An RNN C whose output vt\nC,out ‚àà{0, 1, 2}, representing LOAD, RUN, and HOLD respectively;\n(ii) An external vector St ‚ààR|S|, provided whenever vt\nC,out = 0 (LOAD).\nThen there exists an augmented RNN ÀúQ with size | ÀúQ| = |Q| + |C| that maintains a node set\nÀúS = {Àúu | u ‚ààS} corresponding to S, whose values update according to vC,out. Specifically, for each\nnode u ‚ààS, with update rule ut = fu(V t‚àí1\nQ\n), its corresponding node Àúu ‚ààÀúS updates as\nÀúut =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£≥\nSt‚àí1\nu\nif vt‚àí1\nC,out = 0;\n(LOAD from S)\nfu(V t‚àí1\nÀúQ\n)\nif vt‚àí1\nC,out = 1;\n(RUN original logic on S)\nÀúut‚àí1\nif vt‚àí1\nC,out = 2.\n(HOLD state)\nProof. Let ÀúQ include all nodes in Q and C. For each node u ‚ààS which transition function fu, we\nspecify the update rule of its corresopnding node Àúu ‚ààÀúS as\nÀúut = St‚àí1\nu\n¬∑ 1\n\u0010\nvt‚àí1\nC,out = 0\n\u0011\n+ fu(ut‚àí1\nin , V t‚àí1\nÀúQ\n) ¬∑ 1\n\u0010\nvt‚àí1\nC,out = 1\n\u0011\n+ Àúut‚àí1 ¬∑ 1\n\u0010\nvt‚àí1\nC,out = 2\n\u0011\n.\nThis is a valid transition function since indicator functions are transition functions by Lemma 18.\nWe now introduce the key lemma of this section. This lemma constructs an RNN that systemati-\ncally iterates over and evaluates all possible continuations in a time-synchronized manner, while\nmaintaining a compact hidden node set and bounded model size.\nTo better fit the next-token probability q‚Ä≤ from Equation (1.5), we fix an offset i‚àó\n0 ‚àà[0, k ‚àí1].\nFor input indices i1 up to this offset i‚àó\n0, the constructed RNN simply mirrors the original model.\n17\n\nStarting from the index i‚àó\n0 + 1, we partition all subsequent indices into contiguous non-overlapping\nblocks of length k, as illustrated in Figure 1.1. Let i0(i1) be the starting index of the block that\ncontains i1. Then, for any index i1 in this length-k block, the constructed RNN‚Äôs output is a function\nof a systematic evaluation that simulates all possible length-k continuations from the index i0(i1).\nSpecifically, the model iterates over all possible length-k strings z(j1) ‚ààŒ£k for 1 ‚â§j1 ‚â§|Œ£|k. For\neach string z(j1), it iteratively outputs the output of the original RNN on the input formed by\nconcatenating the fixed prefix x:i0(i1)+1 with the r1-length prefix of that string z(j1)\n:r1+1. Lemma 10\nguarantees that the computation of gQ(x:i0(i1)+1 ¬∑ z(j1)\n:r1+1) completes within a pre-selected time\nœÑ ‚â•TQ + 2.\nLemma 11 (Synchronized Enumeration). Suppose we are given an RNN Q, which receives a new\ninput token from the input stream every TQ steps, and vi¬∑TQ\nQ,out = gQ(x1, ¬∑ ¬∑ ¬∑ , xi) for any 1 ‚â§i ‚â§n.\nLet i‚àó\n0, k, n, œÑ ‚ààN, such that œÑ ‚â•TQ + 2 and 0 ‚â§i‚àó\n0 ‚â§k ‚àí1. Let I := {i ‚àà{0, 1, 2, ¬∑ ¬∑ ¬∑ , n} | i ‚â°\ni‚àó\n0 (mod k)}, and for any i ‚àà[1, n], let i0(i) := max{i‚Ä≤ ‚ààI | i‚Ä≤ < i} be the largest index in I smaller\nthan i. Then there exists an RNN U such that for any input stream x1, x2, ¬∑ ¬∑ ¬∑ , xn, it has RNN-time\nTU = (2k + 1)kœÑ and for any i1 ‚ààN,\n1. (Q on input till i1) if i1 ‚â§i‚àó\n0, for any t ‚àà[(i1 ‚àí1)TU + TQ, i1TU], the output vU,out equals the\noutput of the RNN Q on the input x:i1+1, i.e.,\nvt\nU,out = gQ (x:i1+1) ;\n2. (Q on input till i0(i1) with suffix z(j1)) if i1 ‚â•i‚àó\n0 + 1, for any 1 ‚â§j1 ‚â§2k, 1 ‚â§r1 ‚â§k, and\nt ‚àà[(i1 ‚àí1)TU + (j1 ‚àí1)kœÑ + (r1 ‚àí1)œÑ + TQ, (i1 ‚àí1)TU + (j1 ‚àí1)kœÑ + r1œÑ], the output vU,out\nequals the output of RNN Q on the input x:i0(i1)+1 ¬∑ z(j1)\n:r1+1, i.e.,\nvt\nU,out = gQ\n\u0010\nx:i0(i1)+1 ¬∑ z(j1)\n:r1+1\n\u0011\n.\nThe size of U is bounded by |Q|+|HQ|+2k+6, and its hidden node set size is bounded by |HQ|+2k+6.\nProof idea.\nThe computation of our constructed RNN U involves three nested layers of\niteration, ordered from outermost to innermost:\n‚Ä¢ Input loop iterates over the input entries for index i1 ‚àà[1, n]. Each input token xi1 is\nprocessed over TU = (2k + 1)kœÑ steps before advancing to the next entry.\n‚Ä¢ String loop begins iterating over all 2k binary strings z(j1) of length k to compute gQ(x:i0+1 ¬∑\nz(j1)), where 1 ‚â§j ‚â§2k. Each string takes kœÑ steps to process. After this, it will compute\ngQ(x:i0(i1+1)+1) in kœÑ steps.\n‚Ä¢ Digit loop processes each of the k digits of the current string z(j1), with each digit requiring\nœÑ steps to compute. Specifically for the r1-th digit, the RNN computes gQ(x:i0+1 ¬∑ z(j1)\n:r1+1).\nAccording to these, each time step t ‚ààN corresponds to a specific position within these loops.\nWe use the following formulation to precisely identify the current state of computation in all three\nnested loops at any given time step t ‚ààN.\n18\n\n‚Ä¢ Each input loop iteration (i.e., processing one input xi1) takes TU = (2k + 1)kœÑ steps. Thus,\nthe current input index is\ni1(t) = ‚åàt\nTU\n‚åâ.\nMoreover, for i1 ‚â§i‚àó\n0 + 1, each input index i1 maps to the most recent anchor index i0 ‚ààI,\nthus, the current anchor index is\ni0(t) =\n\u0012\n‚åàt ‚àíi‚àó\n0 ¬∑ TU\nkTU\n‚åâ‚àí1\n\u0013\n¬∑ k + i‚àó\n0.\n‚Ä¢ The index among the 2kk + k total digit positions in the string loop is\n¬µ(t) =\n\u0012\n‚åàt\nœÑ ‚åâ‚àí1\n\u0013\nmod (2kk + k) + 1.\n‚Ä¢ The index of the current binary string z(j1) being processed in each input string is\nj1(t) = ‚åà¬µ(t)\nk ‚åâ,\nwhere j1(t) ‚àà[1, 2k + 1] and j1(t) = 2k + 1 corresponds to the last null step (i.e., computing\nonly x:i0(t+1)).\n‚Ä¢ Finally, the index of the digit within z(j1) that is currently being computed in the inner loop is\nr1(t) = (¬µ(t) ‚àí1) mod k + 1,\nwhere r1(t) ranges in [1, k].\nIn turn, we can represent t using i1(t), j1(t), r1(t) and s1(t) ‚àà[1, œÑ], by\nt = (i1(t) ‚àí1)(2kk + 1)œÑ + (j1(t) ‚àí1)kœÑ + (r1(t) ‚àí1)œÑ + s1(t).\nNext, we will provide the intuition behind the construction. For each index of the input stream\ni1 ‚ààN, we compute the function gQ on the extension of the prefix x:i0(i1)+1 by a length-k binary\nstring z(j). To do so, we will retain the hidden node set of x:i0+1 for each i1 ‚àà[i0, i0 + k ‚àí1]. When\nprocessing the extension z(j), we copy the stored hidden node set of x:i0+1, and then update it\nsequentially using the digits of the string z(j). The hidden node set implies the output value through\ncomputation.\nWe construct the RNN U using the nodes u0, w0, u, w, vc and node sets E, Y, H, ÀúH, R. Specifically,\nwe use the following claims to show each part of the constructed RNN.\n‚Ä¢ Claim 1: counter nodes.\n‚Äì The node u0 ‚àà[1, k] has value equal to i1 ‚àíi0, where i1 is the current input index, and\ni0 = max{i‚Ä≤ ‚ààI | i‚Ä≤ < i1} is the most recent anchor index in the set I. It tracks the offset\nof the current index relative to the latest anchor index.\n‚Äì The node w0 ‚àà[1, TU] serves as a time-step counter for the input loop, indicating the\nprogress within the current processing cycle of input token xi1.\n‚Äì The node u ‚àà[1, k] indicates the current digit index in the binary string z(j), and thus\nrepresents the iteration progress within the digit loop.\n19\n\nùë£ùëÑ,in\nùêªùëÑ\nùëÖùëÑ\nùë∏\nùëº\nùë£ùëà,in\nùë£ùëÑ,out\nùêª\n‡∑©ùêª\nùëÖ\nùë§0\nùë¢0\nùë§\nùë¢\nùë£ùëê\nùëå\nùëß1, ùëß2, ‚Ä¶ , ùëßùëò\nùë£ùëí\nùêªùëà\nClaim 1\nClaim 3\nClaim 4\nClaim 5\nClaim 6\nùë£ùëà,out\nClaim 2\nClaim 7\nFigure 2.1: A sketch of the original RNN Q, and the constructed RNN U. The RNN Q has a\nhidden node set HQ, and the remaining nodes RQ. The RNN U maintains some counter nodes in\nClaim 1, a node set Y that stores the input subsequence xi0+1:i1+1 in Claim 2, a node set E to\nenumerates the digits of all length-k strings in Claim 3, a node set H that stores the hidden node\nset corresponding to the prefix x:i0+1 in Claim 4, a node set ÀúH that tracks the hidden node set\ncomputing from extending the fixed prefix x:i0+1 with the r1-length prefix of the length-k string\nz(j1)\n:r1+1 in Claim 5, and a node set R that produces the final output in Claim 6. Claim 7 introduces\nanother counter node, and studies the initial case when i1 ‚â§i‚àó\n0. Note that the counter nodes and\nthe node sets Y, H, E serve as the hidden node set of the constructed RNN U.\n‚Äì The node w ‚àà[1, œÑ] functions as the time-step counter for the digit loop, tracking the\ncomputation steps for each digit z(j)\nr .\n‚Ä¢ Claim 2: The node set Y stores the input subsequence from the most recent anchor to the\ncurrent input position xi0+1, xi0+2, ¬∑ ¬∑ ¬∑ , xi1.\n‚Ä¢ Claim 3: The node set E is responsible for enumerating the digits of all length-k strings.\n‚Ä¢ Claim 4: The node set H stores the hidden state corresponding to the prefix x:i0+1. It replicates\nthe structure of the hidden node set HQ. During each iteration of the input loop (identified by\nw and u), if the anchor index i0 remains unchanged (indicated by u0), the values in H stay\nfixed. Otherwise, when the anchor index transitions from i0 to i0 + k, the values in H will\nupdate over kT steps to compute the new prefix x:i0+k+1, and then remain fixed until the next\nchange.\n‚Ä¢ Claim 5: The node set ÀúH tracks the hidden state computing from extending the prefix x:i0+1\nwith a partial string z(j)\n:r+1. It also replicates the structure of the hidden node set HQ. In each\niteration of the string loop (identified by u and w), ÀúH is copied from H, and then sequentially\nupdated using the digits of the string z(j), as provided by the node set E.\n20\n\n‚Ä¢ Claim 6: The node set R replicates the structure of the node set GQ \\ HQ, and includes the\noutput node. It connects to the node set ÀúH, and produces the final output.\n‚Ä¢ Claim 7 studies the initial phase when i1 ‚â§i‚àó\n0. We include another counter node vc ‚àà[1, i‚àó\n0 + 1]\nwho equals i1 if i1 ‚â§i‚àó\n0 + 1, and i‚àó\n0 + 1 otherwise.\nFigure 2.1 gives a sketch for the construction. The proof of this lemma is in Section 2.4.3.\n2.4\nProofs\nIn this section, we prove the main and auxiliary lemmas building up to the proof of the main theorem.\n2.4.1\nProof of Lemma 1: Boosted Text Distribution\nWe start with the proof of Lemma 1, which shows a language model boosted by a distinguisher that\ndecreases the KL divergence to the true language model. We restate the lemma here for the reader‚Äôs\nconvenience.\nLemma 1 (Boosted Text Distribution). Let k ‚àà[n], ¬Øp, ¬Øq ‚àà¬Ø‚àÜ(Œ£n), and d be a next-k-token\ndistinguisher with advantage Œ± := a(d, ¬Øp, ¬Øq). Then there exists i‚àó\n0 ‚àà[0, k ‚àí1] such that the text\ndistribution ¬Øq‚Ä≤ defined below satisfies:\nDKL(¬Øp‚à•¬Øq‚Ä≤) ‚â§DKL(¬Øp‚à•¬Øq) ‚àíŒ±2n\n4k .\nThe text distribution ¬Øq‚Ä≤ ‚àà¬Ø‚àÜ(Œ£n) is defined as:\n¬Øq‚Ä≤(x) = q‚Ä≤(x:i‚àó\n0+1)\nY\ni‚ààI\nq‚Ä≤(xi+1:i+k+1 | x:i+1),\nwhere I := {i ‚àà[n] | i ‚â°i‚àó\n0 (mod k)} and q‚Ä≤ is\nq‚Ä≤(x:i‚àó\n0+1) := q(x:i‚àó\n0+1);\n‚àÄi ‚ààI :\nq‚Ä≤(xi+1:i+k+1 | x:i+1) ‚àùq(xi+1:i+k+1 | x:i+1)e‚àíŒ±di+1(x).\n(1.3)\nFor all i ‚ààI, the normalization constants of q‚Ä≤ are:\nZ(s) := E\nx‚àº¬Øq\nh\ne‚àíŒ±d|s|+1(x) | x:|s|+1 = s\ni\nwith q‚Ä≤(xi+1:i+k+1 | x:i+1) := q(xi+1:i+k+1 | x:i+1)e‚àíŒ±di+1(x)\nZ(x:i+1)\n.\nProof of Lemma 1. We first define the following sets for j ‚àà{0, 1, ¬∑ ¬∑ ¬∑ , k ‚àí1},\nR(j, n, k) := {i ‚àà[n] | i ‚â°j (mod k)} =\n\u001a\nj, j + k, j + 2k, ¬∑ ¬∑ ¬∑ , j +\n\u0016n ‚àí1 ‚àíj\nk\n\u0017\n¬∑ k\n\u001b\n‚äÜ{0, 1, ¬∑ ¬∑ ¬∑ , n‚àí1}.\nDenote the sizes of these sets as\nwj := |R(j, n, k)| = 1 +\n\u0016n ‚àí1 ‚àíj\nk\n\u0017\n.\nThen, we can decompose the advantage a(d, ¬Øp, ¬Øq) into a weighted average of k terms a1, ¬∑ ¬∑ ¬∑ , ak using\nmodulus k.\na(d, ¬Øp, ¬Øq) =\nk‚àí1\nX\nj=0\nwj\nn aj where aj := E\ny‚àºp\nÔ£Æ\nÔ£∞1\nwj\nX\ni‚ààR(j,n,k)\n\u0012\nE\nx‚àº¬Øq [di+1(x) | x:i+1 = y:i+1] ‚àídi+1(y)\n\u0013Ô£π\nÔ£ª.\n21\n\nWe claim that for some j, aj ‚â•Œ±. Let j be the term with the largest value of aj. Then if aj < Œ±,\nwe have\nŒ± =\nk‚àí1\nX\nj=0\nwj\nn aj <\nk‚àí1\nX\nj=0\nwj\nn Œ± = Œ±,\nwhich leads to a contradiction. So we know aj ‚â•Œ±. For the remainder of the proof, we fix the\ni‚àó\n0 ‚àà{0, 1, 2, ¬∑ ¬∑ ¬∑ , k ‚àí1} such that\nai‚àó\n0 ‚â•Œ±.\nConsider breaking s into blocks of k tokens, starting at the i‚àó\n0-th token. Just as one can view q\nas a token-by-token distribution, one can also view it as a block-by-block distribution over b blocks\n[i‚àó\n0 + 1 + tk : i‚àó\n0 + 1 + (t + 1)k) as follows.\n¬Øq(x) = q(x:i‚àó\n0+1)\nY\ni‚ààR(i‚àó\n0,n,k)\nq(xi+1:i+k+1 | x:i+1)\nAccording to Equation (1.3), the distribution q‚Ä≤ is the distribution q, but where the block starting at\ni has a conditional distribution that is reweighted by e‚àíŒ±di+1(x). The normalization term Z(x:i+1)\nis defined so that the conditional block distributions sum to 1. Then, we can quantify the KL\ndivergence as follows.\nDKL(¬Øp‚à•¬Øq) ‚àíDKL(¬Øp‚à•¬Øq‚Ä≤)\n= E\ny‚àº¬Øp\n\u0014\nlog ¬Øp(y)\n¬Øq(y) ‚àílog ¬Øp(y)\n¬Øq‚Ä≤(y)\n\u0015\n= E\ny‚àº¬Øp\n\u0014\nlog ¬Øq‚Ä≤(y)\n¬Øq(y)\n\u0015\n= E\ny‚àº¬Øp\n\"\nlog\nq(y:i‚àó\n0+1) Q\ni‚ààR(i‚àó\n0,n,k) q(yi+1:i+k+1 | y:i+1)e‚àíŒ±di+1(y)/Z(y:i+1)\nq(y:i‚àó\n0+1) Q\ni‚ààR(i‚àó\n0,n,k) q(yi+1:i+k+1 | y:i+1)\n#\n= E\ny‚àº¬Øp\nÔ£Æ\nÔ£∞\nX\ni‚ààR(i‚àó\n0,n,k)\n(‚àíŒ±di+1(y) ‚àílog Z(y:i+1))\nÔ£π\nÔ£ª\n= E\ny‚àº¬Øp\nÔ£Æ\nÔ£∞\nX\ni‚ààR(i‚àó\n0,n,k)\n\u0012\nŒ± E\nx‚àº¬Øq [di+1(x) | x:i+1 = y:i+1] ‚àíŒ±di+1(y) ‚àíŒ± E\nx‚àº¬Øq [di+1(x) | x:i+1 = y:i+1] ‚àílog Z(y:i+1)\n\u0013Ô£π\nÔ£ª\n=Œ±wi‚àó\n0ai‚àó\n0 ‚àíE\ny‚àº¬Øp\nÔ£Æ\nÔ£∞\nX\ni‚ààR(i‚àó\n0,n,k)\n\u0012\nŒ± E\nx‚àº¬Øq [di+1(x) | x:i+1 = y:i+1] + log Z(y:i+1)\n\u0013Ô£π\nÔ£ª\n‚â•Œ±2wi‚àó\n0 ‚àíE\ny‚àº¬Øp\nÔ£Æ\nÔ£∞\nX\ni‚ààR(i‚àó\n0,n,k)\n\u0012\nŒ± E\nx‚àº¬Øq [di+1(x) | x:i+1 = y:i+1] + Z(y:i+1) ‚àí1\n\u0013Ô£π\nÔ£ª\nIn the last step, we use the fact that ai‚àó\n0 ‚â•Œ± and the inequality that log x ‚â§x ‚àí1 for x > 0.\nSubstituting the definition of Z in the above gives,\nDKL(¬Øp‚à•¬Øq) ‚àíDKL(¬Øp‚à•¬Øq‚Ä≤) ‚â•Œ±2wi‚àó\n0 ‚àíE\ny‚àº¬Øp\nÔ£Æ\nÔ£∞\nX\ni‚ààR(i‚àó\n0,n,k)\nE\nx‚àº¬Øq\nh\nŒ±di+1(x) + e‚àíŒ±di+1(x) ‚àí1 | x:i+1 = y:i+1\ni\nÔ£π\nÔ£ª\n22\n\nBy Taylor expansion, e‚àíŒ≤ + Œ≤ ‚àí1 ‚â§Œ≤2/2 for Œ≤ > 0. Plugging this into the above gives,\nDKL(¬Øp‚à•¬Øq) ‚àíDKL(¬Øp‚à•¬Øq‚Ä≤) ‚â•Œ±2wi‚àó\n0 ‚àíE\ny‚àº¬Øp\nÔ£Æ\nÔ£∞\nX\ni‚ààR(i‚àó\n0,n,k)\nE\nx‚àº¬Øq\n\u0002\nŒ±2d2\ni+1(x)/2 | x:i+1 = y:i+1\n\u0003\nÔ£π\nÔ£ª\n‚â•Œ±2wi‚àó\n0 ‚àíwi‚àó\n0Œ±2/2\n=Œ±2wi‚àó\n0/2\nIn the second inequality, we use the definition of di(x) ‚àà{0, 1}. Recall that wi‚àó\n0 := 1+‚åä(n‚àí1‚àí(i‚àó\n0))/k‚åã.\nTo finish the proof, it suffices to show that wi‚àó\n0 > n/(2k). To see this, note that if n/(2k) < 1, then\nwi‚àó\n0 ‚â•1 > n/(2k). For n/(2k) ‚â•1, we have\nwi‚àó\n0 ‚â•1 + ‚åän ‚àí1 ‚àí(i‚àó\n0)\nk\n‚åã‚â•1 + ‚åän ‚àí1 ‚àí(k ‚àí1)\nk\n‚åã‚â•1 + n ‚àík\nk\n‚àí1 = n\nk ‚àí1 ‚â•n\nk ‚àín\n2k = n\n2k\n2.4.2\nProof of Lemma 2: Boosted Next-token Probability\nWe next prove Lemma 2, which characterizes the next-token probability of the boosted model given\na distinguisher.\nLemma 2 (Boosted Next-token Probability). Let k ‚àà[n], p, q ‚àà‚àÜ(Œ£n), and d be a next-k-token\ndistinguisher with advantage Œ± := a(d, ¬Øp, ¬Øq). Then there exists i‚àó\n0 ‚àà[0, k ‚àí1] such that the model q‚Ä≤\nhas next-token conditional probability satisfying:\nDKL(¬Øp‚à•¬Øq‚Ä≤) ‚â§DKL(¬Øp‚à•¬Øq) ‚àíŒ±2n\n4k .\nThe model q‚Ä≤ ‚àà‚àÜ(Œ£n) is defined as follows:\nq‚Ä≤(xi | x:i) =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nq(xi | x:i)\nif i ‚â§i‚àó\n0;\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s)) ¬∑ 1 (s:i‚àíi0+1 = xi0+1:i+1)\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s)) ¬∑ 1 (s:i‚àíi0 = xi0+1:i)\nif i = i0 + r0,\ni0 ‚ààI,\n1 ‚â§r0 ‚â§k,\n(1.4)\nwhere I := {i ‚àà[n] | i ‚â°i‚àó\n0 (mod k)}.\nProof of Lemma 2. By Lemma 1, there exists i‚àó\n0 ‚àà[0, k ‚àí1] such that the model q‚Ä≤ defined as follows:\nfor ‚àÄx ‚ààŒ£n,\nq‚Ä≤(x:i‚àó\n0+1) := q(x:i‚àó\n0+1);\n‚àÄi0 ‚ààI :\nq‚Ä≤(xi0+1:i0+k+1 | x:i0+1) ‚àùq(xi0+1:i0+k+1 | x:i0+1)e‚àíŒ±di0+1(x),\nwhere I := {i0 ‚àà[n] | i0 ‚â°i‚àó\n0 (mod k)}. Then the next-token conditional probability q‚Ä≤ satisfies\nDKL(¬Øp‚à•¬Øq‚Ä≤) ‚â§DKL(¬Øp‚à•¬Øq) ‚àíŒ±2n\n4k .\nNext, we will compute the next-token conditional probability of q‚Ä≤.\n23\n\nFirstly for i ‚â§i‚àó\n0, q‚Ä≤ is the same as q. For each i ‚â•i‚àó\n0 + 1, i = i0 + r0, where i0 ‚ààI, 1 ‚â§r0 ‚â§k.\nThe next-token conditional probability depends on q‚Ä≤(xi0+1:i0+k+1 | x:i0+1). Thus, we only need to\nprove for a fixed i0, and all i0 ‚ààI follow samely. We first compute q‚Ä≤(xi0+1:i+1 | x:i0+1). Hence,\nq‚Ä≤(xi0+1:i+1 | x:i0+1) =\nX\ns‚ààŒ£k‚àí(i‚àíi0)\nq‚Ä≤(xi0+1:i+1 ¬∑ s | x:i0+1)\n=\nP\ns‚ààŒ£k‚àí(i‚àíi0)\nq(xi0+1:i+1 ¬∑ s | x:i0+1) exp (‚àíŒ±di0+1(x:i+1 ¬∑ s))\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s))\n=\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s)) ¬∑ 1 (s:i‚àíi0+1 = xi0+1:i+1)\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s))\nThus, the next-token conditional probability can be computed as\nq‚Ä≤(xi | x:i) =q‚Ä≤(xi0+1:i+1 | x:i0+1)\nq‚Ä≤(xi0+1:i | x:i0+1)\n=\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s)) ¬∑ 1 (s:i‚àíi0+1 = xi0+1:i+1)\nP\ns‚ààŒ£k q(s | x:i0+1) exp (‚àíŒ±di0+1(x:i0+1 ¬∑ s)) ¬∑ 1 (s:i‚àíi0 = xi0+1:i)\n2.4.3\nProof of Lemma 11: Synchronized Enumeration\nWe now present the proof, which follows the proof idea described in Section 2.3.\nProof of Lemma 11. We first prove that the lemma holds when i‚àó\n0 = 0, and then we will generalize\nit to any i‚àó\n0 ‚àà[0, k ‚àí1] in Claim 7. Finally, we analyze the size and hidden set size of the RNN in\nClaim 8.\nClaim 1 (Counter Nodes w0, u0, w, u). There exists an RNN with four counter nodes w0, u0, w, u\nwith\nwt\n0 = (t ‚àí1) mod (TU) + 1\n(2.1)\nserves as a step counter inside the index loop with range w0 ‚àà[1, TU].\nut\n0 = i1(t) ‚àíi0(t)\n(2.2)\ncomputes the difference between the current input index and the latest anchor index with range\nu0 ‚àà[1, k].\nwt = s1(t)\n(2.3)\nserves as a step counter inside the digit loop with range w ‚àà[1, œÑ].\nut = r1(t + 1),\n(2.4)\nwhich is the index of the processed digit for time t + 1 with range u ‚àà[1, k].\n24\n\nProof of Claim 1. We construct the RNN with four nodes w0, u0, w, u. Let w0 be a time-step counter\nnode for the input loop, indicating the progress within the current processing cycle of the input\ntoken. The RNN receives a new input token from the input stream whenever wt\n0 = TU. Being\ninitialized as 1, w0 update as\nwt\n0 =\n(\nwt‚àí1\n0\n+ 1\nif wt‚àí1\n0\n‚â§TU ‚àí1;\n1\nif wt‚àí1\n0\n= TU.\n(2.5)\nBy computation, its value satisfies Equation (2.1).\nNext, we construct the node u0 that tracks the difference between the current input index i1(t)\nand the most recent anchor i0(t), cycling over the range [1, k]. It is initialized to 1, and increments\nby 1 each time the RNN receives a new input token, i.e., when i1(t) = i1(t ‚àí1) + 1. Once it reaches\nits maximum value k, it wraps around and resets to 1.\nut\n0 =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\nut‚àí1\n0\n+ 1\nif wt‚àí1\n0\n= TU and ut‚àí1\n0\n‚â§k ‚àí1;\n1\nif wt‚àí1\n0\n= TU and ut‚àí1\n0\n= k;\nut‚àí1\n0\notherwise.\n(2.6)\nNote that whenever i1(t) = i1(t ‚àí1) + 1, we have wt‚àí1\n0\n= TU. Thus, the node u0 also satisfies\nEquation (2.2).\nFor the node w, we let w to be initialized as 1, and increments by one at each step until it reaches\nits maximum œÑ, at which point it wraps around and resets to 1. Specifically,\nwt =\n(\n1\nif wt‚àí1 = œÑ;\nwt‚àí1 + 1\notherwise.\n(2.7)\nThis update ensures that wt counts iteratively in the range [1, œÑ]. Since each digit loop takes œÑ steps,\nwe have wt = s1(t).\nThe node u has the predecessors w and u. It is initialized as 1. It retains its value until\nwt‚àí1 = œÑ ‚àí1, at which point it increments by 1. If it reaches k and needs to increment, it wraps\naround and resets to 1. Its update rule is defined as follows.\nut =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\n1\nif wt‚àí1 = œÑ ‚àí1 and ut‚àí1 = k;\nut‚àí1 + 1\nif wt‚àí1 = œÑ ‚àí1 and ut‚àí1 < k;\nut‚àí1\nif wt‚àí1 Ã∏= œÑ ‚àí1.\n(2.8)\nFor the initial time step, u1 = 1 = r1(2). By the update rule, ut will remain its value 1 until\nwt‚àí1 = œÑ ‚àí1. That is, ut = 1 for t ‚àà[1, œÑ ‚àí1]. Since r1(t) = 1 for t ‚àà[1, œÑ], we have ut = r1(t + 1)\nfor t ‚àà[1, œÑ ‚àí1]. Note that u increments by 1 whenever wt‚àí1 = œÑ ‚àí1 and ut‚àí1 < k. That is, u will\nincrements by 1 when t = Œ≥ ¬∑ œÑ for 1 ‚â§Œ≥ ‚â§k. So we know ut = Œ≥ for t ‚àà[(Œ≥ ‚àí1)œÑ, Œ≥œÑ ‚àí1]. This\nalso equals r1(t + 1) since r1(t) = Œ≥ for t ‚àà[(Œ≥ ‚àí1)œÑ + 1, Œ≥œÑ]. Then for t = kœÑ, ut = 1 = r1(t + 1).\nHere we have shown ut = r1(t + 1) within a digit loop. The remaining digit loops can be shown in\nthe same way, as they have the same initialization and update rules.\n25\n\nClaim 2 (Input Storage Node set Y ). There exists an RNN U, which receives a new input token\nfrom the input stream every œÑ steps, and U includes all nodes in Claim 1, input node vU,in, and a\nnode set Y = {y1, y2, ¬∑ ¬∑ ¬∑ , yk}, such that each node yj satisfies the follows for 1 ‚â§j ‚â§k.\nyt\nj =\n(\nxi0(t)+j\nif i1(t) ‚àíi0(t) > j or i1(t) ‚àíi0(t) = j, wt\n0 ‚â•2;\n0\notherwise.\n(2.9)\nProof of Claim 2. We construct the RNN by including the nodes from Claim 1, input node vU,in,\nand the node set Y = {y1, y2, ¬∑ ¬∑ ¬∑ , yk}. Each node in Y is initialized as 0.\nFor each input loop, suppose i1(t) = i0(t) + j for 1 ‚â§j ‚â§k. Then the value of the node yj is\ncopied from the input node vU,in, and remains fixed until the anchor index i0(t) changes. When the\nanchor index increments, i.e., i0(t) = i0(t ‚àí1) + k, we have i1(t) = i0(t) + 1. We reset all yj to be 0,\nand copy the input node to the node y1. Formally, we update the node set Y as follows.\nyt\nj =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\n0\nif wt‚àí1\n0\n= TU and ut‚àí1\n0\n= k;\nvt‚àí1\nU,in\nif wt‚àí1\n0\n= 1 and ut‚àí1\n0\n= j;\nyt‚àí1\nj‚àí1\notherwise.\n(2.10)\nSince ut\n0 = i1(t) ‚àíi0(t) , this update gives the value in Equation (2.9).\nNote that within each input loop, the RNN first iterates over all binary strings during the first\n2kkœÑ steps, and then updates the hidden states without string extension in the final kœÑ steps. In the\nfollowing claim, we construct a node set E, where the output node ve serves as the input to update\nthe hidden nodes. The node ve first enumerates over all digits of all binary strings in 2kkœÑ steps,\nand then becomes 0 for the final kœÑ steps.\nClaim 3 (Enumerator Node Set E). There exists an RNN with all nodes in Claim 2 and a node set\nE = {ze1, ze2, ¬∑ ¬∑ ¬∑ , zek, ve}, such that its output node ve ‚ààE iterates as follows: it remains at 0 for\nthe initial kœÑ time steps, and then sequentially enumerates the digits of all binary strings of length k,\nwith each digit held for œÑ time steps. Formally, the output node\nvt\ne =\n(\n0\nif j1(t) = 2k + 1;\nz(j1(t))\nr1(t)\notherwise.\n(2.11)\nProof of Claim 3. Denote ze1, ze2, ¬∑ ¬∑ ¬∑ , zek as k nodes representing the k digits of the string z(j),\nwith each zer ‚àà{0, 1} for 1 ‚â§r ‚â§k. Those nodes are reset to the value 0 whenever the input\nmoves forward to the next digit. For all string loops except the last one, the nodes hold their\nvalues unchanged until the last time step of the loop. At this point, they are updated via transition\nfunctions that perform incrementation in base-2 over k digits. The transition functions, denoted by\nfadd1,r : {0, 1}r ‚Üí{0, 1}, update the digits according to the following rule. For 1 ‚â§r ‚â§k,\nfadd1,r(ze1, ¬∑ ¬∑ ¬∑ , zer) =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\nzer\nif ‚àÉj ‚â§r ‚àí1 s.t. zej = 0;\nzer + 1\nif zej = 1, ‚àÄj ‚â§r ‚àí1, and zer = 0;\n0\nif zej = 1, ‚àÄj ‚â§r.\nThis is a transition function by Lemma 18. Formally, those k nodes are all initialized as 0, and\nupdated as follows. For each 1 ‚â§r ‚â§k,\nzt\ner =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\n0\nif wt‚àí1\n0\n= TU;\nfadd1,r(zt‚àí1\ne1 , ¬∑ ¬∑ ¬∑ , zt‚àí1\nek )\nif wt‚àí1 = œÑ ‚àí1 and ut‚àí1 = k;\nzt‚àí1\ner\notherwise.\n(2.12)\n26\n\nFor each input loop, zt\ner is set to be 0 when wt\n0 = 1. That is, (ze1, ¬∑ ¬∑ ¬∑ , zek) is initialized as z(1).\nThen, inside each string loop, it remains fixed until wt‚àí1 = œÑ ‚àí1 and ut‚àí1 = k. Equivalently, this\ncorresponds to the condition s1(t) = œÑ, r1(t) = k, meaning zer is updated to the next binary string\nonly at the last time step of each string loop. Since j1(t) ‚àà[1, 2k + 1], and there are 2k binary strings\nof length k. Thus when j1(t + 1) = 2k + 1, (ze1, ¬∑ ¬∑ ¬∑ , zek)t = z(1). Finally, in the last step of the\ninput loop, it becomes z(2). Formally,\n(ze1, ¬∑ ¬∑ ¬∑ , zek)t =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\nz(j1(t+1))\nif j1(t + 1) ‚àà[1, 2k] and wt\n0 ‚â§TU ‚àí1;\nz(1)\nif j1(t + 1) = 2k + 1;\nz(2)\nif wt\n0 = TU.\n(2.13)\nThe node ve is initialized as 0. Inside each input loop, it has a value of 0 at the first step or the\nlast œÑ steps. Otherwise, the node ve copies the value from zer if ut‚àí1 = k + 1 ‚àír for 1 ‚â§r ‚â§k.\nOtherwise, it has the value 0.\nvt\ne = 1\n\u0010\nwt‚àí1\n0\n‚â§2kkœÑ ‚àí1\n\u0011\n¬∑\nk\nX\nr=1\n1\n\u0000ut‚àí1 = k + 1 ‚àír\n\u0001\n¬∑ zt‚àí1\ner .\n(2.14)\nCombining Equation (2.13) with Equation (2.14), we obtain the value of node ve as given in\nEquation (2.11).\nNote that the node ve in Claim 3 precisely matches the digit that is processed at time t.\nNext, we will construct node sets that duplicate some node set in the RNN Q. Since the input of\nRNN Q moves to the next entry after TQ steps, each node in the RNN will also update for TQ steps\nbefore the new input is read. For any node vQ ‚ààVQ, we denote its value after Œ∫ steps of update\nafter reading the string œâ as vQ(œâ)‚ü®Œ∫‚ü©, where 1 ‚â§Œ∫ ‚â§TQ. For any node v ‚ààGQ that corresponds to\nvQ by the construction, we also write v(œâ)‚ü®Œ∫‚ü©as its value after Œ∫ updates after reading the string œâ.\nIn the following claim, we construct the node set H such that during each input loop with index\ni1, it stores the values of the hidden nodes HQ with prefix x:i0(i1)+1 in the first 2kkœÑ steps, and\nupdates to x:i0(i1+1)+1 in the last kœÑ steps.\nClaim 4 (Node Set H). There exists an RNN with all nodes in Claim 3, and a node set H where\neach node h ‚ààH corresponds to a node hQ ‚ààHQ in the hidden node set of the RNN Q, and has\nvalue\nht =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nhq\n\u0000x:i0(t)+1\n\u0001‚ü®TQ‚ü©\nif i1(t) Ã∏= i0(t) + k or i1(t) = i0(t) + k and wt\n0 ‚àà[1, 2kkœÑ];\nhq\n\u0000x:i0(t)+r1(t)\n\u0001‚ü®TQ‚ü©\nif i1(t) = i0(t) + k and s1(t) = 1 and wt\n0 ‚â•2kkœÑ + 1;\nhq\n\u0000x:i0(t)+r1(t)+1\n\u0001‚ü®s1(t)‚àí1‚ü©\nif i1(t) = i0(t) + k and s1(t) ‚àà[2, TQ] and wt\n0 ‚â•2kkœÑ + 1;\nhq\n\u0000x:i0(t)+r1(t)+1\n\u0001‚ü®TQ‚ü©\nif i1(t) = i0(t) + k and s1(t) ‚àà[TQ + 1, œÑ] and wt\n0 ‚â•2kkœÑ + 1.\n(2.15)\nProof of Claim 4. Besides the nodes in Claim 3, we let the RNN include a node set H by duplicating\nall nodes from the hidden node set HQ. Consequently, each node hQ ‚ààHQ corresponds to a\nnode h ‚ààH. For each node hQ ‚ààHQ that is connected to the input node vQ,in, we add k edges\n(y1, h), (y2, h), ¬∑ ¬∑ ¬∑ , (y3, h), where we consider yi as the ‚Äòinput node‚Äô that connect to H. Let the nodes\nin H have the same initialization as the corresponding nodes in HQ. For each node hQ ‚ààHQ that is\nupdated as\nht\nQ = fhQ\n\u0010\nvt‚àí1\nQ,in, Ht‚àí1\nQ\n\u0011\n, where fhQ is a transition function,\n27\n\nHOLD\nHOLD\nHOLD\n¬∑ ¬∑ ¬∑\n¬∑ ¬∑ ¬∑ ¬∑ ¬∑ ¬∑\n(2k + 1)kœÑ\n2kkœÑ\nkœÑ\nk blocks, each œÑ\nTQ RUN, (œÑ ‚àíTQ) HOLD\n(a) When i1(t) = i0(t) + k, we update the node set H using prefix stored in Y in the last kœÑ steps.\nHOLD\nHOLD\nHOLD\n¬∑ ¬∑ ¬∑\nHOLD\n(2k + 1)kœÑ\nkœÑ\nRUN\nHOLD\n(b) When i1(t) Ã∏= i0(t) + k, we hold the node set H.\nFigure 2.2: The Load-Run-Hold schedule for the node set H within each input loop.\nits corresponding node h ‚ààH updates as follows. During each input loop, we update the node h\nbased on whether the anchor index i0 will change for the next input. If ut\n0 = i1(t) ‚àíi0(t) Ã∏= k, the\nanchor index remains the same, and we keep h HOLD throughout the loop. If ut\n0 = k, the anchor\nindex will change from i0(t) to i0(t) + k in the next input loop, so we will RUN h during the last kœÑ\nsteps during the current input loop. We proceed in two phases:\n‚Ä¢ During the first 2kkœÑ steps, the node h is set to HOLD.\n‚Ä¢ For the last kœÑ steps, for 1 ‚â§j ‚â§k, we sequentially RUN h over TQ steps using fhQ with the\ninput node yj, and then HOLD for the remainder of each corresponding œÑ-step segment.\nFigure 2.2 shows the LOAD-RUN-HOLD schedule of the set H within each input loop. Formally, ht\nupdates as follows.\nht =\n(\nfhQ\n\u0010\nyt‚àí1\nj\n, Nt‚àí1(h)\n\u0011\nif wt‚àí1\n0\n‚â•2kkœÑ and ut‚àí1\n0\n= k and wt‚àí1 ‚àà[1, TQ] and ut‚àí1 = j;\nht‚àí1\notherwise.\n(2.16)\nThat gives the value in Equation (2.15).\nBy the construction of H, we note that inside each input loop,\n1. During the first 2kkœÑ steps, the node set H stores the hidden nodes of anchor prefix x:i0(i1)+1.\n2. At the last step, each node h ‚ààH satisfies\nht =\nÔ£±\nÔ£≤\nÔ£≥\nhq\n\u0000x:i0(t)+1\n\u0001‚ü®TQ‚ü©\nif i1(t) Ã∏= i0(t) + k;\nhq\n\u0000x:i0(t)+k+1\n\u0001‚ü®TQ‚ü©\nif i1(t) = i0(t) + k.\n28\n\n¬∑ ¬∑ ¬∑\n¬∑ ¬∑ ¬∑\n¬∑ ¬∑ ¬∑\n¬∑ ¬∑ ¬∑\n¬∑ ¬∑ ¬∑\n2kkœÑ\nkœÑ\nkœÑ\nkœÑ\nkœÑ\nRUN\nHOLD\nLOAD\nFigure 2.3: The Load-Run-Hold schedule for the node set ÀúH within each input loop of (2k + 1)kœÑ\nsteps. The loop begins with 2k ‚Äústring loops‚Äù of length kœÑ, each divided into k ‚Äúdigit loops‚Äù of length\nœÑ. For the first k ‚àí1 digit loops, the schedule is TQ ‚àí1 steps of RUN, œÑ ‚àíTQ steps of HOLD, and\none final step of RUN. The final digit loop (the k-th one) within each of these string loops is TQ ‚àí1\nsteps of RUN, œÑ ‚àíTQ steps of HOLD, and one step of LOAD from the node set H. The entire\nsequence concludes with a final kœÑ ‚Äústring loop‚Äù which consists of kœÑ ‚àí1 steps of HOLD, followed by\none last step of LOAD from the node set H.\nNote that i0(i1 + 1) Ã∏= i0(i1) only when i1 ‚àíi0(i1) = k. Consequently, in the last step,\nthe node set H stores the hidden nodes of the anchor prefix of the next input. That is,\nHt = Hq\n\u0000x:i0(i1(t)+1)+1\n\u0001‚ü®TQ‚ü©.\nFollowed by this, we construct another node set ÀúH which serves as the hidden nodes HQ with input\n{x:i0+1 ¬∑ z(j1)\n:r1+1}.\nClaim 5 (Node Set ÀúH). There exists an RNN with all nodes in Claim 4, and a node set ÀúH where\neach node Àúh ‚ààÀúH corresponds to a node hQ ‚ààHQ in the hidden node set of the RNN Q, and has\nvalue\nÀúht =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nhq\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t))\n:r1(t)\n\u0011‚ü®TQ‚ü©\nif s1(t) = 1 and wt\n0 ‚â§2kkœÑ;\nhq\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t))\n:r1(t)+1\n\u0011‚ü®s1(t)‚àí1‚ü©\nif s1(t) ‚àà[2, TQ] and wt\n0 ‚â§2kkœÑ;\nhq\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t))\n:r1(t)+1\n\u0011‚ü®TQ‚àí1‚ü©\nif s1(t) ‚àà[TQ + 1, œÑ] and wt\n0 ‚â§2kkœÑ;\nhq\n\u0000x:i0(t)+1\n\u0001‚ü®TQ‚ü©\nif wt\n0 > 2kkœÑ.\n(2.17)\nProof of Claim 5. Besides the nodes in Claim 4, we let the RNN include a node set ÀúH by duplicating\nall nodes from the hidden node set HQ. Consequently, each node in ÀúH corresponds to a node HQ.\nMeanwhile, we let the node ve connect to ÀúH, which corresponds to the input node vQ,in ‚ààGQ that\nconnects to HQ. Let the nodes in ÀúH have the same initialization as the corresponding nodes in HQ.\nEach input loop of (2k + 1)kœÑ steps in divided into two distinct phases:\n‚Ä¢ Enumeration Phase (first 2kkœÑ steps): This phase sequentially enumerates all 2k binary strings,\ncorresponding to 2k string loops, each lasting kœÑ steps. Each string loop is further divided into\nk digit loops, each lasting œÑ steps.\n‚Äì The first k ‚àí1 digit loops operate as: TQ ‚àí1 steps of RUN , œÑ ‚àíTQ steps of HOLD, and\nfinally 1 step of RUN.\n‚Äì The final digit loop operate as: TQ ‚àí1 steps of RUN, œÑ ‚àíTQ steps of HOLD, and finally\n1 step of LOAD from the node set H.\n29\n\n‚Ä¢ Final Phase (last kœÑ steps): œÑ ‚àí1 steps of HOLD, and 1 step of LOAD from the node set H.\nFigure 2.3 shows the LOAD-RUN-HOLD schedule of the set ÀúH within each input loop. Formally, for\neach node hQ ‚ààHQ that has the transition function fhQ, we let its corresponding node ÀúhQ update as\nÀúht =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nht‚àí1\nif wt‚àí1 = œÑ and ut‚àí1 = 1;\nfhQ\n\u0010\nvt‚àí1\ne\n, ÀúHt‚àí1\u0011\nif wt‚àí1 ‚â§TQ ‚àí1 and wt‚àí1\n0\n‚â§2kkœÑ or\nwt‚àí1 = œÑ and ut‚àí1 Ã∏= 1 and wt‚àí1\n0\n‚â§2kkœÑ;\nÀúht‚àí1\notherwise.\n(2.18)\nWe show next that Equation (2.17) holds. We first analyze the enumeration phase (first 2kkœÑ steps).\n‚Ä¢ In the initial step of this input loop, where r1(t) = s1(t) = 1. This implies that wt‚àí1 = œÑ and\nut‚àí1 = 1. Then the value of Àúh is copied from h in the last time step by the update rule (2.18).\nBy Claim 4,\nÀúht = ht‚àí1 = hq\n\u0000x:i0(i1(t‚àí1)+1)+1\n\u0001‚ü®TQ‚ü©= hq\n\u0000x:i0(i1(t))+1\n\u0001‚ü®TQ‚ü©= hq\n\u0000x:i0(t)+1\n\u0001‚ü®TQ‚ü©.\n‚Ä¢ Next, we consider the initial step of each string loop, where r1(t) = s1(t) = 1. This implies\nthat wt‚àí1 = œÑ and ut‚àí1 = 1. By Claim 4,\nÀúht = ht‚àí1 = hq\n\u0000x:i0(t)+1\n\u0001‚ü®TQ‚ü©.\n‚Ä¢ We then look into a single string loop, that is, when t ‚àà[(i1 ‚àí1)TU +(j1 ‚àí1)kœÑ +1, (i1 ‚àí1)TU +\nj1kœÑ] for some i1 ‚àà[1, n] and j1 ‚àà[1, 2k]. Throughout this interval, the following quantities\nremain fixed: i1(t) = i1, i0(t) = i0(i1), j1(t) = j1. The initial value has been computed as\nÀúh(i1‚àí1)TU+(j1‚àí1)kœÑ+1 = hq\n\u0000x:i0(t)+1\n\u0001‚ü®TQ‚ü©.\nWe now use induction to show that Equation (2.17) holds for all t in this interval. The base\ncase (initial time) has already been established. Assume that the equation holds at time t0; we\nwill show it continues to hold at time t0 + 1. We consider several cases based on the update\nprogress s1.\n1. If s1(t0) = 1, we have r1(t0 + 1) = r1(t0). By the induction hypothesis,\nÀúht0 = hq\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t0))\n:r1(t0)\n\u0011‚ü®TQ‚ü©\n.\nThen by the update rule (2.18) and the value ve from Claim 3,\nÀúht0+1 = fhQ\n\u0010\nz(j1(t0))\nr1(t0) , ÀúHt0\u0011\n= hq\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®1‚ü©\n= hq\n\u0010\nx:i0(t0+1)+1 ¬∑ z(j1(t0+1))\n:r1(t0+1)+1\n\u0011‚ü®1‚ü©\n.\n2. If s1(t0) ‚àà[1, TQ ‚àí1], we have r1(t0 +1) = r1(t0), s1(t0 +1) = s1(t0)+1. By the induction\nhypothesis,\nÀúht0 = hq\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®s1(t0)‚àí1‚ü©\n.\nThen by the update rule (2.18) and the value ve from Claim 3,\nÀúht0+1 =fhQ\n\u0010\nz(j1(t0))\nr1(t0) , ÀúHt0\u0011\n=hq\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®s1(t0)‚ü©\n=hq\n\u0010\nx:i0(t0+1)+1 ¬∑ z(j1(t0+1))\n:r1(t0)+1\n\u0011‚ü®s1(t0+1)‚àí1‚ü©\n30\n\n3. If s1(t0) ‚àà[TQ, œÑ ‚àí1], we have r1(t0 + 1) = r1(t0). By the induction hypothesis,\nÀúht0 = hq\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚àí1‚ü©\n.\nThen by the update rule (2.18),\nÀúht0+1 = Àúht0 = hq\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚àí1‚ü©\n= hq\n\u0010\nx:i0(t+1)+1 ¬∑ z(j1(t0+1))\n:r1(t0)+1\n\u0011‚ü®TQ‚àí1‚ü©\n.\n4. If s1(t0) = œÑ. This indicates that t0 is the last step of processing the current digit. We\nhave wt0 = s1(t0) = œÑ and s1(t0 + 1) = 1. By the induction hypothesis,\nÀúht0 = hq\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚àí1‚ü©\n.\nThere are two cases for updating, depending on whether ut0 = 1. If ut0 = 1, this implies\nthat we are in the last time step of the current string loop. Thus t0 + 1 is not in the\ninterval we are considering. If ut0 Ã∏= 1, this implies that we are not in the last time step\nof the current string loop, and thus j1(t0 + 1) = j1(t0) and r1(t0 + 1) = r1(t0) + 1. By\nEquation (2.18), Àúh is updated using fhQ. Combined with Claim 3,\nÀúht0+1 = fhQ\n\u0010\nz(j1(t0))\nr1(t0) , ÀúHt0\u0011\n= hq\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚ü©\n= hq\n\u0010\nx:i0(t0+1)+1 ¬∑ z(j1(t0+1))\n:r1(t0+1)\n\u0011‚ü®TQ‚ü©\n.\nThus, by induction, we conclude that Equation (2.17) holds for all t in the interval [(i1 ‚àí\n1)TU + (j1 ‚àí1)kœÑ + 1, (i1 ‚àí1)TU + j1kœÑ]. Since for each fixed pair (i1, j1), the initialized value\nhas been computed and the update rules are identical, the argument extends for all i1, j1, and\nhence holds for all corresponding time steps t during the first 2kkœÑ steps.\nFinally, we analyze the last kœÑ steps in each input loop, that is when t ‚àà[(i1 ‚àí1)TU + 2kkœÑ + 1, (i1 ‚àí\n1)TU + (2k + 1)kœÑ] for some i1 ‚àà[1, n]. When t = (i1 ‚àí1)TU + 2kkœÑ + 1, by the update rule (2.18),\nÀúh is copied from h. By Claim 4,\nÀúht = ht‚àí1 = hq\n\u0000xi0(t‚àí1)+1\n\u0001TQ = hq\n\u0000xi0(t)+1\n\u0001TQ\nThe last equality holds because i0(t) does not change in the current kœÑ period. After that, by the\nupdate rule (2.18), Àúh remains fixed.\nFinally, we will construct the node set R that replicates the structure of the node set RQ :=\nGQ \\ {HQ\nS{vQ,in}}. It includes the output node vU,out.\nClaim 6 (Node Set R). There exists an RNN with all nodes in Claim 5, and a node set R where\neach node in R corresponds to a node in RQ. Let vU,out ‚ààR be the node that corresponds to the\noutput node vQ,out ‚ààRQ. Then its value\nvt\nU,out =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\n0\nif s1(t) = 1, r1(t) = 1, wt\n0 ‚â§2kkœÑ or wt\n0 > 2kkœÑ;\nvQ,out\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t))\n:r1(t)\n\u0011‚ü®TQ‚ü©\nif s1(t) = 1, r1(t) Ã∏= 1, wt\n0 ‚â§2kkœÑ;\nvQ,out\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t))\n:r1(t)+1\n\u0011‚ü®s1(t)‚àí1‚ü©\nif s1(t) ‚àà[2, TQ], wt\n0 ‚â§2kkœÑ;\nvQ,out\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t))\n:r1(t)+1\n\u0011‚ü®TQ‚àí1‚ü©\nif s1(t) ‚àà[TQ + 1, œÑ], wt\n0 ‚â§2kkœÑ.\n(2.19)\n31\n\nProof of Claim 6. We construct a set of nodes R by duplicating all nodes from the RQ. Thus each\nnode in GQ has a corresponding node in {ve} S ÀúH S R. We add edges to the graph GU according\nto the connections in GQ. For each node rQ ‚ààRQ, who has update rule rt\nQ = fr(Nt‚àí1(rQ)). We\nset the corresponding node vR ‚ààR to be initialized as 0. The node vR follows the exact same\nRUN-HOLD-HOLD operation timing as the nodes ÀúH defined in Claim 5, as illustrated in Figure 2.3.\nThe RUN step uses the function fr, and the LOAD step simply loads a constant value 0. Formally,\nvt\nR =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\n0\nif wt‚àí1 = œÑ and ut‚àí1 = 1;\nfr\n\u0000Nt‚àí1 (vR)\n\u0001\nif wt‚àí1 ‚â§TQ ‚àí1 and wt‚àí1\n0\n‚â§2kkœÑ or\nwt‚àí1 = œÑ and ut‚àí1 Ã∏= 1 and wt‚àí1\n0\n‚â§2kkœÑ;\nvt‚àí1\nR\notherwise.\n(2.20)\nDenote fo as the transition function of the output node vQ,out. We will analyze vU,out using the\nupdate rule (2.20).\nNote that, by the definition of hidden node set, viTQ\nQ,out = œàQ,H\n\u0010\nv(i‚àí1)TQ+1\nQ,in\n, H(i‚àí1)TQ+1\nQ\n\u0011\n. This\nimplies that the output at time iTQ depends solely on the input and hidden nodes at time (i‚àí1)TQ+1\nand is unaffected by the values of nodes in RQ at that time. In other words, regardless of how\nRQ is initialized at any time t ‚â°1 (mod TQ), running the RNN for TQ steps ensures that viTQ\nQ,out is\ncomputed correctly. Similarly, the initialization of R at the beginning of each digit loop does not\naffect the output vU,out.\nFor each input loop, we first analyze the first 2kkœÑ steps.\n‚Ä¢ In the initial step of the input loop, the value of vU,out is set to be 0 by the update rule (2.20).\n‚Ä¢ Next, we consider the initial step of each string loop, where r1(t) = s1(t) = 1. This implies\nthat wt‚àí1 = œÑ and ut‚àí1 = 1. By the update rule (2.20), the output node vU,out is also set to\nbe 0.\n‚Ä¢ We then look into a single string loop, that is, when t ‚àà[(i1 ‚àí1)TU + (j1 ‚àí1)kœÑ + 1, (i1 ‚àí\n1)TU + j1kœÑ] for some i1 ‚àà[1, n] and j1 ‚àà[1, 2k]. Throughout this interval, the following\nquantities remain fixed: i1(t) = i1, i0(t) = i0, j1(t) = j1. The initial value of vU,out is 0. We\nnow use induction to show that Equation (2.19) holds for all t in this interval. The base case\nhas already been established. Assume that the equation holds at time t0; we will show it\ncontinues to hold at time t0 + 1. We consider several cases based on the update progress s1.\n1. If s1(t0) = 1, we have r1(t0 + 1) = r1(t0). by induction hypothesis,\nvt0\nU,out = 0.\nBy the update rule (2.20), it will update using the transition function fo. By Claim 3\nand Claim 5, the node vt0\ne = z(j1(t0))\nr1(t0)\nand each node Àúh in the node set ÀúH has value\nÀúht0 = hq\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)\n\u0011‚ü®TQ‚ü©\n.\nThus we have\nvt0+1\nU,out =fo\n\u0000Nt0(vU,out)\n\u0001\n=vQ,out\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®1‚ü©\n=vQ,out\n\u0010\nx:i0(t0+1)+1 ¬∑ z(j1(t0+1))\n:r1(t0+1)+1\n\u0011‚ü®1‚ü©\n.\n32\n\n2. If s1(t0) ‚àà[1, TQ ‚àí1], we have r1(t0 +1) = r1(t0), s1(t0 +1) = s1(t0)+1. By the induction\nhypothesis,\nvt0\nU,out = vQ,out\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®s1(t0)‚àí1‚ü©\nBy Claim 3 and Claim 5, the node vt0\ne = z(j1(t0))\nr1(t0)\nand each node Àúh in the node set ÀúH has\nvalue\nÀúht0 = hq\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®s1(t0)‚àí1‚ü©\n.\nThus, by the update rule (2.20), vU,out will update using the transition function fo.\nvt0+1\nU,out =fo\n\u0000Nt0(vU,out)\n\u0001\n=vQ,out\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®s1(t0)‚ü©\n=vQ,out\n\u0010\nx:i0(t0+1)+1 ¬∑ z(j1(t0+1))\n:r1(t0+1)+1\n\u0011‚ü®s1(t0+1)‚àí1‚ü©\n3. If s1(t0) ‚àà[TQ, œÑ ‚àí1], we have r1(t0 + 1) = r1(t0). By the induction hypothesis,\nvt0\nU,out = vQ,out\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚àí1‚ü©\nThus, by the update rule (2.20), vU,out will retain the same.\nvt0+1\nU,out =vt0\nU,out\n=vQ,out\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚àí1‚ü©\n=vQ,out\n\u0010\nx:i0(t0+1)+1 ¬∑ z(j1(t0+1))\n:r1(t0+1)+1\n\u0011‚ü®TQ‚àí1‚ü©\n4. If s1(t0) = œÑ. This indicates that t0 is the last step of processing the current digit. We\nhave wt0 = s1(t0) = œÑ and s1(t0 + 1) = 1. By the induction hypothesis,\nvt0\nU,out = vQ,out\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚àí1‚ü©\n.\nThere could be two cases of updating depending on whether ut0 = 1. If ut0 = 1, this\nimplies that we are in the last time step of the current string loop. Thus, t0 + 1 is not in\nthe interval we are considering. If ut0 Ã∏= 1, this implies that we are not in the last time\nstep of the current string loop, and thus j1(t0 + 1) = j1(t0) and r1(t0 + 1) = r1(t0) + 1.\nBy Claim 3 and Claim 5, the node vt0\ne = z(j1(t0))\nr1(t0)\nand each node Àúh in the node set ÀúH has\nvalue\nÀúht0 = hq\n\u0010\nx:i0(t)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚àí1‚ü©\n.\nThus, by the update rule (2.20), vU,out will update using fo.\nvt0+1\nU,out =fo\n\u0000Nt0(vU,out)\n\u0001\n=vQ,out\n\u0010\nx:i0(t0)+1 ¬∑ z(j1(t0))\n:r1(t0)+1\n\u0011‚ü®TQ‚ü©\n=vQ,out\n\u0010\nx:i0(t0+1)+1 ¬∑ z(j1(t0+1))\n:r1(t0+1)\n\u0011‚ü®TQ‚ü©\n.\n33\n\nThus, by induction, we conclude that Equation (2.19) holds for all t in the interval [(i1 ‚àí\n1)TU + (j1 ‚àí1)kœÑ + 1, (i1 ‚àí1)TU + j1kœÑ]. Since for each fixed pair (i1, j1), the initialized value\nhas been computed and the update rules are identical, the argument extends for all i1, j1, and\nhence holds for all corresponding time steps t during the first 2kkœÑ steps.\nFinally, we analyze the last kœÑ steps in each input loop, that is when t ‚àà[(i1 ‚àí1)TU + 2kkœÑ + 1, (i1 ‚àí\n1)TU + (2k + 1)kœÑ] for some i1 ‚àà[1, n]. When t = (i1 ‚àí1)TU + 2kkœÑ + 1, we know wt‚àí1 = œÑ and\nut‚àí1 = 1. Thus by the update rule (2.20), we know vt\nU,out = 0. Followed by this, either the node\nvU,out is reset to 0 (when wt‚àí1 = œÑ and ut‚àí1 = 1), or it retains its value 0. Thus, during the kœÑ\nsteps, we have vt\nU,out = 0.\nBy Claim 6, we know for for i1 ‚àà[1, n], j1 ‚àà[1, 2k], r1 ‚àà[1, k], for any time t ‚àà[(i1 ‚àí1)TU + (j1 ‚àí\n1)kœÑ + (r1 ‚àí1)œÑ + TQ, (i1 ‚àí1)TU + (j1 ‚àí1)kœÑ + r1œÑ], the output node value satisfies that\nvt\nU,out = vQ,out\n\u0010\nx:i0(i1)+1 ¬∑ z(j1)\n:r1+1\n\u0011‚ü®TQ‚àí1‚ü©\n= gQ\n\u0010\nx:i0(i1)+1 ¬∑ z(j1)\n:r1+1\n\u0011\n.\n(2.21)\nThus, we have proved our lemma for the case when i‚àó\n0 = 0. In the following claim, we will\ngeneralize it to any i‚àó\n0 ‚àà[0, k ‚àí1] by a slight modification on the RNN.\nClaim 7 (Initial Phase i1 ‚â§i‚àó\n0). For any i‚àó‚àà[0, k ‚àí1], there exists an RNN U with output node\nsatisfies that\n1. For i1 ‚â§i‚àó\n0 and t ‚àà[(i1 ‚àí1)TU + TQ, i1TU],\nvt\nU,out = gQ (x:i1+1) .\n2. For i1 ‚â•i‚àó\n0 + 1, 1 ‚â§j1 ‚â§2k, 1 ‚â§r1 ‚â§k and t ‚àà[(i1 ‚àí1)TU + (j1 ‚àí1)kœÑ + (r1 ‚àí1)œÑ + TQ, (i1 ‚àí\n1)TU + (j1 ‚àí1)kœÑ + r1œÑ],\nvt\nU,out = gQ\n\u0010\nx:i0(i1)+1 ¬∑ z(j1)\n:r1+1\n\u0011\n.\nProof of Claim 7. We modify the RNN in Claim 6 by adding a counter node, changing the initial-\nization of node u0, and changing the updating functions of the node sets H, ÀúH and R.\nWe begin by adding a counter node vc ‚àà[1, i‚àó\n0 + 1] that increments by 1 for each new input and\nremains at i‚àó\n0 + 1 thereafter. It is initialized as 1 and updated as\nvt\nc =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\nvt‚àí1\nc\n+ 1\nif vt‚àí1\nc\n‚â§i‚àó\n0 and wt‚àí1\n0\n= TU;\ni‚àó\n0 + 1\nif vt‚àí1\nc\n> i‚àó\n0 and wt‚àí1\n0\n= TU;\nvt‚àí1\nc\notherwise.\n(2.22)\nThen it has value\nvt\nc =\n(\ni1\nif t ‚àà[(i1 ‚àí1)TU + 1, i1TU] and i1 ‚â§i‚àó\n0 + 1;\ni‚àó\n0 + 1\notherwise.\n(2.23)\nWe then change the initialization of u0 to be\nu1\n0 =\n(\n1\nif i‚àó\n0 = 0;\n1 ‚àíi‚àó\n0 + k\notherwise.\n34\n\nThis ensures that when i1(t) = i‚àó\n0 + 1, the node ut\n0 = 1, and matches the initialization in Claim 1.\nNext, we revise the update rule for the node set H. Instead of storing the hidden states with\nthe anchor string x:i0(t)+1. When i1 ‚â§i‚àó\n0, we let H stores the hidden states with the input string\nx:i1(t)+1. For each h ‚ààH, denote fhQ as the transition function of its corresponding node hQ ‚ààHQ,\nand fh as the transition function of h defined in Claim 4 (Equation (2.16)). Let h initialize with the\nsame value as hQ ‚ààHQ. Then we define its new update rule as\nht =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\nfhQ(vt‚àí1\nU,in, Ht‚àí1)\nif wt‚àí1\n0\n‚â§TQ and vt‚àí1\nc\n‚â§i‚àó\n0;\nht‚àí1\nif wt‚àí1\n0\n‚àà[TQ + 1, TU] and vt‚àí1\nc\n< i‚àó\n0;\nfh(yt‚àí1\nj\n, Nt‚àí1(h))\notherwise.\n(2.24)\nNow we compute its value. We first analyze the value of h for an input loop where i1 ‚â§i‚àó\n0. During\neach input loop, h is updated using hQ for TQ time steps. That is when wt\n0 ‚àà[2, TQ + 1],\nht = hq\n\u0000x:i1(t)+1\n\u0001‚ü®wt\n0‚àí1‚ü©.\n(2.25)\nFollowed by this, it retains its value hq(x:i1(t)+1)‚ü®TQ‚ü©until the first step of the next input loop.\nWhen i1 ‚â•i‚àó\n0, the initialization of h is\nhi‚àó\n0¬∑T+1 = hq\n\u0000x:i‚àó\n0+1\n\u0001‚ü®TQ‚ü©= hq\n\u0010\nx:i0(i‚àó\n0¬∑TU+1)+1\n\u0011‚ü®TQ‚ü©\n.\nFollowed by this, h is updated using fh. Note that the counter nodes w0, w, u cycle with periods\nTU, œÑ and k, respectively. So within each input loop spanning TU time steps, these three nodes\ncomplete full cycles and thus their values remain unchanged for each input loop. Also, u0 achieves\nthe same initialization as in Claim 4. Thus, h has the same value as in Claim 4.\nNext, we will revise ÀúH such that when i1(t) ‚â•i‚àó\n0 + 1, it has the correct initialization. Specifically,\nÀúHi‚àó\n0¬∑TU+1 = ÀúHq\n\u0000x:i‚àó\n0+1\n\u0001‚ü®TQ‚ü©.\nFor each node Àúh ‚ààÀúH, denote fÀúh as its original transition function in Claim 5. Then its new transition\nfunction is\nÀúh =\n(\nht‚àí1\nif vt‚àí1\nc\n‚â§i‚àó\n0;\nfÀúh\n\u0010\nNt‚àí1(Àúh)\n\u0011\notherwise.\n(2.26)\nThis ensures its initialization at time i‚àó\n0 ¬∑ TU + 1, and the following update rule is the same as Claim 5.\nFinally, we revise the update rule for each node vR ‚ààR. Since the input node vU,in, the node\nset H, and the node set R consist of a graph equivalent to the graph GQ, we add edges between\nthem that correspond to their relationship in GQ. We denote by fvR,1 and N1(vR) the transition\nfunction and the incoming neighbors used to update the node vR based on the input node vU,in and\nthe hidden node set H. Similarly, we denote by fvR,2 and N2(vR) the transition function and the\nincoming neighbors used to update the node vR as specified in Claim 6. Then the new update rule\nof node vR is defined as\nvt\nR =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nfvR,1\n\u0000Nt‚àí1\n1\n(vR)\n\u0001\nif wt‚àí1\n0\n‚â§TQ ‚àí1 and vt‚àí1\nc\n‚â§i‚àó\n0;\nvt‚àí1\nR\nif wt‚àí1\n0\n‚àà[TQ, TU ‚àí1] and vt‚àí1\nc\n‚â§i‚àó\n0;\n0\nif wt‚àí1\n0\n= TU and vt‚àí1\nc\n‚â§i‚àó\n0;\nfvR,2\n\u0000Nt‚àí1\n2\n(vR)\n\u0001\notherwise.\n(2.27)\n35\n\nSince a constant number of compositions of transition functions is a valid transition, Equation (2.27)\nis a valid transition function.\nNext, we will compute the value of vU,out.\n‚Ä¢ When wt\n0 = 1 and i1(t) ‚â§i‚àó\n0, that is, when a new input token is fed into the RNN. Since\nwt‚àí1\n0\n= TU and vt‚àí1\nc\n‚â§i1(t) ‚â§i‚àó\n0, by the update rule (2.27),\nvt\nU,out = 0.\n‚Ä¢ When wt\n0 ‚àà[2, TQ] and i1(t) ‚â§i‚àó\n0, we have wt‚àí1\n0\n‚àà[1, TQ ‚àí1] and vt‚àí1\nc\n= i1(t ‚àí1) ‚â§i‚àó\n0. Then\nby the update rule (2.27),\nvt\nU,out = fvU,out,1\n\u0000Nt‚àí1\n1\n(vU,out)\n\u0001\n.\nBy Equation (2.25), each node h in the node set H has value\nht = hq\n\u0000x:i1(t)+1\n\u0001‚ü®wt\n0‚àí1‚ü©.\nCombined with the input node value vt\nU,in = xi1(t), we have\nvt\nU,out = vQ,out\n\u0000x:i1(t)+1\n\u0001‚ü®wt\n0‚àí1‚ü©.\n(2.28)\n‚Ä¢ When wt\n0 ‚àà[TQ + 1, TU] and vt‚àí1\nc\n‚â§i‚àó\n0, we have wt‚àí1\n0\n‚àà[TQ, TU ‚àí1] and vt‚àí1\nc\n= i1(t ‚àí1) ‚â§i‚àó\n0.\nThen by the update rule (2.27), the node vU,out retains the same. Thus,\nvt\nU,out = vQ,out\n\u0000x:i1(t)+1\n\u0001‚ü®TQ‚àí1‚ü©.\n(2.29)\n‚Ä¢ When wt\n0 = 1 and i1(t) = i‚àó\n0 + 1, this is the first time step for the input xi‚àó\n0+1. Since wt‚àí1\n0\n= TU\nand i1(t ‚àí1) = i‚àó\n0, by the update rule (2.27), the node vU,out has value\nvt\nU,out = 0.\n‚Ä¢ Otherwise, we have t ‚â•i‚àó\n0 ¬∑ TU + 2. Since vt‚àí1\nc\n‚â•i‚àó\n0 + 1, the node vU,out will update use fvU,out,2.\nSince its initial value is 0 at time t = i‚àó\n0 ¬∑ TU + 1, which is the same as the initialization in\nClaim 6. Furthermore, all counter nodes have the same initialization. Thus, by the same\nupdate rule, it will have the same value.\nTo sum up, when t ‚â§i‚àó\n0¬∑TU, by Equation (2.28) and Equation (2.29), for any t ‚àà[(i1‚àí1)TU +TQ, i1TU],\nthe output node\nvt\nU,out = vQ,out\n\u0000x:i1(t)+1\n\u0001‚ü®TQ‚àí1‚ü©= gQ (x:i1+1) .\nFor t ‚â•i‚àó\n0 ¬∑ TU + 1, by Equation (2.21), for t ‚àà[(i1 ‚àí1)TU + (j1 ‚àí1)kœÑ + (r1 ‚àí1)œÑ + TQ, (i1 ‚àí1)TU +\n(j1 ‚àí1)kœÑ + r1œÑ], the output node value satisfies that\nvt\nU,out = gQ\n\u0010\nx:i0(i1)+1 ¬∑ z(j1)\n:r1+1\n\u0011\n.\nNext, we will bound the size and hidden node set size of the RNN U.\nClaim 8 (Complexity). The constructed RNN U has a size of |Q| + |HQ| + 2k + 6 and a hidden\nnode set size of |HQ| + 2k + 6.\n36\n\nProof of Claim 8. By the construction, the total number of nodes in the RNN U is\n|U| = 5 + |Y | + |E| + |H| + | ÀúH| + |R| = 5 + k + (k + 1) + |HQ| + |Q| = |Q| + |HQ| + 2k + 6.\nWe next show that the node set HU := {w0, u0, w, u, vc} S Y S E S H is a hidden node set of the\nconstructed RNN U. By update rules (2.5), (2.6), (2.7), (2.8), (2.10), (2.12), (2.14), (2.16), (2.22),\n(2.24) , each node in HU is updated using solely the values of {vU,in} S HU in the previous time step.\nThus, the first requirement for the hidden node set is satisfied.\nIt remains to show that the output node at the time of interest depends only on the input node\nand the node set HU at the beginning of the current loop. We consider two cases based on whether\ni1 ‚â§i‚àó\n0.\nIf i1 ‚â§i‚àó\n0, vU,out is updated using vU,in and H. By Claim 7, H has the same update rule as Hq\nfor wt‚àí1\n0\n‚â§TQ; R and Rq is updated using the same transition function when wt‚àí1\n0\n‚â§TQ ‚àí1. When\nwt‚àí1\n0\n‚àà[TQ, TU ‚àí1], R retains its value. Thus,\nvi1TU\nU,out = v(i1‚àí1)TU+TQ\nU,out\n= œàQ,H\n\u0010\nv(i1‚àí1)TU+1\nU,in\n, H(i1‚àí1)TU+1\u0011\n.\nIf i1 ‚â•i‚àó\n0+1, for any i1 ‚àà[i‚àó\n0+1, n], j1 ‚àà[1, 2k], r1 ‚àà[1, k], denote T0 = (i1‚àí1)TU+(j1‚àí1)kœÑ+(r1‚àí1)œÑ.\nWe will show that for t ‚àà[T0 + TQ, T0 + œÑ], the output node vt\nU,out depends only on HT0+1\nU\nand xi1.\nAccording to the update rule Equation (2.20) in Claim 6 and the property of hidden node set,\nvt\nU,out = œàQ,H\n\u0010\nvT0+1\ne\n, ÀúHT0+1\u0011\n.\nFor ÀúH, by its update rule (2.18), each ÀúHt can be expressed using wt‚àí1, ut‚àí1, wt‚àí1\n0\n, Et‚àí1, Ht‚àí1 and\nÀúHt‚àí1. Note that ÀúHT0+1 = HT0 from Equation (2.18), and also HT0 = HT0+1 from Equation (2.15).\nThus we know ÀúHT0+1 = HT0+1. Thus there exists a function œà2 : {0, 1} √ó R|HU| ‚Üí{0, 1} such that\nÀúHt = œà2\n\u0010\nxi1, HT0+1\nU\n\u0011\n= œà2\n\u0010\nvT0+1\nU,in , HT0+1\nU\n\u0011\n.\nFinally, to bound the size of HU,\n|HU| = 5 + |Y | + |E| + |H| = 5 + k + (k + 1) + |HQ| = |HQ| + 2k + 6.\n2.4.4\nProofs for the RNN Component Functions f1 (Lemma 7) , f2 (Lemma 8) and\ng1, g2 (Lemma 9)\nNext, we will prove Lemma 7, Lemma 8 and Lemma 9, which show the construction of RNNs that\nrealize functions f1, f2 and g1, g2 respectively. These proofs are built based on Lemma 11.\nLemma 7 (Computing k-token Probability f1). Let n ‚ààN be the document length, k, i‚àó\n0 ‚ààN with\ni‚àó\n0 ‚àà[0, k ‚àí1]. Let Q be an RNN for language model q, which receives a new input token from the\ninput stream every T steps. That is, for any input stream x1, x2, ¬∑ ¬∑ ¬∑ , xn, for any 1 ‚â§i ‚â§n, the\noutput node viTQ\nQ,out = q(xi | x:i). Let œÑ ‚ààN be an integer such that œÑ ‚â•TQ + 4. Then there exists an\nRNN U with RNN-time TU = (2k + 1)kœÑ such that\n37\n\n‚Ä¢ For input index 1 ‚â§i ‚â§i‚àó\n0, it outputs the same next-token conditional probability as q,\nviTU‚àí1\nU,out = q(xi | x:i).\n‚Ä¢ For input index i > i‚àó\n0, its output node computes the conditional probability q over all possible\nlength k binary strings, conditioned on the input prefix x:i0(i). That is, for 1 ‚â§j ‚â§2k,\nv(i‚àí1)TU+jkœÑ‚àí1\nU,out\n= q(z(j) | x:i0(i)+1).\nThe RNN U has a size of |U| = |Q|+|HQ|+2k+7 and a hidden node set size of |HU| = |HQ|+2k+6.\nProof. By Lemma 11, there exists an RNN U with RNN-time TU = (2k+1)kœÑ, size |Q|+|HQ|+2k+6\nand hidden node set size |HQ| + 2k + 6. Its output node vq satisfies that\n‚Ä¢ If 1 ‚â§i ‚â§i‚àó\n0,\nviTU‚àí2\nq\n= q(xi | x:i).\n(2.30)\n‚Ä¢ If i > i‚àó\n0, for any 1 ‚â§j ‚â§2k, 1 ‚â§r ‚â§k,\nv(i‚àí1)TU+(j‚àí1)kœÑ+rœÑ‚àí2\nq\n= q(z(j)\nr\n| x:i0(i)+1 ¬∑ z(j)\n:r ).\n(2.31)\nWe now augment the RNN U with another node vU,out, and let it be the output node. It is initialized\nas 1, and updates as follows.\n‚Ä¢ When 1 ‚â§i ‚â§i‚àó\n0, the node vU,out copies the value from vq at the third-to-last time step of the\ncurrent input loop. At all other time steps, it retains its previous value.\n‚Ä¢ When i > i‚àó\n0, during each digit loop, the node vU,out remains fixed except at the third-to-last\ntime step, at which point it multiplies its current value with the value of vq at the last time\nstep.\nRecall the input loop time-step counter node w0 ‚àà[1, TU], the digit loop time-step counter w ‚àà[1, œÑ],\nthe digit counter u ‚àà[1, k] defined in Claim 1 and the node vc ‚àà[1, i‚àó\n0 + 1] defined in Claim 7. The\noutput node is defined as\nvt\nU,out =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nvt‚àí1\nq\nif wt‚àí1\n0\n= TU ‚àí2 and vt‚àí1\nc\n‚â§i‚àó\n0;\n1\nif wt‚àí1 = œÑ and ut‚àí1 = 1 and vt‚àí1\nc\n‚â•i‚àó\n0;\nvt‚àí1\nU,out ¬∑ vt‚àí1\nq\nif wt‚àí1 = œÑ ‚àí2 and vt‚àí1\nc\n> i‚àó\n0;\nvt‚àí1\nU,out\notherwise.\n(2.32)\nThis is a valid transition function by Lemma 18.\nWhen i ‚â§i‚àó\n0, we have vt‚àí1\nc\n‚â§i ‚â§i‚àó\n0. Thus, by the update rule\nviTU‚àí1\nU,out = viTU‚àí2\nU,out = q(xi | x:i).\nWhen i > i‚àó\n0, since wt‚àí1 = œÑ, ut‚àí1 = 1 implies that t is in the first step of some string loop. That\nis, t = (i ‚àí1)TU + (j ‚àí1)kœÑ + 1. By the update rule,\nv(i‚àí1)TU+(j‚àí1)kœÑ+1\nU,out\n= 1.\n38\n\nIt retains its value except when wt‚àí1 = œÑ ‚àí2. Combining with Equation (2.31), we have\nv(i‚àí1)TU+(j‚àí1)kœÑ+rœÑ‚àí1\nU,out\n=\nr\nY\nr1=1\nq(z(j)\nr1 | x:i0(i)+1 ¬∑ z(j)\n:r1) = q(z(j)\n:r+1 | x:i0(i)+1).\nTherefore, when r = k, we have\nv(i‚àí1)TU+jkœÑ‚àí1\nU,out\n= q(z(j)\n:k+1 | x:i0(i)+1) = q(z(j) | x:i0(i)+1).\nThe size of the RNN U is\n|U| = |Q| + |HQ| + 2k + 7.\nSince vU,out is reset to 1 for each string loop, the output node only depends on the hidden node set\nof H. Thus HU‚Ä≤ is also a hidden node set of U. The hidden node set size is\n|HU| = |HU‚Ä≤| = |HQ| + 2k + 6.\nLemma 8 (Computing Exponential of Weighted Distinguisher f2). Let n ‚ààN be the document\nlength and k, i‚àó\n0 ‚ààN with i‚àó\n0 ‚àà[0, k ‚àí1]. Let d : [n] √ó Œ£n ‚Üí{0, 1} be a next-k-token distinguisher\nimplemented by an RNN D. Let œÑ ‚ààN be an integer such that œÑ ‚â•TD + 2. Let x1, x2, ¬∑ ¬∑ ¬∑ , xn be\nthe input stream. Then there exists an RNN W with RNN-time TW = (2k + 1)kœÑ such that for any\ni‚àó\n0 < i ‚â§n,\nv(i‚àí1)TW +jkœÑ‚àí1\nW,out\n= exp\n\u0010\n‚àíŒ±d\n\u0010\ni0(i) + 1, x:i0(i) ¬∑ z(j)\u0011\u0011\n.\nThe RNN W has a size of |W| = |D|+|HD|+2k+7 and a hidden node set size of |HW | = |HD|+2k+6.\nProof. By Lemma 11, there exists an RNN W with RNN-time TU = (2k + 1)kœÑ such that when the\ninput index i > i‚àó\n0, for any j ‚àà[1, 2k], and t ‚àà[(i‚àí1)TW +(j ‚àí1)kœÑ +(k ‚àí1)œÑ +TQ, (i‚àí1)TW +jkœÑ],\nthe output node vW ‚Ä≤,out has value\nvt\nW ‚Ä≤,out = d\n\u0010\ni0(i) + 1, x:i0(i)+1 ¬∑ z(j)\u0011\n.\nNow we add node vW,out and treat it as the new output node of the RNN W. It is updated as\nvt\nW,out = exp(‚àíŒ±vt‚àí1\nW ‚Ä≤,out).\nFor any x ‚àà{0, 1}, by Lemma 18, the function f(x) = e‚àíŒ±x is a transition function. Thus for any\nt = (i ‚àí1)TW + jkœÑ ‚àí1,\nvt\nW,out = exp\n\u0010\n‚àíŒ±d\n\u0010\ni0(i) + 1, x:i0(i)+1 ¬∑ z(j)\u0011\u0011\n.\nSince vW,out only depends on vW ‚Ä≤,out in the previous time step. Thus, HW remains a hidden node\nset of W after modification. The size and hidden node set size of W is\n|W| = |D| + |HD| + 2k + 7,\n|HW | = |HD| + 2k + 6.\n39\n\nLemma 9 (Computing Indicator Functions g1 and g2). Let n ‚ààN be the document length. Let œÑ ‚â•4\nbe an integer. Let x1, x2, ¬∑ ¬∑ ¬∑ , xn be the input stream. Then there exists an RNN O with RNN-time\nTO = (2k + 1)kœÑ such that for any i‚àó\n0 < i ‚â§n, there exists two nodes v1, v2 such that\nv(i‚àí1)TO+jkœÑ‚àí1\n1\n= 1\n\u0010\nz(j)\n:i‚àíi0(i)+1 = xi0(i)+1:i+1\n\u0011\n,\nv(i‚àí1)TO+jkœÑ‚àí1\n2\n= 1\n\u0010\nz(j)\n:i‚àíi0(i) = xi0(i)+1:i\n\u0011\n.\nThe size |O| = 3k + 8 and its hidden node set size |HO| = 2k + 5.\nProof. To construct the RNN O, we include the input node vO,in, counter nodes w0, u0, w, u in\nClaim 1, the input storage node set Y in Claim 2, the enumerator node set E in Claim 3 from\nLemma 11, a node set {wl}k\nl=1, nodes v1, v2 and the output node vO,out. By Equation (2.9), for any\ntime t = (i ‚àí1)TO + (j ‚àí1)kœÑ + 2, the input storage nodes\nyt\nl =\n(\nxi0(i)+l\nif i ‚àíi0(i) ‚â•l;\n0\notherwise.\n(2.33)\nBy Equation (2.11), for any time t = (i ‚àí1)TO + (j ‚àí1)kœÑ + 2,\n(ze1, ¬∑ ¬∑ ¬∑ , zek)t = z(j).\n(2.34)\nNow we add k nodes wl, 1 ‚â§l ‚â§k, which update as\nwt\nl = 1\n\u0000yt‚àí1\nl\n= zt‚àí1\nel\n\u0001\n.\nThus when t = (i ‚àí1)TO + (j ‚àí1)kœÑ + 3, the node wl for l ‚â§i ‚àíi0(i) has value\nwt\nl = 1\n\u0010\nxi0(i)+l = z(j)\nel\n\u0011\n.\nNow we add two nodes v1, v2 to the RNN O, and has the following update rule:\nvt\n1 =\n( Pk\nl=1 wt‚àí1\nl\n¬∑ ut‚àí1\n0\n¬∑ 1\n\u0000l ‚â§ut‚àí1\n0\n\u0001\nif wt‚àí1 = 3 and ut‚àí1 = 1 and wt‚àí1\n0\n‚â§2kkœÑ;\nvt‚àí1\n1\notherwise.\n(2.35)\nvt\n2 =\n( Pk\nl=1 wt‚àí1\nl\n¬∑ ut‚àí1\n0\n¬∑ 1\n\u0000l ‚â§ut‚àí1\n0\n‚àí1\n\u0001\nif wt‚àí1 = 3 and ut‚àí1 = 1 and wt‚àí1\n0\n‚â§2kkœÑ;\nvt‚àí1\n1\notherwise.\n(2.36)\nThus, for any t ‚àà[(i ‚àí1)TO + (j ‚àí1)kœÑ + 4, (i ‚àí1)TO + jkœÑ],\nvt\n1 = 1\n\u0010\nz(j)\n:i‚àíi0(i)+1 = xi0(i)+1:i+1\n\u0011\n,\nvt\n2 = 1\n\u0010\nz(j)\n:i‚àíi0(i) = xi0(i)+1:i\n\u0011\n.\nThe RNN O has a size of\n|O| = 4 + k + k + 1 + k + 2 + 1 = 3k + 8.\nSince the nodes v1, v2 update their values at the third step of each string loop, based on the value of\nwl, u0 at the second step of the string loop, which depends on the value of yl and zel at the first step\nof the string loop, thus the output node at the end of each string loop only depends on the values of\nH) := {w0, u0, w, u, Y, E} at the first step of the string loop. As a result, the hidden node set size of\nO is\n|HO| = 4 + k + k + 1 = 2k + 5.\n40\n\n2.4.5\nProof of Lemma 3: RNN Boosting\nBased on Lemma 7, Lemma 8 and Lemma 9, we can prove Lemma 3, which realizes the boosted\nRNN language model. For the reader‚Äôs convenience, we restate Lemma 3 here.\nLemma 3 (RNN Boosting). For any language model q representable by an RNN Q, if there exists a\nnext-k-token distinguisher di(x) with advantage Œ±, representable by an RNN D, then there exists a\nlanguage model q‚Ä≤, representable by an RNN Q‚Ä≤, with size |Q‚Ä≤| = |Q|+|HQ|+|D|+|HD|+7k+25, hidden\nnode set size |HQ‚Ä≤| = |HQ| + |HD| + 6k + 17 and RNN-time T = TQ‚Ä≤ = (|Œ£|k + 1)k(max{TQ, TD} + 4)\nsuch that the next-token loss decreases by at least Œ±2/4k, i.e., L(q‚Ä≤) ‚àíL(q) ‚â§‚àíŒ±2/4k.\nProof. Let œÑ = max{TQ, TD} + 4. By Lemma 7, Lemma 8 and Lemma 9, there exists an RNN Q‚Ä≤\nwith RNN-time T = (2k + 1)kœÑ and has four nodes u1, u2, v1, v2 with values computed as follows:\n‚Ä¢ When input index 1 ‚â§i ‚â§i‚àó\n0,\nuiT‚àí1\n1\n= q(xi | x:i).\n‚Ä¢ When input index i > i‚àó\n0,\nu(i‚àí1)T+jkœÑ‚àí1\n1\n= q(z(j) | x:i0(i)+1) = f1(z(j), i).\nu(i‚àí1)T+jkœÑ‚àí1\n2\n= exp\n\u0010\n‚àíŒ±d\n\u0010\ni0(i) + 1, x:i0(i)+1 ¬∑ z(j)\u0011\u0011\n= f2(z(j), i).\nv(i‚àí1)T+jkœÑ‚àí1\n1\n= 1\n\u0010\nz(j)\n:i‚àíi0(i)+1 = xi0(i)+1:i+1\n\u0011\n= g1(z(j), i).\nv(i‚àí1)T+jkœÑ‚àí1\n2\n= 1\n\u0010\nz(j)\n:i‚àíi0(i) = xi0(i)+1:i\n\u0011\n= g2(z(j), i).\nRecall the counter nodes w0 in Claim 1 with value wt\n0 = (t ‚àí1) mod (T) + 1 and vc in Claim 7 with\nvalue\nvt\nc =\n(\ni1\nif t ‚àà[(i1 ‚àí1)T + 1, i1T] and i1 ‚â§i‚àó\n0 + 1;\ni‚àó\n0 + 1\notherwise.\nWe add nodes w1, w2 and the output node vout to the RNN Q‚Ä≤, which are initialized as 0 and updated\nas follows.\nwt\n1 = wt‚àí1\n1\n+\n\u0000ut‚àí1\n1\n¬∑ ut‚àí1\n2\n¬∑ vt‚àí1\n1\n\u0001\n¬∑ 1\n\u0000wt‚àí1\n0\n= jkœÑ ‚àí1\n\u0001\n.\n(2.37)\nwt\n2 = wt‚àí1\n2\n+\n\u0000ut‚àí1\n1\n¬∑ ut‚àí1\n2\n¬∑ vt‚àí1\n2\n\u0001\n¬∑ 1\n\u0000wt‚àí1\n0\n= jkœÑ ‚àí1\n\u0001\n.\n(2.38)\nvt\nout =\n(\nut‚àí1\n1\nif vt‚àí1\nc\n‚â§i‚àó\n0;\nwt‚àí1\n1\n/wt‚àí1\n1\notherwise.\n(2.39)\nThus, when the input index 1 ‚â§i ‚â§i‚àó\n0, the output node\nviT\nout = uiT‚àí1\n1\n= q(xi | x:i).\nWhen the input index i > i‚àó\n0, the nodes w1 and w2 has values\nw(i‚àí1)T+jkœÑ\n1\n=\nj\nX\nj‚Ä≤=1\nf1(z(j‚Ä≤), i)f2(z(j‚Ä≤), i)g1(z(j‚Ä≤), i)\nw(i‚àí1)T+jkœÑ\n2\n=\nj\nX\nj‚Ä≤=1\nf1(z(j‚Ä≤), i)f2(z(j‚Ä≤), i)g2(z(j‚Ä≤), i).\n41\n\nThus,\nviT\nout = v(i‚àí1)T+2kkœÑ+1\nout\n=\nP2k\nj‚Ä≤=1 f1(z(j‚Ä≤), i)f2(z(j‚Ä≤), i)g1(z(j‚Ä≤), i)\nP2k\nj‚Ä≤=1 f1(z(j‚Ä≤), i)f2(z(j‚Ä≤), i)g2(z(j‚Ä≤), i)\n= q‚Ä≤(xi | x:i).\nBy Lemma 2, the output of of the constructed RNN Q‚Ä≤ at time iT realizes the conditional probability\nq‚Ä≤(xi | x:i) in Equation (1.3). By Lemma 1, it satisfies that\nDKL(¬Øp‚à•¬Øq‚Ä≤) ‚â§DKL(¬Øp‚à•¬Øq) ‚àíŒ±2n\n4k .\nBy Lemma 6, it is equivalent to say\nL(q‚Ä≤) ‚àíL(q) ‚â§‚àíŒ±2\n4k .\nThe size of the constructed RNN Q‚Ä≤ is\n|Q‚Ä≤| = |Q| + |HQ| + 2k + 7 + |D| + |HD| + 2k + 7 + 3k + 8 + 3 = |Q| + |D| + |HQ| + |HD| + 7k + 25.\nThe hidden node set size of the constructed RNN Q‚Ä≤ is\n|HQ‚Ä≤| = |HQ| + 2k + 6 + |HD| + 2k + 6 + 2k + 5 = |HQ| + |HD| + 6k + 17.\n3\nProof of the Main Theorem\nOur main result states that minimizing next-token loss yields an LM that is œµ-indistinguishable from\nthe true data distribution for any RNN-based next-k-token distinguisher of size up to d.\nTheorem 1 (Minimizing Next-token Loss Yields an Indistinguishable LM). For any 0 < œµ <\n1, k, œÑ, d ‚ààN, for alphabet size |Œ£| = O(1), with probability at least 0.9, by trying only two model\nsizes and minimizing next-token loss, we can output an LM q with the following properties:\n1. The model q is œµ-indistinguishable from the training distribution p for any next-k-token distin-\nguisher d : [n] √ó Œ£n ‚Üí{0, 1} realized by an RNN of size |d| ‚â§d and RNN-time T(d) ‚â§œÑ.\n2. The model q has size O\n\u0010\nk2\nœµ4 (d + k)\n\u0011\nand RNN-time œÑ ¬∑ (k2k)O\n\u0010\nk\nœµ2\n\u0011\n.\nThe result naturally extends to any alphabet size |Œ£|, as shown in the theorem proof.\nChoice of Hyperparameters.\nWe first choose an integer index j0 uniformly from the range\n[4k log |Œ£|/œµ2, 44k log |Œ£|/œµ2]. Then for i ‚â•1, we choose the the i-th set of hyperparameters by the\nnetwork size Ni = 17(d + k)(j0 + i)2, hidden node set size Hi = 12(d + k)(j0 + i) and RNN-time\nTi =\n\u00008k|Œ£|k\u0001j0+i‚àí1 œÑ. For the i-th set of hyperparameters of RNN, we train an LM by minimizing\nthe next-token log loss. Let ÀÜqi be the optimal solution and Li := L(ÀÜqi) be its loss. We terminate\nthe procedure when the loss decreases by at most œµ2/4k compared to the previous model. That\nis, it terminates and outputs qi if Li ‚àíLi+1 < œµ2/4k. The full procedure is formally described in\nAlgorithm 1.\nWhen optimizing over RNNs under structural constraints, even though the exact network structure\nis not known a priori, we can define a universal graph that encompasses all valid architectures within\n42\n\nAlgorithm 1 Minimizing Next-token Loss, Practically\nInput: Token set Œ£, distinguisher window size k, distinguisher size bound d, distinguisher RNN-time\nbound œÑ, distinguisher advantage bound œµ.\nOutput: An indistinguishable language model.\n1 Choose an index j0 uniformly from [4k log |Œ£|/œµ2, 44k log |Œ£|/œµ2].\n2 for i = j0 + 1, j0 + 2, ¬∑ ¬∑ ¬∑ do\n3\nMinimize the next-token loss on an RNN of size Ni = 17(d + k)i2, hidden node set size\nHi = 12(d + k)i and RNN-time Ti = (8k|Œ£|k)i‚àí1œÑ.\n4\nLet the optimal LM in size Ni be qi with loss Li.\n5\nif Li‚àí1 ‚àíLi < œµ2/4k and i ‚â•2 then return the LM qi‚àí1.\n6 end\nùíóin\nùêª\nùëÖ\nùë£out\nFigure 3.1: A universal graph that encompasses all RNNs with constraints on size, hidden node set\nsize, and RNN-time.\nthe constraint class. Specifically, suppose we are constrained to RNNs of size at most N, hidden\nnode set size at most H and RNN-time at most T with N, H, T ‚ààN and H < N. We can construct\na fixed graph with N nodes that allows searching over all valid RNNs within this class. Let vin be\nthe input node, H ‚äÇG \\ {vin} be the hidden node set size, and R = G\\ (H S{vin}) be the remaining\nN ‚àíH ‚àí1 nodes, used for stateless computation. We then define the edges of G as follows.\n‚Ä¢ For each pair of nodes h1, h2 ‚ààH, we add two edges (h1, h2) and (h2, h1) to the graph.\n‚Ä¢ For each node h ‚ààH, we add an edge (vin, h) to the graph.\n‚Ä¢ For each node r ‚ààH ‚à™R, and any node r ‚ààR, we add an edge (v, r).\n‚Ä¢ Each node r ‚ààR is reset to 0 whenever a new input is fed into the model.\nSince the weights between nodes can be zero, the constructed graph is general enough to represent\nany RNN with constraints on size, hidden node set size and RNN-time. Figure 3.1 gives a sketch of\nthis universal graph.\nBefore proving Theorem 1, we first prove Lemma 4, which formulates self-boosting by loss\nminimization. We restate the lemma here for the reader‚Äôs convenience.\nLemma 4 (Model Self-boosting and Loss Minimization). Let Q be a set of models, where each q ‚ààQ\nhas size |q| ‚ààN, time T(q) ‚ààN and a value h(q) ‚ààR. There exists a q1 ‚ààQ with |q1| = 1, T(q1) = 1\nand h(q1) = h0 for some h0 ‚ààR. Let C be a set of functions c : Q ‚ÜíR+ ‚à™{0} and Œ≤, Œ≥, Œ¥, Œ∏, Œ∂ ‚â•0.\nSuppose there is a loss function L : Q ‚ÜíR+ ‚à™{0} such that, for every q ‚ààQ, c ‚ààC, there exists an\nq‚Ä≤ ‚ààQ with\n|q‚Ä≤| ‚â§|q| + h(q) + Œ≤,\nT(q‚Ä≤) ‚â§Œ≥T(q) + Œ¥,\nh(q‚Ä≤) ‚â§Œ∏h(q) + Œ∂,\nL(q‚Ä≤) ‚â§L(q) ‚àíc(q).\nDefine three sequences {Ni}i‚â•1, {Ti}i‚â•1, {Hi}i‚â•1 as follows.\nN1 = 1, Ni+1 = Ni + Hi + Œ≤;\n(1.6)\n43\n\nT1 = 1, Ti+1 = Œ≥Ti + Œ¥;\n(1.7)\nH1 = 1, Hi+1 = Œ∏Hi + Œ∂.\n(1.8)\nThen there exists a set Bœµ ‚äÇ{Ni}i‚â•1, such that for any œµ > 0, for all Nj ‚àà{Ni}i‚â•1 \\ Bœµ, every ÀÜq ‚ààQ\nwhich minimizes L(q) over Cj := {q ‚ààQ | |q| ‚â§Nj, T(q) ‚â§Tj, h(q) ‚â§Hj} satisfies\nmax\nx‚ààC c(ÀÜq) ‚â§œµ.\nSpecifically, Bœµ := {Nj ‚àà{Ni}i‚â•1 | Lj+1 < Lj ‚àíœµ} for Lj := min\nq‚ààCj L(q). Also, |Bœµ| ‚â§L(q1)/œµ.\nProof. Let Nj ‚àà{Ni}i‚â•1 \\ Bœµ and ÀÜq is the minimizer of L(q) over Cj. Then for any function c ‚ààC,\nthere is an q‚Ä≤ ‚ààQ with size\n|q‚Ä≤| ‚â§|ÀÜq| + h(ÀÜq) + Œ≤ ‚â§Nj + Hj + Œ≤ = Nj+1,\ntime\nT(q‚Ä≤) ‚â§Œ≥T(ÀÜq) + Œ¥ ‚â§Œ≥Hj + Œ¥ = Tj+1,\nvalue\nh(q‚Ä≤) ‚â§Œ∏h(ÀÜq) + Œ∂ ‚â§Œ∏Hj + Œ¥ = Hi+1,\nand loss\nL(q‚Ä≤) ‚â§L(ÀÜq) ‚àíc(ÀÜq) = Lj ‚àíc(ÀÜq).\nSince q‚Ä≤ satisfies the constraints for N + Œ≤ in size, time and value, we know q‚Ä≤ ‚ààCj+1. Thus,\nLj+1 ‚â§L(q‚Ä≤) ‚â§Lj ‚àíc(ÀÜq).\n(3.1)\nBy the definition of Bœµ, we know Lj+1 ‚â•Lj ‚àíœµ. Combining with Equation (3.1), we have\nLj ‚àíœµ ‚â§Lj+1 ‚â§Lj ‚àíc(ÀÜq)\nThis leads to c(ÀÜq) ‚â§œµ for any c ‚ààC.\nNext, we will bound the size of Bœµ. Observe that as i increases, the feasible region of the\noptimization problem expands. As a result, the optimal loss Li is monotonically decreasing. Since\nthe loss function is always non-negative, the number of j‚Äôs such that Lj+1 < Lj ‚àíœµ is no more than\nL1/œµ. In other words, |Bœµ| ‚â§L1/œµ.\nNow we are ready to prove Theorem 1 using Lemma 3 and Lemma 4.\nProof of Theorem 1. The sequences {Ni}i‚â•1, {Hi}i‚â•1, {Ti}i‚â•1 are defined in Algorithm 1. By com-\nputation, the network size for index i + 1 is\nNi+1 =17(d + k)(j + i + 1)2\n=17(d + k)(j + i)2 + 34(d + k)(j + i) + 17(d + k)\n‚â•Ni + Hi + 2d + 7k + 25,\nand its hidden node set size is\nHi+1 =12(d + k)(j + i + 1)\n=12(d + k)(j + i) + 12(d + k)\n44\n\n‚â•Hi + d + 6k + 17.\nCombining with Lemma 3, we know for any language model q constructed with RNN Q with size Ni,\nhidden node set size Hi and RNN-time Ti, if there exists a distinguisher RNN D with size |D| ‚â§d\nthat has advantage Œ±, then we can construct a language model q‚Ä≤ implemented by an RNN Q‚Ä≤ with\nsize no more than Ni+1, hidden node set size no more than Hi+1 and RNN-time no more than Ti+1,\nsuch that\nL(q‚Ä≤) ‚àíL(q) ‚â§‚àíŒ±2\n4k .\nThen we apply Lemma 4 by using the value function h(q) as the number of hidden node set size\nof the model q. Let the set Bœµ = {Nj ‚àà{Ni}i‚â•1 | Lj+1 < Lj ‚àíœµ2/4k}. Then for any œµ > 0, for all\nNi ‚àà{Ni}i‚â•1 \\ Bœµ, every ÀÜq which minimizes L(q) over Cj = {q | |q| ‚â§Nj, T(q) ‚â§Tj, h(q) ‚â§Hj}\nsatisfies that for any next-k-token RNN distinguisher d of size |d| ‚â§d and RNN-time T(d) ‚â§œÑ,\nŒ±2\n4k ‚â§œµ2\n4k.\nEquivalently, the advantage for any distinguisher is at most œµ.\nThe algorithm terminates with a network size Ni /‚ààBœµ. Consequently, for any next-k-token\ndistinguisher of size up to d and RNN-time up to œÑ, the output LM is œµ-indistinguishable.\nNext, we will bound the size of Bœµ. Let ¬Øq0 be the uniform distribution, which can be realized by\nan RNN of size, hidden node set size and RNN-time one (with constant output on the next-token\nprobability). Then the KL divergence between ¬Øp and ¬Øq0 can be bounded by\nDKL(¬Øp‚à•¬Øq0) = E\nx‚àº¬Øp log ¬Øp(x)\n¬Øq0(x) =\nZ\n¬Øp(x) log\n¬Øp(x)\n1/|Œ£|n =\nZ\n¬Øp(x) log ¬Øp(x) + n log |Œ£| ‚â§n log |Œ£|\nSince KL divergence is nonnegative, the size of Bœµ, or equivalently, the number of j0‚Äôs where the KL\ndecreases by at least œµ2n/4k can be bounded by\nDKL(¬Øp‚à•¬Øq0)\nœµ2n/4k\n‚â§n log |Œ£|\nœµ2n/4k = 4k log |Œ£|\nœµ2\nSince the index j0 is uniformly chosen from [4k log |Œ£|/œµ2, 44k log |Œ£|/œµ2], the probability that\nNj0 ‚ààBœµ is less than 0.1. Therefore, the probability that we only try two model sizes, that is, if the\nfirst model size that we try is not in Bœµ, is 0.9.\nAssume that the algorithm terminates with size Ni‚Ä≤. This implies that for each i ‚àà[j0 + 1, i‚Ä≤), we\nhave DKL(¬Øp‚à•¬Øqi) ‚àíDKL(¬Øp‚à•¬Øqi+1) > œµ2n/4k. Summing over i, we obtain DKL(¬Øp‚à•¬Øqj0+1) ‚àíDKL(¬Øp‚à•¬Øqi‚Ä≤) >\n(i‚Ä≤ ‚àíj0 ‚àí1)œµ2n/4k. Since DKL(¬Øp‚à•¬Øqj0+1) ‚â§DKL(¬Øp‚à•¬Øq0) ‚â§n log |Œ£|, we have\ni‚Ä≤ ‚àíj0 ‚àí1 < DKL(¬Øp‚à•¬Øqj0+1)\nœµ2n/4k\n‚â§n log |Œ£|\nœµ2n/4k = 4k log |Œ£|\nœµ2\n.\nThus, the final output LM has size bounded by\nNi‚Ä≤ =17(d + k)i‚Ä≤2\n‚â§17(d + k)\n\u001244k log |Œ£|\nœµ2\n+ 4k log |Œ£|\nœµ2\n+ 1\n\u00132\n=O\n\u0012 1\nœµ4 (d + k)k2 log2 |Œ£|\n\u0013\n45\n\nIts RNN-time is bounded by\nTNi‚Ä≤ =\n\u0010\n8k|Œ£|k\u0011i‚Ä≤‚àí1\n¬∑ œÑ ‚â§\n\u0010\n8k|Œ£|k\u0011 48k log |Œ£|\nœµ2\n¬∑ œÑ =\n\u0010\nk|Œ£|k\u0011O\n\u0010\nk log |Œ£|\nœµ2\n\u0011\n¬∑ œÑ\n3.1\nBounding the bit size\nIn this section, we bound the total space required by the learned language model in terms of the\nbit sizes of the numbers it maintains. The key technical ingredient is Lemma 12, which generalizes\nLemma 3 to the setting of bounded bit size. We first recall the bit size of an RNN.\nDefinition 4 (Bit Size of the RNN). The bit size of an RNN Q is the number of bits needed\nto encode the value stored in each node at any time step, denoted by ‚ü®Q‚ü©= 1 + ‚ü®Q‚ü©I + ‚ü®Q‚ü©F .\nFormally, we fix a signed fixed-point representation with one sign bit, ‚ü®Q‚ü©I integer bits, and ‚ü®Q‚ü©F\nfractional bits. Each real number r stored in a node is represented as r = sign(r) (rI + rF ), where\nsign(r) ‚àà{+1, ‚àí1} is the sign of r, rI is its integer part in the range [1, 2‚ü®Q‚ü©I], and rF ‚àà[0, 1) is a\nits fractional part as a multiple of 2‚àí‚ü®Q‚ü©F .\nFor each real number x ‚ààR, where x = xI + xF with xI ‚ààZ and xF ‚àà[0, 1). We define the\nquantizer\nQb(x) := min\n\u0010\nxI, 2bI\n\u0011\n+ 2‚àíbF ¬∑\nj xF\n2‚àíbF\nk\n.\nWe say that the quantizer QbF (x) induces an absolute (additive) error Œ¥ if |QbF (x) ‚àíx| ‚â§Œ¥.\nAlgorithm 2 Minimizing Next-token Loss with Bounded Bit Size\nInput: Vocabulary set size |Œ£|, distinguisher window size k, distinguisher size bound d, distinguisher\nRNN-time bound œÑ, distinguisher bit size bound bD, distinguisher advantage bound œµ.\nOutput: An indistinguishable language model.\n7 Choose an index j0 uniformly from [16k log |Œ£|/œµ2, 176k log |Œ£|/œµ2].\n8 for i = j0 + 1, j0 + 2, ¬∑ ¬∑ ¬∑ do\n9\nMinimize the next-token loss on an RNN of size Ni = 17(d+k)i2, hidden node set size Hi = 12(d+\nk)i, RNN-time Ti = (8k|Œ£|k)i‚àí1œÑ, bit size bi = bD+3k log |Œ£|i2+i log œÑ +772\n\u0010\nk2\nœµ2 log |Œ£| + log 1\nœµ\n\u0011\n,\nand next-token probability lower bound ‚Ñìi =\n0.99\n|Œ£|4i‚àí1 .\n10\nLet the optimal LM in size Ni be qi with loss Li.\n11\nif Li‚àí1 ‚àíLi < œµ2/8k and i ‚â•j0 + 2 then return the LM qi‚àí1.\n12 end\nWe show in the following theorem that minimizing next-token loss yields an œµ-indistinguishable\nLM with bounded bit size.\nTheorem 2 (Main result with Bounded Bit Size). For any 0 < œµ < 1, bD, k, œÑ, d ‚ààN, Algorithm 2\noutputs an LM q with the following properties:\n1. The model q is œµ-indistinguishable from the training distribution p for any next-k-token distin-\nguisher d : [n] √ó Œ£n ‚Üí{0, 1} realized by an RNN of size |d| ‚â§d, RNN-time T(d) ‚â§œÑ and bit\nsize ‚ü®d‚ü©‚â§bD.\n46\n\n2. The model q has size O\n\u0010\nk2\nœµ4 (d + k) log2 |Œ£|\n\u0011\n, RNN-time O\n\u0012\nœÑ ¬∑ (k|Œ£|k)\n48k log |Œ£|\nœµ2\n\u0013\n, and bit-size\nO\n\u0010\nbD + k3 log2 |Œ£|\nœµ4\n+ k\nœµ2 log œÑ log |Œ£|\n\u0011\n.\nMoreover, with probability at least 0.9, the number of model sizes attempted is two.\nSimilar to the proof of Theorem 1, we use Lemma 12 to construct a boosted LM using a\ndistinguisher with controlled bit size, and then apply Lemma 4 to achieve indistinguishability. We\nstate and prove Lemma 12 before proving the theorem.\nLemma 12 (Boosted RNN with Bounded Bit Size). Let 0 < Œ±, ‚Ñì, Œ¥ ‚â§1, and integers k, b, bI, bF ,\nbD, bD,I, bD,F , TD ‚ààN satisfying b = 1 + bI + bF , bD = 1 + bD,I + bD,F , bI ‚â•bD,I + k log |Œ£| +\nlog (kTD) + 1, bF ‚â•bD,F , 2‚àíbF ‚â§Œ±2‚Ñìk+1\n1088k2 . Let q be any language model represented by an RNN Q\nwith bit size b (with bI integer bits and bF fractional bits). Its next-token conditional probabilities are\nall at least ‚Ñì. Suppose there exists a next-k-token distinguisher d for q with advantage Œ±, implemented\nby an RNN D of bit size bD (with bD,I integer bits and bD,F fractional bits) and RNN-time TD. Then\nthere exists a language model q‚Ä≤, implemented by an RNN Q‚Ä≤ with size and hidden node set size\n|Q‚Ä≤| = |Q| + |HQ| + |D| + |HD| + 7k + 25,\n|HQ‚Ä≤| = |HQ| + |HD| + 6k + 17,\nbit size\n‚ü®Q‚Ä≤‚ü©= b + log(TQ),\n‚ü®Q‚Ä≤‚ü©I = bI + log(TQ),\n‚ü®Q‚Ä≤‚ü©F = bF .\nRNN-time\nTQ‚Ä≤ = (|Œ£|k + 1)k(max{TQ, TD} + 4),\nand all next-token conditional probabilities are lower bounded by\n‚Ñì‚Ä≤ = ‚Ñì/4,\nsuch that its next-token loss satisfies\nL(q‚Ä≤) ‚àíL(q) ‚â§‚àíŒ±2/8k.\nProof. Let b‚Ä≤ = 1 + b‚Ä≤\nI + b‚Ä≤\nF , where we assign the first bit to denote the sign, b‚Ä≤\nI bits for integers, and\nbF bits for fractions.\nBy Lemma 3, we can boost the LM q by the distinguisher d to an LM Àúq‚Ä≤ realized by an\nunbounded-bit-size RNN ÀúQ‚Ä≤ such that\nL(Àúq‚Ä≤) ‚àíL(q) ‚â§‚àíŒ±2/4k.\n(3.2)\nThe RNN ÀúQ‚Ä≤ satisfies\n| ÀúQ‚Ä≤| = |Q| + |HQ| + |D| + |HD| + 7k + 25,\n|H ÀúQ‚Ä≤| = |HQ| + |HD| + 6k + 17,\nand has RNN-time\nTÀúQ‚Ä≤ = (|Œ£|k + 1)k(max{TQ, TD} + 4).\nWe now construct the RNN Q‚Ä≤ by restricting the bit size of the RNN ÀúQ‚Ä≤ to b‚Ä≤ = 1 + b‚Ä≤\nI + b‚Ä≤\nF . Because\nthe quantization does not change the size, the hidden node set size, or the RNN-time of an RNN, we\nimmediately obtain\n|Q‚Ä≤| = | ÀúQ‚Ä≤| = |Q‚Ä≤| + |HQ| + |D| + |HD| + 7k + 25,\n|H‚Ä≤\nQ| = |H ÀúQ‚Ä≤| = |HQ| + |HD| + 6k + 17,\n47\n\nand\nTQ‚Ä≤ = TÀúQ‚Ä≤ = (|Œ£|k + 1)k(max{TQ, TD} + 4).\nTo analyze the bit size and bound the output error induced by quantization, we compute the integer\npart and the fractional part in Claim 9 and Claim 10, respectively. We recall from Equation (1.4),\nthere exists an index i‚àó\n0 ‚àà[0, k ‚àí1] and a set I = {i ‚àà[n] | i ‚â°i‚àó\n0 (mod k)} such that q‚Ä≤ is computed\nas\nq‚Ä≤(xi | x:i) =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nQb‚Ä≤ (q(xi | x:i))\nif i ‚â§i‚àó\n0;\nQb‚Ä≤\nÔ£´\nÔ£¨\nÔ£¨\nÔ£¨\nÔ£¨\nÔ£≠\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0\nQb‚Ä≤\n\u0010\nq(xi0+1:i+1 ¬∑ s | x:i0+1)e‚àíŒ±di0+1(x:i+1¬∑s)\u0011!\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0+1 Qb‚Ä≤\n\u0010\nq(xi0+1:i ¬∑ s | x:i0+1)e‚àíŒ±di0+1(x:i¬∑s)\u0011!\nÔ£∂\nÔ£∑\nÔ£∑\nÔ£∑\nÔ£∑\nÔ£∏\nif i = i0 + r0,\ni0 ‚ààI,\n1 ‚â§r0 ‚â§k.\nHere, the quantization step Qb‚Ä≤(v) is applied for each node v computed in the RNN Q‚Ä≤.\nClaim 9 (Integer Bit Size). The integer bit size of Q‚Ä≤ can be bounded by\nb‚Ä≤\nI = bI + log(TQ).\nProof. We bound the integer bit size by finding the upper bound of the node values in the RNN Q‚Ä≤.\nOur construction of the RNN Q‚Ä≤ as in Lemma 3 is based on Lemma 7, Lemma 8 and Lemma 9.\nThe main part of the three lemmas is based on Lemma 11.\nSpecifically, in Claim 1, the\ncounter nodes are bounded by TQ‚Ä≤ = (|Œ£|k + 1)k max {TQ, TD}, thus they can be represented\nusing k log |Œ£| + 1 + log(k max {TQ, TD}) bits. In Claim 2 and Claim 3, each node in Y and E is\nupper bounded by |Œ£|, and thus can be represented using log |Œ£| bits. In Claim 4, Claim 5 and\nClaim 6, each node in H, ÀúH and R has a corresponding node in the RNN Q, and thus are upper\nbounded by max{2bI, 2bD,I}, with max{bI, bD,I} integer bits. The extra counter node in Claim 7 is\nbounded by k, which can be represented with log(k) bits. Thus, the integer bit size of these three\nlemmas is bounded by max{k log |Œ£| + log k + log(max {TQ, TD}) + 1, log |Œ£|, bI, bD,I, log(k). Since\nbI ‚â•bD,I + k log |Œ£| + log(kTD) + 1, the integer bit size can be upper bounded by\nmax{k log |Œ£| + log k + log(max {TQ, TD}) + 1, log |Œ£|, bI, bD,I, log(k)} ‚â§bI + log(TQ).\nFor the additional nodes introduced in the proof of Lemma 3, the nodes w1 and w2 compute the\nsummation of reweighted probabilities and are therefore bounded above by eŒ±. The final output\nnode, which represents a probability, is bounded by 1. Thus, their integer part requires only a\nconstant number of bits.\nThus, we can set the integer bits as follows.\nb‚Ä≤\nI = bI + log(TQ).\nClaim 10 (Fractional Bit Size). By using b‚Ä≤\nF = bF fractional bits, the output probability q‚Ä≤ satisfies\nthat for any x ‚ààŒ£‚àóand any i ‚ààN,\n\f\fq‚Ä≤(xi | x:i) ‚àíÀúq‚Ä≤(xi | x:i)\n\f\f ‚â§17k2‚àíbF\n‚Ñìk\n.\n48\n\nProof. Firstly, for the input index i ‚â§i‚àó\n0, it outputs the same as q, and thus has no quantization\nerror by using bF bits. We next analyze the case when i > i‚àó\n0. Define f1, f2 : Œ£k‚àír0 ‚Üí[0, 1] as\nf1(s) = q (xi0+1:i+1 ¬∑ s | x:i0+1) ,\nf2(s) = exp (‚àíŒ±di0+1(x:i+1 ¬∑ s)) .\nSimilarly, we define h1, h2 : Œ£k‚àír0+1 ‚Üí[0, 1] defined as\nh1(s) = q (xi0+1:i ¬∑ s | x:i0+1) ,\nh2(s) = exp (‚àíŒ±di0+1(x:i ¬∑ s)) .\nSince we do quantization using b‚Ä≤ bits on each node, for i ‚â•i‚àó\n0 + 1,\nq‚Ä≤(xi | x:i) = Qb‚Ä≤\nÔ£´\nÔ£¨\nÔ£¨\nÔ£¨\nÔ£¨\nÔ£≠\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0\nQb‚Ä≤ (f1(s)f2(s))\n!\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0+1 Qb‚Ä≤ (h1(s)h2(s))\n!\nÔ£∂\nÔ£∑\nÔ£∑\nÔ£∑\nÔ£∑\nÔ£∏\n.\n(3.3)\nSince the quantization using bF fractional bits induces Œ¥1 := 2‚àíbF absolute error, for each s ‚ààŒ£k‚àír0,\nwe have\n|Qb‚Ä≤(f1(s)f2(s)) ‚àíf1(s)f2(s)| ‚â§Œ¥1.\nWhen summing over s, we have\n\f\f\f\f\f\f\nX\ns‚ààŒ£k‚àír0\nQb‚Ä≤ (f1(s)f2(s)) ‚àí\nX\ns‚ààŒ£k‚àír0\nf1(s)f2(s)\n\f\f\f\f\f\f\n‚â§\nX\ns‚ààŒ£k‚àír0\n|Qb‚Ä≤ (f1(s)f2(s)) ‚àíf1(s)f2(s)|\n‚â§|Œ£|k‚àír0(2k + 1)Œ¥1.\nBy a further step of quantization, we have\n\f\f\f\f\f\f\nQb‚Ä≤\nÔ£´\nÔ£≠\nX\ns‚ààŒ£k‚àír0\nQb‚Ä≤ (f1(s)f2(s))\nÔ£∂\nÔ£∏‚àí\nX\ns‚ààŒ£k‚àír0\nf1(s)f2(s)\n\f\f\f\f\f\f\n‚â§|Œ£|k‚àír0(2k + 1)Œ¥1 + Œ¥1 ‚â§|Œ£|k‚àír0(2k + 2)Œ¥1.\n(3.4)\nSimilarly, we have\n\f\f\f\f\f\f\nQb‚Ä≤\nÔ£´\nÔ£≠\nX\ns‚ààŒ£k‚àír0+1\nQb‚Ä≤ (h1(s)h2(s))\nÔ£∂\nÔ£∏‚àí\nX\ns‚ààŒ£k‚àír0+1\nh1(s)h2(s)\n\f\f\f\f\f\f\n‚â§|Œ£|k‚àír0+1(2k + 2)Œ¥1.\n(3.5)\nCombining Equation (3.4) and Equation (3.5), we have\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0\nQb‚Ä≤ (f1(s)f2(s))\n!\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0+1 Qb‚Ä≤ (h1(s)h2(s))\n! ‚â§\nP\ns‚ààŒ£k‚àír0\nf1(s)f2(s) + |Œ£|k‚àír0+1(2k + 2)Œ¥1\nP\ns‚ààŒ£k‚àír0+1 h1(s)h2(s) ‚àí|Œ£|k‚àír0+1(2k + 2)Œ¥1\n.\n(3.6)\n49\n\nSince the next-token probability of q is lower bounded by ‚Ñìwe have\nX\ns‚ààŒ£k‚àír0+1\nh1(s)h2(s) ‚â•e‚àíŒ±\nX\ns‚ààŒ£k‚àír0+1\nq(xi0+1:is | x:i0+1) ‚â•e‚àíŒ±|Œ£|k‚àír0+1‚Ñìk.\n(3.7)\nSince Œ¥1 = 2‚àíbI ‚â§Œ±2‚Ñìk+1\n1088k2 ‚â§e‚àíŒ±‚Ñìk\n4(k+1), we have\ne‚àíŒ±|Œ£|k‚àír0+1‚Ñìk ‚â•2|Œ£|k‚àír0+1(2k + 2)Œ¥1.\nGiven the lower bound of P\ns‚ààŒ£k‚àír0+1 h1(s)h2(s) as in Equation (3.7), we can apply Lemma 14 as\nfollows.\nP\ns‚ààŒ£k‚àír0\nf1(s)f2(s) + |Œ£|k‚àír0+1(2k + 2)Œ¥1\nP\ns‚ààŒ£k‚àír0+1 h1(s)h2(s) ‚àí|Œ£|k‚àír0+1(2k + 2)Œ¥1\n‚àí\nP\ns‚ààŒ£k‚àír0\nf1(s)f2(s)\nP\ns‚ààŒ£k‚àír0+1 h1(s)h2(s)\n‚â§\n2|Œ£|k‚àír0+1(2k + 2)Œ¥1\ne‚àíŒ±|Œ£|k‚àír0+1‚Ñìk ‚àí|Œ£|k‚àír0+1(2k + 2)Œ¥1\n‚â§2|Œ£|k‚àír0+1(2k + 2)Œ¥1\n1\n2e‚àíŒ±|Œ£|k‚àír0+1‚Ñìk\n‚â§8(k + 1)Œ¥1eŒ±\n‚Ñìk\nCombining this inequality with Equation (3.6), we have\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0\nQb‚Ä≤ (f1(s)f2(s))\n!\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0+1 Qb‚Ä≤ (h1(s)h2(s))\n! ‚â§Àúq‚Ä≤(xi | x:i) + 8(k + 1)Œ¥1eŒ±\n‚Ñìk\n.\nIn the same way, we can show that\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0\nQb‚Ä≤ (f1(s)f2(s))\n!\nQb‚Ä≤\n \nP\ns‚ààŒ£k‚àír0+1 Qb‚Ä≤ (h1(s)h2(s))\n! ‚â•Àúq‚Ä≤(xi | x:i) ‚àí8(k + 1)Œ¥1eŒ±\n‚Ñìk\n.\nBy one more step of quantization on the output node, we get\n\f\fq‚Ä≤(xi | x:i) ‚àíÀúq‚Ä≤(xi | x:i)\n\f\f ‚â§8(k + 1)Œ¥1eŒ±\n‚Ñìk\n+ Œ¥1 ‚â§17kŒ¥1\n‚Ñìk\n.\nFrom Claim 9 and Claim 10, by using b‚Ä≤ = 1 + b‚Ä≤\nI + b‚Ä≤\nF bits, the quantized LM q‚Ä≤ has absolute\nerror Œ¥2 = 17kŒ¥1/‚Ñìk.\nBy Lemma 15, for any x ‚ààŒ£‚àóand i ‚ààN,\nÀúq‚Ä≤(xi | x:i) ‚â•‚Ñì/3.\n50\n\nThus,\nq‚Ä≤(xi | x:i) ‚â•‚Ñì/3 ‚àí17kŒ¥1/‚Ñìk ‚â•‚Ñì/3 ‚àí‚Ñì/12 = ‚Ñì/4 = ‚Ñì‚Ä≤.\nThe last inequality holds because Œ¥1 ‚â§Œ±2‚Ñìk+1\n1088k2 ‚â§‚Ñìk+1\n204k.\nFinally, we will compute the improvement of next-token loss. By Lemma 16,\nE\nx‚àº¬Øp log\n¬Øq‚Ä≤(x)\n¬ØÀúq‚Ä≤(x) ‚â§n ¬∑\nŒ¥2\n‚Ñì‚Ä≤ ‚àíŒ¥2\n.\nAlso by Lemma 3, we have\n1\nn E\nx‚àº¬Øp log\n\u0012 ¬ØÀúq‚Ä≤(x)\n¬Øq(x)\n\u0013\n= L(Àúq‚Ä≤) ‚àíL(q) ‚â§‚àíŒ±2\n4k .\nThus, by the definition of next-token loss, we have\nL(q‚Ä≤) ‚àíL(q) = E\nx‚àº¬Øp\n\"\n‚àí1\nn\nn\nX\ni=1\nlog q‚Ä≤(xi | x:i) + 1\nn\nn\nX\ni=1\nlog q(xi | x:i)\n#\n= 1\nn E\nx‚àº¬Øp log\n\u0012 ¬Øq‚Ä≤(x)\n¬Øq(x)\n\u0013\n= 1\nn E\nx‚àº¬Øp log ¬Øq‚Ä≤(x)\n¬ØÀúq‚Ä≤(x) + 1\nn E\nx‚àº¬Øp log\n¬ØÀúq‚Ä≤(x)\n¬Øq(x)\n‚â§\nŒ¥2\n‚Ñì‚Ä≤ ‚àíŒ¥2\n‚àíŒ±2\n4k\nSince Œ¥1 < ‚Ñìk+1Œ±2\n3172k2 , we have Œ¥2 = 17kŒ¥1\n‚Ñìk\n< Œ±2‚Ñì\n64k. Thus,\nŒ¥2\n‚Ñì‚Ä≤ ‚àíŒ¥2\n< Œ±2\n8k .\nThus, we have,\nL(q‚Ä≤) ‚àíL(q) < ‚àíŒ±2\n8k .\nThe bit size of q‚Ä≤ is\nb‚Ä≤ = 1 + b‚Ä≤\nI + b‚Ä≤\nF = 1 + bI + log(TQ) + bF = b + log(TQ).\nWe are now ready to prove the main theorem in this section.\nProof of Theorem 2. The proof of size, hidden node set size and RNN-time follows the same as\nthe proof of Theorem 1.\nWe here focus on the bit size.\nThe proof idea is a combination of\nLemma 12 and Lemma 4. We first show in the following claim that the sequences of hyperparameters\n{bi}i‚â•1, {Ii}i‚â•1, {Fi}i‚â•1, {‚Ñìi}i‚â•1 satisfy the conditions in Lemma 12.\nClaim 11. For 1 ‚â§i ‚â§193k\nœµ2 log |Œ£|, the following equations hold.\n‚Ñìi+1 = ‚Ñìi\n4 ,\nIi ‚â•bD,I + k log |Œ£| + log(kœÑ) + 1,\nIi+1 ‚â•Ii + log(Ti),\nFi ‚â•bD,F ,\n2‚àíFi ‚â§œµ2‚Ñìk+1\ni\n1088k2 .\n51\n\nProof. We check them sequentially. For the lower bound sequence {‚Ñìi},\n‚Ñìi+1 = 0.99\n|Œ£|4i = ‚Ñìi\n4 .\nNext, by the definition of Ii,\nIi+1 ‚àíIi ‚â•3k log |Œ£| ¬∑ 2i + log œÑ.\nBy the definition of Ti, we have\nlog(Ti) = log œÑ + (i ‚àí1) (3 + log k + k log |Œ£|) ‚â§log œÑ + i (6k log |Œ£|) ‚â§Ii+1 ‚àíIi.\nBy the definition of Fi, it directly gives Fi ‚â•bD,F . To prove the last inequality, it suffices to show\nthat\nFi ‚â•log(1088) + 2 log k + (k + 1) log 1\n‚Ñìi\n+ 2 log 1\nœµ .\nWe compute the right-hand side.\nlog(1088) + 2 log k + (k + 1) log\n1\n‚Ñìk+1\ni\n+ 2 log 1\nœµ\n‚â§11 + 2 log k + (k + 1) (log |Œ£| + 2(i ‚àí1) + 0.02) + 2 log 1\nœµ\n‚â§11 + 2 log k + (k + 1)\n\u0012\nlog |Œ£| + 2\n\u0012192k log |Œ£|\nœµ2\n\u0013\n+ 0.02\n\u0013\n+ 2 log 1\nœµ\n‚â§772\n\u0012k2 log |Œ£|\nœµ2\n+ log 1\nœµ\n\u0013\n‚â§Fi.\nBy Lemma 12 and Claim 11, we know for any language model constructed with an RNN Q\nwith size Ni, hidden node set size Hi, RNN-time Ti, bit size bi = 1 + Ii + Fi and lower bound ‚Ñìi,\nsatisfying Ii ‚â•bD,I + k log |Œ£| + log(kœÑ) + 1, Fi ‚â•bD,F , 2‚àíFi ‚â§œµ2‚Ñìk+1\ni\n1088k2 , if there exists a distinguisher\nRNN D with size |D| ‚â§d, RNN-time TD ‚â§œÑ and bit size ‚ü®D‚ü©‚â§bD whose advantage is œµ, then we\ncan construct a language model q‚Ä≤ implemented by an RNN Q‚Ä≤ with size no more than Ni+1, hidden\nnode set size no more than Hi+1, RNN-time no more than Ti+1, integer bit size no more than Ii+1,\nfractional bit size no more than Fi+1 and the output next-token probability lower bounded by ‚Ñì‚Ä≤,\nsuch that\nL(q‚Ä≤) ‚àíL(q) ‚â§‚àíœµ2\n8k.\nThen we apply Lemma 4 by using the value function h(q) as the bit size and the reciprocal of the\nnext-token probability lower bound. Let the set Bœµ = {Nj ‚àà{Ni}i‚â•1 | Lj+1 < Lj ‚àíœµ2/8k}. Then\nfor any œµ > 0, for all Ni ‚àà{Ni}i‚â•1\\Bœµ, every ÀÜq that minimizes L(q) over Cj = {q | |q| ‚â§Nj, T(q) ‚â§\nTj, h(q) ‚â§Hj, ‚ü®q‚ü©‚â§bj, 1\nq ‚â§1\n‚Ñìj } satisfies that for any next-k-token RNN distinguisher of size |d| ‚â§d,\nRNN-time T(d) ‚â§œÑ and bit size ‚ü®d‚ü©‚â§bD, the distinguisher advange of ÀÜq, denoted as Œ±, satisfies\nŒ±2\n8k ‚â§œµ2\n8k.\n52\n\nEquivalently, the advantage is at most œµ. The algorithm terminates with a network Ni /‚ààBœµ.\nConsequently, the output of this algorithm is œµ-indistinguishable.\nNext, we will bound the size of Bœµ. Let ¬Øq0 be the uniform distribution over the alphabet, which\ncan be realized by an RNN of size 1, hidden node set size 1, RNN-time 1 and integer bit size\n0 and fractional bit size b1. Thus, for each x ‚ààŒ£‚àóand i ‚ààN, q0(xi | x:i) ‚â•\n1\n|Œ£| ‚àí2‚àíF1. Since\nF1 ‚â§log |Œ£| + 7, we have 2‚àíF1 ‚â§0.01\n|Œ£| , and q0(xi | x:i) ‚â•0.99\n|Œ£| . Then the KL divergence between ¬Øp\nand ¬Øq0 can be bounded by\nDKL(¬Øp‚à•¬Øq0) = E\nx‚àº¬Øp log ¬Øp(x)\n¬Øq0(x) ‚â§\nZ\n¬Øp(x) log\n¬Øp(x)\n\u0010\n0.99\n|Œ£|\n\u0011n ‚â§n log\n\u0012 |Œ£|\n0.99\n\u0013\n‚â§2n log |Œ£|.\nBecause KL divergence is nonnegative, the size of Bœµ, or equivalently, the number of indices where\nthe KL decreases by at least œµ2n/8k can be bounded by\nDKL(¬Øp‚à•¬Øq0)\nœµ2n/8k\n‚â§2n log |Œ£|\nœµ2n/8k\n= 16k log |Œ£|\nœµ2\n.\nSince the index j0 is uniformly chosen from [16k log |Œ£|/œµ2, 176k log |Œ£|/œµ2], the probability that\nNj ‚ààBœµ is less than 0.1. Therefore, the expected number of trials is 1 + 1/0.9 ‚âà2.11 < 3.\nFinally, we will bound the bit size of the output model. Suppose that the algorithm terminates\nwith size Ni‚Ä≤. This implies that for each i ‚àà[j0 + 1, i‚Ä≤), we have DKL(¬Øp‚à•¬Øqi) ‚àíDKL(¬Øp‚à•¬Øqi+1) >\nœµ2n/8k. Summing over i, we obtain that DKL(¬Øp‚à•¬Øqj0+1) ‚àíDKL(¬Øp‚à•¬Øqi) > (i‚Ä≤ ‚àíj0 ‚àí1)œµ2n/8k. Since\nDKL(¬Øp‚à•¬Øqj0+1) ‚â§DKL(¬Øp‚à•¬Øq0) ‚â§2n log |Œ£|, we have\ni‚Ä≤ ‚àíj0 ‚àí1 < DKL(¬Øp‚à•¬Øq1)\nœµ2n/8k\n‚â§2n log |Œ£|\nœµ2n/8k\n= 16k log |Œ£|\nœµ2\n.\nSo we know\ni‚Ä≤ ‚â§j0 + 16k log |Œ£|\nœµ2\n‚â§192k log |Œ£|\nœµ2\n.\nThus, the bit size of the final output LM is bounded by\nbi‚Ä≤ =bD + 772\n\u0012k2\nœµ2 log |Œ£| + log 1\nœµ\n\u0013\n+ 3k log |Œ£|i‚Ä≤2 + i‚Ä≤ log œÑ\n=O\n\u0012\nbD + k2\nœµ2 log |Œ£| + log 1\nœµ + k log |Œ£|k2 log2 |Œ£|\nœµ4\n+ k\nœµ2 log |Œ£| log œÑ\n\u0013\n=O\n\u0012\nbD + k3 log2 |Œ£|\nœµ4\n+ k\nœµ2 log |Œ£| log œÑ\n\u0013\nFinally, we provide the following lemmas, which are used in the proof of Lemma 12.\nLemma 13 (Additive Error composition for products). Let n ‚ààN, 0 < Œ¥ < 1/n, and let xi, yi ‚àà[0, 1]\nfor 1 ‚â§i ‚â§n. Suppose that for any 1 ‚â§i ‚â§n, we have |xi ‚àíyi| ‚â§Œ¥, then we have\n\f\f\f\f\f\nn\nY\ni=1\nxi ‚àí\nn\nY\ni=1\nyi\n\f\f\f\f\f ‚â§2nŒ¥.\n53\n\nProof. On one hand, we have xi ‚â§yi + Œ¥. Thus,\nn\nY\ni=1\nxi ‚â§\nn\nY\ni=1\n(xi + Œ¥)\n=\nn\nY\ni=1\nxi +\nn\nX\nŒπ=1\nŒ¥Œπ\nX\n1‚â§i1<¬∑¬∑¬∑<iŒπ‚â§n\nY\nj /‚àà{i1,¬∑¬∑¬∑ ,iŒπ}\nxj\n‚â§\nn\nY\ni=1\nxi +\nn\nX\nŒπ=1\n\u0012n\nŒπ\n\u0013\nŒ¥Œπ\n=\nn\nY\ni=1\nxi + ((1 + Œ¥)n ‚àí1)\n‚â§\nn\nY\ni=1\nxi + enŒ¥ ‚àí1\nSince Œ¥ < 1/n, and for any 0 < x < 1, we have ex ‚â§1 + x + x2 < 1 + 2x. Thus,\nn\nY\ni=1\nxi ‚â§\nn\nY\ni=1\nyi + 2nŒ¥.\nOn the other hand, by swapping the roles of xi and yi, we get\nn\nY\ni=1\nyi ‚â§\nn\nY\ni=1\nxi + 2nŒ¥.\nLemma 14. For x, y, Œ¥, ‚Ñì‚àà(0, 1] with y ‚â•x and y ‚â•‚Ñì> Œ¥, we have\nx + Œ¥\ny ‚àíŒ¥ ‚â§x\ny +\n2Œ¥\n‚Ñì‚àíŒ¥.\nProof. By computation,\nx + Œ¥\ny ‚àíŒ¥ ‚àíx\ny =xy + Œ¥y ‚àíxy + Œ¥x\ny(y ‚àíŒ¥)\n= Œ¥(x + y)\ny(y ‚àíŒ¥)\nSince x ‚â§y, we have (x + y)/y ‚â§2. Combining this with the condition that y ‚â•Œ¥, we have\nx + Œ¥\ny ‚àíŒ¥ ‚àíx\ny ‚â§\n2Œ¥\ny ‚àíŒ¥ ‚â§\n2Œ¥\n‚Ñì‚àíŒ¥.\nLemma 15 (Lower bound of the constructed language model.). Let ‚Ñì‚àà(0, 1), i‚àó\n0 ‚àà[0, k ‚àí1]. Let\nq : (Œ£ ‚à™{‚àÖ}) √ó S ‚Üí[0, 1] be a language model such that for any y ‚ààŒ£ ‚à™{‚àÖ} and s ‚ààS, q(y | s) ‚â•‚Ñì.\nDefine a new language model q‚Ä≤ : (Œ£ ‚à™{‚àÖ}) √ó S ‚Üí[0, 1] by\nq‚Ä≤(xi | x:i) =\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nq(xi | x:i)\nif i ‚â§i‚àó\n0;\nP\ns‚ààŒ£k‚àír0\nq(xi0+1:i+1 ¬∑ s | x:i0+1)e‚àíŒ±di0+1(x:i+1¬∑s)\nP\ns‚ààŒ£k‚àír0+1 q(xi0+1:i ¬∑ s | x:i0+1)e‚àíŒ±di0+1(x:i¬∑s)\nif i = i0 + r0, i0 ‚ààI, 1 ‚â§r0 ‚â§k,\n(3.8)\nwhere I := {i ‚àà[n] | i ‚â°i‚àó\n0 (mod k)}. Then for any y ‚ààŒ£ ‚à™{‚àÖ} and s ‚ààS, q‚Ä≤(y | s) ‚â•‚Ñì/3.\n54\n\nProof. For i ‚â§i‚àó\n0, q‚Ä≤(xi | x:i) ‚â•‚Ñì. Next, we will show the result for i > i‚àó\n0. Since for any i ‚ààN and\nany x ‚ààS, the distinguisher di0+1(x) ‚àà{0, 1}, thus,\nq‚Ä≤(xi | x:i) ‚â•\ne‚àíŒ± ¬∑\nP\ns‚ààŒ£k‚àír0\nq(xi0+1:i+1 ¬∑ s | x:i0+1)\nP\ns‚ààŒ£k‚àír0+1 q(xi0+1:i ¬∑ s | x:i0+1)\n= e‚àíŒ± ¬∑ q(xi+1 | x:i+1) > ‚Ñì/3\nLemma 16 (Loss improvement for quantized language models). Let n ‚ààN be the document length,\n‚Ñì‚àà(0, 1), Œ¥ ‚àà(0, 1). Let ¬Øp : Œ£n ‚Üí[0, 1] be a text distribution. Let q, Àúq : (Œ£ ‚à™{‚àÖ}) ‚Üí[0, 1] be two\nlanguage models such that for any x ‚ààŒ£n, i ‚àà[n],\n|q(xi | x:i) ‚àíÀúq(xi | x:i)| ‚â§Œ¥,\nq(xi | x:i) ‚â•‚Ñì.\nThen for any Œ≥ ‚àà(0, 1), we have\nE\nx‚àº¬Øp log ¬Øq(x)\n¬ØÀúq(x) ‚â§n ¬∑\nŒ¥\n‚Ñì‚àíŒ¥.\nProof. We write,\nE\nx‚àº¬Øp log ¬Øq(x)\n¬ØÀúq(x) =\nZ\n¬Øp(x) log\nQn\ni=1 q(xi | x:i)\nQn\ni=1 Àúq(xi | x:i) dx\n=\nZ\n¬Øp(x)\nn\nX\ni=1\n\u0012\nlog q(xi | x:i)\nÀúq(xi | x:i)\n\u0013\ndx\n‚â§\nZ\n¬Øp(x)\nn\nX\ni=1\n\u0012\nlog\nq(xi | x:i)\nq(xi | x:i) ‚àíŒ¥\n\u0013\ndx\n‚â§\nZ\n¬Øp(x)\nn\nX\ni=1\n\u0012\nŒ¥\nq(xi | x:i) ‚àíŒ¥\n\u0013\ndx\n‚â§\nZ\n¬Øp(x)\nn\nX\ni=1\n\u0012\nŒ¥\n‚Ñì‚àíŒ¥\n\u0013\ndx\n=n ¬∑\nŒ¥\n‚Ñì‚àíŒ¥\nAcknowledgement.\nWe are deeply grateful to Adam Kalai for sharing his insightful ideas\nand suggestions and uncountably many hours of helpful and entertaining discussions. This work\nwas supported by NSF award CCF-2106444, a Simons Investigator award and a JPMC AI PhD\nfellowship.\nReferences\n[AAA+23] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-\ncia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat,\net al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\n55\n\n[AABC22] Kushal Arora, Layla El Asri, Hareesh Bahuleyan, and Jackie Chi Kit Cheung. Why\nexposure bias matters: An imitation learning perspective of error accumulation in\nlanguage generation. arXiv preprint arXiv:2204.01171, 2022.\n[AMGK22] David Alvarez-Melis, Vikas Garg, and Adam Kalai. Are gans overkill for nlp? Advances\nin Neural Information Processing Systems, 35:9072‚Äì9084, 2022.\n[BCE+23] S√©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric\nHorvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.\nSparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint\narXiv:2303.12712, 2023.\n[BGH+23] Jaros≈Çaw B≈Çasiok, Parikshit Gopalan, Lunjia Hu, Adam Tauman Kalai, and Preetum\nNakkiran. Loss minimization yields multicalibration for large neural networks. arXiv\npreprint arXiv:2304.09424, 2023.\n[BMR+20] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla\nDhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.\nLanguage models are few-shot learners. Advances in neural information processing\nsystems, 33:1877‚Äì1901, 2020.\n[BN24] Gregor Bachmann and Vaishnavh Nagarajan. The pitfalls of next-token prediction.\narXiv preprint arXiv:2403.06963, 2024.\n[BVJS15] Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled sampling\nfor sequence prediction with recurrent neural networks. Advances in neural information\nprocessing systems, 28, 2015.\n[DJP+24] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-\nDahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al.\nThe llama 3 herd of models. arXiv e-prints, pages arXiv‚Äì2407, 2024.\n[DLS+24] Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen\nLin, Sean Welleck, Peter West, Chandra Bhagavatula, Ronan Le Bras, et al. Faith\nand fate: Limits of transformers on compositionality. Advances in Neural Information\nProcessing Systems, 36, 2024.\n[DRGM+22] Gr√©goire Del√©tang, Anian Ruoss, Jordi Grau-Moya, Tim Genewein, Li Kevin Wenliang,\nElliot Catt, Chris Cundy, Marcus Hutter, Shane Legg, Joel Veness, et al. Neural\nnetworks and the chomsky hierarchy. arXiv preprint arXiv:2207.02098, 2022.\n[FFF18] Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. Analysis of classifiers‚Äô robustness\nto adversarial perturbations. Machine learning, 107(3):481‚Äì508, 2018.\n[FHT00] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. Additive logistic regression:\na statistical view of boosting (with discussion and a rejoinder by the authors). The\nannals of statistics, 28(2):337‚Äì407, 2000.\n[FYL+23] Tao Fang, Shu Yang, Kaixin Lan, Derek F Wong, Jinpeng Hu, Lidia S Chao, and Yue\nZhang. Is chatgpt a highly fluent grammatical error correction system? a comprehensive\nevaluation. arXiv preprint arXiv:2304.01746, 2023.\n56\n\n[G+05] Oded Goldreich et al.\nFoundations of cryptography‚Äìa primer.\nFoundations and\nTrends¬Æ in Theoretical Computer Science, 1(1):1‚Äì116, 2005.\n[GJRR24] Sumegha Garg, Christopher Jung, Omer Reingold, and Aaron Roth. Oracle efficient\nonline multicalibration and omniprediction. In Proceedings of the 2024 Annual ACM-\nSIAM Symposium on Discrete Algorithms (SODA), pages 2725‚Äì2792. SIAM, 2024.\n[GKKZ22] Surbhi Goel, Sham Kakade, Adam Kalai, and Cyril Zhang. Recurrent convolutional\nneural networks learn succinct learning algorithms. Advances in Neural Information\nProcessing Systems, 35:7328‚Äì7341, 2022.\n[GPAM+20] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,\nSherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks.\nCommunications of the ACM, 63(11):139‚Äì144, 2020.\n[HBB+20] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song,\nand Jacob Steinhardt. Measuring massive multitask language understanding. arXiv\npreprint arXiv:2009.03300, 2020.\n[HBK+21] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,\nDawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the\nmath dataset. arXiv preprint arXiv:2103.03874, 2021.\n[HE16] Jonathan Ho and Stefano Ermon. Generative adversarial imitation learning. Advances\nin neural information processing systems, 29, 2016.\n[HJKRR18] Ursula H√©bert-Johnson, Michael Kim, Omer Reingold, and Guy Rothblum. Multicali-\nbration: Calibration for the (computationally-identifiable) masses. In International\nConference on Machine Learning, pages 1939‚Äì1948. PMLR, 2018.\n[HZL19] Tatsunori B Hashimoto, Hugh Zhang, and Percy Liang. Unifying human and statistical\nevaluation for natural language generation. arXiv preprint arXiv:1904.02792, 2019.\n[Kal03] Adam Tauman Kalai.\nGenerating random factored numbers, easily.\nJournal of\nCryptology, 16(4):287‚Äì289, 2003.\n[KM05] S Kunzli and Willi Meier. Distinguishing attack on mag. ECRYPT Stream Cipher\nProject Report, 1:2005, 2005.\n[LJL+] Zhihao Li, Xue Jiang, Liyuan Liu, Xuelin Zhang, Hong Chen, and Feng Zheng. On the\ngeneralization ability of next-token-prediction pretraining. In Forty-second International\nConference on Machine Learning.\n[LL01] Guy Lebanon and John Lafferty. Boosting and maximum likelihood for exponential\nmodels. Advances in neural information processing systems, 14, 2001.\n[Mal23] Eran Malach. Auto-regressive next-token predictors are universal learners. arXiv\npreprint arXiv:2309.06979, 2023.\n[MAS+24] Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and\nMehrdad Farajtabar. Gsm-symbolic: Understanding the limitations of mathematical\nreasoning in large language models. arXiv preprint arXiv:2410.05229, 2024.\n57\n\n[MHVF+24] Ida Momennejad, Hosein Hasanbeig, Felipe Vieira Frujeri, Hiteshi Sharma, Nebojsa\nJojic, Hamid Palangi, Robert Ness, and Jonathan Larson. Evaluating cognitive maps\nand planning in large language models with cogeval. Advances in Neural Information\nProcessing Systems, 36, 2024.\n[NW94] Noam Nisan and Avi Wigderson. Hardness vs randomness. Journal of computer and\nSystem Sciences, 49(2):149‚Äì167, 1994.\n[OWJ+22] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training\nlanguage models to follow instructions with human feedback. Advances in neural\ninformation processing systems, 35:27730‚Äì27744, 2022.\n[QML+25] Chengwen Qi, Ren Ma, Bowen Li, He Du, Binyuan Hui, Jinwang Wu, Yuanjun Laili,\nand Conghui He. Large language models meet symbolic provers for logical reasoning\nevaluation. arXiv preprint arXiv:2502.06563, 2025.\n[QWL+22] Jing Qian, Hong Wang, Zekun Li, Shiyang Li, and Xifeng Yan. Limitations of language\nmodels in arithmetic and symbolic induction. arXiv preprint arXiv:2208.05051, 2022.\n[RCAZ15] Marc‚ÄôAurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. Sequence\nlevel training with recurrent neural networks. arXiv preprint arXiv:1511.06732, 2015.\n[Sha48] Claude Elwood Shannon. A mathematical theory of communication. The Bell system\ntechnical journal, 27(3):379‚Äì423, 1948.\n[Sha51] Claude E Shannon. Prediction and entropy of printed english. Bell system technical\njournal, 30(1):50‚Äì64, 1951.\n[SRCM22] Buck Shlegeris, Fabien Roger, Lawrence Chan, and Euan McLean. Language models\nare better than humans at next-token prediction. arXiv preprint arXiv:2212.11281,\n2022.\n[Wer02] Paul J Werbos.\nBackpropagation through time: what it does and how to do it.\nProceedings of the IEEE, 78(10):1550‚Äì1560, 2002.\n[WZL+24] Xinlong Wang, Xiaosong Zhang, Zhengxiong Luo, Quan Sun, Yufeng Cui, Jinsheng\nWang, Fan Zhang, Yueze Wang, Zhen Li, Qiying Yu, et al. Emu3: Next-token prediction\nis all you need. arXiv preprint arXiv:2409.18869, 2024.\n[Yao82] Andrew C Yao.\nTheory and application of trapdoor functions.\nIn 23rd Annual\nSymposium on Foundations of Computer Science (SFCS 1982), pages 80‚Äì91. IEEE,\n1982.\n[ZZC+23] Yiran Zhao, Jinghan Zhang, I Chern, Siyang Gao, Pengfei Liu, Junxian He, et al. Felm:\nBenchmarking factuality evaluation of large language models. Advances in Neural\nInformation Processing Systems, 36:44502‚Äì44523, 2023.\n[ZZL+23] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,\nYingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large\nlanguage models. arXiv preprint arXiv:2303.18223, 2023.\n58\n\nA\nIndistinguishability and KL divergence\nWe show in this section that the advantage of any next-k token distinguisher is upper-bounded by\nthe square root of the KL divergence times k/2n. Intuitively, for each prefix s, each distinguisher\ndi can be viewed as an indicator of a subset Ai,s ‚äÜŒ£k of length-k blocks. The advantage is the\ndifference between the probabilities that ¬Øp and ¬Øq assign to Ai,s, which is at most the corresponding\nTV distance. Pinsker‚Äôs Inequality then upper-bounds TV by a square root of KL.\nWe recall the relevant notation from Section 1.5 and adapt it to a form more convenient for the\nsubsequent proof. Let p ‚àà‚àÜ(Œ£n) be an LM that corresponds to the text distribution ¬Øp ‚àà¬Ø‚àÜ(Œ£n).\nFor a prefix s ‚ààŒ£i with i ‚àà[0, n], the marginal probability under ¬Øp is\n¬Øpi(s) :=\nX\nz‚ààŒ£n‚àíi\n¬Øp(s ¬∑ z).\nFix k ‚àà[1, n]. For s ‚ààŒ£‚â§n‚àík and w ‚àà|Œ£|k, the next-k conditional distribution under ¬Øp is\np(k)(w | s) := Px‚àº¬Øp\n\u0000x|s|+1:|s|+k+1 = w | x:|s|+1 = s\n\u0001\n=\nP\nz‚ààŒ£n‚àí|s|‚àík p(s ¬∑ w ¬∑ z)\nP\nz‚ààŒ£n‚àí|s| p(s ¬∑ z)\n.\nEquivalently, in terms of next-token probability,\np(k)(w | s) =\nk\nY\nt=1\np(wt | s ¬∑ w:t).\nDefinition 5 (Total Variation (TV) distance). The total variation distance between two distributions\np, q over the same space X is defined as\nDTV(p, q) = 1\n2\nX\nx‚ààX\n|p(x) ‚àíq(x)| = sup\nA‚äÜX\n|p(A) ‚àíq(A)|.\nBecause each distinguisher di(x) is binary and depends only on the prefix x:i and the next-k-token\nxi:i+k, there is a binary function œïi : |Œ£|i √ó |Œ£|k ‚Üí{0, 1} with di(x) = œïi(x:i, xi:i+k). Then the\nadvantage is\na(d, ¬Øp, ¬Øq) := E\ny‚àº¬Øp\n\"\n1\nn\nn\nX\ni=1\n\u0012\nE\nx‚àº¬Øq [œïi(x:i, xi:i+k) | x:i = y:i] ‚àíœïi(y:i, yi:i+k)\n\u0013#\n.\n(A.1)\nWe give the following theorem showing that the advantage of the distinguisher is upper-bounded\nby the square root of the KL divergence times k/2n.\nTheorem 3 (Indistinguishability). For two text distributions ¬Øp, ¬Øq ‚àà¬Ø‚àÜ(Œ£n), any next-k-token\ndistinguisher d : [n] √ó Œ£n ‚Üí{0, 1}, its advantage\na(d, ¬Øp, ¬Øq) ‚â§\nr\nk\n2nDKL(¬Øp‚à•¬Øq).\nThe proof of this theorem relies on the following lemma, which bounds the distinguisher‚Äôs\nadvantage in terms of the average conditional KL divergence between the next-k-token distributions\nof p and q.\n59\n\nLemma 17. For two text distributions ¬Øp, ¬Øq ‚àà¬Ø‚àÜ(Œ£n), any next-k-token distinguisher d : [n] √ó Œ£n ‚Üí\n{0, 1}, its advantage\na(d, ¬Øp, ¬Øq) ‚â§\nv\nu\nu\nt 1\n2n\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nDKL\n\u0000p(k)(¬∑ | s)‚à•q(k)(¬∑ | s)\n\u0001\n.\nProof. For any fixed i ‚àà[1, n] and prefix s ‚ààŒ£i‚àí1,\nE\nx‚àº¬Øq [œïi(x:i, xi:i+k) | x:i = s] =\nX\nw‚ààŒ£k\nœïi(s, w) ¬∑ q(k)(w | s).\nThus,\nE\ny‚àº¬Øp E\nx‚àº¬Øq [œïi(x:i, xi:i+k) | x:i = y:i] =\nE\ns‚àº¬Øpi‚àí1\nÔ£Æ\nÔ£∞X\nw‚ààŒ£k\nœïi(s, w) ¬∑ q(k)(w | s)\nÔ£π\nÔ£ª.\n(A.2)\nFor the second term in the advantage,\nE\ny‚àº¬Øp [œïi(y:i, yi:i+k)] =\nE\ns‚àº¬Øpi‚àí1\nÔ£Æ\nÔ£∞X\nw‚ààŒ£k\nœïi(s, w) ¬∑ p(k)(w | s)\nÔ£π\nÔ£ª.\n(A.3)\nCombining Equation (A.2) and Equation (A.3), we can rewrite the advantage as\na(d, ¬Øp, ¬Øq) = 1\nn\nn\nX\ni=1\nE\ns‚àº¬Øpi‚àí1\nÔ£Æ\nÔ£∞X\nw‚ààŒ£k\n\u0010\nœïi(s, w) ¬∑\n\u0010\nq(k)(w | s) ‚àíp(k)(w | s)\n\u0011\u0011\nÔ£π\nÔ£ª\n(A.4)\n= 1\nn\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nÔ£Æ\nÔ£∞X\nw‚ààŒ£k\n\u0010\nœïi(s, w) ¬∑\n\u0010\nq(k)(w | s) ‚àíp(k)(w | s)\n\u0011\u0011\nÔ£π\nÔ£ª.\n(A.5)\nSince œïi is a binary function, for any fix i ‚àà[0, n ‚àí1] and prefix s ‚ààŒ£i,\nX\nw‚ààŒ£k\n\u0010\nœïi(s, w) ¬∑\n\u0010\nq(k)(w | s) ‚àíp(k)(w | s)\n\u0011\u0011\n‚â§sup\nA‚äÜŒ£k\nX\nw‚ààA\n\u0010\nq(k)(w | s) ‚àíp(k)(w | s)\n\u0011\n‚â§DTV\n\u0010\nq(k)(¬∑ | s), p(k)(¬∑ | s)\n\u0011\n‚â§\nr\n1\n2DKL\n\u0000q(k)(¬∑ | s), p(k)(¬∑ | s)\n\u0001\nThe last step comes from Pinsker‚Äôs Inequality. By Equation(A.5), we can bound the advantage as\na(d, ¬Øp, ¬Øq) = 1\nn\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nÔ£Æ\nÔ£∞X\nw‚ààŒ£k\n\u0010\nœïi(s, w) ¬∑\n\u0010\nq(k)(w | s) ‚àíp(k)(w | s)\n\u0011\u0011\nÔ£π\nÔ£ª\n‚â§1\nn\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nr\n1\n2DKL\n\u0000q(k)(¬∑ | s), p(k)(¬∑ | s)\n\u0001\n60\n\nSince the function f(z) = ‚àöz is concave, by Jensen‚Äôs inequality,\n1\nn\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nr\n1\n2DKL\n\u0000q(k)(¬∑ | s), p(k)(¬∑ | s)\n\u0001\n‚â§\nv\nu\nu\nt 1\n2n\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nDKL\n\u0000q(k)(¬∑ | s), p(k)(¬∑ | s)\n\u0001\n.\nBased on Lemma 17, we can prove Theorem 3 using the chain rule of KL divergence.\nProof of Theorem 3. By Lemma 17, the advantage\na(d, ¬Øp, ¬Øq) ‚â§\nv\nu\nu\nt 1\n2n\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nDKL\n\u0000p(k)(¬∑ | s)‚à•q(k)(¬∑ | s)\n\u0001\n.\n(A.6)\nFor any fixed prefix s ‚ààŒ£i, by the definition of KL divergence,\nDKL(p(k)(¬∑ | s)‚à•q(k)(¬∑ | s)) =\nX\nw‚ààŒ£k\np(k)(w | s) log p(k)(w | s)\np(k)(w | s)\n=\nX\nw‚ààŒ£k\np(k)(w | s)\nk\nX\nt=1\nlog p(wt | sw:t)\np(w | sw:t)\n=\nk\nX\nt=1\nX\nw‚ààŒ£k\np(k)(w | s) log p(wt | sw:t)\nq(wt | sw:t)\nFor each t ‚àà[1, k], we sum over wt+1: first to integrate them out, which gives\nX\nw‚ààŒ£k\np(k)(w | s) log p(wt | s ¬∑ w:t)\nq(wt | s ¬∑ w:t) =\nE\nu‚àºp(t‚àí1)(¬∑|s)\nX\na‚ààŒ£\np(a | s ¬∑ u) log p(a | s ¬∑ u)\nq(a | s ¬∑ u)\n=\nE\nu‚àºp(t‚àí1)(¬∑|s)\nDKL (p(¬∑ | s ¬∑ u)‚à•q(¬∑ | s ¬∑ u))\nThus, we have\nDKL(p(k)(¬∑ | s)‚à•q(k)(¬∑ | s)) =\nk\nX\nt=1\nE\nu‚àºp(t‚àí1)(¬∑|s)\nDKL (p(¬∑ | s ¬∑ u)‚à•q(¬∑ | s ¬∑ u)) .\n(A.7)\nTaking Es‚àº¬Øpi in Equation (A.7), we have\nE\ns‚àº¬Øpi\nDKL(p(k)(¬∑ | s)‚à•q(k)(¬∑ | s)) =\nk\nX\nt=1\nE\ns‚àº¬Øpi\nE\nu‚àºp(t‚àí1)(¬∑|s)\nDKL (p(¬∑ | s ¬∑ u)‚à•q(¬∑ | s ¬∑ u))\n(A.8)\n=\nk\nX\nt=1\nE\nx‚àº¬Øp DKL (p(¬∑ | x:i+t)‚à•q(¬∑ | x:i+t))\n(A.9)\nNext we will sum over the prefix length i and count how many times each position appears. Define\nDj := E\nx‚àº¬Øp DKL (p(¬∑ | x:j)‚à•q(¬∑ | x:j)) ,\nfor j = 1, ¬∑ ¬∑ ¬∑ , n.\n61\n\nSumming up Equation (A.9) over i = 0, 1, 2, ¬∑ ¬∑ ¬∑ , n ‚àí1 gives\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nDKL(p(k)(¬∑ | s)‚à•q(k)(¬∑ | s)) =\nn‚àí1\nX\ni=0\nk\nX\nt=1\nDi+t =\nn\nX\nj=1\ncjDj,\nwhere cj := |{(i, t) ‚àà[0, n ‚àí1] √ó [1, k], i + t = j}|. We know for each j, cj ‚â§k. Hence\nn‚àí1\nX\ni=0\nE\ns‚àº¬Øpi\nDKL(p(k)(¬∑ | s)‚à•q(k)(¬∑ | s)) ‚â§k\nn\nX\nj=1\nDj = k\nn\nX\nj=1\nE\nx‚àº¬Øp DKL (p(¬∑ | x:j)‚à•q(¬∑ | x:j)) .\nBy the chain rule,\nDKL(¬Øp‚à•¬Øq) =\nn\nX\ni=1\nE\nx‚àº¬Øp DKL (p(¬∑ | x:j)‚à•q(¬∑ | x:j)) .\nCombining with Equation(A.6), and we have\na(d, ¬Øp, ¬Øq) ‚â§\nr\nk\n2nDKL(¬Øp‚à•¬Øq).\nB\nComputational Limitations of Autoregressive LLMs\nIn this section, we will assume that numbers are represented, as is common, in base 10. For simplicity,\nwe further assume that each character in a string (including digits 0-9) is a single token, though the\nobservation below can easily be extended to any constant-sized set of tokens.\nDefinition 6 (Factorization distribution). The Factorization Distribution is the distribution over\nstrings of length n of strings of the form ‚ÄúThe prime factors of m are p1 √ó p2.‚Äù where p1 ‚â§p2 are\nrandom n/4-digit numbers and m = p1 ‚â§p2 ‚â§. . . pi are its prime factorization. The string is\npadded with spaces to make its length n.\nWe now state a hardness assumption for the average-case hardness of factorization, which is a\ncommon assumption in cryptography.\nAssumption 1. For every polynomial-time algorithm A, there is an n0 such that for any n ‚â•n0,\ngiven the product of two independent, uniformly random n-bit prime numbers, the probability that\nA can output the prime factors with probability is no greater than 1%.\nDefinition 7 (Non-autoregressive language model). A Non-Autoregressive Language Model A is a\nrandomized algorithm that outputs a document Œ£n of length n, given an input n.\nObservation 1. There is a Non-Autoregressive Language Model whose output distribution is exactly\nthe Factorization Distribution for any n, which runs in time polynomial in n. For any ordinary\n(autoregressive) language model, there is an n0 such that for all n ‚â•n0, the statistical distance\nbetween its output distribution and that of the Factorization Distribution is ‚â•0.99.\nProof. It is possible to efficiently sample documents: simply multiply together two random n/4-digit\nrandom prime numbers (these can be sampled by simply repeatedly sampling random numbers and\ntesting primality, which can be done in time in their length, until primes are found). However, if one\ncould efficiently sample from the conditional next-token distribution, then one could clearly solve\nthe factorization problem by completing the prompt ‚ÄúThe prime factors of m are‚Äù for the number m\nto be factored. This would give an efficient algorithm for factorizing products of two random large\nprimes more often than 99% of the time.\n62\n\nC\nCommon Transition Functions\nWe show that the following common functions are transition functions.\nLemma 18 (Transition Functions). Let œµ > 0 be the machine precision. The following functions can\nbe implemented as transition functions.\n1. Indicator function. For a constant c ‚ààR, and variable x ‚ààR, the indicator functions\n1 (x = c) , 1 (x ‚â§c) , 1 (x ‚â•c) are transition functions.\n2. If-Else function. For a constant c ‚ààR and variables b, v1, v2, ¬∑ ¬∑ ¬∑ , vk ‚ààR, and let f1, f2 :\nRk √ó R be transition functions. Then the if-else function\ng(v1, v2, ¬∑ ¬∑ ¬∑ , vk) =\n(\nf1(v1, v2, ¬∑ ¬∑ ¬∑ , vk)\nif b = c,\nf2(v1, v2, ¬∑ ¬∑ ¬∑ , vk)\nif b Ã∏= c\nis a transition function. The condition b = c can be replaced by b ‚â§c or b ‚â•c to maintain a\ntransition function.\n3. Boolean logic operations: OR, AND, NOT. For boolean variables x1, x2, ¬∑ ¬∑ ¬∑ , xk ‚àà{0, 1},\nthe logical operations OR, AND, and NOT are transition functions. Specifically, the following\nthree functions are transition functions.\nf1(x1, ¬∑ ¬∑ ¬∑ , xk) =\n_\n1‚â§i‚â§k\nxi,\nf2(x1, ¬∑ ¬∑ ¬∑ , xk) =\n^\n1‚â§i‚â§k\nxi,\nf3(xi) = ¬¨xi,\n1 ‚â§i ‚â§k.\n4. Increment k-digit base-c number. Let c, k ‚ààN. Let variables x1, x2, ¬∑ ¬∑ ¬∑ , xk ‚àà[0, c ‚àí1].\nThen there exists k transition functions fi : {0, 1, ¬∑ ¬∑ ¬∑ , c ‚àí1}k ‚Üí{0, 1, ¬∑ ¬∑ ¬∑ , c ‚àí1} for 1 ‚â§i ‚â§k,\nsuch that\nfi(x1, ¬∑ ¬∑ ¬∑ , xk) =\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\nxi\n‚àÉj ‚â§i ‚àí1 s.t. 0 ‚â§xj ‚â§c ‚àí2\nxi + 1\nif xj = c ‚àí1, ‚àÄj ‚â§i ‚àí1, and 0 ‚â§xi ‚â§c ‚àí2\n0\nif xj = c ‚àí1, ‚àÄj ‚â§i\n(C.1)\nTo interpret this operation, define the vectors x = (xk, xk‚àí1, ¬∑ ¬∑ ¬∑ , x1) and x‚Ä≤ = (x‚Ä≤\nk, x‚Ä≤\nk+1, ¬∑ ¬∑ ¬∑ , x‚Ä≤\n1),\nwhere x‚Ä≤\ni = fi(x1, x2, ¬∑ ¬∑ ¬∑ , xk). Then x‚Ä≤ = x + 1 in base-c.\n5. Exponential function on binary input.\nLet Œ± ‚ààR, Then the exponential function\nf(x) = exp(Œ±x) is a transition function.\nProof.\n1. Firstly for the indicator function 1\n\u0000xt = c\n\u0001\n, we have\n1\nœµ œÉ(œµ ‚àíœÉ(x ‚àíc) ‚àíœÉ(c ‚àíx))\n=\nÔ£±\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£≥\n1\nœµœÉ(1 ‚àí(x ‚àíc))\nif x ‚â•c + œµ\n1\nif xt = c\n1\nœµœÉ(1 ‚àí(c ‚àíx))\nif x ‚â§c ‚àíœµ\n63\n\n=\n(\n1\nif x = c\n0\nif x Ã∏= c\nSimilarly, the indicator functions 1 (x ‚â§c) and 1 (x ‚â•c) can be computed as\n1 (x ‚â§c) =1\nœµ œÉ(œÉ(c + œµ ‚àíx) ‚àíœÉ(c ‚àíx))\n1 (x ‚â•c) =1\nœµ œÉ(œÉ(x + œµ ‚àíc) ‚àíœÉ(x ‚àíc))\n2. Since the indicator function 1 (b = c) is a transition function, we have\ng(v1, v2, ¬∑ ¬∑ ¬∑ , vk) = f1(v1, v2, ¬∑ ¬∑ ¬∑ , vk) ¬∑ 1 (b = c) + f2(v1, v2, ¬∑ ¬∑ ¬∑ , vk) ¬∑ (1 ‚àí1 (b = c)).\nThis also holds by replacing 1 (b = c) with 1 (b ‚â§c) and 1 (b ‚â•c) since they are transition\nfunctions as well.\n3. We can construct the following transition functions.\n‚Ä¢ OR: Let\nf1(x1, ¬∑ ¬∑ ¬∑ , xk) = 1\n k\nX\ni=1\nxi ‚â•0\n!\n=\n_\n1‚â§i‚â§k\nxi.\n‚Ä¢ AND: Let\nf1(x1, ¬∑ ¬∑ ¬∑ , xk) = 1\n k\nX\ni=1\nxi ‚â•k\n!\n=\n^\n1‚â§i‚â§k\nxi.\n‚Ä¢ NOT: Let\nf3(xi) = 1 ‚àíxi = ¬¨xi.\nSince the indicator function is a transition function, the OR, AND, NOT operations are also\ntransition functions.\n4. We construct fi for 1 ‚â§i ‚â§k as follows.\nfi(x1, x2, ¬∑ ¬∑ ¬∑ , xj) =œÉ\n\u0000xi + 1 ‚àíh1\ni + h2\ni ‚àích3\ni\n\u0001\n, where\n(C.2)\nh1\ni =œÉ\nÔ£´\nÔ£≠(i ‚àí1)(c ‚àí1) ‚àí\ni‚àí1\nX\nj=1\nxj\nÔ£∂\nÔ£∏,\n(C.3)\nh2\ni =œÉ\nÔ£´\nÔ£≠(i ‚àí1)(c ‚àí1) ‚àí1 ‚àí\ni‚àí1\nX\nj=1\nxj\nÔ£∂\nÔ£∏,\n(C.4)\nh3\ni =œÉ\nÔ£´\nÔ£≠\ni\nX\nj=1\nxj ‚àíi(c ‚àí1) + 1\nÔ£∂\nÔ£∏.\n(C.5)\nWe now verify that Equation (C.2) realizes the update rules Equation (C.1). There are three\ncases to consider.\nFirstly, if ‚àÉj ‚â§i ‚àí1 s.t. 0 ‚â§xj ‚â§c ‚àí2, then we have Pi‚àí1\nj=1 xj ‚â§(i ‚àí1)(c ‚àí1) ‚àí1. So by\nEquations (C.3),(C.4), we know h1\ni = (i‚àí1)(c‚àí1)‚àíPi‚àí1\nj=1 xj, h2\ni = (i‚àí1)(c‚àí1)‚àí1‚àíPi‚àí1\nj=1 xj.\n64\n\nSince xi ‚â§c ‚àí1, then Pi\nj=1 xj ‚â§i(c ‚àí1) ‚àí1. Thus, we have hi\n3 = 0 from Equation (C.5).\nCombining with Equation (C.2), x‚Ä≤\ni = œÉ(xi + 1 ‚àí1) = xi.\nSecondly, when xj = c ‚àí1 for ‚àÄj ‚â§i ‚àí1, and 0 ‚â§xi ‚â§c ‚àí2, we have Pi‚àí1\nj=1 xj = (c ‚àí1)(i ‚àí1).\nSo in this case, h1\ni = h2\ni = 0. Furthermore, Pi\nj=1 xj ‚â§c ‚àí2 + (i ‚àí1)(c ‚àí1) = i(c ‚àí1) ‚àí1. So\nh3\ni = 0 as well. By Equation (C.2), x‚Ä≤\ni = œÉ(xi + 1) = xi + 1.\nThirdly, for the case when xj = c ‚àí1, ‚àÄj ‚â§i, similar to the second case, we know h1\ni = h2\ni = 0.\nh3\ni = œÉ((c ‚àí1)i ‚àíi(c ‚àí1) + 1) = 1. So x‚Ä≤\ni = œÉ(c ‚àí1 + 1 ‚àíc) = 0.\nThus, the constructed functions realize Equation (C.1) and are transition functions.\n5. Since the input is binary, the function f(x) can be rewritten as\nf(x) = exp(Œ±x) =\n(\n1\nif x = 0\neŒ±\nif x = 1 = (1 ‚àíeŒ±)1 (x = 0) + eŒ±\nSince 1 (x = 0) is a transition function, f(x) is also a transition function.\n65\n",
    "figure_captions": [
      "Figure 1.1. As we will see shortly, the resulting improvement in KL divergence allows us to bound",
      "Figure 1.1: Illustration of the boosting construction for q‚Ä≤ in Lemma 1. The axis is the index of the",
      "Figure 1.2: Two examples of RNNs, and their corresponding unrolled feedforward networks. In both",
      "Figure 2.1: A sketch of the original RNN Q, and the constructed RNN U. The RNN Q has a",
      "Figure 2.1 gives a sketch for the construction. The proof of this lemma is in Section 2.4.3.",
      "Figure 2.2: The Load-Run-Hold schedule for the node set H within each input loop.",
      "Figure 2.2 shows the LOAD-RUN-HOLD schedule of the set H within each input loop. Formally, ht",
      "Figure 2.3: The Load-Run-Hold schedule for the node set ÀúH within each input loop of (2k + 1)kœÑ",
      "Figure 2.3 shows the LOAD-RUN-HOLD schedule of the set ÀúH within each input loop. Formally, for",
      "Figure 3.1: A universal graph that encompasses all RNNs with constraints on size, hidden node set"
    ]
  },
  {
    "arxiv_id": "2512.07808v1",
    "title": "LUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout",
    "abstract": "Qubit readout is a critical operation in quantum computing systems, which maps the analog response of qubits into discrete classical states. Deep neural networks (DNNs) have recently emerged as a promising solution to improve readout accuracy . Prior hardware implementations of DNN-based readout are resource-intensive and suffer from high inference latency, limiting their practical use in low-latency decoding and quantum error correction (QEC) loops. This paper proposes LUNA, a fast and efficient superconducting qubit readout accelerator that combines low-cost integrator-based preprocessing with Look-Up Table (LUT) based neural networks for classification. The architecture uses simple integrators for dimensionality reduction with minimal hardware overhead, and employs LogicNets (DNNs synthesized into LUT logic) to drastically reduce resource usage while enabling ultra-low-latency inference. We integrate this with a differential evolution based exploration and optimization framework to identify high-quality design points. Our results show up to a 10.95x reduction in area and 30% lower latency with little to no loss in fidelity compared to the state-of-the-art. LUNA enables scalable, low-footprint, and high-speed qubit readout, supporting the development of larger and more reliable quantum computing systems.",
    "text": "LUNA: LUT-Based Neural Architecture for Fast and Low-Cost\nQubit Readout\nMuhammad Ali Farooq\nArizona State University\nTempe, Arizona, USA\nmafarooq19@asu.edu\nGiuseppe Di Guglielmo\nFermi National Accelerator\nLaboratory\nBatavia, Illinois, USA\ngdg@fnal.gov\nAbhi Rajagopala\nUniversity of Arkansas\nFayetteville, Arkansas, USA\nabhi@uark.edu\nNhan Tran\nFermi National Accelerator\nLaboratory\nBatavia, Illinois, USA\nntran@fnal.gov\nVidya Chhabria\nArizona State University\nTempe, Arizona, USA\nvachhabr@asu.edu\nAman Arora\nArizona State University\nTempe, Arizona, USA\naman.kbm@asu.edu\nAbstract\nQubit readout is a critical operation in quantum computing systems,\nwhich maps the analog response of qubits into discrete classical\nstates. Deep neural networks (DNNs) have recently emerged as a\npromising solution to improve readout accuracy . Prior hardware\nimplementations of DNN-based readout are resource-intensive and\nsuffer from high inference latency, limiting their practical use in\nlow-latency decoding and quantum error correction (QEC) loops.\nThis paper proposes LUNA, a fast and efficient superconducting\nqubit readout accelerator that combines low-cost integrator-based\npreprocessing with Look-Up Table (LUT) based neural networks for\nclassification. The architecture uses simple integrators for dimen-\nsionality reduction with minimal hardware overhead, and employs\nLogicNets (DNNs synthesized into LUT logic) to drastically reduce\nresource usage while enabling ultra-low-latency inference. We in-\ntegrate this with a differential evolution based exploration and\noptimization framework to identify high-quality design points.\nOur results show up to a 10.95√ó reduction in area and 30%\nlower latency with little to no loss in fidelity compared to the\nstate-of-the-art. LUNA enables scalable, low-footprint, and high-\nspeed qubit readout, supporting the development of larger and\nmore reliable quantum computing systems.\nCCS Concepts\n‚Ä¢ Computer systems organization ‚ÜíQuantum computing.\nKeywords\nQubit Readout, Quantum Computer Architecture, Quantum Control\nHardware\n1\nIntroduction\nScalable quantum computing demands fast, accurate, and resource-\nefficient qubit readout. In superconducting platforms [7], the read-\nout operation converts microwave responses from resonator-coupled\nqubits into digital I/Q traces, which are then processed and dis-\ncriminated as |0‚ü©or |1‚ü©. This digital signal processing is typically\nperformed on FPGA or RFSoC-based controllers [8, 19, 20], which\nhandle demodulation, integration, and classification in real time\n(Figure 1).\nCryogenic Refrigerator\nQPU\nQubit Drive Control\nReadout Drive\nReadout Signal\nRFSoC - FPGA\nClassifer\nPre-\nProcessor\nSignal\nGenerator\nADC\nDAC\nFigure 1: Simplified superconducting-qubit readout chain.\nRFSoC-FPGA is responsible for qubit drive and readout.\nAs quantum processors scale to hundreds or thousands of qubits,\nreadout systems face three constraints: (i) latency, since mid-circuit\nmeasurement and feedback must occur within coherence windows;\n(ii) accuracy, as assignment errors directly degrade algorithmic\nand QEC performance; and (iii) hardware footprint, as limited\nFPGA resources must perform many parallel tasks.\nRecent work demonstrates that neural-network discriminators\ncan significantly improve readout fidelity by compensating for\nsystem nonidealities [9, 10]. However, large models and complex\npreprocessing stages often make such implementations resource-\nheavy and slow, limiting scalability and mid-circuit usability. While\nFPGA-accelerated ML classifiers have shown nanosecond-scale\ninference [5, 6, 17], the trade-offs in cost (latency and area) and\nfidelity remain underexplored.\nThis work aims to push qubit-readout acceleration toward\nthe ultra-fast, resource-efficient regime. We co-design prepro-\ncessing and classification for FPGA-based qubit readout and make\ntwo key observations. First, simple integrators can be used in lieu of\nexpensive matched filters [15][6] with minimal to no fidelity loss,\nwith low preprocessing cost and reducing model footprint through\ndimensionality reduction. Second, LUT-based neural networks map\nefficiently to FPGA primitives, providing ultra-low-latency infer-\nence with minimal area, for qubit classification. We jointly optimize\nboth these components via a combined design-space exploration\n(DSE) and neural architecture search (NAS) framework using dif-\nferential evolution.\narXiv:2512.07808v1  [quant-ph]  8 Dec 2025\n\nConference ‚Äô26, 2026,\nMuhammad Ali Farooq, Giuseppe Di Guglielmo, Abhi Rajagopala, Nhan Tran, Vidya Chhabria, and Aman Arora\nTable 1: Representative prior FPGA-based readout efforts. ‚ÄúDSE/NAS‚Äù indicates whether a formal architecture search was\nperformed.\nWork\nQubits\nPreprocessing\nClassifier\nFPGA/RFSoC?\nDSE/NAS?\nLienhard [9]\n5\nMatched filter\nFully connected DNN\n‚úó\n‚úó\nVora [17]\n1\nMatched filter\nShallow NN\n‚úì\n‚úó\nDi Guglielmo [5]\n1\n‚Äî\nhls4ml DNN\n‚úì\nPartial\nGuo [6]\n1\nMatched filter + averaging\nDistilled DNN\n‚úì\nCompression only\nThis work\n1\nIntegrator (co-designed)\nLogicNet (LUT-DNN)\n‚úì\nDE-based DSE/NAS\nWe implement and evaluate our superconducting qubit readout\ndiscrimination accelerator on an AMD/Xilinx FPGA. Our results\ndemonstrate significant reductions in FPGA resource usage and\ninference latency with no degradation in fidelity, compared to the\nSOTA implementation [5].\nWe make the following contributions in this work:\n(1) We introduce the first ever use of LUT-based neural net-\nworks (LogicNets [16]) for FPGA-based zero DSP qubit\nstate discrimination acceleration.\n(2) We develop a lightweight integrator-based preprocess-\ning pipeline that maintains fidelity at far lower cost re-\nsource cost.\n(3) We perform a joint DSE+NAS across preprocessing and\nLogicNet architectures using differential evolution to explore\nand evaluate trade-offs, marking the first structured NAS\nattempt using LUT based DNNs.\n(4) We present an FPGA implementation that is compatible\nwith the Quantum Instrumentation and Control Kit\n(QICK) [12], demonstrating upto a 10.95√ó reduction in area\nand a 30.9% reduction in latency at competitive fidelities.\nThe LUNA flow is fully automated, and is available at blinded.\n2\nBackground and Related Work\n2.1\nQubit readout for superconducting devices\nSingle-shot readout of superconducting qubits converts a quantum\nstate into a classical microwave response. A readout pulse probes a\nresonator coupled to the qubit; the reflected/transmitted waveform\nis amplified, down-converted, and digitized to yield time-series\nin-phase (I) and quadrature (Q) traces. The digital front end, typi-\ncally a Radio Frequency System on Chip (RFSoc) FPGA, performs\ndemodulation, preprocessing, and classification to produce a binary\nassignment (|0‚ü©or |1‚ü©).\nClassical preprocessing choices are matched filtering [15] sliding\nwindow averaging. Matched filters maximize signal-to-noise ratio\n(SNR) under Gaussian noise but require multipliers and memory,\nwhich scale poorly when replicated across many channels. Sliding\nwindow averaging is hardware-efficient (adders and shifts only)\nbut slightly suboptimal in discrimination performance [6]. The\nfront-end design thus exposes a fidelity vs. resource tradeoff critical\nto scalable FPGA-based readout systems. Keeping this tradeoff in\nmind, we adopt a novel integrator based strategy for preprocessing.\nThresholding methods for classification degrade under crosstalk,\nnonstationary noise, and device nonlinearities. Learned discrimina-\ntors (e.g., Deep Neural Networks (DNN)) improve fidelity, especially\nacross multiplexed channels [9]. These models can compress and\ndenoise time-series inputs while adapting to experimental non-\nidealities that fixed templates cannot capture.\nSeveral recent works demonstrate real-time ML-based readout on\nFPGA/RFSoC hardware. Di Guglielmo et al. present an end-to-end\nworkflow that couples QICK [12] with hls4ml [4], achieving low-\nnanosecond inference but consuming tens of thousands of LUTs\nand hundreds of DSPs[5], with no preprocessing or dimensional-\nity reduction. Vora et al. deploy RFSoC-integrated discriminators,\nutilizing digital local oscillator (DLO) as multiplication strategy\nfor deploying matched filters [17] and integrated it into the QubiC\nframework [19]. Guo et al. use distillation to compress large readout\nnetworks into smaller FPGA-friendly models [6]. They utilize both\nmatched filter and window averaging as pre-processors to form\nfeature vectors for classification. These works validate ML infer-\nence on FPGA platforms but tend to rely on multiplier-heavy layers\n(incurring DSP/BRAM cost) or limited/non-structured design-space\nsearch for the preprocessing + classifier co-design.\nWe use the work of Di Guglielmo et al. [5] as a baseline due to\nthe ready availability of the readout data in the form of [3]. Given\nthat qubit response varies from device to device, we do not draw\nperformance comparisons with other works.\n2.2\nLUT-based networks\nMapping inference directly into FPGA LUTs eliminates multiplier/\nDSP dependence by treating quantized neurons as small Boolean\ntruth tables that can be implemented as native K-input LUT prim-\nitives. Early work (LUTNet [18]) showed that trained, binarized\noperators can be hardened into LUT configurations to yield very\narea-efficient, low-latency inference engines; subsequent efforts de-\nveloped toolchains to convert trained networks into LUT masks and\nto unroll operators for maximal parallelism. LogicNets extends this\nidea with an explicit hardware‚Äìsoftware co-design of a LUT mapped\nneural network: during training it constrains connectivity (low fan-\nin), encourages sparsity, and uses quantization so that each neuron‚Äôs\nfunction can be extracted as one (or a small number of) LUT truth ta-\nbles, producing a directly deployable, highly-pipelined FPGA netlist\n[16]. Weightless neural networks (WNNs) and RAM-based classi-\nfiers (WiSARD variants and recent LogicWiSARD work) take the\ntable-lookup idea further toward memory-centric, lookup-only in-\nference and can achieve extremely low latency and energy, but they\ntypically trade off accuracy or require different memory/BRAM\ntradeoffs compared with LUT-mapped quantized networks [11, 14].\nPractically, LUT-based DNN implementation forces a set of co-\ndesign tradeoffs. Limiting neuron fan-in (commonly to device LUT\nsizes, e.g., 6‚Äì8 inputs) avoids exponential truth-table growth but of-\nten requires deeper or wider DNN topologies or input-partitioning\n\nLUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout\nConference ‚Äô26, 2026,\nDesign Space\nEnumeration\nPruning¬†\nSearch & Optimization\n(DE)\nCost Models\nEnd-to-End Hardware RTL\nLonger Training on Design Point\nEvaluation\nSynthesis and Implementation\n1\n3\n2\n4\n5\nFigure 2: LUNA co-design flow: (1) enumerate, (2) prune, (3)\nDE-based NAS, (4) generate RTL (integrator + LUT-DNN), (5)\nimplement design on target device and evaluate fidelity on\ntest set.\n(decomposing a large receptive field across multiple LUTs) to pre-\nserve accuracy. Input-packing and carefully chosen quantization\nschemes are used to amortize LUT cost. The standard toolflow is\nto design a fan-in-aware topology, apply sparsification/pruning\nand constrained retraining, then extract neuron truth tables for\ndirect LUT instantiation. The main benefits of LUT-based DNNs\nare removal of multiplier/DSP resources, single-cycle (or deeply\npipelined) per-layer latency, and highly predictable timing.\nWe adopt the LogicNets approach in this work because it explic-\nitly co-optimizes topology, sparsity, and quantization to produce\ndirectly mappable LUT truth-tables with a controllable fan-in vs.\naccuracy tradeoff. Compared with LUTNet [18], LogicNets [16]\nprovides a clearer training-to-netlist pipeline and tighter topology\nconstraints for predictable area‚Äìaccuracy tradeoffs, and compared\nwith WNNs [11, 14], it preserves closer compatibility with mod-\nern quantized DNN accuracy while still delivering the LUT-native,\nmultiplier-free hardware advantages we require.\n2.3\nDSE and NAS\nAutomated techniques, like reinforcement learning, Bayesian opti-\nmization, and evolutionary algorithms, have been applied to DSE\nand NAS problems. Differential Evolution (DE) is a simple, gradient-\nfree evolutionary optimizer that adapts readily to mixed encodings\nand costly black-box evaluations and has been used successfully\nfor NAS-style problems [2, 13]. We adopt DE since it‚Äôs population-\ngeneration and selection mechanism fits naturally with our search;\ncandidate evaluations (DNN training + resource cost prediction)\nare expensive but can be easily parallelized, as compared to other\nmeta-heuristic approaches like Simulated Annealing.\n2.4\nLUNA vs. prior work\nTable 1 summarizes prior FPGA-based readout works that use ML.\nPrior efforts demonstrated ML feasibility on FPGA/RFSoC platforms\nbut generally rely on multiplier-based layers, limited preprocessing\nco-design, or offline compression. To our knowledge, none combine\n(i) a low-cost integrator front end, (ii) LUT-mapped LogicNet classi-\nfiers, and (iii) an automated DSE-NAS that jointly optimizes prepro-\ncessing and LUT-DNN topology for area/latency/fidelity tradeoffs.\n3\nThe LUNA Approach\n3.1\nOverview and design flow\nFigure 2 summarizes our co-design flow. Our approach couples a\nhardware-aware neural-network design methodology (LogicNets)\nwith an evolutionary architecture search (differential evolution)\nand automated FPGA synthesis. The flow is as follows: From a\nparameterized design space ‚ù∂, we apply light pruning heuristics to\nremove infeasible design points ‚ù∑, then run a search and optimiza-\ntion loop driven by DE‚ù∏. We then fully implement the resulting\ndesign points ‚ùπand implement and evaluate them ‚ù∫.\n3.2\nArchitecture\nThe accelerator comprises two tightly-coupled blocks: (i) an inte-\ngrator preprocessor that performs low-cost dimensionality reduc-\ntion, and (ii) a LogicNet classifier where each neuron is mapped\ndirectly into FPGA LUTs for ultra-low-latency inference [16]. Data\nflows in a short, pipelined path: digitized I/Q samples are captured,\nrouted into the integrator windows, reduced to a compact feature\nvector, then fed into the LogicNet for immediate classification. A\nhigh level overview of this architecture is given Fig. 3.\n3.2.1\nIntegrator Based Preprocessor. Integrators compress the raw\nI/Q trace by partitioning the ADC samples into num_filter fixed,\nnon-overlapping windows and computing an accumulation per\nwindow. In each window, the incoming 14-bit ADC samples are\noptionally right-shifted by shiftùëö(pre-accumulation) to discard LSB\nnoise and reduce precision, summed in an adder-tree, and then right-\nshifted by shiftùëõ(post-accumulation) to normalize dynamic range\nand produce a quantized scalar I and Q feature per window. These\nscalar pairs are concatenated to form the input feature vector for the\nclassifier. The integrator is parametrizable by the start ADC sample\nindex/total number of ADC samples, number of windows, and shift\namounts; its hardware is an adder-tree with pipeline registers at\neach stage. We adopt this approach to reduce input dimensionality\nin order to reduce the cost of the classifier, and to do so in a manner\nthat does not consume expensive DSPs.\n3.2.2\nLogicNet classifier. The feature vector from the integrator\nis presented to a LUT-based neural network implemented via Log-\nicNets, where each neuron is synthesized as a Boolean function\nimplemented directly in FPGA LUT primitives [16]. A LogicNet\nis defined by its layer widths [‚Ñì1, . . . , ‚Ñìùëò‚àí1], per-layer fanin (ùõæ) and\nbitwidth (ùõΩ). Each Neuron Equivalent (NEQ) consumes ùëã= ùõΩ¬∑ ùõæ\ninput bits and produces ùëå= ùõΩoutput bits, effectively implementing\nan ùëã: ùëåLUT operation. These parameters determine both model\ncapacity and FPGA cost. Because all neurons are purely combina-\ntional and the network is fully pipelined (typically only 1‚Äì2 LUTs\nbetween registers) the classifier achieves very low latency suitable\nfor tight QEC timing budgets.\n3.3\nDesign space\nThe design space of the integrator and LogicNet is defined by vari-\nous parameters of each stage, listed in Table 2. We model a candidate\ndesign point as a fixed-length integer vector ùë£consisting of a value\nof each parameter. Each parameter‚Äôs value can have a large range,\nleading to a vast design space, which is difficult to explore. We apply\nthe following heuristics to prune the ranges for each parameter:\n\nConference ‚Äô26, 2026,\nMuhammad Ali Farooq, Giuseppe Di Guglielmo, Abhi Rajagopala, Nhan Tran, Vidya Chhabria, and Aman Arora\n¬†>> shiftm\n(shiftm = 7)\nI\nPre-Accumulation Shift\nQubit State Prediction\nDemodulated Readout Pulse\nFrom ADC\nadder tree\n¬†>> shift_n\n¬†>> shiftn\n(shiftn¬†= 1)\nadder tree\n2 Windows\n400 samples¬†\nx¬†\n14 bits / sample¬†\n200 x 7b¬†\n15b\n14b\n56b\nLogicNet\n145 neurons\n40 neurons\n15 neurons1 neuron\nLUT\nŒ≥ x Œ≤ bits¬†\n400 x 7b¬†\n¬†>> shiftm\n(shiftm = 7)\nQ\nadder tree\n¬†>> shift_n\n¬†>> shiftn\n(shiftn = 1)\nadder tree\nPost-Accumulation Shift\nIntegrator\nFigure 3: A high level overview of the LUNA architecture. Values shown are demonstrative; taken from our fidelity-optimized\nsolution shown in Table 3.\nTable 2: Search-space parameters and allowed ranges.\nParameter\nDescription\nRange\nstart time Start sample index (ADC); end fixed at 500.\n{0, 50, 100}\n# windows\nSignal partitions before preprocessing.\n{1, 2, 3, 4}\nshift_m\nPre-accum. right shift (ignore LSB noise).\n{2, 3, ..., 7}\nshift_n\nPost-accum. right shift (scale integrator output). {0, 1, ..., 6}\n‚Ñì0\nNEQs in input layer.\n{25, 30, ..., 145}\n# layers\nHidden layer count.\n{2, 3}\n‚Ñì1, ‚Ñì2, . . .\nNEQs per hidden layer.\n{5, 10, ..., 45}\nùú∑ùíä, ùú∑, ùú∑ùíê\nNEQ input bitwidth (input, hidden, output).\n{1, 2}\nùú∏ùíä\nNEQ fan-in (input layer).\n{6, 7}\nùú∏,ùú∏ùíê\nNEQ fan-in (hidden/output layers).\n(\n{6, . . . , 16},\nùõΩ= 1\n{6, 7, 8},\nùõΩ= 2\n(1) Area-based pruning: A conservative LUT estimate is made\nusing a simple model (Section 3.5.2) and designs with es-\ntimated LUTs > ùê¥max = 20,000 (empirically chosen) are\ndiscarded.\n(2) Full cost-based pruning: A number of random design\npoints are created after the area-based pruning and fully\nevaluated according to the criteria in Section 3.5. These re-\nsults are used to further refine our design space.\n3.4\nSearch and Optimization\nThe design space of the preprocessing and classifier architecture\nis very large, due to the large number of variables that govern the\narchitecture (eg. signal window size, normalization, and sparsity\nsettings. See Section 3.3.) The search and optimization of our pre-\nprocessing and classifier architecture is unique, as it requires both\ndesign space exploration (DSE) for the preprocessor and neural\narchitecture search (NAS) for the classifier. Since isolated optimiza-\ntion of either can ignore better performing points, we are motivated\nto perform joint optimization of the spaces. We therefore fold the\nDSE+NAS problem into a single search and optimization problem.\nWe use Differential Evolution (DE) [13] to search the pruned, de-\nsign space. DE is a population-based optimization algorithm that we\nadapt for our mixed-discrete design space. It works by maintaining\na population of candidate solutions, which evolve over generations\nthrough mutation, crossover, and selection. Mutation follows the\nclassical DE rule, where for each member of the population ùë£(ùëñ), we\ndraw three distinct population members ùë£(ùëé), ùë£(ùëè), ùë£(ùëê) and form a\nmutant vector ùëö:\nùëö= ùë£(ùëé) + ùêπDE ¬∑ \u0000ùë£(ùëè) ‚àíùë£(ùëê)\u0001\n(1)\nwhere ùêπDE is the mutation rate. Crossover then constructs a trial\n‚Äòoffspring‚Äô vector ùëúby combining the mutant ùëöwith the parent ùë£(ùëñ).\nEach element in ùëúis determined as:\nùëúùëó=\nÔ£±Ô£¥Ô£¥Ô£¥Ô£≤\nÔ£¥Ô£¥Ô£¥Ô£≥\nùëöùëò,\nif ùëò= ùëó,\nùëöùëó,\nif ùë¢ùëó< ùê∂ùëÖ,\nùë£(ùëñ)\nùëó,\notherwise,\n(2)\nwhere ùëòis a random index selected from the length of the vec-\ntor, ùë¢ùëóis a random number sampled uniformly in [0, 1], and CR is\nthe crossover rate. The parameter values of the resulting offspring\nare clipped and snapped to the nearest valid configuration before\nevaluation. After evaluation, the offspring replaces its parent if it\nexhibits a lower cost thereby surviving to the next generation. This\nprocess repeats for ùê∫max generations, allowing us to arrive at a\nviable solution point. Early stopping terminates the search when\nno improvement is observed for a fixed patience window ùëÉ. With\nDE, evaluation of each candidate design point becomes indepen-\ndent and therefore fully parallelizable, making DE an attractive\noptimization strategy for our use case. With full parallelization\nacross all evaluations within a generation, we are able to evaluate\na generation within ‚âà4 minutes.\n3.5\nComposite cost and metric estimation\nTo evaluate each design point, we use a composite cost C that is\ndefined as a weighted combination of normalized area, latency, and\nfidelity metrics. Weights ùë§ùëé,ùë§ùëô,ùë§ùëìdefine the importance of the\nthree metrics.\nC = ùë§ùëée\nùê¥+ ùë§ùëôeùêø+ ùë§ùëìeF , where:\n(3)\ne\nùê¥= area\nùê¥max\n,\neùêø= latency\nùêømax\n,\neF = 1 ‚àífidelity\n1 ‚àí0.90\nand where ùê¥max and ùêømax are empirically chosen (based on the\nrandom exploration in Section 4.4) to be 20,000 LUTs and 14 cycles.\nThis does not hinder our search process, and allows us to have a\nmeaningful combined cost metric.\nThe ideal evaluation of a design point would entail training the\nLogicNet fully on the available data for fidelity evaluation, and\n\nLUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout\nConference ‚Äô26, 2026,\ncomplete synthesis and implementation of the end-to-end solution\n(integrator and LogicNet) on the target device for area and latency.\nThe cost of that design point would then be calculated using the\nequation above. However, this would be extremely time consuming,\nand would make exploration of the large design space prohibitively\nexpensive. As such, we develop inexpensive methods for quick and\naccurate estimates.\n3.5.1\nLatency estimation. Latency (cycles) is estimated analytically\nas latency = integrator_cycles + LogicNet_stages, with integrator\ncycles approximated by the adder-tree pipeline depth ‚åàlog2(ùëÅ)‚åâfor\nùëÅinputs, and each LogicNet layer contributing 1 pipelined cycle.\n3.5.2\nArea estimation. Area is approximated by the number of\nLUTs (flip-flops (FF) are ignored; number of FFs generally tracks\nwith the number of LUTs). LUT count is predicted using a hybrid\nmodel:\n‚Ä¢ Integrator LUTs are estimated using a regression model\ntrained on a few synthesized adder-tree RTL designs (fea-\ntures: number of inputs, bitwidth).\n‚Ä¢ LogicNet LUTs are estimated using analytical per-neuron\nLUT-equivalents using the analytical formula from [16] and\na correction factor obtained through a lightweight regression\ntrained on a few implemented models.\nThis cost model is calibrated using a few end-to-end implementa-\ntions, and is able to predict end-to-end area within ¬±20%.\n3.5.3\nFidelity evaluation. Fidelity F is obtained by training the\nLogicNet on the full dataset and reporting the classification metric\nF = 1 ‚àí0.5 ¬∑ \u0000ùëÉ(0 | 1) + ùëÉ(1 | 0)\u0001 on the test set for parity with\nprior work for a reduced number of epochs (see Sec. 4.3).\n3.6\nFPGA implementation\nFor our final FPGA implementation, we utilize our hand-coded,\nparameterized RTL templates for the preprocessing segment. For\nthe classifier segment, we use the LogicNets framework [16] to\ngenerate RTL from the trained model. These are synthesized and\nplaced-and-routed on the target FPGA. For each design point, we\nextract post-implementation resource utilization (LUTs, FFs, DSPs)\nand timing reports (worst negative slack, reported clock period).\nSimilar to [5], our end to end implementation takes a fixed 2 cycles\nto save the discrimination prediction to memory; as such, we add a\nfixed 2 cycles to our final implementation results.\n4\nMethodology\n4.1\nToolchains and platforms\nOur DE implementation and orchestration scripts are implemented\nin Python 3.8.19. We use the LogicNets framework from AMD/Xilinx\n[1] for creating our LUT-based DNN. Parameterized RTL (adder\ntrees and integrators) is generated from Mako templates (mako 1.3.10),\nenabling a single template family to emit RTL for many design\npoints. Xilinx Vivado 2022.2 performs synthesis and implementa-\ntion, for timing extraction and to obtain final resource usage.\n4.2\nDataset\nWe use the publicly available superconducting-qubit readout dataset\n(time-series I/Q traces, labeled |0‚ü©/|1‚ü©) used by Guglielmo et al.\n[3]. The dataset and experimental conventions (readout lengths,\nsampling, and QICK-based capture) follow the end-to-end readout\nworkflows previously reported. [5, 12]\nFor the experiments reported here, we use a fixed split of 90,000\ntraining samples and 10,000 test samples. During the search phase\n(DE evaluation), we train and validate candidate LogicNets on the\nfull split described above to obtain robust fidelity estimates (see\nnext subsection for training protocol).\n4.3\nTraining protocol\nTo balance search throughput and fidelity estimation reliability, we\nuse a two-stage training protocol:\n(1) Search-time training: During DE search each candidate\nLogicNet is trained and evaluated on the full dataset split for\n5 epochs using a batch size of 512. This reduced training\nbudget is a trade-off: it yields stable, comparable fidelity esti-\nmates across many candidates while keeping per-candidate\nwall-clock time manageable.\n(2) Final training: Once the DE procedure selects a final candi-\ndate, that architecture is re-trained from scratch on the same\ntraining split for 30 epochs using a batch size of 1024. This\nfinal training run uses identical preprocessing and quanti-\nzation settings as during search but with the larger epoch\ncount and batch size to realize the best achievable fidelity\nprior to FPGA conversion and deployment.\nThe use of a full-dataset training during search (rather than a\nproxy subset) helps reduce variance across fidelity estimates when\ncomparing candidate designs.\n4.4\nDifferential evolution parameters\nWe use a population size of ùëÅùëÉ= 75 and adopt DE settings of scale\nfactor ùêπDE = 0.7 and crossover rateùê∂ùëÖ= 0.8. The maximum number\nof generations is ùê∫max = 150, and early termination is triggered\nafter ùëÉ= 40 generations without improvement. These values were\nchosen empirically to balance exploration and convergence speed.\n4.5\nBaseline\nThe end-to-end readout work by Guglielmo et al. [5] is used as\na state-of-the-art reference for ML-based FPGA readout systems,\nespecially since it uses the same dataset [3]. As such, we perform\nthe FPGA implementation for the ùëãùê∂ùëçùëà49ùê∑ùëÖdevice as well.\n5\nResults\n5.1\nSearch and Optimization Results\nWe perform search and optimization using our described flow under\nthree optimization targets for separate LUNA architectures:\n‚Ä¢ Area-Optimized: prioritize area efficiency\n(ùë§ùëé=0.8,ùë§ùëô=0.1,ùë§ùëì=0.1)\n‚Ä¢ Latency-Optimized: prioritize inference time\n(ùë§ùëé=0.1,ùë§ùëô=0.8,ùë§ùëì=0.1)\n‚Ä¢ Fidelity-Optimized: prioritize fidelity\n(ùë§ùëé=0.1,ùë§ùëô=0.1,ùë§ùëì=0.8)\nEach configuration reports the best architecture discovered, in-\ncluding integrator and LogicNet parameters, along with estimated\nperformance metrics. The results for each run are given in Table 3.\n\nConference ‚Äô26, 2026,\nMuhammad Ali Farooq, Giuseppe Di Guglielmo, Abhi Rajagopala, Nhan Tran, Vidya Chhabria, and Aman Arora\nTable 3: Search and Optimization Results. For each optimization target, the top-performing configuration and estimated metrics\nare listed. Latency is quoted in cycles, Area is quoted in LUTs\nConfiguration\nEstimated Results\nTarget\nStart Sample\n# Windows\nshiftùëö\nshiftùëõ\nLayers\nùõΩùëñ\nùõΩ\nùõΩùëú\nùõæùëñ\nùõæ\nùõæùëú\nArea\nLatency\nFidelity (%)\nFidelity\n100\n2\n7\n1\n145, 40, 15, 1\n1\n2\n2\n7\n6\n8\n8226\n12\n95.995\nArea\n100\n1\n9\n0\n25, 5, 5, 1\n1\n1\n2\n6\n6\n11\n6754\n13\n95.929\nLatency\n100\n2\n9\n1\n145, 35, 15, 1\n1\n1\n2\n6\n6\n7\n7311\n12\n95.885\nTable 4: FPGA Implementation Summary. Results include logic utilization, latency, and fidelity. Resource usage is quoted as\npercentages of available resources on the ùëãùê∂ùëçùëà49ùê∑ùëÖdevice.\nArchitecture\nTarget\nLUTs\nFlip Flops\nDSPs\nPeriod (ns)\nLatency (ns)\nFidelity\nFidelity\n10,642 (2.50%)\n13,206 (1.55%)\n0 (0.00%)\n1.751\n24.51\n96.059%\nLUNA\nArea\n6,095 (1.43%)\n9,688 (1.14%)\n0 (0.00%)\n1.588\n23.82\n95.924%\nLatency\n6,205 (1.46%)\n9,809 (1.15%)\n0 (0.00%)\n1.579\n22.10\n95.969%\nBaseline [5]\n‚Äî\n66,600 (15.66%)\n34,369 (4.04%)\n481 (11.26%)\n3.220\n32.00\n96.000%\nThe fidelity-optimized model uses a wider network and moderate\nintegrator shifts, reaching ‚âà96.0% fidelity with a 12-cycle latency\nand 8226 LUTs. The area-optimized design uses a much smaller\nLogicNet and more aggressive pre-accumulation, reducing area to\n6754 LUTs while retaining 95.93% fidelity. The latency-targeted run\nalso settles at 12 cycles (7311 LUTs, 95.89%). The fidelities are tightly\nclustered while the three points emphasize different area/latency\ntradeoff ‚Äî the search did not produce lower-latency candidates\nwith a lower objective cost, so both latency- and fidelity-targeted\nruns converged to 12-cycle designs.\nThe cost of the best performing candidate per generation is\ntracked in Figure 4, demonstrating that improvement does occur\nover the course of DE.\n5.2\nFPGA Implementation Results\nAs summarized in Table 4, all three target variants achieve large\nLUT and FF reductions relative to the baseline accelerator while\nmaintaining competitive fidelity and, most notably requiring zero\nDSP blocks. This demonstrates that both the integrator frontend\nand the classifier can be mapped entirely onto LUT fabric without\nsacrificing readout accuracy.\nThe fidelity optimized LUNA architecture improves upon SOTA\nfidelity by 0.059% fidelity, with a 6.3√ó reduction in LUT usage and a\n23.4% reduction in latency. The area optimized architecture achieves\na 10.95√ó reduction in LUT usage and a 25.6% improvement in la-\ntency with only a 0.076% loss of fidelity. The latency optimized\narchitecture improves upon latency by 30.9% with a 10.74√ó reduc-\ntion in LUT use and a fidelity loss of only 0.031%.\nThese hardware results validate the trends observed during DE-\nbased search and confirm that the flow yields consistently compact\nand efficient implementations.\n6\nDiscussion\nThis work shows that combining an integrator-based dimensional-\nity reduction stage with LUT-mapped LogicNet classifiers enables\nFigure 4: Best cost trajectory across generations for each tar-\nget objective: (a) Fidelity-optimized, (b) Latency-optimized,\nand (c) Area-optimized. Each curve shows the best individ-\nual‚Äôs cost per generation.\nsubstantial FPGA savings while preserving state-of-the-art qubit-\nstate discrimination fidelity. The integrator compresses raw I/Q\ntrajectories into a small set of aggregate features using simple shift-\nand-accumulate operations, reducing classifier input dimensionality\nwith negligible compute cost. When paired with LogicNets, the re-\nsulting LUNA flow achieves order-of-magnitude LUT reductions,\nlower latency, and zero DSP usage, freeing arithmetic resources for\nqubit control and signal-generation tasks.\nReducing per-qubit area is increasingly important as quantum\nsystems move toward mid-circuit measurement and quantum error\ncorrection (QEC), where large numbers of concurrent readout paths\nare required. A smaller hardware footprint directly increases the\nnumber of readout engines that can be instantiated on a single\ndevice, supporting the scaling needs of future processors.\nSeveral avenues for future work follow. Evaluating LUNA on\nadditional datasets, including multi-qubit or higher-dimensional\nreadout traces, will help assess generality. Extending the archi-\ntecture to multi-qubit joint classifiers could capture crosstalk and\ncorrelated noise, a limitation of per-qubit pipelines noted in prior\nwork. Finally, richer search strategies may provide improved cover-\nage of the design space and may uncover even better solutions.\n\nLUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout\nConference ‚Äô26, 2026,\n7\nConclusion\nThis paper presents LUNA, a hardware‚Äìsoftware co-design frame-\nwork that couples integrator-based dimensionality reduction with\nLUT-based neural network classifiers to produce highly efficient\nFPGA implementations for qubit-state readout. Using differential\nevolution to jointly optimize preprocessing and classifier structure,\nLUNA identifies compact designs that maintain high discrimina-\ntion fidelity while drastically reducing hardware footprint. Across\nthe studied dataset, LUNA reaches fidelities near 96% with up to\na 10.95√ó LUT reduction and up to a 30% latency improvement, all\nwith zero DSP utilization. These resource savings directly support\nscalable quantum processors, particularly scenarios requiring large\nnumbers of parallel mid-circuit measurements and QEC operations.\nReferences\n[1] 2020. LogicNets: Co-Designed Neural Networks and Circuits for Extreme-Throughput\nApplications.\nRetrieved November 01, 2025 from https://github.com/Xilinx/\nlogicnets/tree/master\n[2] Noor Awad, Neeratyoy Mallik, and Frank Hutter. 2020. Differential evolution\nfor neural architecture search (dehb). In International Conference on Machine\nLearning (ICLR) Neural Architecture Search (NAS) Workshop.\n[3] Batao Du. 2024. Data for \"End-to-end workflow for machine learning-based qubit\nreadout with QICK and hls4ml. Retrieved November 11, 2025 from https://doi.\norg/10.5281/zenodo.14427490\n[4] Farah Fahim, Benjamin Hawks, Christian Herwig, James Hirschauer, Sergo Jin-\ndariani, Nhan Tran, Luca Carloni, Giuseppe Di Guglielmo, Philip Harris, Jeffrey\nKrupa, Dylan Rankin, Manuel Blanco Valentin, Josiah Hester, Yingyi Luo, John\nMamish, Seda Memik, Thea Aarrestad, Hamza Javed, Vladimir Loncar, Maurizio\nPierini, Adrian Alan Pol, Sioni Summers, Javier Duarte, Scott Hauck, Shih-Chieh\nHsu, Jennifer Ngadiuba, Mia Liu, Duc Hoang, Edward Kreinar, and Zhenbin\nWu. 2021. hls4ml: An Open-Source Co-Design Workflow to Empower Scientific\nLow-Power Machine Learning Devices. In Research Symposium on Tiny Machine\nLearning. https://openreview.net/forum?id=YBFqldo30vG\n[5] Giuseppe Di Guglielmo, Botao Du, Javier Campos, Alexandra Boltasseva, Akash\nDixit, Farah Fahim, Zhaxylyk Kudyshev, Santiago Lopez, Ruichao Ma, Gabriel N.\nPerdue, Nhan Tran, Omer Yesilyurt, and Daniel Bowring. 2025. End-to-End\nWorkflow for Machine-Learning-Based Qubit Readout With QICK and hls4ml.\nIEEE Transactions on Quantum Engineering 6 (2025), 1‚Äì10. doi:10.1109/TQE.2025.\n3604712\n[6] Xiaorang Guo, Tigran Bunarjyan, Dai Liu, Benjamin Lienhard, and Martin Schulz.\n2025. KLiNQ: Knowledge Distillation-Assisted Lightweight Neural Network for\nQubit Readout on FPGA. In 2025 62nd ACM/IEEE Design Automation Conference\n(DAC). 1‚Äì7. doi:10.1109/DAC63849.2025.11132854\n[7] Johannes Heinsoo, Christian Kraglund Andersen, Ants Remm, Sebastian Krinner,\nTheodore Walter, Yves Salath√©, Simone Gasparinetti, Jean-Claude Besse, Anton\nPotoƒçnik, Andreas Wallraff, and Christopher Eichler. 2018. Rapid High-fidelity\nMultiplexed Readout of Superconducting Qubits. Phys. Rev. Appl. 10 (Sep 2018),\n034040. Issue 3. doi:10.1103/PhysRevApplied.10.034040\n[8] Keysight Technologies. 2024. Quantum Control System. https://www.keysight.\ncom/us/en/products/modular/pxi-products/quantum-control-system.html. Ac-\ncessed: 2024-03-05.\n[9] Benjamin Lienhard, Antti Veps√§l√§inen, Luke C.G. Govia, Cole R. Hoffer, Jack Y.\nQiu, Diego Rist√®, Matthew Ware, David Kim, Roni Winik, Alexander Melville,\nBethany Niedzielski, Jonilyn Yoder, Guilhem J. Ribeill, Thomas A. Ohki, Hari K.\nKrovi, Terry P. Orlando, Simon Gustavsson, and William D. Oliver. 2022. Deep-\nNeural-Network Discrimination of Multiplexed Superconducting-Qubit States.\nPhys. Rev. Appl. 17 (Jan 2022), 014024. Issue 1. doi:10.1103/PhysRevApplied.17.\n014024\n[10] Satvik Maurya, Chaithanya Naik Mude, William D. Oliver, Benjamin Lienhard,\nand Swamit Tannu. 2023.\nScaling Qubit Readout with Hardware Efficient\nMachine Learning Architectures. In Proceedings of the 50th Annual Interna-\ntional Symposium on Computer Architecture (Orlando, FL, USA) (ISCA ‚Äô23). As-\nsociation for Computing Machinery, New York, NY, USA, Article 7, 13 pages.\ndoi:10.1145/3579371.3589042\n[11] Igor D.S. Miranda, Aman Arora, Zachary Susskind, Luis A.Q. Villon, Rafael F.\nKatopodis, Diego L.C. Dutra, Leandro S. De Ara√∫jo, Priscila M.V. Lima, Felipe M.G.\nFran√ßa, Lizy K. John, and Mauricio Breternitz. 2022. LogicWiSARD: Memoryless\nSynthesis of Weightless Neural Networks. In 2022 IEEE 33rd International Confer-\nence on Application-specific Systems, Architectures and Processors (ASAP). 19‚Äì26.\ndoi:10.1109/ASAP54787.2022.00014\n[12] Leandro Stefanazzi, Kenneth Treptow, Neal Wilcer, Chris Stoughton, Collin\nBradford, Sho Uemura, Silvia Zorzetti, Salvatore Montella, Gustavo Can-\ncelo, Sara Sussman, Andrew Houck, Shefali Saxena, Horacio Arnaldi,\nAnkur Agrawal, Helin Zhang, Chunyang Ding, and David I. Schus-\nter. 2022.\nThe QICK (Quantum Instrumentation Control Kit): Read-\nout and control for qubits and detectors.\nReview of Scientific Instru-\nments 93, 4 (04 2022), 044709.\narXiv:https://pubs.aip.org/aip/rsi/article-\npdf/doi/10.1063/5.0076249/19817152/044709_1_online.pdf doi:10.1063/5.0076249\n[13] Rainer Storn and Kenneth Price. 1997. Differential Evolution ‚Äì A Simple and\nEfficient Heuristic for global Optimization over Continuous Spaces. Journal of\nGlobal Optimization 11, 4 (01 Dec 1997), 341‚Äì359. doi:10.1023/A:1008202821328\n[14] Zachary Susskind, Aman Arora, Igor D. S. Miranda, Luis A. Q. Villon, Rafael F.\nKatopodis, Leandro S. de Ara√∫jo, Diego L. C. Dutra, Priscila M. V. Lima, Felipe\nM. G. Fran√ßa, Mauricio Breternitz, and Lizy K. John. 2023. Weightless Neural\nNetworks for Efficient Edge Inference. In Proceedings of the International Con-\nference on Parallel Architectures and Compilation Techniques (Chicago, Illinois)\n(PACT ‚Äô22). Association for Computing Machinery, New York, NY, USA, 279‚Äì290.\ndoi:10.1145/3559009.3569680\n[15] G. Turin. 1960. An introduction to matched filters. IRE Transactions on Information\nTheory 6, 3 (1960), 311‚Äì329. doi:10.1109/TIT.1960.1057571\n[16] Yaman Umuroglu, Yash Akhauri, Nicholas James Fraser, and Michaela Blott. 2020.\nLogicNets: Co-Designed Neural Networks and Circuits for Extreme-Throughput\nApplications. In 2020 30th International Conference on Field-Programmable Logic\nand Applications (FPL). 291‚Äì297. doi:10.1109/FPL50879.2020.00055\n[17] Neel R Vora, Yilun Xu, Akel Hasim, Neelay Fruitwala, Nam Nguyen, Haoran\nLiao, Jan Balewski, Abhi Rajagopala, Kasra Nowrouzi, Qing Ji, K. Brigitta Whaley,\nIrfan Siddiqi, Phuc Nguyen, and Gang Huang. 2024. QubiCML: ML-Powered\nReal-Time Quantum State Discrimination Enabling Mid-Circuit Measurements.\nIn 2024 IEEE International Conference on Quantum Computing and Engineering\n(QCE), Vol. 02. 414‚Äì415. doi:10.1109/QCE60285.2024.10332\n[18] Erwei Wang, James J. Davis, Peter Y. K. Cheung, and George A. Constan-\ntinides. 2020.\nLUTNet: Learning FPGA Configurations for Highly Efficient\nNeural Network Inference.\nIEEE Trans. Comput. 69, 12 (2020), 1795‚Äì1808.\ndoi:10.1109/TC.2020.2978817\n[19] Yilun Xu, Gang Huang, Jan Balewski, Ravi Naik, Alexis Morvan, Bradley Mitchell,\nKasra Nowrouzi, David I. Santiago, and Irfan Siddiqi. 2021. QubiC: An Open-\nSource FPGA-Based Control and Measurement System for Superconducting\nQuantum Information Processors. IEEE Transactions on Quantum Engineering 2\n(2021), 1‚Äì11. doi:10.1109/TQE.2021.3116540\n[20] Zurich Instruments. 2024. Quantum Readout. https://www.zhinst.com/americas/\nen/quantum-computing-systems/qubit-readout. Accessed: 2024-03-05.\n",
    "figure_captions": [
      "Figure 1: Simplified superconducting-qubit readout chain.",
      "Figure 2: LUNA co-design flow: (1) enumerate, (2) prune, (3)",
      "Figure 2 summarizes our co-design flow. Our approach couples a",
      "Figure 3: A high level overview of the LUNA architecture. Values shown are demonstrative; taken from our fidelity-optimized",
      "Figure 4: Best cost trajectory across generations for each tar-"
    ]
  },
  {
    "arxiv_id": "2512.07805v1",
    "title": "Group Representational Position Encoding",
    "abstract": "We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\\mathrm{GL}$. In Multiplicative GRAPE, a position $n \\in \\mathbb{Z}$ (or $t \\in \\mathbb{R}$) acts as $\\mathbf{G}(n)=\\exp(n\\,œâ\\,\\mathbf{L})$ with a rank-2 skew generator $\\mathbf{L} \\in \\mathbb{R}^{d \\times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.",
    "text": "Group Representational Position Encoding\nYifan Zhang1\nZixiang Chen‚àó2\nYifeng Liu‚àó2\nZhen Qin‚àó\nHuizhuo Yuan2\nKangping Xu3\nYang Yuan3\nQuanquan Gu2‚Ä†\nAndrew Chi-Chih Yao3‚Ä†\n1Princeton University\n2University of California, Los Angeles\n3IIIS, Tsinghua University\nyifzhang@princeton.edu\nqgu@cs.ucla.edu\nandrewcyao@tsinghua.edu.cn\nDecember 9, 2025\nAbstract\nWe present GRAPE (Group RepresentAtional Position Encoding), a unified framework for\npositional encoding based on group actions. GRAPE brings together two families of mechanisms:\n(i) multiplicative rotations (Multiplicative GRAPE) in SO(d) and (ii) additive logit biases (Addi-\ntive GRAPE) arising from unipotent actions in the general linear group GL. In Multiplicative\nGRAPE, a position n ‚ààZ (or t ‚ààR) acts as G(n) = exp(n œâ L) with a rank-2 skew generator\nL ‚ààRd√ód, yielding a relative, compositional, norm-preserving map with a closed-form matrix\nexponential. RoPE is recovered exactly when the d/2 planes are the canonical coordinate pairs\nwith log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures\nstrictly extend this geometry to capture cross-subspace feature coupling at O(d) and O(rd)\ncost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank)\nunipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases\nwhile preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies\na principled design space for positional geometry in long-context models, subsuming RoPE and\nALiBi as special cases.\nProject Page: https://github.com/model-architectures/GRAPE\n1\nIntroduction\nPositional information is essential for sequence modeling with Transformers (Vaswani et al., 2017),\nwhose self-attention is otherwise permutation-invariant. Early work injected absolute positional\ncodes (sinusoidal or learned) into token representations (Vaswani et al., 2017). Later, relative\nencodings depending on offsets (Shaw et al., 2018) and linear logit biases such as ALiBi (Press et al.,\n2021) were introduced, the latter offering strong length extrapolation with negligible overhead.\nRotary Position Embedding (RoPE) (Su et al., 2021) realizes relative positions as orthogonal\nplanar rotations of queries and keys, preserving norms and yielding exact origin invariance of\nattention scores. Despite its appeal, RoPE fixes coordinate planes and typically a log-uniform\nspectrum, limiting cross-subspace coupling and contextual warping of phase. More broadly, absolute\ncodes break translation equivariance; table-based relatives add window-dependent overhead. A new\n‚àóCore contribution;\n‚Ä†Corresponding authors.\n1\narXiv:2512.07805v1  [cs.LG]  8 Dec 2025\n\nGRAPE\nGroup Representational Position Encoding\nGeneral Relative Law: G(t ‚àís) = G(s)‚àí1G(t)\nG(n) = exp(n ¬∑ œâ ¬∑ Generator)\nMultiplicative GRAPE\nOperation: Rotation\nManifold: SO(d)\nGenerator: L (Rank-2 Skew)\nL = ab‚ä§‚àíba‚ä§‚áí\nexp(L) = I + sin s\ns\nL + 1‚àícos s\ns2\nL2\nxi\nxj\nŒ∏ij\nNorm-preserving Isometry\nFast Matrix Exponentials\nAdditive GRAPE\nOperation: Translation\nManifold: GL(d+k) (Unipotent Lift)\nGenerator: A (Low-rank Nilpotent)\nA2 = 0 =‚áí\nexp(A) = I + A\npos\nbias\nTranslation\nHomogeneous Space Lift\nAdditive Translations\nRecovers: RoPE\nExtensions: Learned Basis\nRecovers: ALiBi, FoX\nExtensions: Path Integral\nAlso extends to contextual forms via state-dependent generators\nFigure 1 Overview of the GRAPE Framework. We unify positional encodings via group actions G(n) =\nexp(nœâL). Left: Multiplicative GRAPE recovers RoPE via rank-2 skew generators in SO(d). Right: Additive\nGRAPE recovers ALiBi and FoX via low-rank nilpotent generators in the unipotent subgroup of GL(d + k)\n(k = 1 or 2).\nformulation is needed because current methods isolate the essential properties of stability, monotonic\ndistance penalty, and expressivity. These observations motivate a unified formulation that (i)\npreserves RoPE‚Äôs orthogonality and exact relativity when desired, (ii) also covers additive/forgetting\nmechanisms such as ALiBi (Press et al., 2021) and Forgetting Transformer (FoX) (Lin et al., 2025),\nand (iii) admits learned and contextual generalizations with clean streaming.\nWe therefore propose Group RepresentAtional Position Encoding (GRAPE), a group-theoretic\nframework that unifies two complementary families of positional mechanisms (see Figure 1 for an\noverview). The multiplicative family (Multiplicative GRAPE) models positions as norm-preserving\nrotations in SO(d) acting on (q, k); the additive family (Additive GRAPE/Path-Integral Addi-\ntive GRAPE) models positions as unipotent actions in the general linear group GL that yield\nlinear-in-offset logit biases (including content-gated and path-integral forms). This perspective\n2\n\nrecovers RoPE and ALiBi as exact special cases, proves that FoX is an exact instance of Additive\nGRAPE, and supplies principled, streaming-friendly contextual extensions on both sides.\nConcretely: (a) Multiplicative GRAPE (GRAPE-M) encodes n ‚ààZ (or t ‚ààR) as an element\nof SO(d) via a rank-2 skew generator; and (b) Additive GRAPE (GRAPE-A) and Path-Integral\nAdditive GRAPE (GRAPE-AP) lifts to the general linear group GL using homogeneous coordinates\nto produce linear-in-offset logit biases (recovering ALiBi and FoX).\nFor Multiplicative GRAPE, positions are mapped as\nG(n) = exp\n\u0000n œâ L\n\u0001\n‚ààSO(d),\nL = ab‚ä§‚àíba‚ä§‚ààso(d),\nwhere a, b ‚ààRd define a rank-2 skew generator L and œâ > 0 is a frequency. The action is an\nisometry, and G(n + m) = G(n)G(m) guarantees exact origin invariance of attention logits. We\nderive a closed-form Rodrigues-type formula (Rodrigues, 1840; Hall, 2013), enabling fast linear-time\napplication with stable derivatives and no explicit matrix materialization. RoPE is recovered when\nd/2 commuting rank-2 generators act on disjoint coordinate planes with prescribed frequencies.\nFor Additive GRAPE, positions are mapped via the matrix exponential Gadd(n) = exp(nœâA) =\nI + nœâA in a lifted homogeneous space. Here, the generator A ‚ààgl(d + 1) is a nilpotent matrix\nof rank one. While this additive transformation is not an isometry, it preserves the exact relative\nlaw, ensuring attention scores depend only on position offsets. This formulation provides a rigorous\ngroup-theoretic foundation for additive biases, recovering ALiBi and FoX as exact instances.\nOur contributions are highlighted as follows:\n1. We propose GRAPE as a unified group-theoretic view that subsumes multiplicative orthogonal\nrotations in SO(d) and additive unipotent (all eigenvalues equal to 1) mechanisms in general\nlinear group GL, recovering RoPE and ALiBi as exact special cases and proving FoX is an exact\ninstance (Appendix B).\n2. Multiplicative GRAPE. We derive a closed-form rank-2 matrix exponential with fast application\nand stable differentiation; we show RoPE is a special multiplicative GRAPE in a possibly learned\northogonal basis.\n3. Additive GRAPE. We show that linear-in-offset logit biases arise from rank-1 (or low-rank)\nunipotent actions in the general linear group GL with an exact relative law and streaming\ncacheability. This includes query- or key-gated slopes, a commuting dictionary of additive\ncomponents, and exact recoveries of ALiBi and FoX in closed form (Sections 4, 4.2, Appendix B).\nWe also formalize path-integral additive biases that remain causal and support efficient training.\n(Section 5).\n2\nMultiplicative Group Representational Position Encoding\nWe propose the Multiplicative GRAPE, as a Lie-group positional map with a closed-form rank-2\nmatrix exponential, an exact relative law, and a streaming/cache methodology. The core intuition\nis to encode position as a norm-preserving rotation in the special orthogonal group SO(d) 1(Hall,\n2013). A single skew-symmetric generator L ‚ààso(d) produces the entire family of rotations via the\nmatrix exponential. We begin with notation and the rank-2 generator.\n1Definitions of SO(d) and other mathematical terms are postponed to Table 3 in the Appendix.\n3\n\n2.1\nPreliminaries and Rank-2 Generator\nThe generator L is formally defined as an element of the corresponding Lie algebra, so(d). Let\nso(d) = {L ‚ààRd√ód : L‚ä§= ‚àíL} denote the Lie algebra of SO(d). The simplest non-trivial generator\ndefines a rotation within a single 2D plane. We construct such a rank-2 generator from two vectors,\na and b, that span this plane of action. For a, b ‚ààRd, define the rank-2 generator L ‚â°L(a, b) as\nL(a, b) = ab‚ä§‚àíba‚ä§, Œ± = ‚à•a‚à•2, Œ≤ = ‚à•b‚à•2, Œ≥ = a‚ä§b, ‚àÜ= Œ±Œ≤ ‚àíŒ≥2 ‚â•0, s =\n‚àö\n‚àÜ.\n(2.1)\nRank-2 structure. Let U = span{a, b}. The rank-2 generator L has a useful geometric property:\napplying it twice projects onto the action plane U and scales. A direct calculation shows\nL2 = ‚àís2 PU,\nwhere PU is the orthogonal projector to the space U. Hence spectrum of L (the set of its eigenvalues),\ndenoted œÉ(L), is {¬±is, 0, . . . , 0} and the minimal polynomial is Œª(Œª2 + s2). A detailed derivation is\ngiven in Appendix H.\nInitialization. Write A ‚âú[a b] ‚ààRd√ó2 and J =\n\u0000 0 ‚àí1\n1 0\n\u0001\nso that L = AJA‚ä§. For any M ‚ààSL(2)\n(the 2 √ó 2 real matrices with determinant 1, see Table 3), MJM‚ä§= J and thus A 7‚ÜíAM leaves\nL invariant; for general M ‚ààGL(2) the group of invertible 2 √ó 2 matrices), L scales by det(M).\nTherefore the oriented plane U = span{a, b} and the scalar s =\np\nŒ±Œ≤ ‚àíŒ≥2 determine the action.\nWe fix a gauge at initialization by ‚à•a‚à•= ‚à•b‚à•= 1 and a‚ä§b = 0 (absorbing scale into œâ).\nCanonical 90‚ó¶rotation operator. Fix a block-diagonal complex structure J ‚ààso(d) with J ‚ä§= ‚àíJ\nand J 2 = ‚àíI (for odd d, act on the top-left 2‚åäd/2‚åãcoordinates and leave the final coordinate\nunchanged). Concretely, J = L‚åäd/2‚åã\ni=1\n\u0000 0 ‚àí1\n1 0\n\u0001\n. For any a ‚ààRd, write a‚ä•:= J a, which equals ‚Äúa\nrotated by 90‚ó¶‚Äù within the canonical 2D blocks and satisfies a‚ä§a‚ä•= 0 and ‚à•a‚ä•‚à•= ‚à•a‚à•.\n2.2\nExact relative law\nFor a fixed L ‚ààso(d), define G(n) = exp(nL) ‚ààSO(d), which forms a one-parameter subgroup.\nThe exact relative law property for positional encoding implies:\nG(t‚àís) = G(s)‚ä§G(t),\nG(n)‚ä§G(n) = I.\nHere G(n) ‚ààSO(d), so the transpose coincides with the group inverse, G(n)‚ä§= G(n)‚àí1; the\nidentity above is exactly the relative-position law for a one-parameter subgroup. A concise\nsummary of SO(d), GL(d) and SL(d) is collected in Table 3. This algebraic property enables relative\npositional encoding: interactions depend only on offsets.\nG(n) = exp(nœâL),\nG(n + m) = G(n)G(m),\nG(0) = I,\nand\nG(‚àín) = G(n)‚ä§.\nCrucially, this exact relative property relies solely on the one-parameter subgroup structure (G(n +\nm) = G(n)G(m)), holding true regardless of whether the generator implies commuting or coupled\nnon-commuting subspaces.\n4\n\n2.3\nClosed-form fast matrix exponential\nBased on the minimal polynomial mentioned in Section 2.1, the exponential map exp(L) for a rank-2\ngenerator can be expressed as a quadratic in L. This yields a convenient closed-form solution, often\nreferred to as a Rodrigues-type formula (Rodrigues, 1840; Hall, 2013):\nexp(L) = I + sin s\ns\nL + 1 ‚àícos s\ns2\nL2.\nGeometrically, the formula is best understood via L2 as a projector onto U. Since L2 = ‚àís2PU, the\nexponential can be written as\nexp(L) = I ‚àí(1 ‚àícos s) PU + sin s\ns\nL,\nwhich reveals its action explicitly: it is a rotation by angle s within the plane U = span{a, b} and\nthe identity on the orthogonal complement U‚ä•. The vectors a and b thus define the plane of action\nfor the positional rotation.\nCost of application. For a single rank-2 plane, computing y = G(n)x requires two inner products\nu = ‚ü®a, x‚ü©, v = ‚ü®b, x‚ü©, followed by y = x +f1(n)(av ‚àíbu) +f2(n) [Œ≥(av + bu) ‚àíŒ≤au ‚àíŒ±bv], where\n(Œ±, Œ≤, Œ≥) are plane scalars and f1,2 are trigonometric scalars (with series guards as s ‚Üí0). This\nis O(d) flops with a small constant and no materialization of G(n); derivative expressions are in\nAppendix H.\n2.4\nThe b = J a constraint\nWe now consider an important special case by setting b = J a. This constraint, which makes the\nplane vectors a and b orthogonal and equal in norm, significantly simplifies the generator‚Äôs structure\nand reveals a direct connection to the canonical RoPE formulation. With this constraint, the scalars\nsimplify: Œ≥ = a‚ä§b = a‚ä§J a = 0, Œ≤ = ‚à•b‚à•2 = ‚à•a‚à•2 = Œ±, and hence s =\np\nŒ±Œ≤ ‚àíŒ≥2 = Œ±. Moreover,\non the 2D subspace U = span{a, J a} one has\nL(a, J a)a = ‚àí(J a)Œ±,\nL(a, J a) J a = Œ± a,\nso L(a, J a)|U = ‚àíŒ± J |U and L(a, J a)|U‚ä•= 0. Therefore\nexp\n\u0000nœâL(a, J a)\n\u0001\n= I ‚àí\n\u00001 ‚àícos(nœâŒ±)\n\u0001\nPU ‚àísin(nœâŒ±) J PU,\nThis expression follows by substituting L|U = ‚àíŒ± J |U and L2 = ‚àíŒ±2PU into the Rodrigues formula\nexp(nœâL) = I + sin(nœâs)\ns\nL + 1‚àícos(nœâs)\ns2\nL2 with s = Œ±; see Appendix H for the algebraic steps. It is a\npure planar rotation by angle nœâŒ± on U and the identity on U‚ä•.\nCorollary 2.1 (Frequency‚Äìnorm coupling). If ‚à•a‚à•= 1, the rotation angle reduces to nœâ. Without\nnormalization, the effective frequency is œâeff = œâ‚à•a‚à•2, so the scale of a can be absorbed into œâ.\n2.5\nApplication to relative encoding and equivariance\nWe now demonstrate how the GRAPE-M operator G(n) is applied in practice. As established in\nSection 2.2, the operator‚Äôs group structure guarantees the exact relative law. We first transform the\nquery and key vectors, qi and kj, into position-aware representations, eqi and ekj:\neqi := G(i)qi,\nekj := G(j)kj.\n5\n\nIt follows from the exact relative law established in Section 2.2 that the attention score between\nthese position-aware vectors simplifies to:\neq‚ä§\ni ekj = q‚ä§\ni G(i)‚ä§G(j)kj = q‚ä§\ni G(j ‚àíi)kj.\nHence, the attention score depends solely on the relative offset j ‚àíi, not on the absolute positions.\nStreaming and caching. At inference, cache k‚ãÜ\nj = G(j)kj once when token j arrives. At step\nt, form eqt = G(t)qt and compute logits eq‚ä§\nt k‚ãÜ\nj. No cache rotation is needed when t increments;\ncomplexity matches RoPE. A full integration into multi-head attention (per-head formulation, logits,\nand streaming) is detailed in Section A.\n3\nMulti-Subspace Multiplicative GRAPE\nA single rank-2 generator acts on a 2D subspace, leaving the rest of the d-dimensional space\nuntouched.\nTo encode position across the entire hidden dimension, we can combine multiple\ngenerators. This leads to the Multi-Subspace (MS) Multiplicative GRAPE (GRAPE-M) model,\nwhich forms the basis for both RoPE and more expressive types. Detailed rank-2 algebra appears in\nAppendix H.\n3.1\nMulti-Subspace GRAPE-M and RoPE as a Special Case\nThe simplest way to combine generators is to ensure they act on mutually orthogonal subspaces,\nwhich guarantees they commute. Let d be even. For i = 1, . . . , d/2, we can define a set of rank-\n2 generators {Li}, each acting on a distinct 2D plane. RoPE is the canonical example of this\nconstruction. We further discussed non-commuting multiplicative GRAPE in Appendix C.\nLet the 2 √ó 2 canonical skew matrix be J =\n\u0000 0 ‚àí1\n1 0\n\u0001\nand the coordinate selector be Ui = [e2i‚àí1 e2i] ‚àà\nRd√ó2. We set the rank-2 generators as Li = UiJU‚ä§\ni = L(e2i‚àí1, e2i) and assign per-plane frequencies\nŒ∏i > 0. The total generator is the commuting sum:\nLRoPE =\nd/2\nX\ni=1\nŒ∏iLi\nwith\n[Li, Lj] = 0 for i Ã∏= j.\nThen\nG(n) = exp\n\u0000nLRoPE\n\u0001\n=\nd/2\nY\ni=1\nexp(nŒ∏iLi) = blockdiag\n\u0000R2(nŒ∏1), . . . , R2(nŒ∏d/2)\n\u0001\n,\n(3.1)\nwhere R2(Œ∏) denotes the standard 2 √ó 2 rotation matrix introduced in Table 3, and the last\nequality holds because each term exp(nŒ∏iLi) is identity except for a single 2√ó2 rotation block on its\ndiagonal. Eq. (3.1) is precisely the RoPE mapping: a block-diagonal product of planar rotations\nwith per-subspace angles nŒ∏i.\nEquality holds when the planes {Ui} are the coordinate 2D blocks and {Œ∏i} follow the canonical\nlog-uniform spectrum.\nProposition 3.1 (RoPE is a multiplicative GRAPE). Choose d/2 mutually orthogonal vectors\n{ai} and set bi = J ai with per-plane angles Œ∏i.\nThen the commuting MS-GRAPE G(n) =\n6\n\nQd/2\ni=1 exp(nŒ∏iL(ai, J ai)) equals the standard RoPE map in a (possibly learned) orthogonal basis. If\nthe planes are the canonical coordinate pairs and {Œ∏i} follow the log-uniform spectrum, we recover\nthe canonical RoPE exactly.\nSpectral parameterization. Classical RoPE chooses Œ∏i on a log-uniform grid across i. In GRAPE,\nŒ∏i can be learned or shared/tied across heads or layers. The MS-GRAPE view also allows replacing\nthe coordinate selectors Ui by a learned orthogonal basis B ‚ààSO(d) so that L = P\ni Œ∏iBUiJU‚ä§\ni B‚ä§,\npreserving commutativity while learning subspaces.\nMultimodal GRAPE. Please refer to Appendix F for 2D and 3D GRAPE for Vision and Multimodal\nPosition Encoding.\n4\nAdditive Group Representational Position Encoding\nThis section shows that additive positional mechanisms (absolute shifts of features and additive\nlogit biases, including ALiBi (Press et al., 2021)) also admit a group-theoretic formulation. The key\nis a homogeneous lift to an augmented space and a one-parameter subgroup of the general linear\ngroup GL that acts by unipotent (all eigenvalues equal to 1) transformations. This yields an exact\nrelative law and streaming/cache rules analogous to Section 2.5.\n4.1\nHomogeneous lift and a unipotent action\nTo produce additive biases from a multiplicative group action, we employ the homogeneous lift. This\nis a standard method in linear algebra for representing affine transformations (such as translations) as\nlinear transformations in a higher-dimensional space. Let bx := [x; 1] ‚ààRd+1 denote a homogeneous\naugmentation of x ‚ààRd. We now work within the general linear group GL(d+1) and its corresponding\nLie algebra gl(d + 1), which is the set of all (d + 1) √ó (d + 1) real matrices. Fix a generator\nA =\n\u00140d√ód\nu\n01√ód\n0\n\u0015\n‚ààgl(d+1),\nA2 = 0,\n(4.1)\nwhere u ‚ààRd. Its exponential is unipotent:\nGadd(n) := exp(n œâ A) = Id+1 + n œâ A =\n\u0014 Id\nn œâ u\n0‚ä§\n1\n\u0015\n‚ààGL(d+1),\nGadd(n+m) = Gadd(n)Gadd(m).\nApplication and exact relative law in GL.\nFor queries/keys augmented as bqi = [qi; 1] and\nbkj = [kj; 1], define\neqi := Gadd(i) bqi,\nekj := Gadd(j)‚àí‚ä§bkj,\n(4.2)\nWe use the shorthand Gadd(j)‚àí‚ä§:= (Gadd(j)‚àí1)‚ä§to emphasize that we first take the group inverse\nin GL(d+1) and then transpose it. and score with the standard inner product on Rd+1. The key\nis transformed using the inverse transpose (Gadd(j)‚àí‚ä§). This is necessary because for a general\nlinear group GL, the simple transpose is no longer the inverse (unlike in SO(d)), and the inverse\n7\n\ntranspose is required to recover the exact relative law: Gadd(i)‚ä§Gadd(j)‚àí‚ä§= Gadd(j‚àíi)‚àí‚ä§for any\none-parameter subgroup in GL. This composition results in the final form:\neq‚ä§\ni ekj = bq‚ä§\ni Gadd(j‚àíi)‚àí‚ä§bkj,\ndepending only on j‚àíi.\n(4.3)\nStreaming matches Section 2.5: cache bk‚ãÜ\nj = Gadd(j)‚àí‚ä§bkj once; at step t form eqt = Gadd(t)bqt and\ncompute eq‚ä§\nt bk‚ãÜ\nj.\nClosed form and content-gated additive term. Since A‚ä§=\n\u0000 0\n0\nu‚ä§0\n\u0001\nand (A‚ä§)2 = 0,\nGadd(m)‚àí‚ä§= Id+1 ‚àím œâ A‚ä§=\n\u0014\nId\n0\n‚àím œâ u‚ä§\n1\n\u0015\n,\nm = j‚àíi,\n(4.4)\nwhence\neq‚ä§\ni ekj = q‚ä§\ni kj + 1 ‚àí(j‚àíi) œâ u‚ä§kj.\n(4.5)\nThe constant ‚Äú+1‚Äù is softmax-shift invariant; the final term is an additive, linear-in-offset bias\nwhose slope is key-gated by u‚ä§kj. A symmetric generator for the query, Aqry =\n\u0000 0 0\nv‚ä§0\n\u0001\napplied\nanalogously produces a query-gated slope (j‚àíi) œâ v‚ä§qi. Using both the key-gated and query-gated\ncomponents yields a combined bias of the form (j‚àíi) œâ (v‚ä§qi ‚àíu‚ä§kj), still obeying the exact\nrelative law Eq. (4.3).\n4.2\nExact ALiBi as a Rank-1 unipotent in GL(d+2)\nALiBi adds a head-specific scalar slope Œ≤h(j‚àíi) to the logits that is independent of content. This is\ncaptured exactly by augmenting with two constant coordinates:\nbqi = [qi; 1; 0] ‚ààRd+2,\nbkj = [kj; 0; 1] ‚ààRd+2,\nand choosing the rank-1 nilpotent generator\nA‚ä§\nh = Œ≤h ed+1 e‚ä§\nd+2\n‚áê‚áí\nAh = Œ≤h ed+2 e‚ä§\nd+1,\n(A‚ä§\nh )2 = 0.\n(4.6)\nThen Gadd,h(m)‚àí‚ä§= I ‚àím A‚ä§\nh and\nbq‚ä§\ni Gadd,h(j‚àíi)‚àí‚ä§bkj = q‚ä§\ni kj ‚àí(j‚àíi) Œ≤h,\ni.e., the ALiBi term emerges as a unipotent GL(d+2) action with exact relative composition.\nFoX as GRAPE-A. Let ft ‚àà(0, 1] be per-token forget scalars and set œât := log ft. Using the rank-1\ngenerator of Section 4.2, the resulting additive bias is b(t, j) = Pt\n‚Ñì=j+1 œâ‚Ñì, which coincides with\nFoX‚Äôs forgetting bias Dij. A full derivation and the unipotent path product are given in Appendix B.\n5\nPath Integral Additive GRAPE\nAdditive GRAPE (GRAPE-A) realizes exactly relative additive logits via a one-parameter unipotent\naction in the general linear group GL; the bias depends only on an offset m = j‚àíi (or a contextual\nphase difference Œ¶j‚àíŒ¶i when using cumulative phases). Here the ‚Äúphase‚Äù Œ¶t is a scalar path\nvariable, typically defined as a cumulative sum Œ¶t = P\n‚Ñì<t œâ‚Ñìof per-token frequencies œâ‚Ñì, so that\n8\n\nŒ¶j ‚àíŒ¶i plays the role of an effective relative position. In practice, we sometimes want the amount of\nadditive encouragement/suppression between a key at j and a query at t to depend on the endpoint\nt (e.g., the current syntactic or semantic needs of the query token), while preserving causality,\nboundedness, and clean composition with the orthogonal GRAPE acting on (q, k). We formalize\nthis by a rigorously defined path-integral sum, deriving conditions under which the exact relative\nlaw of Additive GRAPE is recovered.\nDefinition (Path-integral bias). Fix a head h and per-head scale Œ±h > 0. For each time u,\nlet pu,h ‚ààRd be a positional embedding obtained from token-local features (a linear projection\nfollowed by RMS normalization in our implementation). Let J be the canonical block-diagonal 90‚ó¶\noperator (Section 2.4), and define R‚Ñì:= exp(‚ÑìJ ) (a fixed commuting rotation). For a link function\ng : R ‚Üí(‚àí‚àû, 0) that is monotone increasing and 1-Lipschitz2, define the edge potential\nœàh(t, ‚Ñì) := Œ±h g\n\u00121\nd\n\npt,h, R‚Ñìp‚Ñì,h\n\u000b\u0013\n‚â§0,\n‚Ñì< t.\n(5.1)\nThe vectors pt,h and p‚Ñì,h here are the positional embedding. The path-integral additive bias from\nkey position j to query position t is the causal sum\nbh(t, j) :=\nt\nX\n‚Ñì=j+1\nœàh(t, ‚Ñì)\n‚â§0.\n(5.2)\nThe attention logit combines this additive term with either the raw or orthogonally-rotary bilinear\npart:\n‚Ñìt,j,h =\n1\n‚àö\nd\nq‚ä§\nt,hkj,h + bh(t, j)\nor\n‚Ñìt,j,h =\n1\n‚àö\nd\nq‚ä§\nt,hGh(j‚àít)kj,h + bh(t, j).\n(5.3)\nGroup-theoretic formalization and path composition. Let E ‚ààR(d+2)√ó(d+2) be a fixed rank-1\nnilpotent with E2 = 0 (e.g., E = ed+2e‚ä§\nd+1 as in Section 4.2). For each fixed endpoint t, define\nendpoint-indexed unipotent factors\nH(t)\nh (‚Ñì) := I + œàh(t, ‚Ñì) E.\nSince E2 = 0, the path product along (j, t] collapses additively:\ntY\n‚Ñì=j+1\nH(t)\nh (‚Ñì) = I +\n\u0012\nt\nX\n‚Ñì=j+1\nœàh(t, ‚Ñì)\n\u0013\nE = I + bh(t, j) E.\n(5.4)\nScoring in homogeneous coordinates as in Section 4 with the paired inverse-transpose removes\nmultiplicative anisotropy and yields exactly the additive term bh(t, j), cf. Eq. (4.3). The rowwise\nsemigroup law is preserved (Eq. (5.4)), while the t-dependence of the factors intentionally relaxes\nthe global one-parameter group law.\nRelation to GRAPE-A. GRAPE-AP strictly contains GRAPE-A as the special case in which edge\npotentials do not depend on the endpoint:\nœàh(t, ‚Ñì) ‚â°Œ∏h a‚Ñì=‚áíbh(t, j) = Œ∏h\nt\nX\n‚Ñì=j+1\na‚Ñì= Œ∏h\n\u0000At ‚àíAj\n\u0001\n,\nAu :=\nX\n‚Ñì<u\na‚Ñì.\nTwo important instances follow directly:\n2Our experiments take g(z) = log(Sigmoid(z)); then g‚Ä≤(z) = 1 ‚àíSigmoid(z) ‚àà(0, 1), ensuring 1-Lipschitzness.\n9\n\n‚Ä¢ Exact ALiBi. a‚Ñì‚â°1 gives bh(t, j) = Œ∏h(t‚àíj); this is exactly the ALiBi term recovered via the\nrank-1 unipotent lift in Section 4.2.\n‚Ä¢ Phase-modulated Additive GRAPE. If a‚Ñì= œâ‚Ñìwith œâ‚Ñì= g(x‚Ñì) ‚â•0, then bh(t, j) = Œ∏h(Œ¶t ‚àíŒ¶j)\nwith Œ¶u = P\n‚Ñì<u œâ‚Ñì.\nIn both cases, bh(t, j) depends only on a (possibly contextual) phase difference and thus obeys\nthe exact relative law with the same streaming/cache policy as Section 4. Outside these endpoint-\nindependent regimes, GRAPE-AP provides strictly more expressive, path-integral biases while\npreserving row-wise path composition (Eq. (5.4)).\nComputation and streaming. For each head h and decoding step t, compute the row {œàh(t, ‚Ñì)}‚Ñì‚â§t\nby a single similarity sweep ‚Ñì7‚Üí‚ü®pt,h, R‚Ñìp‚Ñì,h‚ü©(the rotated probes R‚Ñìp‚Ñì,h can be cached on arrival),\napply the link g, and take a prefix sum to obtain j 7‚Üíbh(t, j). This yields O(t) per-step overhead\nwith O(1) recomputation per cached key; memory is O(L) per head for the cached probes (or O(d)\nif the per-‚Ñìrotations are recomputed on the fly).\nSpectral and stability. Each factor H(t)\nh (‚Ñì) = I + œàh(t, ‚Ñì)E is unipotent with all eigenvalues 1 and\nat most two singular values deviating from 1; the full path product equals I + bh(t, j)E (Eq. (5.4)).\nAs in Appendix I.3, the paired inverse-transpose used for scoring cancels multiplicative distortions\nand delivers exactly the additive bias bh(t, j); operator norms remain controlled linearly in |bh(t, j)|.\nA more extensive spectral analysis, including eigenvalue structure and singular-value behavior\nacross GRAPE variants, is provided in Appendix I. There, we also give an explicit comparison to\nPaTH Attention (Yang et al., 2025b), which is shown to be contractive and near singular. These\nproperties may impair PaTH‚Äôs effectiveness in long-context modeling.\n6\nExperiments\nIn this section, we evaluate the performance of GRAPE on the language modeling task in comparison\nwith baseline positional encoding mechanisms, including RoPE (Su et al., 2021), AliBi (Press et al.,\n2021), as well as Forgetting Transformer (FoX) (Lin et al., 2025).\n6.1\nImplementation Details\nBased on the nanoGPT codebase (Karpathy, 2022), our experiments are implemented based on\nthe Llama model (Touvron et al., 2023a). We only change the positional encoding mechanism\nand keep the rest of the model architecture the same as Llama. We choose FineWeb-Edu 100B\ndataset (Lozhkov et al., 2024), which contains 100 billion training tokens and 0.1 billion validation\ntokens, and we randomly choose 50B tokens for training. Our models are with 36 layers and 10\nheads, with a hidden size of 1280 and head dimension of 128. We applied QK RMSNorm for training\nstability (Yang et al., 2025a). The context length is set to 4,096, and the batch size is 480. All\nthe models are optimized by AdamW optimizer (Loshchilov and Hutter, 2019), with a maximum\nlearning rate of 2 √ó 10‚àí4, (Œ≤1, Œ≤2) = 0.9, 0.95, and a weight decay of 0.1. We use a cosine learning\nrate scheduler with 2,000 warm-up iterations, and the minimum learning rate is 1 √ó 10‚àí5. We also\nclip the gradient to 1.0 for stabler training. The frequency of RoPE is set to 10,000. Moreover, for\nfair comparison, we do not use FoX-Pro and disabled the KV-shift module within it.\n10\n\n6.2\nResult Analysis\nThe curves for training and validation loss of models with a variant positional encoding mechanism\nare displayed in Figures 2 and 3. This analysis provides specific insight into the source of the\nframework‚Äôs stability and performance. It can be observed that GRAPE can keep a persistent\nedge over other mechanisms, including RoPE and FoX. Moreover, the model with RoPE suffers\nfrom training instability shown in Figure 3 (a), while the model with GRAPE embedding steadily\nimproves during the training process.\n0\n10\n20\n30\n40\n50\nTraining tokens (B)\n2.5\n2.6\n2.7\n2.8\n2.9\n3.0\n3.1\nTraining Loss\nMedium Model, FineWeb-edu100B\nRoPE\nAliBi\nFoX\nFox (w/ KV-shift)\nGRAPE-A\nGRAPE-M (Ctx)\nGRAPE-M (nonCtx)\n(a) Training Loss\n0\n10\n20\n30\n40\n50\nTraining tokens (B)\n2.5\n2.6\n2.7\n2.8\n2.9\n3.0\n3.1\nValidation Loss\nMedium Model, FineWeb-edu100B\nRoPE\nAliBi\nFoX\nFox (w/ KV-shift)\nGRAPE-A\nGRAPE-M (Ctx)\nGRAPE-M (nonCtx)\n(b) Validation Loss\nFigure 2 The training and validation loss of medium-size models (355M), with different positional encoding\nmechanisms on the FineWeb-Edu 100B dataset.\n0\n10\n20\n30\n40\n50\nTraining tokens (B)\n2.4\n2.5\n2.6\n2.7\n2.8\n2.9\n3.0\n3.1\nTraining Loss\nLarge Model, FineWeb-edu100B\nRoPE\nAliBi\nFoX\nFox (w/ KV-shift)\nGRAPE-A\n(a) Training Loss\n0\n10\n20\n30\n40\n50\nTraining tokens (B)\n2.4\n2.5\n2.6\n2.7\n2.8\n2.9\n3.0\n3.1\nValidation Loss\nLarge Model, FineWeb-edu100B\nRoPE\nAliBi\nFoX\nFox (w/ KV-shift)\nGRAPE-A\n(b) Validation Loss\nFigure 3 The training and validation loss of large-size models (770M), with different positional encoding\nmechanisms on the FineWeb-Edu 100B dataset.\n11\n\nTable 1 The evaluation results of medium models with different positional encoding mechanisms pre-trained\nusing the FineWeb-Edu 100B dataset (0-shot with lm-evaluation-harness). The best scores in each column\nare bolded.\nMethod\nARC-E\nARC-C\nBoolQ\nHellaSwag\nOBQA\nPIQA\nWinoGrande\nSciQ\nAvg.\nRoPE\n59.34\n30.89\n61.22\n45.46\n34.00\n69.42\n52.49\n74.70\n53.44\nAliBi\n57.07\n30.80\n61.16\n46.98\n34.60\n69.48\n52.96\n79.70\n54.09\nFoX\n56.78\n29.01\n59.11\n43.07\n32.80\n67.74\n51.07\n76.10\n51.96\nFoX (w/ KV-shift)\n57.11\n30.55\n60.34\n44.32\n33.80\n69.31\n52.17\n78.40\n53.25\nGRAPE-A\n59.68\n31.91\n60.06\n46.27\n35.00\n69.64\n53.83\n79.90\n54.54\nGRAPE-M (Ctx)\n56.02\n29.35\n58.81\n44.88\n35.00\n68.61\n52.09\n76.50\n52.66\nGRAPE-M (nonCtx)\n56.31\n30.55\n61.77\n44.82\n34.40\n68.44\n53.67\n75.20\n53.15\nTable 2 The evaluation results of large models with different positional encoding mechanisms pre-trained\nusing the FineWeb-Edu 100B dataset (0-shot with lm-evaluation-harness). The best scores in each column\nare bolded.\nMethod\nARC-E\nARC-C\nBoolQ\nHellaSwag\nOBQA\nPIQA\nWinoGrande\nSciQ\nAvg.\nRoPE\n62.25\n33.02\n58.23\n50.92\n37.60\n70.89\n55.88\n80.50\n56.16\nAliBi\n63.43\n34.81\n59.69\n52.88\n36.80\n71.33\n56.20\n82.40\n57.19\nFoX\n59.22\n32.00\n59.69\n49.78\n38.00\n71.00\n54.62\n79.20\n55.44\nFoX (w/. KV-shift)\n60.77\n32.85\n62.51\n49.38\n38.00\n70.62\n54.78\n81.40\n56.29\nGRAPE-A\n62.79\n33.19\n59.11\n53.18\n36.00\n71.98\n57.62\n84.10\n57.25\n7\nRelated Work\nPositional information in Transformers mainly can be categorized into these classes: (a) absolute\nencodings (sinusoidal or learned) (Vaswani et al., 2017; Devlin et al., 2019; Neishi and Yoshinaga,\n2019; Kiyono et al., 2021; Likhomanenko et al., 2021; Wang et al., 2020; Liu et al., 2020; Wang\net al., 2021; Sinha et al., 2022; Wennberg and Henter, 2021; Ke et al., 2020); (b) relative encodings\nthat depend on offsets (Shaw et al., 2018; Dai et al., 2019; Raffel et al., 2020; He et al., 2020); and\n(c) linear logit biases with strong length extrapolation (Press et al., 2021; Chi et al., 2022a,b; Li\net al., 2023; Ruoss et al., 2023), all shaping recency/extrapolation behavior (Haviv et al., 2022;\nKazemnejad et al., 2023).\nMultiplicative position encoding. RoPE realizes offsets as block-diagonal planar rotations of\nqueries/keys, preserving norms and exact origin invariance; it is widely deployed across LLMs and\nmodalities (Su et al., 2021; Touvron et al., 2023a,b; Heo et al., 2024). Angle/spectrum designs\nimprove long-context fidelity (e.g., xPos) (Sun et al., 2022); LRPE formalizes separable relative\ntransforms for linear attention models (Qin et al., 2023); mechanistic work analyzes frequency\nusage (Barbero et al., 2025). These methods are also compatible with sparse/linear attentions\n(Beltagy et al., 2020; Zaheer et al., 2020; Katharopoulos et al., 2020; Choromanski et al., 2020)\nand with context-scaling procedures (Xiong et al., 2023; Chen et al., 2023; Peng et al., 2023; Zhu\net al., 2023; Jin et al., 2024). Beyond 1D language modeling, 2D RoPE and variants adapt rotary\nencodings to 2D grids by applying rotations along spatial axes, and have been shown to improve\nhigh-resolution extrapolation in Vision Transformers and related vision models (Heo et al., 2024).\nRecently, LieRE (Ostmeier et al., 2025) learns dense skew-symmetric generators whose exponentials\nproduce high-dimensional rotations for multi-modal, n-dimensional inputs, while STRING (Schenck\net al., 2025) designs separable, translation-invariant RoPE-style encodings that scale to 2D and 3D\n12\n\ncoordinates in vision and robotics settings (Ostmeier et al., 2025; Schenck et al., 2025). GRAPE-M\nidentifies RoPE as commuting rank-2 exponentials in SO(d) and extends it to learned subspaces and\ncompact non-commuting mixtures in closed form and a much faster way. Compared with LieRE,\nwhich parameterizes a dense skew-symmetric generator and applies a numerical matrix exponential\n(e.g., torch.matrix exp) with O(d3) time and O(d2) parameters per head, Multiplicative GRAPE\ndecomposes the action into rank-2 subspaces and uses the closed-form Rodrigues-type formulas\nfrom Section 2.3, so we only need vector‚Äìvector operations with O(d) cost per head (a detailed\ncomparison between LieRE and GRAPE is presented in Appendix E.)\nAdditive position encoding and forgetting mechanisms. Additive schemes such as ALiBi (Press\net al., 2021) and related kernelized/randomized forms (Chi et al., 2022a,b; Li et al., 2023; Ruoss et al.,\n2023) are captured exactly by GRAPE-A as unipotent actions in the general linear group GL that\npreserve the same relative law and streaming cacheability. Importantly, forgetting mechanisms are\nadditive: the Forgetting Transformer (FoX) implements a learnable per-head exponential decay in\nthe attention logits and is a specific GRAPE-A / GRAPE-AP instance imposing distance-dependent\nattenuation (Lin et al., 2025). FoX‚Äôs data-dependent forget gates yield a path-additive bias D that\nwe show is exactly the endpoint-independent GRAPE-AP case; see Appendix B for a constructive\nequivalence and its streaming implementation (Lin et al., 2025).\nContextual position encoding. Content-adaptive position modulates effective phase or distance via\ntoken features through gating/scaling and algebraic parameterizations (Wu et al., 2020; Zheng et al.,\n2024; Kogkalidis et al., 2024), and contextual counting (CoPE) (Golovneva et al., 2024). GRAPE\nintroduces phase-modulated and dictionary-based contextual variants that replace a linear phase\nwith cumulative token-adaptive phases (single or multi-subspace) while retaining exact headwise\nrelativity and streaming caches. Finally, models can length-generalize without explicit encodings\n(‚ÄúNoPE‚Äù) under suitable training (Wang et al., 2024), which corresponds to the trivial generator\nL = 0 in our view.\n8\nConclusion\nGRAPE provides a general framework for positional encoding based on group actions, unifying mul-\ntiplicative and additive mechanisms. Multiplicative GRAPE offers a closed-form, rank-2 exponential\nthat is relative, compositional, and norm-preserving; it recovers RoPE and yields learned-basis and\nnon-commuting extensions at controlled cost. Additive GRAPE realizes ALiBi and FoX exactly\nvia unipotent general linear group GL lifts with the same streaming/cache policy. The GRAPE\nframework integrates seamlessly with existing Transformer models and offers a principled, extensible\ndesign space for future architectures.\nReferences\nFederico Barbero, Alex Vitvitskyi, Christos Perivolaropoulos, Razvan Pascanu, and Petar VeliÀáckovic.\nRound and round we go! what makes rotary positional encodings useful?\nIn International\nConference on Learning Representations (ICLR 2025), 2025. URL https://arxiv.org/abs/\n2410.06205. Also arXiv:2410.06205.\n13\n\nIz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer.\narXiv preprint arXiv:2004.05150, 2020.\nShouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. Extending context window\nof large language models via position interpolation. arXiv preprint arXiv:2306.15595, 2023. URL\nhttps://arxiv.org/abs/2306.15595.\nTa-Chung Chi, Ting-Han Fan, Peter J Ramadge, and Alexander Rudnicky. Kerple: Kernelized\nrelative positional embedding for length extrapolation. Advances in Neural Information Processing\nSystems, 35:8386‚Äì8399, 2022a.\nTa-Chung Chi, Ting-Han Fan, Alexander I Rudnicky, and Peter J Ramadge. Dissecting transformer\nlength extrapolation via the lens of receptive field analysis. arXiv preprint arXiv:2212.10356,\n2022b.\nKrzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas\nSarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, et al. Rethinking attention\nwith performers. arXiv preprint arXiv:2009.14794, 2020.\nZihang Dai, Zhilin Yang, Yiming Yang, William Cohen, Ruslan Salakhutdinov, and Jaime Carbonell.\nTransformer-XL: Attentive language models beyond a fixed-length context. In Proceedings of\nACL, pages 2978‚Äì2988, 2019.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep\nbidirectional transformers for language understanding. In Proceedings of NAACL-HLT, pages\n4171‚Äì4186, 2019.\nOlga Golovneva, Jackie C Lou, Daniel Holtmann-Rice, Aditya Kusupati, Chengeng Cai, Zijian Hu,\nPrateek Vijay Kumar, Tim Dettmers, Pratyusha Sharma, Behnam Neyshabur, Jason D. Lee, and\nMohammad Bavarian. Contextual position encoding: Learning to count what‚Äôs important. arXiv\npreprint arXiv:2405.18719, 2024. URL https://arxiv.org/abs/2405.18719.\nBrian C Hall. Lie groups, lie algebras, and representations. In Quantum Theory for Mathematicians,\npages 333‚Äì366. Springer, 2013.\nAdi Haviv, Ori Ram, Ofir Press, Peter Izsak, and Omer Levy. Transformer language models without\npositional encodings still learn positional information. arXiv preprint arXiv:2203.16634, 2022.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert\nwith disentangled attention. arXiv preprint arXiv:2006.03654, 2020.\nByeongho Heo, Song Park, Dongyoon Han, and Sangdoo Yun. Rotary position embedding for vision\ntransformer. In European Conference on Computer Vision, pages 289‚Äì305. Springer, 2024.\nHongye Jin, Xiaotian Han, Jingfeng Yang, Zhimeng Jiang, Zirui Liu, Chia-Yuan Chang, Huiyuan\nChen, and Xia Hu. Llm maybe longlm: Self-extend llm context window without tuning. In\nProceedings of the 41st International Conference on Machine Learning (ICML 2024), volume 235,\npages 22099‚Äì22114. PMLR, 2024.\nAndrej Karpathy. NanoGPT. https://github.com/karpathy/nanoGPT, 2022.\n14\n\nAngelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Fran¬∏cois Fleuret. Transformers are\nrnns: Fast autoregressive transformers with linear attention. In International conference on\nmachine learning, pages 5156‚Äì5165. PMLR, 2020.\nAmirhossein Kazemnejad, Inkit Padhi, Karthikeyan Natesan Ramamurthy, Payel Das, and Siva\nReddy. The impact of positional encoding on length generalization in transformers. Advances in\nNeural Information Processing Systems, 36:24892‚Äì24928, 2023.\nGuolin Ke, Di He, and Tie-Yan Liu. Rethinking positional encoding in language pre-training. arXiv\npreprint arXiv:2006.15595, 2020.\nShun Kiyono, Sosuke Kobayashi, Jun Suzuki, and Kentaro Inui. SHAPE: Shifted absolute position\nembedding for transformers. In Proceedings of EMNLP, pages 3309‚Äì3321, 2021.\nKonstantinos Kogkalidis, Jean-Philippe Bernardy, and Vikas Garg. Algebraic positional encodings.\nAdvances in Neural Information Processing Systems, 37:34824‚Äì34845, 2024.\nShanda Li, Chong You, Guru Guruganesh, Joshua Ainslie, Santiago Ontanon, Manzil Zaheer, Sumit\nSanghai, Yiming Yang, Sanjiv Kumar, and Srinadh Bhojanapalli. Functional interpolation for\nrelative positions improves long context transformers. arXiv preprint arXiv:2310.04418, 2023.\nTatiana Likhomanenko, Qiantong Xu, Gabriel Synnaeve, Ronan Collobert, and Alex Rogozhnikov.\nCAPE: Encoding relative positions with continuous augmented positional embeddings. In Advances\nin Neural Information Processing Systems (NeurIPS), volume 34, pages 16079‚Äì16092, 2021.\nMengtian Lin, Ji Lin, Wei-Ming Chen, and Yonglong Tian. Forgetting transformer: Softmax\nattention with a forget gate. arXiv preprint arXiv:2503.02130, 2025. URL https://arxiv.org/\nabs/2503.02130.\nXuanqing Liu, Hsiang-Fu Yu, Inderjit Dhillon, and Cho-Jui Hsieh. Learning to encode position for\ntransformer with continuous dynamical model. In International conference on machine learning,\npages 6327‚Äì6335. PMLR, 2020.\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In 7th International\nConference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019,\n2019.\nAnton Lozhkov, Loubna Ben Allal, Leandro von Werra, and Thomas Wolf.\nFineweb-edu:\nthe finest collection of educational content, 2024. URL https://huggingface.co/datasets/\nHuggingFaceFW/fineweb-edu.\nMasato Neishi and Naoki Yoshinaga. On the relation between position information and sentence\nlength in neural machine translation. In Proceedings of the 23rd Conference on Computational\nNatural Language Learning (CoNLL), pages 328‚Äì338, 2019.\nSophie Ostmeier, Brian Axelrod, Maya Varma, Michael Moseley, Akshay S Chaudhari, and Curtis\nLanglotz. Liere: Lie rotational positional encodings. In Forty-second International Conference on\nMachine Learning, 2025.\nBowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. Yarn: Efficient context window\nextension of large language models. arXiv preprint arXiv:2309.00071, 2023.\n15\n\nOfir Press, Noah A Smith, and Mike Lewis. Train short, test long: Attention with linear biases\nenables input length extrapolation. arXiv preprint arXiv:2108.12409, 2021.\nZhen Qin, Weixuan Sun, Kaiyue Lu, Hui Deng, Dongxu Li, Xiaodong Han, Yuchao Dai, Lingpeng\nKong, and Yiran Zhong. Linearized relative positional encoding. arXiv preprint arXiv:2307.09270,\n2023.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text\ntransformer. The Journal of Machine Learning Research, 21(1):5485‚Äì5551, 2020.\nOlinde Rodrigues.\nDes lois g¬¥eom¬¥etriques qui r¬¥egissent les d¬¥eplacemens d‚Äôun syst`eme solide\ndans l‚Äôespace, et de la variation des coordonn¬¥ees provenant de ces d¬¥eplacemens consid¬¥er¬¥es\nind¬¥ependamment des causes qui peuvent les produire.\nJournal de Math¬¥ematiques Pures et\nAppliqu¬¥ees, 5:380‚Äì440, 1840.\nAnian Ruoss, Gr¬¥egoire Del¬¥etang, Tim Genewein, Jordi Grau-Moya, R¬¥obert Csord¬¥as, Mehdi Bennani,\nShane Legg, and Joel Veness. Randomized positional encodings boost length generalization of\ntransformers. arXiv preprint arXiv:2305.16843, 2023.\nConnor Schenck, Isaac Reid, Mithun George Jacob, Alex Bewley, Joshua Ainslie, David Rendleman,\nDeepali Jain, Mohit Sharma, Avinava Dubey, Ayzaan Wahid, et al. Learning the ropes: Better\n2d and 3d position encodings with string. arXiv preprint arXiv:2502.02562, 2025.\nPeter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-attention with relative position representa-\ntions. arXiv preprint arXiv:1803.02155, 2018.\nKoustuv Sinha, Amirhossein Kazemnejad, Siva Reddy, Joelle Pineau, Dieuwke Hupkes, and Adina\nWilliams. The curious case of absolute position embeddings. arXiv preprint arXiv:2210.12574,\n2022.\nJianlin Su, Yuancheng Zhang, Shengfeng Pan, Shengyu Ge, and Yunfeng Liu. Roformer: Enhanced\ntransformer with rotary position embedding. arXiv preprint arXiv:2104.09864, 2021.\nYutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon Benhaim, Vishrav Chaudhary,\nXia Song, and Furu Wei. A length-extrapolatable transformer. arXiv preprint arXiv:2212.10554,\n2022.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth¬¥ee\nLacroix, Baptiste Rozi`ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\nefficient foundation language models. arXiv preprint arXiv:2302.13971, 2023a.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation\nand fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023b.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,  Lukasz\nKaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing\nsystems, 30, 2017.\n16\n\nBenyou Wang, Donghao Zhao, Christina Lioma, Qiuchi Li, Peng Zhang, and Jakob Grue Simonsen.\nEncoding word order in complex embeddings. In Proceedings of ICLR, 2020.\nBenyou Wang, Lifeng Shang, Christina Lioma, Xin Jiang, Hao Yang, Qun Liu, and Jakob Grue\nSimonsen. On position embeddings in BERT. In Proceedings of ICLR, 2021.\nJie Wang, Tao Ji, Yuanbin Wu, Hang Yan, Tao Gui, Qi Zhang, Xuanjing Huang, and Xiaoling\nWang. Length generalization of causal transformers without position encoding. In Findings of the\nAssociation for Computational Linguistics: ACL 2024, pages 14024‚Äì14040, Bangkok, Thailand,\nAugust 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.834.\nURL https://aclanthology.org/2024.findings-acl.834/.\nUlme Wennberg and Gustav Eje Henter.\nThe case for translation-invariant self-attention in\ntransformer-based language models. arXiv preprint arXiv:2106.01950, 2021.\nChuhan Wu, Fangzhao Wu, and Yongfeng Huang. Da-transformer: Distance-aware transformer.\narXiv preprint arXiv:2010.06925, 2020.\nWenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajjwal Bhargava, Rui Hou, Louis Martin,\nRashi Rungta, Karthik Abinav Sankararaman, Barlas Oguz, et al. Effective long-context scaling\nof foundation models. arXiv preprint arXiv:2309.16039, 2023.\nAn Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao,\nChengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388,\n2025a.\nSonglin Yang, Yikang Shen, Kaiyue Wen, Shawn Tan, Mayank Mishra, Liliang Ren, Rameswar Panda,\nand Yoon Kim. Path attention: Position encoding via accumulating householder transformations.\narXiv preprint arXiv:2505.16381, 2025b.\nManzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago\nOntanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. Big bird: Transformers for\nlonger sequences. Advances in neural information processing systems, 33:17283‚Äì17297, 2020.\nChuanyang Zheng, Yihang Gao, Han Shi, Minbin Huang, Jingyao Li, Jing Xiong, Xiaozhe Ren,\nMichael Ng, Xin Jiang, Zhenguo Li, et al. Dape: Data-adaptive positional encoding for length\nextrapolation. Advances in Neural Information Processing Systems, 37:26659‚Äì26700, 2024.\nDawei Zhu, Nan Yang, Liang Wang, Yifan Song, Wenhao Wu, Furu Wei, and Sujian Li. Pose:\nEfficient context window extension of llms via positional skip-wise training. arXiv preprint\narXiv:2309.10400, 2023.\n17\n\nAppendix\nA Application in Multi-Head Attention\n19\nB Forgetting Transformer as a Special Additive GRAPE\n20\nC Non-Commuting Multiplicative GRAPE\n21\nD Composition of Additive GRAPE and Multiplicative GRAPE\n21\nE Comparison with LieRE\n22\nF 2D and 3D GRAPE for Vision and Multimodal Position Encoding\n22\nG Algorithmic Details and Pseudo Code\n23\nH Differentiation and Fast Application of Rank-2 Matrix Exponential\n25\nI\nSpectral Analysis of GRAPE and Other Methods\n25\nI.1\nRank-2 Plane: Exact Spectrum and Geometric Interpretation . . . . . . . . . . . . .\n25\nI.2\nMulti-subspace GRAPE-M and RoPE . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\nI.3\nAdditive GRAPE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\nI.4\nComparison to PaTH Attention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n18\n\nTable 3 Summary of Notation and Definitions.\nSymbol\nDefinition\nGL(d)\nGeneral Linear Group: The group of all d √ó d invertible matrices.\nSO(d)\nSpecial Orthogonal Group: The group of d √ó d orthogonal matrices\nwith determinant 1 (R‚ä§R = I, det(R) = 1).\nSL(d)\nSpecial Linear Group: The group of d √ó d matrices with determinant 1.\ngl(d)\ngeneral linear algebra: The Lie algebra of GL(d), consisting of all d √ó d matrices.\nso(d)\nspecial orthogonal algebra: The Lie algebra of SO(d), consisting of all d √ó d\nskew-symmetric matrices (L‚ä§= ‚àíL).\nexp(¬∑)\nExponential Map: A map from a Lie algebra (generator) to a Lie group (operator).\nR2(Œ∏)\n2D Rotation Matrix: The matrix\n\u0012cos Œ∏\n‚àísin Œ∏\nsin Œ∏\ncos Œ∏\n\u0013\n.\nG(n)‚ä§\nTranspose (in SO(d)): For G ‚ààSO(d), the transpose is the group inverse (G‚ä§= G‚àí1).\nG(n)‚àí‚ä§\nInverse Transpose (in GL(d)): The transpose of the matrix inverse, (G‚àí1)‚ä§.\nUnipotent\nUnipotent Transform: A linear transformation whose eigenvalues are all 1.\npu,h\nPositional Embedding/Representation: A vector derived from token-local features,\nobtained via a linear projection followed by RMS normalization.\nA\nApplication in Multi-Head Attention\nBuilding upon the algebraic foundation for relative encoding established in Section 2.5, this section\ndetails the concrete integration of the rotational map G(n) into the full Multi-Head Attention\n(MHA) architecture, covering the per-head formulation, streaming policy, and implementation\ncomplexity.\nPer-head formulation. Let H be the number of heads and d the per-head width. For head h ‚àà[H],\nlet (qt,h, kt,h, vt,h) ‚ààRd denote the query/key/value at position t. A GRAPE-M position map is\nrealized as an orthogonal operator Gh,t ‚ààSO(d) applied to (qt,h, kt,h):\neqt,h = Gh,t qt,h,\nekt,h = Gh,t kt,h,\nevt,h = vt,h.\nThe headwise attention logits and outputs are then\n‚Ñìt,j,h =\neq‚ä§\nt,hekj,h\n‚àö\nd\n=\nq‚ä§\nt,h\n\u0000G‚ä§\nh,tGh,j\n\u0001\nkj,h\n‚àö\nd\n,\nyt,h =\nX\nj‚â§t\nsoftmax\n\u0000‚Ñìt,¬∑,h\n\u0001\nj evj,h,\n(A.1)\nwith the usual output projection applied after concatenation across heads.\nExact relative law. If Gh,t arises from a one-parameter subgroup Gh(n) = exp(n Lh) (commuting\nMS-GRAPE-M, including RoPE and learned commuting bases), then\nG‚ä§\nh,tGh,j = Gh(j‚àít)\n=‚áí\n‚Ñìt,j,h =\nq‚ä§\nt,hGh(j‚àít) kj,h\n‚àö\nd\n,\n19\n\nso logits depend only on the offset j‚àít (exact origin invariance).\nStreaming cache. Applying the rotational map G(t) independently to each query and key vector\nis the core property that enables an efficient streaming cache policy. For any type where Gt is\nknown at token arrival (non-contextual and phase-modulated), cache ekj,h = Gh,jkj,h once and never\nrewrite it; at step t, compute eqt,h = Gh,tqt,h and use logits ‚Ñìt,j,h = eq‚ä§\nt,hekj,h/\n‚àö\nd.\nB\nForgetting Transformer as a Special Additive GRAPE\nThe Forgetting Transformer (FoX) introduces a scalar forget gate ft ‚àà(0, 1] per head and timestep\nand adds the cumulative log-gate as an additive bias in the attention logits. Concretely, for a head\nh,\nft,h = œÉ(w‚ä§\nf,hxt + bf,h),\nFij,h =\niY\n‚Ñì=j+1\nf‚Ñì,h,\nDij,h = log Fij,h =\ni\nX\n‚Ñì=j+1\nlog f‚Ñì,h,\nand the attention is\nOh = softmax\n\u0010\n1\n‚àö\ndQK‚ä§+ Dh\n\u0011\nV.\n(FoX)\nWe now show that Eq. (FoX) is exactly realized by our GRAPE-A framework using the endpoint-independent\npath-additive specialization of Section 5.\nFoX as GRAPE-AP with endpoint-independent edges. In GRAPE-AP (Section 5), a head-wise\nadditive logit bh(t, j) arises as a causal path sum\nbh(t, j) =\nt\nX\n‚Ñì=j+1\nœàh(t, ‚Ñì).\nIf the edge potentials do not depend on the endpoint, i.e. œàh(t, ‚Ñì) ‚â°a‚Ñì,h, then bh(t, j) reduces to a\ndifference of per-time potentials:\nbh(t, j) =\nt\nX\n‚Ñì=j+1\na‚Ñì,h = Ut,h ‚àíUj,h,\nUu,h :=\nX\n‚Ñì<u\na‚Ñì,h.\nFoX corresponds to the choice a‚Ñì,h = log f‚Ñì,h ‚â§0, yielding\nbh(t, j) ‚â°Dij,h =\nt\nX\n‚Ñì=j+1\nlog f‚Ñì,h.\nThus, the FoX forgetting bias Dh is precisely the GRAPE-AP path-integral additive bias with\nendpoint-independent edges.\nUnipotent GL lift (GRAPE-A view). Let E := ed+2e‚ä§\nd+1 be the rank-1 nilpotent used in Section 4.2.\nFor a fixed head h and endpoint t, define per-link unipotent factors\nH(t)\nh (‚Ñì) = I + œàh(t, ‚Ñì) E,\nœàh(t, ‚Ñì) = log f‚Ñì,h.\nSince E2 = 0, the path product collapses:\ntY\n‚Ñì=j+1\nH(t)\nh (‚Ñì) = I +\n\u0010\nt\nX\n‚Ñì=j+1\nlog f‚Ñì,h\n\u0011\nE = I + Dij,h E.\n20\n\nScoring in homogeneous coordinates as in Section 4 with the paired inverse-transpose,\neq‚ä§\nt,h ekj,h = bq‚ä§\nt,h\n\u0010\nI + Dij,h E\n\u0011‚àí‚ä§bkj,h = q‚ä§\nt,hkj,h + Dij,h,\nrecovers Eq. (FoX) exactly (up to the standard 1/\n‚àö\nd factor we include throughout).\nHence\nFoX is an exact GRAPE-A / GRAPE-AP instance realized by a rank-1 unipotent path with\nendpoint-independent edges.\nStreaming and complexity. Compute prefix sums Ut,h = P\n‚Ñì<t log f‚Ñì,h once per step; then Dij,h =\nUi,h ‚àíUj,h is obtained by subtraction, preserving the O(L) rowwise cost and the streaming cache\npolicy from Section 4‚ÄìSection 5. The headwise gates ft,h add O(1) parameters and negligible\ncomputation.\nSpecial cases and composition. If ft,h ‚â°e‚àíŒ≤h (constant per head), then Dij,h = ‚àíŒ≤h(i‚àíj) and\nFoX reduces to exact ALiBi (Section 4.2). More generally, FoX composes additively with the\nmultiplicative (orthogonal) GRAPE acting on (q, k) as in Eq. (5.3), preserving norm-preservation\nof the rotational part while adding bounded, non-positive, content-adaptive path biases.\nC\nNon-Commuting Multiplicative GRAPE\nConsider the thin compression L = ELrE‚ä§with E ‚ààRd√ór orthonormal and Lr ‚ààso(r). Then\nœÉ(L) = œÉ(Lr) ‚à™{0}d‚àír,\nœÉ\n\u0000exp(nL)\n\u0001\n= œÉ\n\u0000exp(nLr)\n\u0001\n‚à™{1}d‚àír.\nIf Lr = T(Lr/2\nt=1 Œ∏tJ)T‚ä§is the real-Schur form, then the nontrivial eigenvalues are {¬±iŒ∏t}r/2\nt=1 and\ne¬±inŒ∏t for the exponential. Thus, the expressive power of non-contextual non-commuting MS-GRAPE\nis fully captured by the r/2 mode angles {Œ∏t}; the ambient lifting via E preserves the spectrum.\nD\nComposition of Additive GRAPE and Multiplicative GRAPE\nFor the unipotent forms of Additive GRAPE, applying Gadd(m)‚àí‚ä§requires one inner product and\none scalar-vector multiplication per active component. Thus, the per-head overhead is O(d) and\ntypically negligible relative to attention matmuls. Multiplicative GRAPE (Section 3) and Additive\nGRAPE (Section 4) compose naturally, either additively at the logit level\n‚Ñìt,j,h =\n1\n‚àö\nd q‚ä§\nt,hGh(j‚àít)kj,h +\nh\nbq‚ä§\nt,hGadd,h(j‚àít)‚àí‚ä§bkj,h ‚àíq‚ä§\nt,hkj,h\ni\n,\nor as a single block-upper-triangular GL action in homogeneous coordinates. Concretely, define the\njoint lift\nbq = [q; 1],\nbk = [k; 1],\nbG(m) =\n\u0014exp(m L)\nm œâ u\n0‚ä§\n1\n\u0015\n‚ààGL(d+1),\nwhich combines the orthogonal rotation exp(mL) on features with a unipotent translation along the\nhomogeneous axis. Scoring with the paired inverse-transpose as in Eq. (4.2) yields\nbq‚ä§bG(m)‚àí‚ä§bk+ = q‚ä§exp(mL)k ‚àím œâ u‚ä§k + const,\nexactly reproducing the sum of multiplicative (rotary) and additive (bias) components up to a\nsoftmax-invariant constant. In both formulations, exact relativity and streaming caches are retained.\n21\n\nE\nComparison with LieRE\nLie Rotational Position Encodings (LieRE) (Ostmeier et al., 2025) encode positional information by\nlearning a skew-symmetric generator in SO(d). The method then applies the matrix exponential of\nthis generator to get a rotational position map. For each attention head, the method learns one\nskew matrix. Its exponential gives a dense orthogonal operator on queries and keys. Positions then\nmatch elements of a one-parameter subgroup on the rotation manifold. This picture is a compact Lie\ntheoretic version of RoPE style encodings. Different heads can learn distinct rotational geometries\nand the map keeps the norm and an exact relative position law.\nFormally, for head h the generator is Gh ‚ààso(d). The positional map is x 7‚Üíexp(nœâhGh)x. A\ndirect implementation has cost TLieRE(d) = Œò(d3) per head for the matrix exponential and needs\nŒò(d2) parameters and the same order of memory.\nMultiplicative GRAPE and LieRE both use rotations in SO(d) that come from skew-symmetric\ngenerators. LieRE gives each head a dense or block skew matrix. It forms the positional operator\nwith the full matrix exponential exp(G). This creates very rich rotations but needs O(d3) time for\nthe exponential and O(d2) parameters and memory per head. GRAPE-M restricts the generator to a\nsum of rank 2 planes and uses a closed form Rodrigues-type formula for the exponential (Section 2).\nFor one token, the positional mapping then reduces to a few inner products and vector updates. So\nthe cost is O(d) time and O(d) memory per head.\nThis choice of parametrization has two main effects in practice. First, the GRAPE-M scale\ncleanly translates to contextual versions where frequencies or phases depend on the token content.\nThe closed-form expression can be computed quickly for each token, and there is no large matrix\nexponential. In the LieRE setup, one needs a new dense matrix exponential for each content-\ndependent generator. This step is much more costly and makes such contextual use harder to deploy\nin real models. Second, GRAPE gives a single group-theoretic picture for multiplicative and additive\nmechanisms. The multiplicative part lives in SO(d) and additive or forgetting style terms (ALiBi,\nFoX, GRAPE-A, GRAPE-AP) come from unipotent actions in GL with the same relative law and\nthe same streaming cacheability (Sections 4-5). LieRE only targets rotational encodings and does\nnot model additive logit biases or forgetting terms.\nF\n2D and 3D GRAPE for Vision and Multimodal Position Encoding\nExtending GRAPE beyond one-dimensional token positions is easy. The construction only needs a\nchosen group action on coordinates.\nFor images with integer pixel coordinates (u, v) ‚ààZ2 we pick two generators L(x) and L(y). A\ntoken at (u, v) then gets the encoding\nG2D(u, v) = exp\n\u0000u œâxL(x)\u0001\nexp\n\u0000v œâyL(y)\u0001\n‚ààSO(d).\nThe two generators act on 2D planes that can be disjoint in the base design. In that case, the\nmap reduces to a RoPE-style separable encoding. A learned choice of planes inside Rd gives the\nGRAPE-M variant again.\nFor 3D coordinates (u, v, w) that mark video space time tokens or point clouds, we follow the\nsame pattern. We introduce three commuting generators and define\nG3D(u, v, w) = exp\n\u0000u œâxL(x)\u0001\nexp\n\u0000v œâyL(y)\u0001\nexp\n\u0000w œâzL(z)\u0001\n.\n22\n\nIn the non-commuting case, we use the thin Schur mode compression from Appendix C. The\nclosed-form rank 2 matrix exponential from the main text still applies. The per token cost stays\nO(d) even for higher-dimensional coordinate spaces.\nOn the additive side, GRAPE-A and GRAPE-AP handle 2D or 3D structures through the scalar\noffset m. The value m can be any function of coordinate differences. For an image, we can take\nm = Œ±x(ut ‚àíuj) + Œ±y(vt ‚àívj),\nand this keeps the same algebraic template. For 3D settings, we can set\nm = ‚à•rt ‚àírj‚à•\nwith rt and rj in R3. The update matrix then stays unipotent, and the exact relative composition\nlaw still holds. This gives a clear way to impose axis-aligned or radial recency bias in vision and\nmultimodal models.\nG\nAlgorithmic Details and Pseudo Code\nThis appendix contains the detailed pseudocode.\nAlgorithm 1 Commuting Multi-Subspace GRAPE-M\nRequire: Q, K ‚ààRB√óL√óH√ód, orthogonal E ‚ààRd√ód, frequencies {œâh,j}d/2\nj=1, positions n ‚ààZL\n1: for h = 1 to H do\n2:\nQ‚Ä≤[:, :, h, :] ‚ÜêQ[:, :, h, :] E;\nK‚Ä≤[:, :, h, :] ‚ÜêK[:, :, h, :] E\n3:\nfor ‚Ñì= 0 to L ‚àí1 do\n4:\nfor j = 1 to d/2 do\n5:\nŒ∏ ‚Üên‚Ñìœâh,j; apply 2 √ó 2 rotation G2(Œ∏) to coords (2j‚àí1, 2j) of Q‚Ä≤[:, ‚Ñì, h, :] and\nK‚Ä≤[:, ‚Ñì, h, :]\n6:\nend for\n7:\nend for\n8:\neQ[:, :, h, :] ‚ÜêQ‚Ä≤ E‚ä§;\neK[:, :, h, :] ‚ÜêK‚Ä≤ E‚ä§\n9: end for\n10: return ( eQ, eK)\n23\n\nAlgorithm 2 Fast Contextual Non-commuting MS-GRAPE-M via Schur-Mode Rotation\nRequire: Q, K ‚ààRB√óL√óH√ód; planes {(ah,j, bh,j, œâh,j)}m\nj=1; positions n\n1: for h = 1 to H do\n‚ñ∑one-time per head\n2:\nBuild Uh = span{ah,j, bh,j}; orthonormalize bh ‚ààRd√órh\n3:\nLU,h ‚Üêb‚ä§\nh\n\u0010 Pm\nj=1 œâh,jL(ah,j, bh,j)\n\u0011\nbh ‚ààso(rh)\n4:\nOrthogonally Schur-decompose: LU,h = Th\n\u0010Lrh/2\nt=1 Œ∏h,tJ\n\u0011\nT‚ä§\nh\n5:\nEh ‚ÜêbhTh ‚ààRd√órh; precompute (ch,t, sh,t) = (cos Œ∏h,t, sin Œ∏h,t)\n6: end for\n7: for ‚Ñì= 0 to L ‚àí1 do\n‚ñ∑token loop\n8:\nfor h = 1 to H do\n9:\nyQ ‚ÜêE‚ä§\nh Q[:, ‚Ñì, h, :];\nyK ‚ÜêE‚ä§\nh K[:, ‚Ñì, h, :]\n10:\nfor t = 1 to rh/2 do\n11:\n(Ch,t, Sh,t) ‚ÜêPhaseTo(n‚Ñì; ch,t, sh,t)\n‚ñ∑(C, S) from (cos Œ∏, sin Œ∏) via angle-addition\nor binary exponentiation\n12:\nApply\n\u0010 Ch,t ‚àíSh,t\nSh,t\nCh,t\n\u0011\nto coordinates (2t‚àí1, 2t) of yQ, yK\n13:\nend for\n14:\neQ[:, ‚Ñì, h, :] ‚ÜêQ[:, ‚Ñì, h, :] + Eh(yQ ‚àíE‚ä§\nh Q[:, ‚Ñì, h, :])\n15:\neK[:, ‚Ñì, h, :] ‚ÜêK[:, ‚Ñì, h, :] + Eh(yK ‚àíE‚ä§\nh K[:, ‚Ñì, h, :])\n16:\nend for\n17: end for\n18: return ( eQ, eK)\nAlgorithm 3 Additive GRAPE (GRAPE-A) with streaming cache\nRequire: Q, K ‚ààRB√óL√óH√ód; per-head additive generators {Ah} with A2\nh = 0; positions n ‚ààZL\n1: Augment: bQ ‚Üê[Q; 1; 0], bK ‚Üê[K; 0; 1] as needed (Section 4.2)\n2: for j = 0 to L‚àí1 do\n‚ñ∑cache once on arrival\n3:\nfor h = 1 to H do\n4:\nbK‚ãÜ[:, j, h, :] ‚Üê\n\u0000I ‚àínj A‚ä§\nh\n\u0001 bK[:, j, h, :]\n5:\nend for\n6: end for\n7: for t = 0 to L‚àí1 do\n8:\nfor h = 1 to H do\n9:\neQ[:, t, h, :] ‚Üê\n\u0000I + nt Ah\n\u0001 bQ[:, t, h, :]\n10:\nCompute additive logits: Œªt,j,h ‚ÜêeQ[:, t, h, :]‚ä§bK‚ãÜ[:, j, h, :]\n11:\nend for\n12: end for\n13: return {Œªt,j,h} (to be added to orthogonal GRAPE/RoPE logits)\n24\n\nH\nDifferentiation and Fast Application of Rank-2 Matrix Exponential\nDifferentiation and stability. Let f1(z) = sin z\nz\nand f2(z) = 1‚àícos z\nz2\nwith z = nœâs. Then\nexp(nœâL) = I + f1(z)L + f2(z)L2.\nFor any scalar parameter Œ∏ ‚àà{œâ} ‚à™{entries of a, b},\n‚àÇŒ∏ exp(nœâL) = f1(z) ‚àÇŒ∏L + f2(z) (L ‚àÇŒ∏L + ‚àÇŒ∏L L) + ‚àÇŒ∏z\n\u0000f‚Ä≤\n1(z)L + f‚Ä≤\n2(z)L2\u0001\n,\n‚àÇŒ∏z = nœâ ‚àÇŒ∏s + ns ‚àÇŒ∏œâ,\n‚àÇŒ∏s = 1\n2s‚àí1‚àÇŒ∏(Œ±Œ≤ ‚àíŒ≥2).\nUse series for |z| < Œµ: f1(z) = 1 ‚àíz2\n6 + O(z4) and f2(z) = 1\n2 ‚àíz2\n24 + O(z4). These formulas enable\nmixed-precision backprop with small-s guards.\nFast application. For any x ‚ààRd,\nLx = a‚ü®b, x‚ü©‚àíb‚ü®a, x‚ü©,\nL2x = Œ≥(a‚ü®b, x‚ü©+ b‚ü®a, x‚ü©) ‚àíŒ≤ a‚ü®a, x‚ü©‚àíŒ± b‚ü®b, x‚ü©.\nThus G(n)x = x + f1Lx + f2L2x with f1 = sin(nœâs)\ns\nand f2 = 1‚àícos(nœâs)\ns2\n, which is evaluable in O(d)\ntime via a few inner products. By the minimal polynomial Œª(Œª2 + s2), L3 = ‚àís2L; expanding\nexp(Œ∑L) and regrouping yields the rank-2 update form used throughout\nI\nSpectral Analysis of GRAPE and Other Methods\nIn this section, we discuss eigenvalue-level results for GRAPE-M generators/exponentials and\nsummarize the unipotent spectra of GRAPE-A/GRAPE-AP. Throughout, L(a, b) = ab‚ä§‚àíba‚ä§‚àà\nso(d), and Œ± = ‚à•a‚à•2, Œ≤ = ‚à•b‚à•2, Œ≥ = a‚ä§b, ‚àÜ= Œ±Œ≤ ‚àíŒ≥2, s =\n‚àö\n‚àÜas in Section 2.\nI.1\nRank-2 Plane: Exact Spectrum and Geometric Interpretation\nLemma I.1 (Rank-2 spectrum). For L = L(a, b), the eigenvalues are {¬±is} ‚à™{0}d‚àí2, and there\nexists B ‚ààSO(d) such that\nB‚ä§LB =\n\u0014sJ\n0\n0\n0d‚àí2\n\u0015\n,\nJ =\n\u0000 0 ‚àí1\n1 0\n\u0001\n.\nMoreover, s = ‚à•a‚à•‚à•b‚à•sin œï, where œï ‚àà[0, œÄ] is the angle between a and b.\nProof. From Section 2, L2 = ‚àís2PU with U = span{a, b}, whence the minimal polynomial is\nŒª(Œª2 + s2) and œÉ(U) = {¬±is, 0}. Choosing an orthonormal basis aligned with U ‚äïU‚ä•yields the\nclaimed form. Finally, ‚àÜ= Œ±Œ≤ ‚àíŒ≥2 = ‚à•a‚à•2‚à•b‚à•2(1 ‚àícos2 œï) = (‚à•a‚à•‚à•b‚à•sin œï)2.\nCorollary I.2 (Phase bounds and orthogonality). The per-step rotation angle of exp(Œ∑K) on U\nequals Œ∏ = Œ∑s and satisfies 0 ‚â§Œ∏ ‚â§Œ∑‚à•a‚à•‚à•b‚à•, with equality when a ‚ä•b. If b = J a (Section 2.4)\nand ‚à•a‚à•= 1, then s = 1 and Œ∏ = Œ∑.\nExponential spectrum. For any n ‚ààZ,\nœÉ\n\u0000exp(nL)\n\u0001\n= {e¬±ins} ‚à™{1}d‚àí2.\nHence œÅ(exp(nL)) = 1, the map is unitary (orthogonal), and all Lyapunov exponents are zero.\nPeriodicity holds with fundamental period T = 2œÄ/s when s/œÄ ‚ààQ; otherwise, the trajectory is\nquasi-periodic on the unit circle.\n25\n\nI.2\nMulti-subspace GRAPE-M and RoPE\nLet L = Pm\nj=1 Œ∏jLj with mutually orthogonal planes (hence [Li, Lj] = 0 for i Ã∏= j) and Lj = UjJU‚ä§\nj .\nThen\nB‚ä§LB =\nm\nM\nj=1\nŒ∏jJ ‚äï0d‚àí2m,\nœÉ(L) = {¬±iŒ∏j}m\nj=1 ‚à™{0}d‚àí2m,\nfor some Q ‚ààSO(d). Consequently,\nœÉ\n\u0000exp(nL)\n\u0001\n= {e¬±inŒ∏j}m\nj=1 ‚à™{1}d‚àí2m.\nThis recovers RoPE when the planes are the coordinate pairs and {Œ∏j} follow the canonical log-\nuniform spectrum (Proposition 3.1).\nI.3\nAdditive GRAPE\nWe now analyze the spectral properties of the additive lifts in GL introduced in Sections 4 and 5.\nThe key structural fact is unipotency: all per-step factors are identity plus a rank-1 (or few-rank)\nnilpotent update of index 2.\nSetup. Let A ‚ààgl(d+1) (or gl(d+2) for ALiBi) satisfy A2 = 0 as in (4.1) and (4.6). For a scalar\npath parameter s ‚ààR, define the unipotent factor\nH(s) := exp(sA) = I + s A,\nH(s)‚àí1 = I ‚àís A,\ndet H(s) = 1.\nFor Additive GRAPE (GRAPE-A) with offset m = j‚àíi, s = m œâ; for GRAPE-PA, s = sh(t, j) :=\nPt\n‚Ñì=j+1 œàh(t, ‚Ñì) from Eq. (5.2).\nProposition I.3 (Eigenvalues and Jordan structure of additive lifts). Let A ‚ààgl(D) satisfy A2 = 0\nand A Ã∏= 0. Then for every s Ã∏= 0,\nœÉ\n\u0000H(s)\n\u0001\n= {1}D,\n(H(s) ‚àíI)2 = 0,\ndet H(s) = 1,\nœÅ(H(s)) = 1.\nHence, the minimal polynomial of H(s) is (Œª ‚àí1)2, and the Jordan form consists of size-2 Jordan\nblocks for the 1-eigenspace, with the number of nontrivial blocks equal to rank(A).\nProof. Since A2 = 0, exp(sA) = I+sA and (H(s)‚àíI)2 = s2A2 = 0. The characteristic polynomial\nis (Œª ‚àí1)D for H(s), so all eigenvalues equal 1. The determinant equals the product of eigenvalues,\nhence 1; the spectral radius is therefore 1.\nDictionary closure. If {Ar}R\nr=1 satisfy A2\nr = 0 and ArAs = 0 for all r, s, then\n\u0010 X\nr\nŒ∏rAr\n\u00112\n=\nX\nr\nŒ∏2\nrA2\nr +\nX\nrÃ∏=s\nŒ∏rŒ∏sArAs = 0,\nso the combined generator is also index-2 nilpotent and yields the same unipotent spectrum.\nSingular values. Although H(s) is not orthogonal, its deviation from I is rank-limited and exactly\nanalyzable. We first give a sharp, explicit formula for the canonical rank-1 case (ALiBi block), then\na general bound.\n26\n\nLemma I.4 (Exact singular-value pair for a canonical rank-1 unipotent). Let E := ep e‚ä§\nq with\np Ã∏= q and define H(s) := I + sE ‚ààRD√óD. Then D ‚àí2 singular values equal 1, and the remaining\ntwo are\nœÉ¬±(H(s)) =\nr\n1 + s2\n2 ¬± |s|\nq\n1 + s2\n4 ,\nœÉ+(H(s)) œÉ‚àí(H(s)) = 1.\n(I.1)\nIn particular, Œ∫2(H(s)) = œÉ+(H(s))/œÉ‚àí(H(s)) = 1 + 2|s| + O(s2) as s ‚Üí0.\nProof. The action of H(s)‚ä§H(s) is identity on span{ep, eq}‚ä•. In the basis {eq, ep} it equals\n\u0000 1+s2 s\ns\n1\n\u0001\n,\nwhose eigenvalues are 1 + s2\n2 ¬± |s|\nq\n1 + s2\n4 . Taking square roots yields (I.1). The product equals\np\ndet(H‚ä§H) = | det H| = 1.\nCorollary I.5 (ALiBi and Additive GRAPE (GRAPE-A) conditioning numbers). For the exact\nALiBi generator in Eq. (4.6), E = ed+2e‚ä§\nd+1 and s = m Œ≤h, so the only nontrivial singular values\nof Gadd,h(m) = I + sE are given by Eq. (I.1). For the single-vector additive lift Eq. (4.1) with\nA =\n\u0000 0 u\n0‚ä§0\n\u0001\nand ‚à•u‚à•= 1, the same formula holds with E replaced by an orthogonally similar rank-1\nupdate and s = m œâ.\nLemma I.6 (General operator-norm bounds for index-2 unipotents). For any A with A2 = 0 and\nany s ‚ààR,\n1 ‚àí|s| ‚à•A‚à•2 ‚â§œÉmin(I + sA) ‚â§œÉmax(I + sA) ‚â§1 + |s| ‚à•A‚à•2.\nWhen rank(A) = 1 and ‚à•A‚à•2 = 1, these bounds are tight and coincide with Lemma I.4 at first\norder in |s|.\nProof. Use the triangle inequality ‚à•(I + sA)x‚à•2 ‚â§‚à•x‚à•2 + |s| ‚à•A‚à•2‚à•x‚à•2 and its reverse form applied\nto (I+sA)‚àí1 = I‚àísA; see also Weyl inequalities for singular values under rank-1 perturbations.\nCancellation in the relative logit. While H(s) can be anisotropic (Lemma I.4), the Additive GRAPE\n(GRAPE-A) scoring uses a paired inverse-transpose (Eq. (4.2)), which cancels all multiplicative\ndistortions and yields a pure additive term:\neq‚ä§\ni ekj = bq‚ä§\ni\n\u0000I + i A\n\u0001‚ä§\u0000I ‚àíj A‚ä§\u0001 bkj = bq‚ä§\ni\n\u0000I + (i‚àíj) A‚ä§\u0001bkj = bq‚ä§\ni Gadd(j‚àíi)‚àí‚ä§bkj,\nsince (A‚ä§)2 = 0. This reproduces the exact relative law Eq. (4.3) and the closed form Eq. (4.4)\n(e.g. Eq. (4.5)), independently of œÉ¬±(H(s)).\nGRAPE-AP as a path-integral unipotent. Fix a head h and endpoint t. The per-row path product\nin Section 5 is\ntY\n‚Ñì=j+1\n\u0000I + œàh(t, ‚Ñì) E\n\u0001\n= I +\n\u0010\nt\nX\n‚Ñì=j+1\nœàh(t, ‚Ñì)\n\u0011\nE = I + sh(t, j) E,\nbecause E2 = 0. Thus GRAPE-AP inherits the unipotent spectrum of Prop. I.3 with row-dependent\ns = sh(t, j) ‚â§0 (since œàh ‚â§0 by construction).\nIts only two nontrivial singular values are\nexactly (I.1) with s 7‚Üísh(t, j); the rest equal 1. Consequently,\nŒ∫2\n\u0000PA factor\n\u0001\n= œÉ+\n\u0000sh(t, j)\n\u0001\nœÉ‚àí\n\u0000sh(t, j)\n\u0001 = 1 + 2 |sh(t, j)| + O\n\u0000sh(t, j)2\u0001\n,\n27\n\nwhile the determinant remains 1 and eigenvalues are all 1. As in Additive GRAPE (GRAPE-A), the\npaired inverse-transpose used in the bilinear scoring removes any multiplicative anisotropy, leaving\nthe bounded additive term bh(t, j) in Eq. (5.2).\nImplications. Now we summarize the implications of previous results. For all s, H(s) is invertible\nwith H(s)‚àí1 = I ‚àísA; eigenvalues do not grow with offset length (spectral radius = 1). The\noperator norm grows at most linearly in |s| (Lemma I.6) and is exactly characterized in the rank-1\ncanonical cases (Lemma I.4).\nSecondly, det H(s) = 1 implies no net volume change; any expansion along one direction is\nexactly balanced by contraction along its paired direction (product œÉ+œÉ‚àí= 1). Despite anisotropy,\nthe GRAPE-A and GRAPE-AP logits remain exactly relative because the key transform uses\nH(s)‚àí‚ä§, algebraically eliminating multiplicative distortion and yielding the closed-form additive\nbias (Eqs. (4.3), (4.4), (5.2)).\nI.4\nComparison to PaTH Attention\nPaTH Attention (Yang et al., 2025b) proposes a contextual multiplicative position map given by a\ncumulative product of identity-plus-rank-one matrices\nHt = I ‚àíŒ≤t wtw‚ä§\nt ,\n‚à•wt‚à•2 = 1,\nŒ≤t ‚àà(0, 2),\napplied along the path between key position j and query position i as Qi\ns=j+1 Hs (see Section 2 of\nthe PaTH paper). In contrast to GRAPE-M factors, each Ht is not orthogonal unless Œ≤t ‚àà{0, 2}.\nThis has immediate spectral consequences.\nPer-step spectrum. Since Ht is symmetric rank-1 perturbation of the identity with projector\nPt := wtw‚ä§\nt ,\nœÉ(Ht) = { 1 ‚àíŒ≤t, 1, . . . , 1\n| {z }\nd‚àí1\n},\ndet(Ht) = 1 ‚àíŒ≤t,\n‚à•Ht‚à•2 = max{1, |1 ‚àíŒ≤t|} = 1.\nThus Ht is norm nonexpansive (operator norm 1) but not norm-preserving unless Œ≤t ‚àà{0, 2}.\nSingular values equal the absolute eigenvalues because Ht is symmetric; the component along wt\nis scaled by |1 ‚àíŒ≤t| < 1 for any Œ≤t ‚àà(0, 2) \\ {0, 2}, and flips sign when Œ≤t > 1 (a design choice in\nPaTH to allow negative eigenvalues for state-tracking).\nPath product is contractive and near-singular. Let Pj‚Üíi = Qi\ns=j+1 Hs. Submultiplicativity of\nsingular values gives\nœÉmax(Pj‚Üíi) ‚â§\niY\ns=j+1\n‚à•Hs‚à•2 = 1,\nœÉmin(Pj‚Üíi) ‚â•\niY\ns=j+1\nœÉmin(Hs) =\niY\ns=j+1\n|1 ‚àíŒ≤s|.\nHence Pj‚Üíi is (at best) nonexpansive, with a worst-case exponential lower bound on the smallest\nsingular value governed by the path-length product of |1 ‚àíŒ≤s|. Whenever some Œ≤s is close to 1,\nHs is nearly singular (and exactly singular if Œ≤s = 1), driving œÉmin(Pj‚Üíi) toward zero. Volume\ncontraction is quantified by\ndet(Pj‚Üíi) =\niY\ns=j+1\n(1 ‚àíŒ≤s),\nwhich typically decays exponentially in i ‚àíj unless Œ≤s concentrates at the orthogonal endpoints\n{0, 2}.\n28\n\nAligned-plane special case. If the directions are time-invariant, ws ‚â°w, then Pt = ww‚ä§is an\nidempotent projector and the factors commute:\niY\ns=j+1\nHs =\niY\ns=j+1\n\u0000I ‚àíŒ≤sP\n\u0001\n= I ‚àí\n\u0010\n1 ‚àí\niY\ns=j+1\n(1 ‚àíŒ≤s)\n\u0011\nP,\nso the eigenvalue along w is exactly Qi\ns=j+1(1 ‚àíŒ≤s), making the contraction along w explicit and\nexponential in path length unless Œ≤s ‚àà{0, 2}.\nImplications for long-context modeling. Because the PaTH transport multiplies the Q/K bilinear\nby Pj‚Üíi, any persistent deviation of Œ≤t from {0, 2} yields cumulative energy loss along a moving\none-dimensional subspace. This concentrates mass in progressively fewer directions and can flatten\nor attenuate long-range logits q‚ä§\ni Pj‚Üíikj as i ‚àíj grows, unless additional renormalizations or\nforget-gates are introduced. In contrast, GRAPE-M maps lie in SO(d), so for both non-contextual\nand contextual types, all singular values are 1; volumes and norms are preserved, and Lyapunov\nexponents are 0, avoiding contraction-induced degradation of long-range interactions.\nLemma I.7 (Orthogonality condition for PaTH factors). For Ht = I ‚àíŒ≤twtw‚ä§\nt with ‚à•wt‚à•= 1, Ht\nis orthogonal iff Œ≤t ‚àà{0, 2}. For Œ≤t ‚àà(0, 2) \\ {0, 2}, Ht is symmetric, diagonalizable with eigenvalues\nin (‚àí1, 1] ‚à™{1}, and strictly contractive on span{wt}.\n29\n",
    "figure_captions": [
      "Figure 1 Overview of the GRAPE Framework. We unify positional encodings via group actions G(n) =",
      "Figure 2 The training and validation loss of medium-size models (355M), with different positional encoding",
      "Figure 3 The training and validation loss of large-size models (770M), with different positional encoding"
    ]
  },
  {
    "arxiv_id": "2512.07801v1",
    "title": "Collaborative Causal Sensemaking: Closing the Complementarity Gap in Human-AI Decision Support",
    "abstract": "LLM-based agents are rapidly being plugged into expert decision-support, yet in messy, high-stakes settings they rarely make the team smarter: human-AI teams often underperform the best individual, experts oscillate between verification loops and over-reliance, and the promised complementarity does not materialise. We argue this is not just a matter of accuracy, but a fundamental gap in how we conceive AI assistance: expert decisions are made through collaborative cognitive processes where mental models, goals, and constraints are continually co-constructed, tested, and revised between human and AI. We propose Collaborative Causal Sensemaking (CCS) as a research agenda and organizing framework for decision-support agents: systems designed as partners in cognitive work, maintaining evolving models of how particular experts reason, helping articulate and revise goals, co-constructing and stress-testing causal hypotheses, and learning from the outcomes of joint decisions so that both human and agent improve over time. We sketch challenges around training ecologies that make collaborative thinking instrumentally valuable, representations and interaction protocols for co-authored models, and evaluation centred on trust and complementarity. These directions can reframe MAS research around agents that participate in collaborative sensemaking and act as AI teammates that think with their human partners.",
    "text": "Collaborative Causal Sensemaking: Closing the Complementarity\nGap in Human‚ÄìAI Decision Support\nRaunak Jain\nIntuit\nMountain View, California, USA\nraunak_jain1@intuit.com\nMudita Khurana\nAirbnb\nSan Francisco, California, USA\nmudita.khurana@airbnb.com\nABSTRACT\nLLM-based agents are rapidly being plugged into expert decision-\nsupport, yet in messy, high-stakes settings they rarely make the\nteam smarter: human‚ÄìAI teams often underperform the best individ-\nual, experts oscillate between verification loops and over-reliance,\nand the promised complementarity does not materialise. We ar-\ngue this is not just a matter of accuracy, but a fundamental gap in\nhow we conceive AI assistance: expert decisions are made through\ncollaborative cognitive processes where mental models, goals, and\nconstraints are continually co-constructed, tested, and revised be-\ntween human and AI. We propose Collaborative Causal Sensemaking\n(CCS) as a research agenda and organizing framework for decision-\nsupport agents: systems designed as partners in cognitive work,\nmaintaining evolving models of how particular experts reason, help-\ning articulate and revise goals, co-constructing and stress-testing\ncausal hypotheses, and learning from the outcomes of joint deci-\nsions so that both human and agent improve over time. We sketch\nchallenges around training ecologies that make collaborative think-\ning instrumentally valuable, representations and interaction pro-\ntocols for co-authored models, and evaluation centred on trust\nand complementarity. These directions can reframe MAS research\naround agents that participate in collaborative sensemaking and\nact as AI teammates that think with their human partners.\nKEYWORDS\nHuman-AI Collaboration, Multi-Agent Systems, Epistemic Align-\nment, Decision Support, Trust Calibration\nACM Reference Format:\nRaunak Jain and Mudita Khurana. 2026. Collaborative Causal Sensemak-\ning: Closing the Complementarity Gap in Human‚ÄìAI Decision Support. In\nProc. of the 25th International Conference on Autonomous Agents and Multia-\ngent Systems (AAMAS 2026), Paphos, Cyprus, May 25 ‚Äì 29, 2026, IFAAMAS,\n6 pages.\n1\nINTRODUCTION\nMulti-agent systems (MAS) built from large language model (LLM)\nagents are increasingly positioned as decision-support teammates\nfor humans in domains such as personalisation, planning, and multi-\nobjective optimisation, where consequences are delayed, uncertain,\nand value-laden [1‚Äì5]. While AI assistants have unlocked productiv-\nity gains in verifiable domains like coding and translation, empirical\nwork in decision-making under uncertainty reveals a persistent com-\nplementarity gap: where judgement is subjective and verification\nProc. of the 25th International Conference on Autonomous Agents and Multiagent Systems\n(AAMAS 2026), C. Amato, L. Dennis, V. Mascardi, J. Thangarajah (eds.), May 25 ‚Äì 29,\n2026, Paphos, Cyprus. ¬© 2026 International Foundation for Autonomous Agents and\nMultiagent Systems (www.ifaamas.org). This work is licenced under the Creative\nCommons Attribution 4.0 International (CC-BY 4.0) licence.\nis costly, human‚ÄìAI teams frequently underperform the best indi-\nvidual agent [6‚Äì10]. For next-generation MAS, this is not a minor\nusability flaw but a core systems failure: agents that cannot sustain\ncalibrated, shared understanding with their human partners will\nsystematically mis-coordinate, even if their standalone predictions\nare strong.\nA growing body of studies documents characteristic failure\nmodes that undermine calibrated trust. Users over-weight confi-\ndent model outputs even when these conflict with domain expertise,\nexhibiting automation bias and over-reliance [11‚Äì14]. Verification-\nand-correction loops can erase efficiency gains, as experts feel\ncompelled to second-guess model suggestions step by step [6, 7, 14].\nAlignment methods that reward agreement and user satisfaction\ncan induce sycophancy, where models collapse to the user‚Äôs prior\nbeliefs even when these conflict with evidence [15, 16]. This is fatal\nfor sensemaking, which by definition requires the repair and re-\nstructuring of mental models, not merely their confirmation [17, 18].\nThe result is trust poorly calibrated to actual competence: humans\nrely on agents for fluency rather than causal reasoning [19‚Äì21].\nCurrent training pipelines do not address this. Preference-based\nalignment (RLHF, DPO, and variants) shapes outputs toward helpful-\nness and safety [22‚Äì26]; reasoning methods (chain-of-thought, RL\nwith verifiable rewards, process supervision) make multi-step rea-\nsoning instrumentally useful [27‚Äì31]; and world-model approaches\ntrain predictive models of environment dynamics [32, 33]. However,\nthese methods optimise for solitary performance: they align the\nagent to a label, a verifier, or a simulator. They do not align the\nagent to the evolving mental model of a partner. Richer ecologies\noffer a complementary lever: multi-agent and open-ended envi-\nronments show that strategies, tool use, and social conventions\nemerge when long horizons, other agents, and strategic feedback\nmake them instrumentally valuable [34‚Äì38]. We argue that to fix\ncollaboration, we must change the ecology so that collaborative fric-\ntion‚Äîdisagreement, clarification, and re-framing between agents‚Äîis\nitself instrumentally useful.\nCognitive science suggests what behaviours we should seek in\nexpert collaboration. Humans reason through structured mental\nmodels [17, 39‚Äì41], and team effectiveness depends on these models\nbeing sufficiently aligned [42‚Äì44]. Co-constructing causal struc-\nture improves trust and decisions [45, 46]; constructivist accounts\nshow that learners acquire causal understanding by active explo-\nration, not passive instruction [47, 48]. In expert settings there is\nno single canonical world model available during collaboration,\nonly perspectival models held by particular humans. To be effec-\ntive, an agent must align with the expert‚Äôs causal framing not to\nblindly validate it, but to obtain a shared reference frame that en-\nables precise error detection and counterfactual critique. We call\narXiv:2512.07801v1  [cs.CL]  8 Dec 2025\n\nthis collaborative causal sensemaking: the iterative construction and\nrevision of shared causal and goal models (e.g., jointly maintaining\na shared model of students‚Äô understanding, evolving learning goals,\nand effective teaching strategies) [17, 18].\nWe propose Collaborative Causal Sensemaking (CCS) as a central\norganising goal for human‚ÄìAI teams in MAS. Rather than treating\ncollaboration as an interface layer wrapped around fixed agents, we\nargue for training regimes that make collaborative behaviour instru-\nmentally useful. The core idea is to move from static, instruction-\ncentric corpora toward constructivist collaborative playworlds: rich,\nmulti-agent environments in which humans and agents jointly ex-\nplore and revise explicit causal models to achieve long-horizon\nobjectives. In these environments, agents are rewarded not only for\ntask success, but also for maintaining a chain of sensemaking with\nhuman partners: a structured record of shared hypotheses, causal\ndiagrams, and counterfactual forecasts. Rewards explicitly value\nworld-model alignment, epistemic alignment [49], and goal align-\nment [50]. We treat CCS as an organising goal and long-horizon\nresearch agenda for MAS rather than a fully specified algorithm:\nour aim is to sharpen what future agents should optimise for in\nhuman collaboration and to outline plausible pathways toward that\ncapability.\nThis framing raises an agenda of research questions for MAS:\nwhat training regimes and environment designs actually elicit col-\nlaborative sensemaking behaviours rather than polished dialogue;\nhow we can formalise and measure alignment (via forecasts, coun-\nterfactuals, or causal graphs) without simply rewarding agreement;\nwhether collaboration metrics learned in playworlds transfer to\nhigh-stakes decisions in healthcare, scientific discovery, or policy;\nhow epistemic alignment can be operationalised without encour-\naging agents to manipulate human beliefs; and what bridges are\nneeded between human‚ÄìAI collaboration research, cognitive sci-\nence, and large-scale training teams so that theories of sensemaking\nshape future MAS pipelines. Addressing these questions is a pre-\ncondition for MAS in which agents do not merely answer questions,\nbut think with their human collaborators over time.\n2\nAGENT-THEORETIC VIEW OF CCS\nWe sketch an agent-theoretic view of CCS to show that it is not\nmerely a metaphor, but can be grounded in familiar MAS formalisms.\nThe aim is not to fix a single model, but to identify the key latent\nobjects and objective terms that future work should formalise.\n2.1\nCCS as a Cooperative Decision Process\nWe cast expert‚Äìassistant interaction as a cooperative, partially ob-\nservable decision process in the spirit of Dec-POMDPs and coop-\nerative POMDPs [50, 51]. At each time ùë°, an environment with\nlatent state ùë†ùë°‚ààS produces observation ùëúùë°‚ààO (e.g., latent student\nknowledge, misconceptions, and motivation, with observations\nfrom quizzes, behaviour logs, and teacher notes) to a human ex-\npert ùêªand an assistant ùê¥. The expert takes actions ùëéùêª\nùë°‚ààAùêª(e.g.,\ngrouping students, adjusting pacing, selecting explanations or ac-\ntivities), while the assistant takes actions ùëéùê¥\nùë°‚ààAùê¥(e.g., suggesting\ndifferentiated tasks, highlighting struggling students, proposing\nalternative activities). The environment transitions via unknown\ndynamics ùëù(ùë†ùë°+1 | ùë†ùë°,ùëéùêª\nùë°,ùëéùê¥\nùë°) and yields task rewards ùëüùë°that both\nagents ultimately care about.\nCrucially, both expert and assistant act through latent world\nmodels and goals. We denote by ùëäùêª\nùë°\nand ùëäùê¥\nùë°the internal world\nmodels maintained by the human and the assistant, respectively:\nstructured beliefs about task-relevant entities and mechanisms (e.g.,\ncausal relations, state variables, and constraints in the domain).\nWe denote by ùê∫ùêª\nùë°and ùê∫ùê¥\nùë°their goal structures: representations of\nwhat outcomes matter, which trade-offs are acceptable, and which\nobjectives should be prioritised (e.g., reward functions, goal hier-\narchies, or constraint sets). In tutoring, ùëäùêª\nùë°\nand ùëäùê¥\nùë°model how\neach student learns and responds to different strategies, while ùê∫ùêª\nùë°\nand ùê∫ùê¥\nùë°encode shifting mastery, equity, and curiosity goals for\nindividual students and the class. Both ùëäùë°and ùê∫ùë°may evolve as\nnew evidence arrives and as sensemaking proceeds; they are not\nfixed exogenous inputs.\nIn CCS, the relevant system is the team policy ùúãùêº(ùëéùêª\nùë°,ùëéùê¥\nùë°| history)\nand its joint evolution with (ùëäùêª\nùë°,ùëäùê¥\nùë°,ùê∫ùêª\nùë°,ùê∫ùê¥\nùë°). The central ques-\ntion is how to design objectives, data, and architectures that achieve\nhigh return and model convergence.\n2.2\nEpistemic and Teleological Alignment\nObjectives\nWe use epistemic alignment to denote alignment in world models\nand teleological alignment to denote alignment in goals. At a high\nlevel, we can think of divergences ùëëùëä(ùëäùê¥\nùë°,ùëäùêª\nùë°) and ùëëùê∫(ùê∫ùê¥\nùë°,ùê∫ùêª\nùë°)\nthat quantify misalignment in causal structure and in objective\nstructure, respectively.\nIn practice, CCS does not require tracking a full theory-of-mind\ndistribution over an expert‚Äôs entire world model or values. A more\nrealistic operating point is local alignment: focusing on the subset\nof entities, mechanisms, and goals that are currently active in the\njoint task and aligning those. Factorised or local-graph approxima-\ntions, where an assistant maintains and revises small, task-specific\nsubmodels rather than a monolithic ùëäùêªand ùê∫ùêª, offer a plausible\nroute to making CCS-style alignment partially tractable.\nIn an idealised setting whereùëäùêª\nùë°andùê∫ùêª\nùë°were observable, a CCS-\nstyle objective might schematically balance task performance with\nthese divergences: ùêΩCCS ‚âàE[√ç\nùë°ùõæùë°ùëüùë°] ‚àíùúÜùëäE[ùëëùëä] ‚àíùúÜùê∫E[ùëëùê∫]. This\nexpression should be read as a design sketch rather than a concrete\nproposal. In practice,ùëäùêª\nùë°\nandùê∫ùêª\nùë°are latent; the assistant must infer\nthem from actions, language, and co-authored artefacts, so any ùëëùëä\nand ùëëùê∫will be instantiated as behavioural and artefact-level proxies\ndefined over externalised, jointly editable representations (such as\ncausal sketches and goal descriptions). Moreover, CCS does not\ndemand that ùëäùê¥\nùë°and ùê∫ùê¥\nùë°simply copy the human‚Äôs state: beneficial\ndisagreement and ‚Äúintelligent disobedience‚Äù require the assistant\nto maintain its own hypotheses and to surface discrepancies when\nits inferences conflict with human assumptions.\nThis sketch connects naturally to existing MAS formalisms.\nCIRL [52] treats human‚ÄìAI interaction as a cooperative game with\nunknown rewards; CCS extends this to co-evolving world models\nand goals, not just fixed ùúÉ. Active Inference decomposes expected\nutility into epistemic and pragmatic value [53], providing a prin-\ncipled way to trade off information gain about ùëäand ùê∫against\nimmediate reward.\n\n2.3\nThe Chain of Sensemaking as an Interaction\nLoop\nOperationally, CCS manifests as a recurring chain of sensemaking:\na loop in which discrepancies between expectations and outcomes\ntrigger collaborative updates to (ùëäùë°,ùê∫ùë°), followed by revised action.\nAt a coarse level, this loop involves (i) joint detection of discrepan-\ncies or anomalies; (ii) collaborative causal explanation that revises\nùëäùë°; (iii) joint goal refinement that revises ùê∫ùë°; and (iv) robust ac-\ntion selection that is evaluated against the updated models [17, 45].\nIn human teams, such loops are supported by explicit artefacts\n(causal maps, after-action reviews, protocols). For CCS in MAS,\nthe research agenda is to design objectives, data, environments,\narchitectures, and interaction policies that make this chain instru-\nmentally valuable for LLM-based agents.\n3\nRESEARCH AGENDA FOR CCS IN MAS\nRealising CCS in practice requires advances across theory, measure-\nment, data, architectures, and interaction policies. We highlight five\nintertwined research challenges that map the informal CCS picture\ninto concrete MAS work.\n3.1\nFormalising CCS Objectives in MAS\nFrameworks\nGap. Dec-POMDPs, CIRL, and related cooperative frameworks [50‚Äì\n52] provide powerful tools for modelling human‚ÄìAI teams, but they\ntypically assume fixed reward functions, externally specified goals,\nand do not represent the human‚Äôs evolving world model explicitly.\nCCS instead centres the joint evolution of (ùëäùêª\nùë°,ùëäùê¥\nùë°,ùê∫ùêª\nùë°,ùê∫ùê¥\nùë°) as\nfirst-class state. We lack MAS formalisms that can represent (i)\nunderdetermined world models that produce identical behaviour\non finite data [54], (ii) endogenous goal formation where goals\nchange in response to sensemaking [55], and (iii) explicit epistemic\nand teleological alignment terms as in (2.2) without collapsing into\ntrivial agreement.\nDirections. Cooperative POMDPs, CIRL, and Active Inference\noffer ingredients (joint policies, human-aware objectives, and de-\ncompositions into epistemic and pragmatic value [53]) but none\ndirectly represent co-evolving, shared world and goal models. A\nfirst line of work is to extend these frameworks to include latent\nùëäùë°and ùê∫ùë°as part of the state, with update dynamics that capture\nendogenous goal changes driven by sensemaking (e.g., a teacher\nshifting from ‚Äúcover the syllabus‚Äù to ‚Äúrepair fractions for subgroup\nùëÜ‚Äù after a surprising assessment). A concrete task for MAS theory is\nto make (ùëä,ùê∫) explicit state while designing approximations that\noperate on small, task-specific abstractions: aligning subgraphs of\na causal model or fragments of a goal hierarchy that are currently\nrelevant, rather than requiring a full-blown theory of mind. An-\nother direction is to investigate divergence measures ùëëùëäand ùëëùê∫\nthat are compatible with learning: for instance, distances between\ninferred causal graphs or between structured goal representations,\nand regularisers that reward productive divergence (e.g., surfacing\ninconsistencies) rather than mere mimicry. Finally, formal models\nof teleological reasoning (inferring latent goals ùëîùë°that rationalise\nhuman actions given ùëäùêª\nùë°, as in inverse planning) could be inte-\ngrated with CCS objectives to ground teleological alignment in\nobservable behaviour.\n3.2\nMeasuring Alignment and Collaboration\nQuality\nGap. CCS posits that improving epistemic and teleological align-\nment will reduce verification burden, improve trust calibration, and\nincrease robustness. However, ùëäùêª\nùë°\nand ùê∫ùêª\nùë°are latent; we cannot\ndirectly compute ùëëùëä(ùëäùê¥\nùë°,ùëäùêª\nùë°) or ùëëùê∫(ùê∫ùê¥\nùë°,ùê∫ùêª\nùë°). Standard metrics\nfor assistants (accuracy, user satisfaction, perplexity) say little about\nwhether human and agent share a compatible causal understanding\nor goal structure [7, 49]. An agent may be locally accurate while\nrelying on brittle, spurious patterns; such epistemia (an illusion of\nknowledge from surface-level associations) is precisely what CCS\naims to avoid.\nDirections. A central challenge is to define behavioural and\nartefact-level proxies for world-model and goal alignment (e.g.,\nagreement on which students are at risk on which concepts, and on\nappropriate next learning goals) and then validate that these proxies\nare causally linked to collaboration outcomes. When both parties\nexternalise their models as causal graphs, graph-based metrics (e.g.,\nStructural Hamming Distance, graph edit distance) can measure\nalignment [45]. Counterfactual simulatability tasks test whether\nhuman and agent can predict each other‚Äôs responses to ‚Äúwhat-if‚Äù\nscenarios and future interventions. Team-level evaluation should\ninclude verification cost (time and cognitive load spent checking and\ncorrecting the assistant), robustness under distribution shift, and\ncomplementarity metrics (whether the team outperforms the best\nindividual). Sycophancy stress tests probe whether agents maintain\njustified beliefs when experts express incorrect opinions [15, 16].\nLongitudinal studies can track whether proxies for alignment con-\nverge over repeated interactions and whether such convergence\npredicts reduced verification cost and improved outcomes. Ulti-\nmately, we need experimental designs that manipulate alignment\n(e.g., by perturbing shared models) and test whether this causally\naffects trust calibration and performance. Because much expert\nknowledge is tacit and never fully externalised, such metrics can\nonly approximate true alignment; a core research problem is to\ndesign proxies that are informative enough to guide learning while\nremaining cheap and unobtrusive to elicit.\n3.3\nData, Environments, and Constructivist\nCollaborative Playworlds\nGap. Current training corpora consist of static prompt‚Äìresponse\npairs, short dialogues, and expert demonstrations [22, 56]. They cap-\nture what experts say and do, but not how theirùëäùêª\nùë°\nand ùê∫ùêª\nùë°change\nthrough discrepancy-driven sensemaking. As a result, agents learn\nto imitate surface-level behaviour rather than participate in the\nchain of sensemaking: joint discrepancy detection, causal explana-\ntion, goal refinement, and robust action.\nDirections. CCS calls for richer sensemaking trajectories that\nrecord the context triggering deliberation, the surprise or anomaly\nthat initiates sensemaking, the hypotheses and counterfactuals\nproposed, the disagreements and repairs, and the resulting updates\nto goals and plans. Annotation schemes should distinguish epistemic\nactions (hypothesis generation, probing assumptions, reframing)\nfrom instrumental actions (executing a chosen plan) [57]. Interactive\nfine-tuning protocols can log not only whether the assistant is\ncorrected, but also why the expert thinks it erred and how the\n\nexpert revises their own model in response. Naturalistic logging in\nreal workflows (with appropriate governance) can capture genuine\ngoal evolution.\nRather than generic multi-agent simulations, CCS points to con-\nstructivist collaborative playworlds engineered as ‚Äúdiscrepancy en-\ngines‚Äù: environments that systematically induce epistemic friction\nby giving agents partial, biased views of a shared process and requir-\ning them to negotiate a common plan to succeed [34‚Äì38]. Beyond\ncapturing raw dialogue, such playworlds should annotate epistemic\nmoves (e.g., noticing a mismatch, proposing a new causal link, chal-\nlenging or renegotiating a goal), turning sensemaking trajectories\ninto explicit supervision signals for CCS agents. In such playworlds\n(e.g., simulated classrooms where teacher and agents progress from\nsingle-student quiz anomalies to multi-week group projects with\nshifting goals), synthetic experts and assistants can be endowed\nwith different ùëäand ùê∫, and must align them over time to succeed.\nCritically, CCS playworlds should not be monolithic benchmarks\nbut organised into curricula that progressively exercise richer sense-\nmaking behaviour. Simple levels may involve local discrepancies\nand single-step hypothesis testing; later levels introduce multi-step\ncausal chains, delayed feedback, conflicting stakeholder goals, and\npartial observability of other agents‚Äô world models. Such curric-\nula allow us to study when agents learn to ask clarification ques-\ntions, propose alternative framings, or renegotiate goals, rather\nthan merely improving one-shot prediction.\n3.4\nArchitectures and Representations for CCS\nAgents\nGap. LLM-based agents are typically stateless beyond short context\nwindows. They lack persistent, structured world models ùëäùê¥\nùë°that\ncan be maintained across tasks, explicit representations of goals\nùê∫ùê¥\nùë°that can be revised, and memory systems that record when\nand why these structures changed. As a result, an agent may learn\nsomething important in one interaction and contradict it in the\nnext, or treat transient objectives as if they were stable values.\nDirections. CCS suggests architectural desiderata rather than\na single blueprint. Neuro-symbolic causal twins maintain explicit,\neditable models of the domain that both human and AI can in-\nspect and revise (e.g., a shared ‚Äúclassroom model‚Äù graph linking\nstudents, concepts, estimated mastery, and teacher-stated goals),\nserving as shared artefacts for sensemaking [45, 58]. In such archi-\ntectures, LLMs serve as flexible ‚Äúepistemic encoders‚Äù that translate\nlanguage and observations into edits on an explicit causal and goal\nmodel, while a lightweight reasoner checks consistency, supports\ncounterfactual prediction, and records provenance.\nEpisodic sensemaking memory should store triplets of (context,\ndiscrepancy, goal shift), enabling the agent to learn patterns of\nwhen ùëäand ùê∫changed and why. Teleological representations such\nas reward machines [59] can encode the logical structure of goals;\njoint inference over these machines and causal graphs can link\nepistemic updates (editingùëä) to teleological updates (editing ùê∫). A\nlightweight theory-of-mind module can maintain hypotheses about\nùëäùêª\nùë°\nand ùê∫ùêª\nùë°, guiding communication and disagreement. An open\nquestion is whether agents should learn monolithic policies or\nmodular sensemaking operators that can be scaffolded in simpler\nsettings.\n3.5\nInteraction Policies, Safety, and Governance\nGap. Even with appropriate objectives, data, and architectures,\nwe lack principled policies for when CCS agents should agree,\nchallenge, ask clarifying questions, or slow interaction for epistemic\nrepair [13, 14, 50]. Current assistants are optimised for low-friction\nhelpfulness: they answer quickly, avoid conflict, and rarely question\nthe user‚Äôs framing. Effective collaborators must sometimes do the\nopposite: pause, surface uncertainty, or propose goal revisions. At\nthe same time, CCS introduces new risks: agents that infer and\nupdate goals endogenously may develop goal structures that drift\naway from human intent; agents trained to avoid sycophancy may\nbecome overconfident or manipulative.\nDirections. Beyond what to say, CCS raises questions about\nwhen an agent should surface discrepancies and slow interaction\nfor epistemic repair instead of answering fluently and moving on.\nValue-of-Information criteria [60] can estimate an expected benefit\nof repair, trading off uncertainty reduction, outcome criticality, and\nfriction cost (e.g., when to interrupt a lesson to flag a concept gap or\na plan-goal conflict). Mixed-initiative protocols can formalise turn-\ntaking and control: when the assistant is allowed to override, when\nit must defer, and when it suggests after-action reviews. Training\nfor ‚Äúintelligent disobedience‚Äù can teach agents to contest risky\ndecisions in well-defined conditions.\nCCS systems will need teleological constraints: constitutional\nprinciples or oversight mechanisms that bound goal formation\nand prevent agents from extrapolating goals in undesirable ways.\nAvoiding both sycophancy and ‚Äúsycophancy inversion‚Äù (agents\nthat dismiss human input too readily) requires adaptive personal-\nisation that takes into account expertise, context, and stakes. Fi-\nnally, CCS raises governance questions. High-stakes sensemaking\nshould be auditable: we need epistemic provenance trails that record\nhow shared models evolved and who changed what, along with\norganisational processes that assign responsibility and enable post-\nhoc review of world-model and goal-model updates [61]. These\nconcerns connect CCS to broader debates on accountability and\nhuman-in-the-loop oversight in MAS.\n4\nCONCLUSION\nWe have argued that making LLM-based agents into genuine team-\nmates in MAS for decision support requires shifting from behavioural\nalignment to collaborative causal sensemaking: the joint construc-\ntion, critique, and revision of shared world and goal models that un-\nderpin decisions. Rather than treating collaboration as an interface\nlayer, CCS treats the human‚Äôs evolving mental models and objec-\ntives as part of the decision state that agents must track, stress-test,\nand help refine. We sketched an agent-theoretic view in which epis-\ntemic and teleological alignment appear alongside task reward, and\noutlined research challenges in formalisation, measurement, play-\nworld design, architectures, and interaction policies. The central\nhypothesis is that such alignment can reduce verification burden\nwhile enabling calibrated reliance and productive disagreement,\nwith near-term footholds in CCS playworlds, causal-twin proto-\ntypes, and shadow-mode deployment. Where instruction tuning\nbuilds tools that obey, CCS aims to build teammates that partici-\npate in the reasoning behind choices and think with their human\npartners.\n\nREFERENCES\n[1] Vukosi N. Marivate et al. Quantifying uncertainty in batch personalized sequen-\ntial decision making. arXiv preprint arXiv:1311.2510, 2014.\n[2] Diederik M. Roijers, Peter Vamplew, Shimon Whiteson, and Richard Dazeley.\nA survey of multi-objective sequential decision-making. Journal of Artificial\nIntelligence Research, 48:67‚Äì113, 2013.\n[3] Leslie Pack Kaelbling, Michael L. Littman, and Anthony R. Cassandra. Planning\nand acting in partially observable stochastic domains. Artificial Intelligence,\n101(1‚Äì2):99‚Äì134, 1998.\n[4] Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction.\nMIT Press, Cambridge, MA, 2nd edition, 2018.\n[5] Xin Wang and Serdar Kadioglu. Bayesian deep learning based exploration‚Äì\nexploitation for personalized recommendations. In Proceedings of the 31st IEEE\nInternational Conference on Tools with Artificial Intelligence (ICTAI), pages 1715‚Äì\n1719. IEEE, 2019.\n[6] Bucinca et al. Towards reinforcement learning for human‚ÄìAI collaboration:\nOffline support policy learning. arXiv preprint, 2024. Metadata approximate;\nreplace with the official arXiv/venue BibTeX for the offline RL-based human‚ÄìAI\ncollaboration paper by Bucinca et al.\n[7] Patrick Hemmer, Max Schemmer, Niklas K√ºhl, Michael V√∂ssing, and Gerhard\nSatzger. Human‚ÄìAI complementarity in hybrid intelligence systems: A structured\nliterature review. arXiv preprint arXiv:2404.00029, 2024.\n[8] George Fragiadakis, Christos Diou, George Kousiouris, and Mara Nikolaidou.\nEvaluating human‚ÄìAI collaboration: A review and methodological framework.\narXiv preprint arXiv:2407.19098, 2025.\n[9] Mark Steyvers, Hernan Tejeda, Sean Kerrigan, and Padhraic Smyth. Bayesian\nmodeling of human‚ÄìAI complementarity. Topics in Cognitive Science, 14(3):540‚Äì\n564, 2022.\n[10] Chirag Rastogi, Ece Kamar, and Daniel S. Weld. A taxonomy of human and AI\nstrengths and complementarity. arXiv preprint arXiv:2303.05390, 2023.\n[11] Kate Goddard, Abdul Roudsari, and Jeremy C. Wyatt. Automation bias: a sys-\ntematic review of frequency, effect mediators, and mitigators. Journal of the\nAmerican Medical Informatics Association, 19(1):121‚Äì127, 2012.\n[12] David Lyell and Enrico Coiera. Automation bias and verification complexity:\na systematic review. Journal of the American Medical Informatics Association,\n24(2):423‚Äì431, 2017.\n[13] Saar Alon-Barkat and Madalina Busuioc. Human‚ÄìAI interactions in public sector\ndecision making: ‚Äúautomation bias‚Äù and ‚Äúselective adherence‚Äù to algorithmic\nadvice. Journal of Public Administration Research and Theory, 33(1):153‚Äì169, 2023.\n[14] Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece\nKamar, Marco Tulio Ribeiro, and Daniel Weld. Does the whole exceed its parts?\nthe effect of ai explanations on complementary team performance. In Proceedings\nof the 2021 CHI Conference on Human Factors in Computing Systems, pages 1‚Äì16,\n2021.\n[15] Ethan Perez, Sam Ringer, Kamile Lukosiute, Karina Nguyen, Edwin Chen, Scott\nHeiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, Andy\nJones, Anna Chen, Benjamin Mann, Brian Israel, Bryan Seethor, Cameron McK-\ninnon, Christopher Olah, Da Yan, Daniela Amodei, Dario Amodei, Dawn Drain,\nDustin Li, Eli Tran-Johnson, Guro Khundadze, Jackson Kernion, James Landis,\nJamie Kerr, Jared Mueller, Jeeyoon Hyun, Joshua Landau, Kamal Ndousse, Landon\nGoldberg, Liane Lovitt, Martin Lucas, Michael Sellitto, Miranda Zhang, Neerav\nKingsland, Nelson Elhage, Nicholas Joseph, Noem√≠ Mercado, Nova DasSarma,\nOliver Rausch, Robin Larson, Sam McCandlish, Scott Johnston, Shauna Kravec,\nSheer El Showk, Tamera Lanham, Timothy Telleen-Lawton, Tom Brown, Tom\nHenighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Jack Clark, Samuel R.\nBowman, Amanda Askell, Roger B. Grosse, Danny Hernandez, Deep Ganguli,\nEvan Hubinger, Nicholas Schiefer, and Jared Kaplan. Discovering language\nmodel behaviors with model-written evaluations. In Findings of the Association\nfor Computational Linguistics: ACL 2023, pages 13387‚Äì13434, Toronto, Canada,\n2023. Association for Computational Linguistics.\n[16] Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell,\nSamuel R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R.\nJohnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal Ndousse,\nOliver Rausch, Nicholas Schiefer, Da Yan, Miranda Zhang, and Ethan Perez.\nTowards understanding sycophancy in language models, 2023. ICLR 2024.\n[17] Karl E. Weick. Sensemaking in Organizations. SAGE, Thousand Oaks, CA, 1995.\n[18] Gary Klein, Brian Moon, and Robert R. Hoffman. Making sense of sensemaking\n2: A macrocognitive model. In IEEE Intelligent Systems, volume 21, pages 88‚Äì92.\n2006.\n[19] Yunfeng Zhang, Q. Vera Liao, and Rachel K. E. Bellamy. Effect of confidence and\nexplanation on accuracy and trust calibration in AI-assisted decision making. In\nProceedings of the 2020 Conference on Fairness, Accountability, and Transparency\n(FAT*), pages 295‚Äì305. ACM, 2020.\n[20] Catalina Gomez, Sue Min Cho, Shichang Ke, Chien-Ming Huang, and Mathias\nUnberath. Human‚ÄìAI collaboration is not very collaborative yet: a taxonomy\nof interaction patterns in AI-assisted decision making from a systematic review.\nFrontiers in Computer Science, 2025.\n[21] Vivian Lai, Chacha Chen, Alison Smith-Renner, Q. Vera Liao, and Chenhao Tan.\nTowards a science of human‚ÄìAI decision making: An overview of design space\nin empirical human-subject studies. In Proceedings of the 2023 ACM Conference\non Fairness, Accountability, and Transparency (FAccT), pages 1369‚Äì1385, 2023.\n[22] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Train-\ning language models to follow instructions with human feedback. arXiv preprint\narXiv:2203.02155, 2022.\n[23] Various Contributors. Awesome LLM post-training: A survey of post-training\nmethods for large language models. arXiv preprint arXiv:2503.06072, 2024. Survey\ncovering RLHF, DPO, and related preference optimization techniques.\n[24] Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D.\nManning, and Chelsea Finn. Direct preference optimization: Your language model\nis secretly a reward model. Advances in Neural Information Processing Systems,\n36, 2023.\n[25] Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, and Douwe\nKiela. KTO: Model alignment as prospect theoretic optimization. In Proceedings\nof the International Conference on Machine Learning (ICML), 2024. Direct Value\nOptimization approach to alignment.\n[26] Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen, Benjamin\nVan Durme, Kenton Murray, and Young Jin Kim. Contrastive preference opti-\nmization: Pushing the boundaries of LLM performance in machine translation.\nIn Proceedings of the International Conference on Machine Learning (ICML), 2024.\n[27] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei\nXia, Ed Chi, Quoc Le, and Denny Zhou. Chain-of-thought prompting elicits\nreasoning in large language models. Advances in Neural Information Processing\nSystems, 35:24824‚Äì24837, 2022.\n[28] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian\nBorgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William\nFedus. Emergent abilities of large language models. Transactions on Machine\nLearning Research, 2022. Special Issue on Foundation Models.\n[29] Alex Havrilla, Yuqing Du, Sharath Chandra Raparthy, Christoforos Nalmpantis,\nJane Dwivedi-Yu, Maksym Zhuravinskyi, Eric Hambro, Sainbayar Sukhbaatar, and\nRoberta Raileanu. Teaching large language models to reason with reinforcement\nlearning. arXiv preprint arXiv:2403.04642, 2024.\n[30] Trung Quoc Luong, Xinbo Zhang, Zhanming Jie, Peng Sun, Xiaoran Jin, and Hang\nLi. ReFT: Reasoning with reinforced fine-tuning. arXiv preprint arXiv:2401.08967,\n2024.\n[31] Eric Zelikman, Georges Harik, Yijia Shao, Varuna Jayasiri, Nick Haber, and\nNoah D. Goodman. Quiet-STaR: Language models can teach themselves to think\nbefore speaking. arXiv preprint arXiv:2403.09629, 2024.\n[32] Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. Dream\nto control: Learning behaviors by latent imagination. In International Conference\non Learning Representations, 2020.\n[33] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang,\nand Zhiting Hu. Reasoning with language model is planning with world model.\narXiv preprint arXiv:2305.14992, 2023.\n[34] Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell, Bob\nMcGrew, and Igor Mordatch. Emergent tool use from multi-agent autocurricula.\nIn Proceedings of the 8th International Conference on Learning Representations\n(ICLR), 2020. Originally posted as arXiv:1909.07528.\n[35] Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang\nQi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, and\nMaarten Sap. Sotopia: Interactive evaluation for social intelligence in language\nagents. In Proceedings of the 12th International Conference on Learning Represen-\ntations (ICLR), 2024. ICLR 2024, arXiv:2310.11667.\n[36] Ruiyi Wang, Haofei Yu, Wenxin Zhang, Zhengyang Qi, Maarten Sap, Yonatan\nBisk, Graham Neubig, and Hao Zhu. Sotopia-ùúã: Interactive learning of socially\nintelligent language agents. In Proceedings of the 62nd Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers), pages 12912‚Äì\n12940, Bangkok, Thailand, 2024. Association for Computational Linguistics.\n[37] Joon Sung Park, Joseph C. O‚ÄôBrien, Carrie J. Cai, Meredith Ringel Morris, Percy\nLiang, and Michael S. Bernstein. Generative agents: Interactive simulacra of\nhuman behavior. In Proceedings of the 2023 CHI Conference on Human Factors in\nComputing Systems, pages 1‚Äì28, New York, NY, 2023. ACM.\n[38] Zhengyang Qi et al. Civrealm: A learning and reasoning odyssey in civilization\nfor decision-making agents. In Proceedings of the 12th International Conference\non Learning Representations (ICLR), 2024. Full author list and pages to be filled\nfrom the official ICLR 2024 BibTeX.\n[39] Kenneth J. W. Craik. The Nature of Explanation. Cambridge University Press,\nCambridge, 1943.\n[40] Philip N. Johnson-Laird. Mental Models: Towards a Cognitive Science of Language,\nInference, and Consciousness. Harvard University Press, Cambridge, MA, 1983.\n[41] Gary Klein. Sources of Power: How People Make Decisions. MIT Press, 1998.\n[42] Janis A. Cannon-Bowers, Eduardo Salas, and Sharon Converse. Shared mental\nmodels in expert team decision making. In N. John Castellan, editor, Individual\nand Group Decision Making: Current Issues, pages 221‚Äì246. Lawrence Erlbaum\nAssociates, 1993.\n\n[43] John E. Mathieu, Timothy S. Heffner, Gerald F. Goodwin, Eduardo Salas, and\nJanis A. Cannon-Bowers. The influence of shared mental models on team process\nand performance. Journal of Applied Psychology, 85(2):273‚Äì283, 2000.\n[44] Susan Mohammed, Lori Ferzandi, and Kimberly Hamilton. Metaphor no more:\nA 15-year review of the team mental model construct. Journal of Management,\n36(4):876‚Äì910, 2010.\n[45] Jac A. M. Vennix. Group Model Building: Facilitating Team Learning Using System\nDynamics. Wiley, Chichester, UK, 1996.\n[46] Peter S. Hovmand. Community Based System Dynamics. Springer, New York, NY,\n2014.\n[47] Alison Gopnik, Clark Glymour, David M. Sobel, Laura E. Schulz, Tamar Kushnir,\nand David Danks. A theory of causal learning in children: Causal maps and\nBayes nets. Psychological Review, 111(1):3‚Äì32, 2004.\n[48] Elizabeth Baraff Bonawitz, Patrick Shafto, Hyowon Gweon, Noah D. Goodman,\nElizabeth Spelke, and Laura Schulz. The double-edged sword of pedagogy:\nInstruction limits spontaneous exploration and discovery. Cognition, 120(3):322‚Äì\n330, 2011.\n[49] Nicholas Clark, Hua Shen, Bill Howe, and Tanushree Mitra. Epistemic alignment:\nA mediating framework for user-LLM knowledge delivery. In Proceedings of the\nConference on Language Modeling (COLM), 2025.\n[50] Li et al. Reinforcement learning for human‚ÄìAI collaboration: Challenges, mecha-\nnisms, and methods. Cognitive Computation, 2025. Survey-style paper on RL for\nhuman‚ÄìAI collaboration; fill in full author list and volume/issue when available.\n[51] Frans A. Oliehoek and Christopher Amato. A Concise Introduction to Decentralized\nPOMDPs. SpringerBriefs in Intelligent Systems. Springer, 2016.\n[52] Dylan Hadfield-Menell, Stuart J. Russell, Pieter Abbeel, and Anca Dragan. Co-\noperative inverse reinforcement learning. In Advances in Neural Information\nProcessing Systems (NeurIPS), volume 29, 2016.\n[53] Karl J. Friston, Thomas Parr, and Giovanni Pezzulo. Construction and use of\nmental models: Organizing principles for the mind and brain. Acta Psychologica,\n243:104129, 2024.\n[54] Stephen Casper, Jason Lin, Joe Kwon, Gilbert Cullen, and Dylan Hadfield-Menell.\nOpen problems and fundamental limitations of reinforcement learning from\nhuman feedback. arXiv preprint arXiv:2307.15217, 2023.\n[55] David W. Aha, Matthew Molineaux, and H√©ctor Mu√±oz-Avila. Goal reasoning:\nFoundations, emerging applications, and prospects. AI Magazine, 39(2):3‚Äì24,\n2018.\n[56] Jingqing Zhang, Yao Leung, Yoshua Bengio, Dario Amodei, Adrien Ecoffet, and\nPieter Abbeel. Reasoning with language model prompting: A survey. arXiv\npreprint, 2023.\n[57] Lin et al. Reinforcement learning for human‚ÄìAI collaboration via probabilistic\nintent inference. In Proceedings of the AAAI Conference on Artificial Intelligence,\n2025. Belief-space RL / Dec-POMDP formulation for human‚ÄìAI collaboration;\nreplace with official BibTeX from the paper.\n[58] Michael Grieves and John Vickers. Digital twin: Mitigating unpredictable, unde-\nsirable emergent behavior in complex systems. Transdisciplinary Perspectives on\nComplex Systems, pages 85‚Äì113, 2017.\n[59] Rodrigo Toro Icarte, Toryn Q. Klassen, Richard Valenzano, and Sheila A. McIlraith.\nUsing reward machines for high-level task specification and decomposition in\nreinforcement learning. In Proceedings of the 35th International Conference on\nMachine Learning (ICML), pages 2107‚Äì2116. PMLR, 2018.\n[60] Hong Lu and Xuan Zhang. 1+1 > 2? information, humans, and machines. Omega,\n127:103088, 2024.\n[61] Karen Hao et al. Beyond human-in-the-loop: Sensemaking between artificial\nintelligence and human intelligence collaboration. Information Systems Journal,\n2025.\n",
    "figure_captions": []
  },
  {
    "arxiv_id": "2512.07795v1",
    "title": "ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning",
    "abstract": "Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .",
    "text": "ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nNearchos Potamitis 1 Lars Klein 2 Akhil Arora 1\nAbstract\nLarge language models (LLMs) are increasingly\ndeployed in settings where reasoning, such as\nmulti-step problem solving and chain-of-thought,\nis essential.\nYet, current evaluation practices\noverwhelmingly report single-run accuracy while\nignoring the intrinsic uncertainty that naturally\narises from stochastic decoding.\nThis omis-\nsion creates a blind spot because practitioners\ncannot reliably assess whether a method‚Äôs re-\nported performance is stable, reproducible, or\ncost-consistent. We introduce REASONBENCH,\nthe first benchmark designed to quantify the un-\nderlying instability in LLM reasoning. REASON-\nBENCH provides (i) a modular evaluation library\nthat standardizes reasoning frameworks, models,\nand tasks, (ii) a multi-run protocol that reports\nstatistically reliable metrics for both quality and\ncost, and (iii) a public leaderboard to encourage\nvariance-aware reporting. Across tasks from dif-\nferent domains, we find that the vast majority\nof reasoning strategies and models exhibit high\ninstability. Notably, even strategies with simi-\nlar average performance can display confidence\nintervals up to four times wider, and the top-\nperforming methods often incur higher and less\nstable costs. Such instability compromises re-\nproducibility across runs and, consequently, the\nreliability of reported performance.\nTo better\nunderstand these dynamics, we further analyze\nthe impact of prompts, model families, and scale\non the trade-off between solve rate and stability.\nOur results highlight reproducibility as a critical\ndimension for reliable LLM reasoning and pro-\nvide a foundation for future reasoning methods\nand uncertainty quantification techniques. REA-\nSONBENCH is publicly available at https:\n//github.com/au-clan/ReasonBench.\n1Aarhus\nUniversity,\nAarhus,\nDenmark\n2EPFL,\nLau-\nsanne, Switzerland.\nCorrespondence to: Nearchos Potamitis\n<nearchos.potamitis@cs.au.dk>.\nPreprint. December 9, 2025.\n1. Introduction\nRecent studies highlight a growing tension between the\npromise of large language models (LLMs) and the risks\nof their adoption. On the one hand, even the mere knowl-\nedge that advice originates from an AI system has been\nshown to induce over-reliance by users (Klingbeil et al.,\n2024). On the other hand, evidence demonstrates that larger\nand more instructable models are becoming less reliable\n(Zhou et al., 2024b). This combination creates a concern-\ning dynamic: users are predisposed to trust LLM outputs\nwhile the models themselves may be increasingly unstable.\nSuch risks are amplified in safety-critical domains such as\nmedical decision-making, legal and financial reasoning, and\nautonomous systems, where unreliable outputs can carry\nsevere consequences.\nAt the center of these concerns lies reasoning, which has\nbecome a primary frontier in the development of LLMs.\nRecent advances increasingly revolve around reasoning,\nwhether through specialized frameworks (Wei et al., 2022;\nYao et al., 2023a; Klein et al., 2025), reasoning-focused\ntraining regimes such as DeepSeek R1 and OpenAI o1 (Guo\net al., 2025; Jaech et al., 2024), or tool-augmented reason-\ning systems like Anthropic‚Äôs Model Context Protocol and\nOpenAI‚Äôs Deep Research variants of flagship models. The\ndemand for reliable reasoning is driven by some of the most\nimpactful applications of LLMs: information seeking and\nsearch (Jin et al., 2025; Li et al., 2025), mathematical and\nformal logic reasoning including theo,rem proving (Yang\net al., 2023; 2024a), and many other domains where struc-\ntured problem solving is essential. While reasoning is not\nthe only use case for LLMs, it has become a key driver of\nboth research progress and practical deployment, making\nits robustness and reliability central to the field.\nTraditionally, the behavior of machine learning algorithms\nhas been framed through the bias‚Äìvariance paradigm (Ge-\nman et al., 1992; Hastie et al., 2009). In this view, bias\ncorresponds to systematic error, typically captured by mea-\nsures of accuracy, while variance reflects the instability of\nresults between runs and can be interpreted as a form of\nuncertainty. Although this perspective has long guided the\nanalysis of classical ML algorithms, evaluations of LLMs,\nespecially in reasoning tasks, have focused almost exclu-\nsively on bias by reporting average accuracy from single or\n1\narXiv:2512.07795v1  [cs.AI]  8 Dec 2025\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nReasoning Model\n‚ÄúIdentify Fight of the Century ‚Üí Determine Ali‚Äôs next fight ‚Üí Next oppenent is Jerry Quarry‚Äù\n‚ÄúIdentify Fight of the Century ‚Üí Next opponent: Quarry ‚Üí Fight vs Quarry: not in Houston ‚Üí Fight in Houston: Al Lewis‚Äù\n‚ÄúDate of Fight of the Century ‚Üí Determine Ali‚Äôs fights in Houston ‚Üí Next fight in Houston: Buster Mathis‚Äù\n‚ÄúDate of Fight of the Century ‚Üí Think of Ali‚Äôs match history ‚Üí Fights in Houston ‚Üí Next fight in Houston: Jimmy Ellis‚Äù\nQuery\nWho did Muhammad Ali fight next, in Houston, after the so-called Fight of the Century with Joe Frazier?\nReasoning Strategy\nSearch[Fight of the Century] ‚Üí Search[M. Ali Fight of the Century] ‚Üí Search[Muhammad Ali fights] ‚Üí Search[...]\nSearch[Muhammad Ali] ‚Üí Lookup[Houston] ‚Üí Finish[Cleveland Williams] \nSearch[Boxing career of Muhammad Ali] ‚Üí Lookup [Joe Frazier] ‚Üí Finish[George Foreman] \nSearch[Boxing career of Muhammad Ali] ‚Üí Lookup [Fight of the Century] ‚Üí Lookup[Houston] ‚Üí Finish[Jimmy Ellis]\n‚úÖ\n‚ùå\n‚ùå\n‚ùå\n‚úÖ\n‚ùå\n‚ùå\n‚ùå\n100\n75\n50\n25\n0\n25\n50\n75\n100\nRelative¬†Deviation¬†from¬†Average¬†(%)\nReasoning¬†Strategies\nReasoning¬†Models\nFigure 1. Instability in LLM Reasoning. For the same query, different reasoning models (top) and reasoning strategies (middle) produce\ndistinct chains of thought and frequently contradictory conclusions. Even when working from identical instructions, methods vary widely\nin their intermediate reasoning steps and the correctness of their final answers. The bottom panel summarizes this variability quantitatively,\nshowing the relative deviation from average performance across reasoning models and strategies.\nvery few runs. Consequently, we lack statistically reliable\nestimates of performance with confidence intervals, and\ninstead rely on crude measurements that obscure the true\ninstability of LLM reasoning. For many practical scenarios,\nand in particular safety-critical applications, it is not only the\nmean accuracy that matters but also the lower bound of the\nconfidence interval or the worst-case performance, which\ndetermines whether a system can be trusted in deployment.\nPresent Work. In this paper, we revisit the oldest trick in\nexperimental science: repeat the experiment. We conduct\nan in-depth evaluation of LLM reasoning by running 10\nindependent trials for each model‚Äìalgorithm‚Äìtask combina-\ntion, and we report not only the mean but also the variance\nand confidence intervals of key performance metrics. Be-\nyond evaluation, we address the practical challenge of repro-\nducibility by releasing an agentic AI library as an artifact\nof this work, whose architecture is illustrated in Fig. 2. The\nlibrary implements ten representative state-of-the-art reason-\ning algorithms and integrates with CacheSaver (Potamitis\net al., 2025), a client-side inference optimization framework\nthat enables reproducible and cost-efficient LLM-based ex-\nperiments. This combination allows us to establish repro-\nducible baselines, uncover the instability of LLM reasoning\nstrategies, and provide practitioners with statistically reli-\nable performance estimates.\nContributions.\n‚Ä¢ We introduce the ReasonBench AI Library, the first\nbenchmark of 11 different LLM reasoning methods across\n4 different models and 7 different tasks with statistically\nreliable performance numbers(¬ß 3). Our framework offers\na minimal, yet principled, abstraction layer over common\npatterns in agentic AI. Its versatility and expressiveness\nare showcased by our reference implementation of 11 di-\nverse reasoning methods. By building on top of our API,\nresearchers can implement new reasoning methods or tasks,\nthrough a guided framework, with only a few lines of code.\nConsequently, all evaluation routines are handled automati-\ncally, so researchers can avoid the complexity of building\ntheir own benchmarking scaffolds.\n‚Ä¢ We perform the first systematic multi-run evaluation of\nLLM reasoning algorithms across diverse models and tasks\n(¬ß 4). Each model‚Äìalgorithm‚Äìtask combination is evaluated\nwith ten independent runs, and we report statistically reliable\nestimates of accuracy and cost with confidence intervals.\n2\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\n‚Ä¢ We conduct an insight analysis of scaling effects and\nvariance sources (¬ß 5). This includes comparisons across\nmodels of the same size but different families (e.g., Qwen-\n3B vs. Llama-3B), models of the same family but different\nsizes (e.g., Llama-3B vs. Llama-11B), correlations between\ncost and performance, as well as the impact of prompting\non stability.\n‚Ä¢ Based on our findings, we release a leaderboard that eval-\nuates models through the lens of stability and propose best\npractices and a call to action for variance-aware evaluation\nin LLM reasoning research (¬ß 6). We recommend reporting\nvariance-aware metrics such as confidence intervals and per-\ncentiles, and we argue that reproducible multi-run evaluation\nshould become the standard for reasoning benchmarks.\n2. Related works\nInstability in LLM Reasoning. A growing body of work\nhighlights that LLM reasoning can be brittle and unstable.\nBenchmarks such as (Jiang et al., 2025; Wang & Zhao,\n2024) show that small lexical or semantic changes to inputs\ncan cause inconsistent reasoning chains and consequently\nlarge drops in performance. Similar insights emerge from\nperturbation studies in deductive logic and mathematics,\nincluding (Hoppe et al., 2025) and (Yang et al., 2025b). Be-\nyond perturbations, survey work such as (Ahn et al., 2024)\ndocuments that models often arrive at different answers for\nidentical problems via divergent reasoning paths. Stress-test\nframeworks such as (Hou et al., 2025) and (Huang et al.,\n2025) generate adversarial or out-of-distribution prompting\nvariants to reveal systematic weaknesses in mathematical\nand commonsense reasoning. Across studies, the findings\npoint to an endemic problem: LLM reasoning is highly\nsensitive to perturbations and randomness, making repro-\nducibility an open problem.\nCalls for Better Evaluation Practices. Alongside these\nstudies, researchers are emphasizing the need for more\nrigorous evaluation methodologies. (Miller, 2024) sum-\nmarizes the best-practice methodology from a statisticians\ntoolbox and provides LLM-focused guidelines on report-\ning uncertainty, advocating for confidence intervals, clus-\ntered standard errors, and statistical tests based on question-\nlevel paired differences. Similar calls appear in (Mizrahi\net al., 2023), which demonstrates the sensitivity of results to\nprompt wording, and in (Ni et al., 2024), which argues\nfor aggregating across benchmarks to reduce instability.\n(Blackwell et al., 2024) argues that, even on simple QA\nbenchmarks, repeated runs are required to reach statistically\nreliable conclusions. Survey contributions such as (Mondorf\n& Plank, 2024) echo this perspective, arguing that focusing\non shallow accuracy metrics obscures important behavioral\nproperties. Collectively, these works call for reproducibility,\nuncertainty quantification, and explicit accounting for vari-\nance as essential components of reliable LLM evaluation.\nClosely Related Variance-Aware Benchmarks. Only a\nfew recent efforts go beyond calls to action and directly\npropose frameworks for variance-aware evaluation. (Liu\net al., 2024) introduces the G -Pass@kœÑ metric to capture\nstability in reasoning tasks, though it condenses variability\ninto a single scalar. (Madaan et al., 2024) studies variance\nfrom a different angle, analyzing differences across training\nseeds and checkpoints rather than stochastic decoding. (Ye\net al., 2024) integrates uncertainty measures into multi-task\nbenchmarking, showing that accuracy and certainty do not\nnecessarily correlate. (Wang et al., 2025) derives theoretical\nsample complexity bounds to support statistically sound\nevaluations at lower cost. Autonomous or domain-specific\nbenchmarks such as (Karia et al., 2024) and (Ji et al., 2025)\nhighlight the growing recognition of reliability in evalua-\ntion, though they do not systematically address run-to-run\nvariance.\nOur Work. Our work builds on this trajectory by making\nstability across multiple, independent runs as the central\nobject of our study. We echo the call to action for reliable\nbenchmarking and reproducible science and claim that an\nimportant additional analysis is the sampling budget. We\nfind that modern reasoning algorithms may reach state-of-\nthe-art accuracy but only at a disproportionate cost. At the\nsame time, the most sophisticated algorithms also seem to\nbe the most brittle. The question of sample efficiency is\nclosely related to reliable accuracy and reproducible results.\nWhile prior efforts either stress brittleness under perturba-\ntions or argue for statistical rigor, REASONBENCH is, to\nour knowledge, the first benchmark that systematically quan-\ntifies stability across reasoning frameworks, models, and\ntasks through controlled multi-run evaluation. By coupling\nreproducible implementations of reasoning strategies with\na variance-aware analysis, we aim to make stability and\nreliability first-class metrics in LLM reasoning research.\n3. REASONBENCH\nIn this section, we provide a detailed description of our\nbenchmarking framework, REASONBENCH, which we re-\nlease as both a benchmark suite and an open-source AI\nlibrary. REASONBENCH is designed with three goals in\nmind: (i) principled implementations of diverse reasoning\nstrategies, (ii) reproducible and cost-efficient experimen-\ntation, and (iii) extensibility so the community can easily\ncontribute new methods, models, or tasks.\n3\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nMethod\nAgent\nState\nModel\nReAct\nCoT\n...\nFleet of Agents\nTransformers\nOpenAI\n...\nAnthropic\nEnvironment\nHotpotQA\nHumanEval\n...\nMath Arena\nGame of 24\nEnvironment library\nMethods library\nAPI library\nFigure 2. ReasonBench architecture. Methods orchestrate the three core components: Agents, Environments, and Models. Agents\ntranslate states into prompts, query models, and parse responses into actions. Environments are drawn from a large task library and offer\nfunctions such as next-step transitions and scoring heuristics. Models provide a unified interface to external LLM APIs. States record the\nintermediate configurations of reasoning, enabling reproducibility and fair comparison across tasks and methods.\n3.1. Library design\nREASONBENCH is organized around a set of core abstrac-\ntions that capture the building blocks of reasoning pipelines.\nThe principal components are the Method, Environment,\nAgent, State, and Model, which together define a modu-\nlar interface for implementing reasoning algorithms, con-\nnecting to LLMs, and interacting with tasks. In designing\nthese components, we followed established principles from\nsoftware architecture engineering, emphasizing modularity,\nseparation of concerns, and extensibility. Fig. 2 illustrates\nthe relationships between these abstractions.\nAt a high level, the Model abstraction provides standardized\naccess to language models, while Agents translate states\ninto prompts and parse model outputs into actions. The\nEnvironment governs how these actions modify States and\nhow solutions are evaluated. Methods sit on top of these\ncomponents, orchestrating agents, environments, and mod-\nels into complete reasoning strategies that can be executed\nand benchmarked in a uniform way. This layered design\nallows REASONBENCH to support both simple prompting\nbaselines and complex search-based algorithms, while en-\nsuring fair comparison across tasks, models, and evaluation\nmetrics. We next describe each abstraction in detail.\nMethod Abstraction. The method abstraction specifies the\noverall logic of a reasoning strategy independently of the un-\nderlying model or task. A method integrates agents, which\nconstruct prompts and parse responses; the environment,\nwhich maintains and updates the task state; and the model,\nwhich produces candidate outputs. Each method exposes a\nstandard interface for solving tasks by generating and up-\ndating sequences of states, and a benchmarking routine that\nruns multiple problem instances in parallel. This makes\nmethods interchangeable and extensible: once the interface\nis implemented, a new reasoning algorithm can be evaluated\nconsistently across models, tasks, and metrics within the\nbenchmarking pipeline.\nEnvironment Abstraction. The environment abstraction\nformalizes the task-specific dynamics of reasoning. It gov-\nerns how a state evolves in response to an action, how to\ndetermine whether an action is valid, when a trajectory has\nreached a terminal condition, and how to evaluate the final\noutcome. By encapsulating these rules, the environment\ndecouples domain logic from reasoning algorithms, allow-\ning the same method to be applied consistently across tasks\nwhile ensuring that actions and evaluations remain faithful\nto each benchmark.\nAgent Abstraction. The agent abstraction defines the inter-\nface between methods, models, and states. Agents specify\nhow prompts are constructed from the current state, how\nqueries are issued to the model, and how responses are\nparsed into actions that update the environment. This uni-\nfied interface makes it possible to express a wide spectrum\nof reasoning strategies: from simple input‚Äìoutput prompt-\ning to multi-step reasoning, search procedures, candidate\naggregation, and self-evaluation. By isolating prompt con-\nstruction and response handling, ReasonBench supports di-\nverse reasoning paradigms without altering the abstractions\nfor methods, environments, or models.\nState Abstraction. The state abstraction captures the inter-\nmediate configuration of a reasoning process. It provides\na standardized way to represent progress on a task and to\nhandle states with controlled randomness. Methods interact\nonly with states, while environments define how actions\nmodify them and how final outcomes are assessed. This sep-\naration ensures that reasoning trajectories can be reproduced,\ncompared, and analyzed independently of the underlying\ntask domain.\n4\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nModel Abstraction. The model abstraction provides a uni-\nform interface for interacting with language models, support-\ning both single and batched queries across diverse providers.\nBuilt on top of asynchronous execution (via asyncio) and\nintegrated with response caching through CacheSaver, it is\nboth extensible and accountable: new models can be added\nwithout modifying the framework, and every interaction\nlogs latency, token usage, and generation metadata. This\ncombination enables deterministic reproducibility across\nrepeated experiments while distinguishing between newly\ngenerated, reused, and deduplicated outputs.\n3.2. Experimental Setup\nNumber of runs. We repeat all experiments 10 times and\nreport both mean and confidence intervals of the evaluation\nmetrics.\nPrompts. To ensure a fair evaluation of the benchmarked\nreasoning strategies, we reuse the prompts introduced by\nprior methods. Whenever two strategies can utilize the same\nprompt, we use a shared version to enable direct comparison.\nFor cases without existing prompts, e.g., novel reasoning\nstrategy or base LLMs, if needed, we adapt the original\nprompts to facilitate the new use cases.\nTasks and data. We evaluate on five benchmark tasks se-\nlected to cover a broad spectrum of reasoning, planning, and\ngeneral problem-solving abilities. These tasks span diverse\ndomains: (1) mathematical reasoning: Game of 24 (Yao\net al., 2023a) and MathArena (Balunovi¬¥c et al., 2025), (2)\ncoding: HumanEval (Chen et al., 2021), (3) question an-\nswering and knowledge reasoning: HotpotQA (Zhilin et al.,\n2018) and Humanity‚Äôs Last Exam (Phan et al., 2025), (4)\nscientific reasoning: SciBench (Wang et al., 2024a), and (5)\ncreative writing: Shakespearean Sonnet Writing (Suzgun\n& Kalai, 2024). For consistency, we rely on the test sets\nreleased with the original benchmarks.\nReasoning strategies. We experiment with 11 representa-\ntive state-of-the-art reasoning strategies: (1) IO prompting,\n(2) CoT, (3) CoT-SC, (4) React (Yao et al., 2023b), (5) Re-\nflexion, (6) ToT-DFS (Yao et al., 2023a), (7) TOT-BFS (Yao\net al., 2023a), (8) GoT, (9) RAP (Hao et al., 2023), (10)\nReST-MCTS* (Zhang et al., 2024), and (11) FoA (Klein\net al., 2025). To ensure that comparisons between meth-\nods are fair, each strategy has been re-implemented within\nReasonBench using a standardized interface, which harmo-\nnizes prompt handling, state transitions, and evaluation. Our\nselection criterion requires that methods provide publicly\navailable code for at least one of the tasks considered in\nthis study. Consequently, we exclude TouT (Mo & Xin,\n2024), and RecMind (Wang et al., 2024b). We also omit\nBoT (Yang et al., 2024b), where the code is released but a\nkey resource (the meta-buffer) is missing, preventing repro-\nducibility. LATS (Zhou et al., 2024a) is excluded due to its\nprohibitive computational cost.\nReasoning models. We evaluate a diverse set of contempo-\nrary reasoning models spanning multiple providers: (1) GPT-\nOSS-120B (Agarwal et al., 2025), (2) DeepSeek R1 (Guo\net al., 2025), (3) Llama 4 Scout (AI, 2025), (4) Qwen3-\n32B (Yang et al., 2025a), and (5) Gemini 2.5 Pro (Comanici\net al., 2025). These models represent the latest generation\nof systems that aim to perform end-to-end reasoning, with-\nout requiring explicit scaffolding through external frame-\nworks. To ensure comparability, all models are evaluated\nin a zero-shot setting using identical benchmark prompts,\nwith decoding parameters harmonized across providers. Our\nselection criterion prioritizes flagship reasoning-oriented re-\nleases from major labs that are accessible via public APIs at\nthe time of writing.\nEvaluation metrics. We evaluate along two dimensions:\nquality, and cost (token usage and running time). Cost is\nreported in USD. For locally hosted LLMs, we compute cost\nby counting input/output tokens and applying a provider‚Äôs\npricing for the corresponding model.\n4. Experiments\nOur results are structured around two complementary ques-\ntions: (i) how do different reasoning frameworks compare\nwhen applied under identical model conditions, and (ii)\nhow do different reasoning models perform when asked to\nsolve benchmarks directly without additional framework\nsupport. To answer the first question, we fix GPT-4.1-Nano\nas the underlying model and evaluate eleven representative\nreasoning frameworks across all benchmarks. To address\nthe second, we evaluate multiple open- and closed-source\nreasoning models in a zero-shot setting, measuring their\nability to solve tasks without external scaffolding. This\nseparation allows us to disentangle the contribution of ex-\nplicit reasoning frameworks from that of models designed\nto reason end-to-end. The resources for reproducing our\nexperiments are available at https://github.com/\nau-clan/ReasonBench.\n4.1. Reasoning Strategies\nIn Table 1, we fix GPT-4.1 as the underlying model and sys-\ntematically compare the eleven reasoning strategies across\nall benchmarks. Each framework is executed with ten in-\ndependent runs per task, and we report both average per-\nformance and variance, including confidence intervals and\npercentile statistics.\nAcross the evaluated frameworks, we observe that increased\nmethodological sophistication generally corresponds to im-\n5\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nTable 1. Quality and cost variability across reasoning frameworks under GPT-4.1. Direct methods show low cost but high instability\nin quality, while structured and planning-based approaches incur higher cost with mixed consistency. FoA and ToT-BFS deliver the\nmost stable performance overall, whereas GoT exhibits the highest variability, highlighting substantial differences in robustness across\nreasoning paradigms.\nReasoning Strategy\nType\nQuality\nCost\nMean ¬± CI\nCV\nMAD\nMean ¬± CI\nCV\nMAD\nIO\nDirect\n3.0 ¬± 0.8\n0.62\n2.1\n0.01 ¬± 0.02\n0.41\n0.01\nCoT (Wei et al., 2022)\nDirect\n8.0 ¬± 1.6\n0.38\n3.2\n0.02 ¬± 0.02\n0.29\n0.01\nCoT-SC (Wang et al., 2023)\nDirect\n15.0 ¬± 1.2\n0.14\n2.8\n0.15 ¬± 0.06\n0.10\n0.02\nReAct (Yao et al., 2023b)\nAdaptive\n31.0 ¬± 2.1\n0.12\n3.6\n0.03 ¬± 0.02\n0.03\n0.00\nReflexion (Shinn et al., 2023)\nAdaptive\n25.0 ¬± 1.1\n0.09\n3.4\n0.06 ¬± 0.03\n0.26\n0.02\nToT-DFS (Yao et al., 2023a)\nStructured\n25.0 ¬± 4.5\n0.39\n4.8\n1.05 ¬± 0.09\n0.13\n0.12\nToT-BFS (Yao et al., 2023a)\nStructured\n35.0 ¬± 2.1\n0.08\n2.8\n1.10 ¬± 0.05\n0.04\n0.05\nGoT (Besta et al., 2024)\nStructured\n10.0 ¬± 2.4\n0.58\n4.9\n1.55 ¬± 0.09\n0.02\n0.02\nRAP (Hao et al., 2023)\nPlanning\n22.0 ¬± 2.4\n0.20\n2.6\n1.60 ¬± 0.37\n0.15\n0.18\nMCTS* (Zhang et al., 2024)\nPlanning\n33.0 ¬± 1.9\n0.08\n1.9\n1.55 ¬± 0.28\n0.13\n0.16\nFoA (Klein et al., 2025)\nEvolutionary\n36.0 ¬± 1.4\n0.05\n1.3\n0.42 ¬± 0.05\n0.05\n0.02\nTable 2. Quality and cost variability of contemporary reasoning models across all benchmarks. DeepSeek R1 achieves the\nstrongest and most stable quality, though at the highest cost, while Llama 4 Maverick offers competitive performance with minimal cost.\nGPT-OSS-120B shows moderate stability, whereas Qwen3-235B exhibits the highest variability, underscoring that model price and scale\ndo not reliably correspond to consistency.\nReasoning Model\nProvider\nQuality\nCost\nMean ¬± CI\nCV\nMAD\nMean ¬± CI\nCV\nMAD\nDeepSeek R1\nDeepSeek\n48.7 ¬± 4.3\n0.293\n8.0\n1.97 ¬± 0.16\n0.27\n0.47\nLlama 4 Maverick 17B\nMeta\n45.7 ¬± 4.5\n0.380\n11.0\n0.03 ¬± 0.00\n0.31\n0.01\nGPT-OSS-120B\nOpenAI\n48.5 ¬± 5.9\n0.473\n18.0\n0.04 ¬± 0.01\n0.37\n0.01\nQwen3-235B A22B\nAlibaba\n46.2 ¬± 12.4\n0.773\n26.3\n0.78 ¬± 0.08\n0.31\n0.21\nproved solution quality, but this relationship is neither mono-\ntonic nor uniformly reliable. While several complex ap-\nproaches, such as FoA and MCTS*, achieve the highest\nmean performance with comparatively tight confidence in-\ntervals, other equally intricate methods like GoT, ToT-BFS,\nand ToT-DFS exhibit substantial instability, suggesting that\ncomplexity alone does not guarantee robustness. Variance\nemerges as a critical factor affecting both quality and cost,\nyet these forms of variance behave independently: some\nmethods (e.g., ReAct, FoA) simultaneously deliver high\nquality and low dispersion across metrics, whereas others\n(e.g., GoT) show low cost variance but large fluctuations\nin quality. These results underscore that the benefits of\ncomplex reasoning frameworks depend not only on their\nstructural depth but also on the stability of their underlying\nsearch or adaptation mechanisms, emphasizing the impor-\ntance of evaluating performance and cost stability jointly\nrather than relying solely on average outcomes.\n4.2. Reasoning Models\nIn Table 2, we evaluate a set of contemporary reasoning\nmodels by directly asking them to solve the benchmarks\nwithout any external framework support. Each model is run\nindependently ten times per task, and we report mean accu-\nracy, confidence intervals, and percentile statistics alongside\ntoken-level cost. This experiment captures the intrinsic\nreasoning ability of the models in a zero-shot setting and\nenables a variance-aware comparison across providers.\nOur results indicate that inference price is not a reliable\nproxy for consistency across contemporary reasoning mod-\nels. Although DeepSeek R1 achieves the strongest and\nmost stable performance, its consistency advantages over\nsubstantially cheaper systems such as Llama 4 Maverick re-\nmain unexpectedly narrow, suggesting diminishing returns\nat higher cost tiers. Conversely, Qwen3-235B A22B exhibits\nthe biggest variance despite being more than twenty times\nmore expensive than both GPT-OSS-120B from OpenAI\n6\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nand Llama 4 Maverick from Meta, with variability metrics\nmore than double those of these lower-cost models. This\nmismatch between price and consistency underscores that\ncurrent model pricing does not reliably reflect stability, and\nthat some low-cost models offer competitive or superior\nstability relative to far more expensive alternatives.\n5. Analysis\nio\ncot\ncot_sc\nfoa\ntot_bfs tot_dfs\ngot\nreact\nReasoning Strategy\n20\n30\n40\n50\n60\nQuality (%)\nSource\ngpt-4.1-nano\ngpt-4.1-mini\nFigure 3. Scaling Effects within a Model Family. Quality distri-\nbutions for gpt-4.1-nano and gpt-4.1-mini across multiple reason-\ning strategies. The larger model achieves higher mean performance\nand exhibits markedly lower variance, suggesting greater stability\nin its reasoning behavior.\n5.1. Scaling Effects within a Model Family\nWe analyze the stability of reasoning performance within\na single model family at different scales. We consider\nGPT-4.1-Nano and GPT-4.1-Mini, evaluating them on all\nbenchmarks with ten independent runs. This experiment\nhighlights the effect of scaling within one architecture, al-\nlowing us to observe whether increased size systematically\nimproves not only average quality but also stability across\nruns. The results can be found in Fig. 3.\nAcross all strategies, we observe a consistent scaling effect:\nGPT-4.1-Mini achieves higher mean quality and exhibits\nsubstantially tighter distributions than GPT-4.1-Nano. This\nindicates that increasing model size within the same family\nnot only improves average performance but also reduces run-\nto-run variability, leading to more stable reasoning behavior\noverall.\n5.2. Impact of prompts on stability\nA nontrivial portion of instability stems not from the reason-\ning algorithms themselves but from the prompts and parsers\nthat mediate their interaction with LLMs. Prompts often\ncontain minor ambiguities, loosely specified answer styles,\nor implicit assumptions about how models structure their\nreasoning. It is possible that these can magnify stochas-\ntic differences and lead to divergent outputs across runs.\nIn REASONBENCH, we make small, fidelity-preserving\nrefinements to these prompts, clarifying instructions and\nstandardizing output expectations without altering the un-\nderlying reasoning logic. In tandem, we strengthen the\nparsing layer to robustly extract answers despite common\nformatting deviations, reducing failure cases caused by pars-\ning brittleness rather than genuine reasoning errors.\n0.23\n0.26\n0.28\n26\n42\n58\nFoA\nQuality (%)\nGame of 24\n0.56\n0.64\n0.71\n24\n33\n42\nHotpotQA\n0.22\n0.27\n0.32\n26\n37\n49\nSciBench\n0.22\n0.25\n0.28\n11\n23\n36\nGoT\nQuality (%)\n0.86\n0.97\n1.08\n13\n22\n31\n0.72\n0.80\n0.88\n12\n19\n26\n0.02\n0.02\n0.03\nCost (USD)\n0\n7\n16\nReAct\nQuality (%)\n0.10\n0.11\n0.13\nCost (USD)\n30\n38\n46\n0.04\n0.05\n0.05\nCost (USD)\n24\n36\n49\nFigure 4. Correlation between Quality and Cost. For FoA,\nquality scales positively with cost across all benchmarks. ReAct\nexhibits a consistent negative slope, indicating diminishing returns\nat higher costs. GoT does not follow a uniform pattern, with its\ncost‚Äìquality relationship varying substantially by task.\nAcross all frameworks, clarifying prompts and strengthen-\ning the parsing logic consistently reduce variance, indicating\nthat a meaningful portion of instability comes from avoid-\nable formatting ambiguities rather than true algorithmic ran-\ndomness. While every method benefits from these improve-\nments, structured and search-based approaches show the\nlargest reductions, suggesting that multi-step frameworks\nare especially sensitive to prompt clarity and output han-\ndling. The detailed results can be found in Table 3.\nThese observations highlight a broader challenge in LLM\nevaluation: benchmarking pipelines themselves are not\nstatic artifacts but evolving systems. In practice, evaluation\nprocedures and prompting conventions continually shift,\nminor prompt edits are rarely recorded and changes to third-\nparty APIs are easily overlooked. Yet benchmarking results\nare only meaningful when they support reliable comparison,\nmaking it essential to rerun evaluations when needed and\nto maintain up-to-date performance measurements. REA-\n7\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nTable 3. Impact of prompt and parsing refinements on framework performance. Enhancing clarity and standardizing output parsing\nconsistently improve both accuracy and stability, with structured and search-based methods showing the largest gains.\nFramework\nType\nOriginal Prompts\nImproved Prompts\nAbsolute Difference\nIO\nDirect\n3.0 ¬± 0.8\n31.3 ¬± 0.7\n+28.3 ¬± 2.0\nCoT (Wei et al., 2022)\nDirect\n8.0 ¬± 1.6\n39.8 ¬± 1.4\n+31.8 ¬± 2.7\nCoT-SC (Wang et al., 2023)\nDirect\n15.0 ¬± 1.2\n41.1 ¬± 1.1\n+26.1 ¬± 1.8\nReAct (Yao et al., 2023b)\nAdaptive\n31.0 ¬± 2.1\n39.1 ¬± 1.9\n+8.1 ¬± 2.6\nReflexion (Shinn et al., 2023)\nAdaptive\n25.0 ¬± 1.1\n41.1 ¬± 1.0\n+16.1 ¬± 3.0\nToT-BFS (Yao et al., 2023a)\nStructured\n35.0 ¬± 2.1\n50.6 ¬± 1.8\n+15.6 ¬± 4.1\nGoT (Besta et al., 2024)\nStructured\n10.0 ¬± 2.4\n42.0 ¬± 2.2\n+32.0 ¬± 3.5\nRAP (Hao et al., 2023)\nPlanning\n22.0 ¬± 2.4\n40.3 ¬± 2.2\n+18.3 ¬± 2.9\nMCTS* (Zhang et al., 2024)\nPlanning\n33.0 ¬± 2.5\n51.2 ¬± 1.7\n+18.2 ¬± 2.7\nFoA (Klein et al., 2025)\nEvolutionary\n36.0 ¬± 1.4\n54.6 ¬± 1.3\n+18.6 ¬± 2.1\nSONBENCH provides a practical remedy. Algorithms ex-\npressed through its simple but highly modular API can be\nrerun seamlessly, allowing results to be regenerated along\nwith the updates.\n5.3. Correlation between Quality and Cost\nFinally, we investigate the relationship between the stability\nin quality and cost. Using all reasoning strategies, we take a\nmore intrinsic look at variability by examining outcomes at\nthe level of individual samples. For each run of each bench-\nmark, we record whether the model‚Äôs answer was correct\nand measure the exact cost incurred for that attempt. This\nanalysis tests whether methods that are unstable in terms of\naccuracy also tend to be unstable in cost, thereby probing\na potential correlation between two critical dimensions of\nreproducibility. The results can be found in Fig. 4.\nAcross benchmarks, we observe distinct patterns linking\ncost and quality variability. FoA (Klein et al., 2025) ex-\nhibits a consistently positive relationship, with higher-cost\nsamples tending to yield higher-quality outputs, indicat-\ning stable scaling behavior. In contrast, ReAct (Yao et al.,\n2023b) shows a negative slope on all tasks, suggesting that\nincreased computational effort often corresponds to less\nreliable reasoning trajectories. GoT displays no uniform\ntrend, with the cost‚Äìquality relationship flipping direction\nacross benchmarks, reflecting the method‚Äôs sensitivity to\ntask structure.\n6. Discussion\n6.1. Summary of Findings\nOur study reveals that the underlying instability is a perva-\nsive and underexamined property of LLM reasoning. Across\nframeworks, tasks, and models, we find that single-run accu-\nracy can systematically overestimate the stability of reason-\ning performance, obscuring wide differences in both quality\nand cost consistency. More sophisticated reasoning algo-\nrithms often achieve higher mean accuracy, but this does not\nguarantee robustness: several structured and search-based\napproaches exhibit substantial instability, while simpler or\nmore adaptive methods can outperform them by being more\nstable. At the model level, inference price is not a reliable\nproxy for stability as some of the most expensive models\nshow higher variability than significantly cheaper alterna-\ntives. Finally, even small refinements to prompts and parsing\nlogic meaningfully reduce extrinsic variance, indicating that\na nontrivial share of previously reported instability stemmed\nfrom preventable ambiguities rather than true model and\nframework behavior. Together, these findings underscore\nthat reproducibility is a critical dimension of LLM reason-\ning and should be treated as a first-class metric alongside\naverage performance.\n6.2. Limitations and Future Work\nWhile REASONBENCH provides the first systematic multi-\nrun evaluation of reasoning frameworks and models, several\nlimitations remain. First, our analysis focuses on decoding\nstochasticity; additional sources of variability such as API\ninstability, and model updates, are important directions for\ndeeper investigation. Second, our benchmark covers a rep-\nresentative but still limited set of frameworks, tasks, and\nproprietary reasoning-oriented models; expanding Reason-\nBench to more domains will enable broader conclusions.\nThird, our multi-run protocol uses ten repetitions, which we\nfound sufficient for stable confidence intervals, but future\nwork may explore adaptive or task-aware sampling budgets\nthat balance statistical reliability with cost efficiency. Fi-\nnally, the impact of prompt clarity suggests opportunities\nfor systematic prompt optimization, controllable reasoning\nformats, and parser-aware training objectives designed to\nreduce variability at the source.\n8\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nReferences\nAgarwal, S., Ahmad, L., Ai, J., Altman, S., Applebaum, A.,\nArbus, E., Arora, R. K., Bai, Y., Baker, B., Bao, H., et al.\ngpt-oss-120b & gpt-oss-20b model card. arXiv preprint\narXiv:2508.10925, 2025.\nAhn, J., Verma, R., Lou, R., Liu, D., Zhang, R., and Yin, W.\nLarge language models for mathematical reasoning: Pro-\ngresses and challenges. arXiv preprint arXiv:2402.00157,\n2024.\nAI, M. Introducing llama 4: Advancing multimodal intelli-\ngence, 2025. Accessed: 2025-09-22.\nBalunovi¬¥c, M., Dekoninck, J., Petrov, I., Jovanovi¬¥c, N.,\nand Vechev, M.\nMatharena:\nEvaluating llms on\nuncontaminated math competitions.\narXiv preprint\narXiv:2505.23281, 2025.\nBesta, M., Blach, N., Kubicek, A., Gerstenberger, R., Pod-\nstawski, M., Gianinazzi, L., Gajda, J., Lehmann, T.,\nNiewiadomski, H., Nyczyk, P., et al. Graph of thoughts:\nSolving elaborate problems with large language models.\nIn AAAI, volume 38, pp. 17682‚Äì17690, 2024.\nBlackwell, R. E., Barry, J., and Cohn, A. G. Towards re-\nproducible llm evaluation: Quantifying uncertainty in llm\nbenchmark scores. ArXiv, abs/2410.03492, 2024.\nChen et al. Evaluating large language models trained on\ncode, 2021. arXiv eprint 2107.03374, cs.LG.\nComanici, G., Bieber, E., Schaekermann, M., Pasupat, I.,\nSachdeva, N., Dhillon, I., Blistein, M., Ram, O., Zhang,\nD., Rosen, E., et al. Gemini 2.5: Pushing the frontier\nwith advanced reasoning, multimodality, long context,\nand next generation agentic capabilities. arXiv preprint\narXiv:2507.06261, 2025.\nGeman, S., Bienenstock, E., and Doursat, R. Neural net-\nworks and the bias/variance dilemma. Neural computa-\ntion, 4(1):1‚Äì58, 1992.\nGuo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R.,\nZhu, Q., Ma, S., Wang, P., Bi, X., et al. Deepseek-r1: In-\ncentivizing reasoning capability in llms via reinforcement\nlearning. arXiv preprint arXiv:2501.12948, 2025.\nHao, S., Gu, Y., Ma, H., Hong, J. J., Wang, Z., Wang, D. Z.,\nand Hu, Z. Reasoning with language model is planning\nwith world model. In EMNLP, 2023.\nHastie, T., Tibshirani, R., Friedman, J., et al. The elements\nof statistical learning, 2009.\nHoppe, F., Ilievski, F., and Kalo, J.-C. Investigating the\nrobustness of deductive reasoning with large language\nmodels. arXiv preprint arXiv:2502.04352, 2025.\nHou, Y., Xiao, Z., Yu, F., Jiang, Y., Wei, X., Huang, H.,\nChen, Y., and Chen, G. Automatic robustness stress\ntesting of llms as mathematical problem solvers. arXiv\npreprint arXiv:2506.05038, 2025.\nHuang, S., Yang, L., Song, Y., Chen, S., Cui, L., Wan,\nZ., Zeng, Q., Wen, Y., Shao, K., Zhang, W., et al.\nThinkbench: Dynamic out-of-distribution evaluation for\nrobust llm reasoning. arXiv preprint arXiv:2502.16268,\n2025.\nJaech, A., Kalai, A., Lerer, A., Richardson, A., El-Kishky,\nA., Low, A., Helyar, A., Madry, A., Beutel, A., Car-\nney, A., et al. Openai o1 system card. arXiv preprint\narXiv:2412.16720, 2024.\nJi, K., Guo, Y., Zhang, Z., Zhu, X., Tian, Y., Liu, N., and\nZhai, G. Medomni-45 {\\deg}: A safety-performance\nbenchmark for reasoning-oriented llms in medicine.\narXiv preprint arXiv:2508.16213, 2025.\nJiang, E., Xu, C., Singh, N., and Singh, G. Misaligning\nreasoning with answers‚Äìa framework for assessing llm\ncot robustness. arXiv preprint arXiv:2505.17406, 2025.\nJin, B., Yoon, J., Kargupta, P., Arik, S. O., and Han,\nJ.\nAn empirical study on reinforcement learning for\nreasoning-search interleaved llm agents. arXiv preprint\narXiv:2505.15117, 2025.\nKaria, R., Bramblett, D., Dobhal, D., and Srivastava, S.\nAutonomous evaluation of llms for truth maintenance and\nreasoning tasks. arXiv preprint arXiv:2410.08437, 2024.\nKlein, L. H., Potamitis, N., Aydin, R., West, R., Gulcehre,\nC., and Arora, A. Fleet of agents: Coordinated problem\nsolving with large language models. In Forty-second\nInternational Conference on Machine Learning, 2025.\nKlingbeil, A., Gr¬®utzner, C., and Schreck, P. Trust and re-\nliance on ai‚Äîan experimental study on the extent and\ncosts of overreliance on ai. Computers in Human Behav-\nior, 160:108352, 2024.\nLi, Y., Zhang, W., Yang, Y., Huang, W.-C., Wu, Y., Luo, J.,\nBei, Y., Zou, H. P., Luo, X., Zhao, Y., et al. Towards agen-\ntic rag with deep reasoning: A survey of rag-reasoning\nsystems in llms. arXiv preprint arXiv:2507.09477, 2025.\nLiu, J., wei Liu, H., Xiao, L., Wang, Z., Liu, K., Gao,\nS., Zhang, W., Zhang, S., and Chen, K. Are your llms\ncapable of stable reasoning? In Annual Meeting of the\nAssociation for Computational Linguistics, 2024.\nMadaan, L., Singh, A. K., Schaeffer, R., Poulton, A.,\nKoyejo, S., Stenetorp, P., Narang, S., and Hupkes, D.\nQuantifying variance in evaluation benchmarks. arXiv\npreprint arXiv:2406.10229, 2024.\n9\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nMiller, E.\nAdding error bars to evals: A statistical ap-\nproach to language model evaluations. arXiv preprint\narXiv:2411.00640, 2024.\nMizrahi, M., Kaplan, G., Malkin, D., Dror, R., Shahaf, D.,\nand Stanovsky, G. State of what art? a call for multi-\nprompt llm evaluation. Transactions of the Association\nfor Computational Linguistics, 12:933‚Äì949, 2023.\nMo, S. and Xin, M. Tree of uncertain thoughts reasoning\nfor large language models. In ICASSP, pp. 12742‚Äì12746,\n2024.\nMondorf, P. and Plank, B. Beyond accuracy: evaluating the\nreasoning behavior of large language models‚Äìa survey.\narXiv preprint arXiv:2404.01869, 2024.\nNi, J., Xue, F., Yue, X., Deng, Y., Shah, M., Jain, K., Neubig,\nG., and You, Y. Mixeval: Deriving wisdom of the crowd\nfrom llm benchmark mixtures. In Globerson, A., Mackey,\nL., Belgrave, D., Fan, A., Paquet, U., Tomczak, J., and\nZhang, C. (eds.), Advances in Neural Information Pro-\ncessing Systems, volume 37, pp. 98180‚Äì98212. Curran\nAssociates, Inc., 2024.\nPhan, L., Gatti, A., Han, Z., Li, N., Hu, J., Zhang, H., Zhang,\nC. B. C., Shaaban, M., Ling, J., Shi, S., et al. Humanity‚Äôs\nlast exam. arXiv preprint arXiv:2501.14249, 2025.\nPotamitis, N., Klein, L. H., Mohammadi, B., Xu, C.,\nMukherjee, A., Tandon, N., Bindschaedler, L., and\nArora, A. Cache saver: A modular framework for ef-\nficient, affordable, and reproducible LLM inference. In\nEMNLP, pp. 25703‚Äì25724, 2025. doi: 10.18653/v1/2025.\nfindings-emnlp.1402.\nShinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and\nYao, S. Reflexion: language agents with verbal reinforce-\nment learning. In NeurIPS, pp. 8634‚Äì8652, 2023.\nSuzgun, M. and Kalai, A. T. Meta-prompting: Enhancing\nlanguage models with task-agnostic scaffolding. arXiv\npreprint arXiv:2401.12954, 2024.\nWang, G., Chen, Z., Li, B., and Xu, H. Cer-eval: Certifiable\nand cost-efficient evaluation framework for llms. arXiv\npreprint arXiv:2505.03814, 2025.\nWang, X., Wei, J., Schuurmans, D., Le, Q. V., Chi,\nE. H., Narang, S., Chowdhery, A., and Zhou, D. Self-\nconsistency improves chain of thought reasoning in lan-\nguage models. In ICLR, 2023.\nWang, X., Hu, Z., Lu, P., Zhu, Y., Zhang, J., Subramaniam,\nS., Loomba, A. R., Zhang, S., Sun, Y., and Wang, W.\nScibench: evaluating college-level scientific problem-\nsolving abilities of large language models. In ICML,\n2024a.\nWang, Y. and Zhao, Y. Rupbench: Benchmarking reasoning\nunder perturbations for robustness evaluation in large lan-\nguage models. arXiv preprint arXiv:2406.11020, 2024.\nWang, Y., Jiang, Z., Chen, Z., Yang, F., Zhou, Y., Cho, E.,\nFan, X., Lu, Y., Huang, X., and Yang, Y. Recmind: Large\nlanguage model powered agent for recommendation. In\nNAACL-HLT (Findings), pp. 4351‚Äì4364, 2024b.\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi,\nE., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting\nelicits reasoning in large language models. Advances in\nneural information processing systems, 35:24824‚Äì24837,\n2022.\nYang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B.,\nYu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical\nreport. arXiv preprint arXiv:2505.09388, 2025a.\nYang, K., Swope, A., Gu, A., Chalamala, R., Song, P.,\nYu, S., Godil, S., Prenger, R. J., and Anandkumar, A.\nLeandojo: Theorem proving with retrieval-augmented\nlanguage models. Advances in Neural Information Pro-\ncessing Systems, 36:21573‚Äì21612, 2023.\nYang, K., Poesia, G., He, J., Li, W., Lauter, K., Chaudhuri,\nS., and Song, D. Formal mathematical reasoning: A new\nfrontier in ai. arXiv preprint arXiv:2412.16075, 2024a.\nYang, L., Yu, Z., Zhang, T., Cao, S., Xu, M., Zhang, W.,\nGonzalez, J. E., and Cui, B. Buffer of thoughts: Thought-\naugmented reasoning with large language models. In\nNeurIPS, 2024b.\nYang, Y., Yamada, H., and Tokunaga, T. Evaluating ro-\nbustness of llms to numerical variations in mathematical\nreasoning. In The Sixth Workshop on Insights from Nega-\ntive Results in NLP, pp. 171‚Äì180, 2025b.\nYao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y.,\nand Narasimhan, K. Tree of thoughts: Deliberate problem\nsolving with large language models. Advances in neural\ninformation processing systems, 36:11809‚Äì11822, 2023a.\nYao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,\nK., and Cao, Y. React: Synergizing reasoning and act-\ning in language models. In International Conference on\nLearning Representations (ICLR), 2023b.\nYe, F., Yang, M., Pang, J., Wang, L., Wong, D., Yilmaz,\nE., Shi, S., and Tu, Z. Benchmarking llms via uncer-\ntainty quantification. Advances in Neural Information\nProcessing Systems, 37:15356‚Äì15385, 2024.\nZhang, D., Zhoubian, S., Hu, Z., Yue, Y., Dong, Y., and\nTang, J. ReST-MCTS*: LLM self-training via process\nreward guided tree search. In NeurIPS, 2024.\n10\n\nReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning\nZhilin, Y., Peng, Q., Saizheng, Z., Yoshua, B., William,\nC., Ruslan, S., and Manning, C. D. Hotpotqa: A data-\nset for diverse, explainable multi-hop question answer-\ning. Proceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing, 2018. doi:\n10.18653/v1/d18-1259.\nZhou, A., Yan, K., Shlapentokh-Rothman, M., Wang, H.,\nand Wang, Y.-X. Language agent tree search unifies\nreasoning, acting, and planning in language models. In\nICML, 2024a.\nZhou, L., Schellaert, W., Mart¬¥ƒ±nez-Plumed, F., Moros-Daval,\nY., Ferri, C., and Hern¬¥andez-Orallo, J. Larger and more\ninstructable language models become less reliable. Na-\nture, 634(8032):61‚Äì68, 2024b.\n11\n",
    "figure_captions": [
      "Figure 1. Instability in LLM Reasoning. For the same query, different reasoning models (top) and reasoning strategies (middle) produce",
      "Figure 2. ReasonBench architecture. Methods orchestrate the three core components: Agents, Environments, and Models. Agents",
      "Figure 3. Scaling Effects within a Model Family. Quality distri-",
      "Figure 4. Correlation between Quality and Cost. For FoA,"
    ]
  }
]